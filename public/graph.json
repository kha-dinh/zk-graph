{
  "notes": [
    {"filename":"README.md","filenameStem":"README","path":"styles/write-good/README.md","absPath":"/home/khadd/mynotes/styles/write-good/README.md","title":"","link":"[[styles/write-good/README]]","lead":"Based on [write-good](https://github.com/btford/write-good).","body":"Based on [write-good](https://github.com/btford/write-good).\n\n\u003e Naive linter for English prose for developers who can't write good and wanna learn to do other stuff good too.\n\n```\nThe MIT License (MIT)\n\nCopyright (c) 2014 Brian Ford\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n```","snippets":["Based on [write-good](https://github.com/btford/write-good)."],"rawContent":"Based on [write-good](https://github.com/btford/write-good).\n\n\u003e Naive linter for English prose for developers who can't write good and wanna learn to do other stuff good too.\n\n```\nThe MIT License (MIT)\n\nCopyright (c) 2014 Brian Ford\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n```\n","wordCount":197,"tags":[],"metadata":{},"created":"2023-07-03T03:19:12.459881699Z","modified":"2023-07-03T03:19:09.982931599Z","checksum":"8826e2193035d98c38a7ef1560f1677ce7e9c305e2de48d469276e877b2d42f7"},
    {"filename":"3eot91og.md","filenameStem":"3eot91og","path":"3eot91og.md","absPath":"/home/khadd/mynotes/3eot91og.md","title":"(Virtualized) I/O Security","link":"[[3eot91og]]","lead":"#virtualization #security In","body":"#virtualization #security In\n\n## Threats\n\n### DMA attacks\n\nMost devices are capable performing DMA, which may be used to corrupt kernel\nmemory if the device is buggy or controlled by attackers.\n\n### Malicious peripherals\n\nCertain devices are more easily corruptible than than others. For example, it is\nunlikely for PCI-e devices to be corrupted, but USB/bluetooth devices are easily\nplugged into the system, and can be easily manufactured.\n\nHowever, in confidential computing scenario, devices are provided by the\nuntrusted hypervisor, which must be assume to be unsafe.\n\n### Virtualized IO\n\nVirtualized I/O adds more complexity to I/O security. For confidential VMs,\naccess control of hardware devices becomes more complicated. There is now a\nthree-way concerns. Aside from isolation of VM from host, cross VM, now the host\nmust also be prevented from accessing devices assigned to a CVM.\n\nVirtualized I/O faces a fundamental challenge between performance and security.\nThat is, allowing the VM to directly access to the hardware device (i.e., the\nI/O memory regions) enables great performances. However, the devices might be\nprogrammed to perform malicious accesses. It may use DMA to illegally access\nhost memory and also memory of other VMs.\n\n## Isolation for security\n\nThe IOMMU and related hardware allows the hypervisor to isolate device's DMA\naccesses [[hxm4jt6e]].\n\nRISC-V have a potentially more scalable protection model with a PKU-like domains\n[@feng2024siopmp].\n\nRelated:\n\n- [[8qvweuj8]]\n- [[hxm4jt6e]]\n\n## Filtering for security\n\nEven with IOMMU isolation, devices can still attack the kernel through malicious\npackets (more of an interface attack [[yef2w9yc]]). This is more concerning for\nbluetooth and USB devices that are easily pluggable. Another approach for\nsecurity to install packet filters to check for malformed packets\n[@tian2019lbm].","snippets":["#virtualization #security In"],"rawContent":"# (Virtualized) I/O Security\n\n#virtualization #security In\n\n## Threats\n\n### DMA attacks\n\nMost devices are capable performing DMA, which may be used to corrupt kernel\nmemory if the device is buggy or controlled by attackers.\n\n### Malicious peripherals\n\nCertain devices are more easily corruptible than than others. For example, it is\nunlikely for PCI-e devices to be corrupted, but USB/bluetooth devices are easily\nplugged into the system, and can be easily manufactured.\n\nHowever, in confidential computing scenario, devices are provided by the\nuntrusted hypervisor, which must be assume to be unsafe.\n\n### Virtualized IO\n\nVirtualized I/O adds more complexity to I/O security. For confidential VMs,\naccess control of hardware devices becomes more complicated. There is now a\nthree-way concerns. Aside from isolation of VM from host, cross VM, now the host\nmust also be prevented from accessing devices assigned to a CVM.\n\nVirtualized I/O faces a fundamental challenge between performance and security.\nThat is, allowing the VM to directly access to the hardware device (i.e., the\nI/O memory regions) enables great performances. However, the devices might be\nprogrammed to perform malicious accesses. It may use DMA to illegally access\nhost memory and also memory of other VMs.\n\n## Isolation for security\n\nThe IOMMU and related hardware allows the hypervisor to isolate device's DMA\naccesses [[hxm4jt6e]].\n\nRISC-V have a potentially more scalable protection model with a PKU-like domains\n[@feng2024siopmp].\n\nRelated:\n\n- [[8qvweuj8]]\n- [[hxm4jt6e]]\n\n## Filtering for security\n\nEven with IOMMU isolation, devices can still attack the kernel through malicious\npackets (more of an interface attack [[yef2w9yc]]). This is more concerning for\nbluetooth and USB devices that are easily pluggable. Another approach for\nsecurity to install packet filters to check for malformed packets\n[@tian2019lbm].\n","wordCount":283,"tags":["security","virtualization"],"metadata":{},"created":"2024-12-02T08:43:57.559168583Z","modified":"2024-12-10T05:12:37.870258882Z","checksum":"f222499d2c28a068798b067cd06adb5bd8be43eada3c1ec9c8d649783e2bfc16"},
    {"filename":"3gcsctdg.md","filenameStem":"3gcsctdg","path":"3gcsctdg.md","absPath":"/home/khadd/mynotes/3gcsctdg.md","title":"05/11 Meeting","link":"[[3gcsctdg]]","lead":"Give credits to varys and klotski, establish differences","body":"Give credits to varys and klotski, establish differences\n\nRerandomization rate: real number\n\n5. Focus on with respect to requirements\n\nProblem: don't write with technical specificity.\n\n5.2: Why attacker does not know which page fetched in (ORAM, stash)\n\nrandomizing page\n\n- sequence: leave out\n- to discussion: Arbitrary dummy accesses\n\n1. show false positive case\n\n   - describe period of measurement\n   - More descriptive\n   - bash\n\n- Varys 5.2 .2, 5.5.2\n- Explain with respect to result\n\n- It is impractical to measure single\n\n---\n\n- Termination decision\n\n  - Grace period vs. varys\n\n- 5 steps of rerand rate\n  - What is normal rerand rate\n\n---\n\n10 times klotski\n\n- show real numbers\n\n---\n\nredesign:\n\n- use threshold","snippets":["Give credits to varys and klotski, establish differences"],"rawContent":"# 05/11 Meeting\n\nGive credits to varys and klotski, establish differences\n\nRerandomization rate: real number\n\n5. Focus on with respect to requirements\n\nProblem: don't write with technical specificity.\n\n5.2: Why attacker does not know which page fetched in (ORAM, stash)\n\nrandomizing page\n\n- sequence: leave out\n- to discussion: Arbitrary dummy accesses\n\n1. show false positive case\n\n   - describe period of measurement\n   - More descriptive\n   - bash\n\n- Varys 5.2 .2, 5.5.2\n- Explain with respect to result\n\n- It is impractical to measure single\n\n---\n\n- Termination decision\n\n  - Grace period vs. varys\n\n- 5 steps of rerand rate\n  - What is normal rerand rate\n\n---\n\n10 times klotski\n\n- show real numbers\n\n---\n\nredesign:\n\n- use threshold\n","wordCount":119,"tags":[],"metadata":{},"created":"2024-11-09T07:33:07.666348525Z","modified":"2024-11-09T07:11:08.863757311Z","checksum":"372d213a6641769fe2a96cf3df5d5deea3e50cb91ac8ffc7f3765fc85a8a8a38"},
    {"filename":"2023-07-09.md","filenameStem":"2023-07-09","path":"daily/2023-07-09.md","absPath":"/home/khadd/mynotes/daily/2023-07-09.md","title":"2023-07-09","link":"[[daily/2023-07-09]]","lead":"#archive #daily","body":"#archive #daily\n\nI don't know where to put this question so I'm gonna put it here. I am trying to\nmake a page fault handler that serves physical memory from a pre-allocated\nphysical memory region. To do that, I allocate memory at boot time using\n`pt-\u003efa-\u003efalloc()` and store the physical address. I then extended `ukvmem` to\nintroduce a custom VMA type to register my page fault handler. E.g.,\n\n```c\nstatic int vma_op_custom_fault(__unused struct uk_vma *vma,\n                                     struct uk_vm_fault *fault)\n{\n  __paddr_t paddr = get_allocated_paddr();\n  /* initialize memory  */\n fault-\u003epaddr = paddr;\n  return 0;\n}\n```\n\nHowever, for some reason, memory write does not go through, and I got junk data\nwhen reading from the mapped address. Here is a simple test case:\n\n```c\n va = __VADDR_ANY;\n uk_vma_map_custom(vas, \u0026va, 0x10000, PROT_RW, UK_VMA_MAP_UNINITIALIZED,\n    NULL);\n memset((void *)va, 0xAB, 0x100);\n memset((void *)va + 0x100, 0xCD, 0x100);\n uk_hexdumpk(KLVL_INFO, (void *)va, 0x1000,\n      UK_HXDF_COMPRESS | UK_HXDF_ADDR, UK_HXDF_GRPQWORD);\n```\n\nHere is the console output. The first `memset` would create the `20 07` pattern\nin memory.\n\n```\n[    0.304939] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07\n[    0.322053] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.326263] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.344048] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```\n\nStrangely enough, when I compile the test file with `isr` flag, or use\n`memset_isr`, the problem does not happen.\n\n```\n[    0.305990] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab\n[    0.323425] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.327827] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.345547] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```","snippets":["#archive #daily"],"rawContent":"# 2023-07-09\n\n#archive #daily\n\nI don't know where to put this question so I'm gonna put it here. I am trying to\nmake a page fault handler that serves physical memory from a pre-allocated\nphysical memory region. To do that, I allocate memory at boot time using\n`pt-\u003efa-\u003efalloc()` and store the physical address. I then extended `ukvmem` to\nintroduce a custom VMA type to register my page fault handler. E.g.,\n\n```c\nstatic int vma_op_custom_fault(__unused struct uk_vma *vma,\n                                     struct uk_vm_fault *fault)\n{\n  __paddr_t paddr = get_allocated_paddr();\n  /* initialize memory  */\n fault-\u003epaddr = paddr;\n  return 0;\n}\n```\n\nHowever, for some reason, memory write does not go through, and I got junk data\nwhen reading from the mapped address. Here is a simple test case:\n\n```c\n va = __VADDR_ANY;\n uk_vma_map_custom(vas, \u0026va, 0x10000, PROT_RW, UK_VMA_MAP_UNINITIALIZED,\n    NULL);\n memset((void *)va, 0xAB, 0x100);\n memset((void *)va + 0x100, 0xCD, 0x100);\n uk_hexdumpk(KLVL_INFO, (void *)va, 0x1000,\n      UK_HXDF_COMPRESS | UK_HXDF_ADDR, UK_HXDF_GRPQWORD);\n```\n\nHere is the console output. The first `memset` would create the `20 07` pattern\nin memory.\n\n```\n[    0.304939] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07\n[    0.322053] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.326263] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.344048] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```\n\nStrangely enough, when I compile the test file with `isr` flag, or use\n`memset_isr`, the problem does not happen.\n\n```\n[    0.305990] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab\n[    0.323425] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.327827] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.345547] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```\n","wordCount":391,"tags":["daily","archive"],"metadata":{},"created":"2023-07-09T14:15:54.119097732Z","modified":"2024-11-18T05:53:05.63469042Z","checksum":"0b4bcf35f0ff7df9ba5941571fd6fe54a892065daa710b5d1af7beeb89df2f41"},
    {"filename":"2023-07-12.md","filenameStem":"2023-07-12","path":"daily/2023-07-12.md","absPath":"/home/khadd/mynotes/daily/2023-07-12.md","title":"2023-07-12","link":"[[daily/2023-07-12]]","lead":"#daily","body":"#daily\n\n# Message to unikraft\n\nRegarding page table isolation. I plan to first implement the features we\ndiscussed earlier, randomization and page table unmapping/sealing.\n\nRandomization\n\n- Currently the page table's virtual addresses are direct-mapped by\n  `pgarch_pt_map` and `pgarch_pt_unmap`. We probably only need to provide an\n  alternative implementation that map to a random address.\n- To support this, we may use a secondary direct-mapped area address that is\n  randomized at boot time.\n- Another approach is to use the heap memory space to map the page table\n  addresses. The addresses are naturally randomized by the heap allocator.\n\nPage-table unmapping/sealing\n\n- We need to keep track of the virtual addresses of the page table, then unmap\n  them when the page table update is finished, then re-map them on page faults\n  or page table updates.\n- I guess we can insert a hook in `pg_pt_alloc` used to allocate the page table\n  to collect the page table virtual addresses in a list. We can then insert the\n  code to unmap/remap these pages where the page table is accessed.\n  - I see only 4 main entry points of the page table: `pg_page_mapx`,\n    `pg_page_split`, `pg_page_setattr`, and `pg_page_unmmap`.\n- How are the direct-mapped pages mapped? I don't see the direct-mapped pages\n  being mapped in the source.","snippets":["#daily"],"rawContent":"# 2023-07-12\n\n#daily\n\n# Message to unikraft\n\nRegarding page table isolation. I plan to first implement the features we\ndiscussed earlier, randomization and page table unmapping/sealing.\n\nRandomization\n\n- Currently the page table's virtual addresses are direct-mapped by\n  `pgarch_pt_map` and `pgarch_pt_unmap`. We probably only need to provide an\n  alternative implementation that map to a random address.\n- To support this, we may use a secondary direct-mapped area address that is\n  randomized at boot time.\n- Another approach is to use the heap memory space to map the page table\n  addresses. The addresses are naturally randomized by the heap allocator.\n\nPage-table unmapping/sealing\n\n- We need to keep track of the virtual addresses of the page table, then unmap\n  them when the page table update is finished, then re-map them on page faults\n  or page table updates.\n- I guess we can insert a hook in `pg_pt_alloc` used to allocate the page table\n  to collect the page table virtual addresses in a list. We can then insert the\n  code to unmap/remap these pages where the page table is accessed.\n  - I see only 4 main entry points of the page table: `pg_page_mapx`,\n    `pg_page_split`, `pg_page_setattr`, and `pg_page_unmmap`.\n- How are the direct-mapped pages mapped? I don't see the direct-mapped pages\n  being mapped in the source.\n","wordCount":211,"tags":["daily"],"metadata":{},"created":"2023-07-12T07:59:25.823625705Z","modified":"2024-11-18T05:53:15.697228836Z","checksum":"06a7d263037ecc0b57ae2445a98cde7eaac813dbafaa9bdff3f0eb0b80d54cbb"},
    {"filename":"2023-07-26.md","filenameStem":"2023-07-26","path":"daily/2023-07-26.md","absPath":"/home/khadd/mynotes/daily/2023-07-26.md","title":"2023-07-26","link":"[[daily/2023-07-26]]","lead":"#daily","body":"#daily\n\nThis figure is awesome (in [shared_mem_handling.h](https://github.com/ReMon-MVEE/ReMon/blob/master/MVEE/Inc/arch/amd64/shared_mem/shared_mem_handling.h))\n```c\n    /* +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     * | _ | _ | _ _ _ | _ | _ | _ | _ _ | _ _ _ _ | _ _ | _ _ | _ | _ | _ _ _ | _ _ | _ | _ | _ _ _ _ | _ |\n     * +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     *  \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         \\\n     *   \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         +-\u003e REX present\n     *    \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   +-\u003e REX prefixes [WRXB]\n     *     \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   +-\u003e prefix group 1 present\n     *      \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     +-\u003e prefix group 2 present\n     *       \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       +-\u003e prefix group 1\n     *        \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   +-\u003e prefix group 2\n     *         \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   +-\u003e prefix group 3\n     *          \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     +-\u003e prefix group 4\n     *           \\   \\   \\       \\   \\   \\   \\     \\         \\     +-\u003e VEX size\n     *            \\   \\   \\       \\   \\   \\   \\     \\         +-\u003e VEX.L\n     *             \\   \\   \\       \\   \\   \\   \\     +-\u003e VEX.vvvv\n     *              \\   \\   \\       \\   \\   \\   +-\u003e VEX.mmmmm\n     *               \\   \\   \\       \\   \\   +-\u003e EVEX.R'\n     *                \\   \\   \\       \\   +-\u003e EVEX.X\n     *                 \\   \\   \\       +-\u003e EVEX.V'\n     *                  \\   \\   +-\u003e EVEX.aaa\n     *                   \\   +-\u003e EVEX.z\n     *                    +-\u003e EVEX.b\n     *                    \n     *                    */\n```","snippets":["#daily"],"rawContent":"# 2023-07-26\n#daily\n\nThis figure is awesome (in [shared_mem_handling.h](https://github.com/ReMon-MVEE/ReMon/blob/master/MVEE/Inc/arch/amd64/shared_mem/shared_mem_handling.h))\n```c\n    /* +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     * | _ | _ | _ _ _ | _ | _ | _ | _ _ | _ _ _ _ | _ _ | _ _ | _ | _ | _ _ _ | _ _ | _ | _ | _ _ _ _ | _ |\n     * +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     *  \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         \\\n     *   \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         +-\u003e REX present\n     *    \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   +-\u003e REX prefixes [WRXB]\n     *     \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   +-\u003e prefix group 1 present\n     *      \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     +-\u003e prefix group 2 present\n     *       \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       +-\u003e prefix group 1\n     *        \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   +-\u003e prefix group 2\n     *         \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   +-\u003e prefix group 3\n     *          \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     +-\u003e prefix group 4\n     *           \\   \\   \\       \\   \\   \\   \\     \\         \\     +-\u003e VEX size\n     *            \\   \\   \\       \\   \\   \\   \\     \\         +-\u003e VEX.L\n     *             \\   \\   \\       \\   \\   \\   \\     +-\u003e VEX.vvvv\n     *              \\   \\   \\       \\   \\   \\   +-\u003e VEX.mmmmm\n     *               \\   \\   \\       \\   \\   +-\u003e EVEX.R'\n     *                \\   \\   \\       \\   +-\u003e EVEX.X\n     *                 \\   \\   \\       +-\u003e EVEX.V'\n     *                  \\   \\   +-\u003e EVEX.aaa\n     *                   \\   +-\u003e EVEX.z\n     *                    +-\u003e EVEX.b\n     *                    \n     *                    */\n```\n\n\n","wordCount":314,"tags":["daily"],"metadata":{},"created":"2023-07-26T02:38:51.583773191Z","modified":"2023-07-26T02:40:19.753295681Z","checksum":"321e0803b887e255f3cd1e32fa742fb0c7520b7fdcd1bb4c18d7a66d25fb7c59"},
    {"filename":"2023-08-10.md","filenameStem":"2023-08-10","path":"daily/2023-08-10.md","absPath":"/home/khadd/mynotes/daily/2023-08-10.md","title":"2023-08-10","link":"[[daily/2023-08-10]]","lead":"#daily","body":"#daily\n\n- I feel lost after a week off. It feels like the momentum is gone.\n- There needs to be a task management system to tackle this; whenever you feel like you don't know what to do, just pick the most urgent task from the list.\n\n- Regarding ObliVM\n  - Need to port Unikraft to SEV\n  - Need to update writing\n  - Need to port real applications","snippets":["#daily"],"rawContent":"# 2023-08-10\n#daily\n\n- I feel lost after a week off. It feels like the momentum is gone.\n- There needs to be a task management system to tackle this; whenever you feel like you don't know what to do, just pick the most urgent task from the list.\n\n- Regarding ObliVM\n  - Need to port Unikraft to SEV\n  - Need to update writing\n  - Need to port real applications\n\n\n\n\n\n","wordCount":70,"tags":["daily"],"metadata":{},"created":"2023-08-10T07:33:38.089767774Z","modified":"2023-08-10T07:45:09.590361476Z","checksum":"5a3740cb2056bb4c70d9d11c7f8cec8438423544c908254a8edaeafdc58b5cd5"},
    {"filename":"2023-08-23.md","filenameStem":"2023-08-23","path":"daily/2023-08-23.md","absPath":"/home/khadd/mynotes/daily/2023-08-23.md","title":"2023-08-23","link":"[[daily/2023-08-23]]","lead":"#daily","body":"#daily\n\n# State of the things\n\n## Capacity\n\n- Github repo must be up, but the code can be delayed\n- A presentation is needed. Need to prepare for at least 1 month\n- Paper: Final version is almost done\n\n- Need to apply for VISA\n\n## Project: Oblv\n\n- Need to port unikraft to support SEV-SNP\n- Writing hasn't been touched for a while\n- Reading: important related works are not grokked\n  - Cosmix\n  - InvisiPage\n  - Klotski\n  - Autarky\n\n## CLG\n\n- writing is progressing, with some important points fleshed out\n-\n\n## Other\n\n- Rustsan?\n\n# Way forward\n\n-","snippets":["#daily"],"rawContent":"# 2023-08-23\n\n#daily\n\n# State of the things\n\n## Capacity\n\n- Github repo must be up, but the code can be delayed\n- A presentation is needed. Need to prepare for at least 1 month\n- Paper: Final version is almost done\n\n- Need to apply for VISA\n\n## Project: Oblv\n\n- Need to port unikraft to support SEV-SNP\n- Writing hasn't been touched for a while\n- Reading: important related works are not grokked\n  - Cosmix\n  - InvisiPage\n  - Klotski\n  - Autarky\n\n## CLG\n\n- writing is progressing, with some important points fleshed out\n-\n\n## Other\n\n- Rustsan?\n\n# Way forward\n\n-\n","wordCount":104,"tags":["daily"],"metadata":{},"created":"2023-08-23T08:51:56.182014346Z","modified":"2024-11-18T05:53:35.309062513Z","checksum":"756b87d6e1ce549110bb40af3a811d2c93ce3c2eca6dcac681b5144bb41e79f5"},
    {"filename":"2024-05-22.md","filenameStem":"2024-05-22","path":"daily/2024-05-22.md","absPath":"/home/khadd/mynotes/daily/2024-05-22.md","title":"2024-05-22","link":"[[daily/2024-05-22]]","lead":"#daily","body":"#daily\n\n# Outline\n\nToday I asked Hajeong to give his feedbacks on the document for positioning my\npaper [this](https://ssnote.skku.edu/C8eOyrK1Q9K4Rog0uXldbw?both). Mainly, the\ncontent can be summarized in a this table:\n\n| Approaches                                                   | Works                        | Overheads                                                | Non-Intrusive\\* | Kernel \u0026 User | Unmodified binaries | Leverage CVM opportunities | Paging SC | Ciphertext SC             | cache SC                       |\n| ------------------------------------------------------------ | ---------------------------- | -------------------------------------------------------- | --------------- | ------------- | ------------------- | -------------------------- | --------- | ------------------------- | ------------------------------ |\n| Hardware paging isolation                                    | (Invisipage, Sanctum,...)    | Low                                                      | No              | Yes           | No                  | No                         | Yes       | Yes                       | No                             |\n| Security monitor                                             | (eOPF)                       | Medium?                                                  | No              | Yes           | Yes                 | No                         | Yes       | Yes (theoretically, eOPF) | Yes (eOPF)                     |\n| Compiler-based obfuscation                                   | (Obfuscuro, Klotski, Obelix) | Very High                                                | Yes             | No            | No                  | No                         | Yes       | Yes (Obelix)              | Yes (Obfuscuro)                |\n| Dynamic + static binary instrumentation                      | (Cipherfix)                  | High                                                     | Yes             | No            | Yes                 | No                         | No        | Yes                       | No                             |\n| IngonitOS: OS-level design leveraging direct hardware access | **IngonitOS**                | Low ~ High (Reasonable baseline + Configurable security) | Yes             | Yes           | Yes                 | Yes                        | Yes       | Yes\\*                     | Yes\\* (Based on configuration) |\n\nHe then changed it to something more simple (and maybe more clear). Main\nfeedbacks was:\n\n- Use of ambiguous words (full-system, intrusive)\n- \"Leverage CVM opportunities\" is unclear\n- Why do we need to compare against hardware-based approaches?\n- Put what is the most important upfront. E.g., people would care about security\n  first.\n\nMore lessons:\n\n- Respect the reader. Don't assume they will read the explanation, table should\n  be self-explanatory.\n- Beautify it. Find ways to beautify, even when it is a draft. Advisor is also a\n  reader.\n- Comparison target: choose reasonable ones. E.g., directly relevant works.","snippets":["#daily"],"rawContent":"# 2024-05-22\n\n#daily\n\n# Outline\n\nToday I asked Hajeong to give his feedbacks on the document for positioning my\npaper [this](https://ssnote.skku.edu/C8eOyrK1Q9K4Rog0uXldbw?both). Mainly, the\ncontent can be summarized in a this table:\n\n| Approaches                                                   | Works                        | Overheads                                                | Non-Intrusive\\* | Kernel \u0026 User | Unmodified binaries | Leverage CVM opportunities | Paging SC | Ciphertext SC             | cache SC                       |\n| ------------------------------------------------------------ | ---------------------------- | -------------------------------------------------------- | --------------- | ------------- | ------------------- | -------------------------- | --------- | ------------------------- | ------------------------------ |\n| Hardware paging isolation                                    | (Invisipage, Sanctum,...)    | Low                                                      | No              | Yes           | No                  | No                         | Yes       | Yes                       | No                             |\n| Security monitor                                             | (eOPF)                       | Medium?                                                  | No              | Yes           | Yes                 | No                         | Yes       | Yes (theoretically, eOPF) | Yes (eOPF)                     |\n| Compiler-based obfuscation                                   | (Obfuscuro, Klotski, Obelix) | Very High                                                | Yes             | No            | No                  | No                         | Yes       | Yes (Obelix)              | Yes (Obfuscuro)                |\n| Dynamic + static binary instrumentation                      | (Cipherfix)                  | High                                                     | Yes             | No            | Yes                 | No                         | No        | Yes                       | No                             |\n| IngonitOS: OS-level design leveraging direct hardware access | **IngonitOS**                | Low ~ High (Reasonable baseline + Configurable security) | Yes             | Yes           | Yes                 | Yes                        | Yes       | Yes\\*                     | Yes\\* (Based on configuration) |\n\nHe then changed it to something more simple (and maybe more clear). Main\nfeedbacks was:\n\n- Use of ambiguous words (full-system, intrusive)\n- \"Leverage CVM opportunities\" is unclear\n- Why do we need to compare against hardware-based approaches?\n- Put what is the most important upfront. E.g., people would care about security\n  first.\n\nMore lessons:\n\n- Respect the reader. Don't assume they will read the explanation, table should\n  be self-explanatory.\n- Beautify it. Find ways to beautify, even when it is a draft. Advisor is also a\n  reader.\n- Comparison target: choose reasonable ones. E.g., directly relevant works.\n","wordCount":317,"tags":["daily"],"metadata":{},"created":"2024-05-28T09:41:30.428071513Z","modified":"2024-11-18T05:53:45.011677535Z","checksum":"a3d82bf16ca374dc2dc3bb1b4e6f6b1cfd0f5cda656a9003105939550c885dec"},
    {"filename":"rmi02wh7.md","filenameStem":"rmi02wh7","path":"rmi02wh7.md","absPath":"/home/khadd/mynotes/rmi02wh7.md","title":"40Hz binaural beats enhance cognitive functions","link":"[[rmi02wh7]]","lead":"40hz (or gamma wave) binaural beats has been shown in studies to improve certain\nbrain functions [@adaikkan2019gamma].","body":"40hz (or gamma wave) binaural beats has been shown in studies to improve certain\nbrain functions [@adaikkan2019gamma].\n\n- Accelerate outcome of attentional blink (AB) tasks [@ross202040hz].","snippets":["40hz (or gamma wave) binaural beats has been shown in studies to improve certain\nbrain functions [@adaikkan2019gamma]."],"rawContent":"# 40Hz binaural beats enhance cognitive functions\n\n40hz (or gamma wave) binaural beats has been shown in studies to improve certain\nbrain functions [@adaikkan2019gamma].\n\n- Accelerate outcome of attentional blink (AB) tasks [@ross202040hz].\n","wordCount":33,"tags":[],"metadata":{},"created":"2024-12-09T04:15:21.688058138Z","modified":"2024-12-09T04:15:06.172051626Z","checksum":"feea148e25d1536f31e8111c1e2318a32df626cdc5d1c3b288eb8e0fd062a389"},
    {"filename":"c7cva598.md","filenameStem":"c7cva598","path":"c7cva598.md","absPath":"/home/khadd/mynotes/c7cva598.md","title":"AMD Secure Encrypted Virtualization (SEV)","link":"[[c7cva598]]","lead":"#sev #virtualization #tee #amd","body":"#sev #virtualization #tee #amd\n\nAMD's Secure Encrypted Virtualization (SEV) enables TEEs at the granularity of\nvirtual machines.\n\n# Memory encryption\n\nThe CPU employs a secure processor (SP) that transparently encrypts/decrypts\ndata when they are written into the memory pages of the encrypted VMs.\n\nEncryption is performed with a per-cVM key maintained by the CPU,c called the VM\nencryption key (VEK). It is indexed by the ASID of the VM.\n\nA flag called the c-bit indicates whether a page should be encrypted or not. The\nlocation of the c-bit may be different depending on the platform. The Linux's\nsupport for SEV check for the c-bit location using `CPUID 8000_001F[EBX]`.\n(`get_sev_encryption_bit` in `x86/boot/compressed/mem_encrypt.S`).\n\n## Behavior\n\nAMD manual, volume 2, 15.34.5:\n\n\u003e Memory access on behalf of instruction fetches and guest page table walks are\n\u003e always treated as private, regardless of the software value of the C-bit.\n\nIn other words, implicit memory accesses performed by the hardware are always\nprivate (maybe prefetching is an exception). Making instruction fetches private\nprevents the host from injecting code into the virtual machine. Making the page\ntable walk private prevents the host from tampering with the Guest mapping.\nHowever, this is insufficient, due to the unprotected gPA-\u003ehPA mapping, as shown\nin some papers (@morbitzer2018severed). SEV-SNP remedied this issue by\nprotecting this mapping.\n\nThis may have two implications in implementing kernel:\n\n- Before the software writes into the code page, (e. Howeverg., before\n  relocation), the c-bit of those pages must be set (#need-verifivation),\n- Software operations on the page table must be careful, since sometimes c-bit\n  may consume physical address bits.\n\n## Interaction between host and guest PTEs\n\nThe c-bit is stored in _both_ the host PTEs and the guest PTEs. Its effect is\ndetermined from the combination of the two c-bit in gPT and NPT.\n\n|               | host c-bit                 |                            |\n| ------------- | -------------------------- | -------------------------- |\n| guest c-bit   | 0                          | 1                          |\n| ------------- | -------------------------- | -------------------------- |\n| 0             | not encrypted              | encrypted with host key    |\n| 1             | encrypted with guest key   | encrypted with guest key   |\n\n29/03/96\n\n5:6:7\n\n## SEV-ES\n\nThe original design of SEV does not encrypt the VM states upon VM exit. This\nleads to attacks that can extract information from the VM based on the register\nstate.\n\nSEV-Encrypted State (ES) solve this issue by also encrypting the VM states upon\nVMEXIT. It splits the virtual machine control block (VMCB) into two areas, a\ncontrol area and a save area (VMSA). The VMSA is encrypted with the VEK upon\nVMEXIT.\n\n## Automatic and non-automatic exits\n\nNow, every exit from the guest into the hypervisor (`VMEXIT`) is categorized\ninto Automatic Exit (AE) and Non-automatic Exit (NAE).\n\nAE consists of basically all interrupts that are trigger by the hypervisor.\nSince these interrupt does not require knowledge of VM register state, all of VM\nregisters will be encrypted and stored into the VMSA.\n\nNAE are the remaining exits, i.e., faults triggered by the VM. Faults can be\ntriggered by the hardware exception such as page fault, or executing a privilege\ninstruction (e.g., write into CR3). In this case, the guest might want to share\nsome register states with the hypervisor.\n\nHence, a `VC` exception (VMM Communication Exception) is generated by the CPU,\nwith the cauuse of exception. The VM then invoke the handler to handle the\nfault. The handler can copy the selected VM registers into a shared page, called\nthe Guest Hypervisor Communication Block (GHCB), which is non-encrypted. It then\ntriggers an AE with a call to `VMGEXIT`, so that the host can serve the fault.\n\n# SEV-SNP\n\n## Mapping integrity protection\n\nSEV-Secure Nested Paging (SNP) adds integrity protection to SEV, that protect\nthe encrypted pages from replaying (replaced with an old page), being mapped to\ntwo regions, and being remapped.\n\nIt uses an Reseve Page Mapping (RMP), which is a table maintained by the\nhardware to keep the mapping metatada for each physical pages. All memory write\naccesses look up the RMP to verify the mapping correctness.\n\nEven with the RMP mapping protection, a malicious VMM could still tammper with\nthe permission flags in the page table entries @qin2023protecting. For instance,\na malicious hypervisor can overwrite the present bit in the NPT, that indicate\nwheter the page is inside memory. When the VM access the page, a nested page\nfault will be trigger.\n\n## VMPL\n\nSEV-SNP also includes the Virtual Machine Privilege Level (VMPL) security\nmechanism. It adds privilege levels within the encrypted VM.\n\nHecate @ge2022hecate uses this feature to implement an in-VM hypervisor that\nhandle the VM-VMM interactions for an unmodified, un-enlighteneda OS. It puts\nthe hypervisor in VMPL layer 0, and the guest VM in VMPL level 4, then have the\nVMM forwards all faults into the in-VM VMM for handling.\n\n# I/O operations in SEV\n\nSee [[zmt276jl]].\n\n# Related notes\n\n- [[d3nt6uix]]\n- [[s16ct1rj]]","snippets":["#sev #virtualization #tee #amd"],"rawContent":"# AMD Secure Encrypted Virtualization (SEV)\n\n#sev #virtualization #tee #amd\n\nAMD's Secure Encrypted Virtualization (SEV) enables TEEs at the granularity of\nvirtual machines.\n\n# Memory encryption\n\nThe CPU employs a secure processor (SP) that transparently encrypts/decrypts\ndata when they are written into the memory pages of the encrypted VMs.\n\nEncryption is performed with a per-cVM key maintained by the CPU,c called the VM\nencryption key (VEK). It is indexed by the ASID of the VM.\n\nA flag called the c-bit indicates whether a page should be encrypted or not. The\nlocation of the c-bit may be different depending on the platform. The Linux's\nsupport for SEV check for the c-bit location using `CPUID 8000_001F[EBX]`.\n(`get_sev_encryption_bit` in `x86/boot/compressed/mem_encrypt.S`).\n\n## Behavior\n\nAMD manual, volume 2, 15.34.5:\n\n\u003e Memory access on behalf of instruction fetches and guest page table walks are\n\u003e always treated as private, regardless of the software value of the C-bit.\n\nIn other words, implicit memory accesses performed by the hardware are always\nprivate (maybe prefetching is an exception). Making instruction fetches private\nprevents the host from injecting code into the virtual machine. Making the page\ntable walk private prevents the host from tampering with the Guest mapping.\nHowever, this is insufficient, due to the unprotected gPA-\u003ehPA mapping, as shown\nin some papers (@morbitzer2018severed). SEV-SNP remedied this issue by\nprotecting this mapping.\n\nThis may have two implications in implementing kernel:\n\n- Before the software writes into the code page, (e. Howeverg., before\n  relocation), the c-bit of those pages must be set (#need-verifivation),\n- Software operations on the page table must be careful, since sometimes c-bit\n  may consume physical address bits.\n\n## Interaction between host and guest PTEs\n\nThe c-bit is stored in _both_ the host PTEs and the guest PTEs. Its effect is\ndetermined from the combination of the two c-bit in gPT and NPT.\n\n|               | host c-bit                 |                            |\n| ------------- | -------------------------- | -------------------------- |\n| guest c-bit   | 0                          | 1                          |\n| ------------- | -------------------------- | -------------------------- |\n| 0             | not encrypted              | encrypted with host key    |\n| 1             | encrypted with guest key   | encrypted with guest key   |\n\n29/03/96\n\n5:6:7\n\n## SEV-ES\n\nThe original design of SEV does not encrypt the VM states upon VM exit. This\nleads to attacks that can extract information from the VM based on the register\nstate.\n\nSEV-Encrypted State (ES) solve this issue by also encrypting the VM states upon\nVMEXIT. It splits the virtual machine control block (VMCB) into two areas, a\ncontrol area and a save area (VMSA). The VMSA is encrypted with the VEK upon\nVMEXIT.\n\n## Automatic and non-automatic exits\n\nNow, every exit from the guest into the hypervisor (`VMEXIT`) is categorized\ninto Automatic Exit (AE) and Non-automatic Exit (NAE).\n\nAE consists of basically all interrupts that are trigger by the hypervisor.\nSince these interrupt does not require knowledge of VM register state, all of VM\nregisters will be encrypted and stored into the VMSA.\n\nNAE are the remaining exits, i.e., faults triggered by the VM. Faults can be\ntriggered by the hardware exception such as page fault, or executing a privilege\ninstruction (e.g., write into CR3). In this case, the guest might want to share\nsome register states with the hypervisor.\n\nHence, a `VC` exception (VMM Communication Exception) is generated by the CPU,\nwith the cauuse of exception. The VM then invoke the handler to handle the\nfault. The handler can copy the selected VM registers into a shared page, called\nthe Guest Hypervisor Communication Block (GHCB), which is non-encrypted. It then\ntriggers an AE with a call to `VMGEXIT`, so that the host can serve the fault.\n\n# SEV-SNP\n\n## Mapping integrity protection\n\nSEV-Secure Nested Paging (SNP) adds integrity protection to SEV, that protect\nthe encrypted pages from replaying (replaced with an old page), being mapped to\ntwo regions, and being remapped.\n\nIt uses an Reseve Page Mapping (RMP), which is a table maintained by the\nhardware to keep the mapping metatada for each physical pages. All memory write\naccesses look up the RMP to verify the mapping correctness.\n\nEven with the RMP mapping protection, a malicious VMM could still tammper with\nthe permission flags in the page table entries @qin2023protecting. For instance,\na malicious hypervisor can overwrite the present bit in the NPT, that indicate\nwheter the page is inside memory. When the VM access the page, a nested page\nfault will be trigger.\n\n## VMPL\n\nSEV-SNP also includes the Virtual Machine Privilege Level (VMPL) security\nmechanism. It adds privilege levels within the encrypted VM.\n\nHecate @ge2022hecate uses this feature to implement an in-VM hypervisor that\nhandle the VM-VMM interactions for an unmodified, un-enlighteneda OS. It puts\nthe hypervisor in VMPL layer 0, and the guest VM in VMPL level 4, then have the\nVMM forwards all faults into the in-VM VMM for handling.\n\n# I/O operations in SEV\n\nSee [[zmt276jl]].\n\n# Related notes\n\n- [[d3nt6uix]]\n- [[s16ct1rj]]\n","wordCount":819,"tags":["tee","sev","virtualization","amd","need-verifivation"],"metadata":{},"created":"2023-05-26T07:17:27.667130146Z","modified":"2024-06-20T10:48:46.859298415Z","checksum":"5936f7c65f571d83dff0fbbd68db2f4ceda20af43540c611f42206535b7cfd79"},
    {"filename":"0x59ndm7.md","filenameStem":"0x59ndm7","path":"0x59ndm7.md","absPath":"/home/khadd/mynotes/0x59ndm7.md","title":"ANSI Colors","link":"[[0x59ndm7]]","lead":"Note: `\\e` may be replaced by `\\033`","body":"Note: `\\e` may be replaced by `\\033`\n\n## Regular Colors\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[0;30m | Black  |\n| \\e[0;31m | Red    |\n| \\e[0;32m | Green  |\n| \\e[0;33m | Yellow |\n| \\e[0;34m | Blue   |\n| \\e[0;35m | Purple |\n| \\e[0;36m | Cyan   |\n| \\e[0;37m | White  |\n\n## Bold\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[1;30m | Black  |\n| \\e[1;31m | Red    |\n| \\e[1;32m | Green  |\n| \\e[1;33m | Yellow |\n| \\e[1;34m | Blue   |\n| \\e[1;35m | Purple |\n| \\e[1;36m | Cyan   |\n| \\e[1;37m | White  |\n\n## Underline\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[4;30m | Black  |\n| \\e[4;31m | Red    |\n| \\e[4;32m | Green  |\n| \\e[4;33m | Yellow |\n| \\e[4;34m | Blue   |\n| \\e[4;35m | Purple |\n| \\e[4;36m | Cyan   |\n| \\e[4;37m | White  |\n\n## Background\n\n| Value  | Color  |\n| ------ | ------ |\n| \\e[40m | Black  |\n| \\e[41m | Red    |\n| \\e[42m | Green  |\n| \\e[43m | Yellow |\n| \\e[44m | Blue   |\n| \\e[45m | Purple |\n| \\e[46m | Cyan   |\n| \\e[47m | White  |\n\n## High Intensity\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[0;90m | Black  |\n| \\e[0;91m | Red    |\n| \\e[0;92m | Green  |\n| \\e[0;93m | Yellow |\n| \\e[0;94m | Blue   |\n| \\e[0;95m | Purple |\n| \\e[0;96m | Cyan   |\n| \\e[0;97m | White  |\n\n## Bold High Intensity\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[1;90m | Black  |\n| \\e[1;91m | Red    |\n| \\e[1;92m | Green  |\n| \\e[1;93m | Yellow |\n| \\e[1;94m | Blue   |\n| \\e[1;95m | Purple |\n| \\e[1;96m | Cyan   |\n| \\e[1;97m | White  |\n\n## High Intensity backgrounds\n\n| Value     | Color  |\n| --------- | ------ |\n| \\e[0;100m | Black  |\n| \\e[0;101m | Red    |\n| \\e[0;102m | Green  |\n| \\e[0;103m | Yellow |\n| \\e[0;104m | Blue   |\n| \\e[0;105m | Purple |\n| \\e[0;106m | Cyan   |\n| \\e[0;107m | White  |\n\n## Reset\n\n| Value | Color |\n| ----- | ----- |\n| \\e[0m | Reset |\n\n## other styles\n\n```bash\necho -e \"\\e[1mbold\\e[0m\"\necho -e \"\\e[3mitalic\\e[0m\"\necho -e \"\\e[3m\\e[1mbold italic\\e[0m\"\necho -e \"\\e[4munderline\\e[0m\"\necho -e \"\\e[9mstrikethrough\\e[0m\"\necho -e \"\\e[31mHello World\\e[0m\"\necho -e \"\\x1B[31mHello World\\e[0m\"\n```\n\n- [src]: https://gist.github.com/JBlond/2fea43a3049b38287e5e9cefc87b2124","snippets":["Note: `\\e` may be replaced by `\\033`"],"rawContent":"# ANSI Colors\n\nNote: `\\e` may be replaced by `\\033`\n\n## Regular Colors\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[0;30m | Black  |\n| \\e[0;31m | Red    |\n| \\e[0;32m | Green  |\n| \\e[0;33m | Yellow |\n| \\e[0;34m | Blue   |\n| \\e[0;35m | Purple |\n| \\e[0;36m | Cyan   |\n| \\e[0;37m | White  |\n\n## Bold\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[1;30m | Black  |\n| \\e[1;31m | Red    |\n| \\e[1;32m | Green  |\n| \\e[1;33m | Yellow |\n| \\e[1;34m | Blue   |\n| \\e[1;35m | Purple |\n| \\e[1;36m | Cyan   |\n| \\e[1;37m | White  |\n\n## Underline\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[4;30m | Black  |\n| \\e[4;31m | Red    |\n| \\e[4;32m | Green  |\n| \\e[4;33m | Yellow |\n| \\e[4;34m | Blue   |\n| \\e[4;35m | Purple |\n| \\e[4;36m | Cyan   |\n| \\e[4;37m | White  |\n\n## Background\n\n| Value  | Color  |\n| ------ | ------ |\n| \\e[40m | Black  |\n| \\e[41m | Red    |\n| \\e[42m | Green  |\n| \\e[43m | Yellow |\n| \\e[44m | Blue   |\n| \\e[45m | Purple |\n| \\e[46m | Cyan   |\n| \\e[47m | White  |\n\n## High Intensity\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[0;90m | Black  |\n| \\e[0;91m | Red    |\n| \\e[0;92m | Green  |\n| \\e[0;93m | Yellow |\n| \\e[0;94m | Blue   |\n| \\e[0;95m | Purple |\n| \\e[0;96m | Cyan   |\n| \\e[0;97m | White  |\n\n## Bold High Intensity\n\n| Value    | Color  |\n| -------- | ------ |\n| \\e[1;90m | Black  |\n| \\e[1;91m | Red    |\n| \\e[1;92m | Green  |\n| \\e[1;93m | Yellow |\n| \\e[1;94m | Blue   |\n| \\e[1;95m | Purple |\n| \\e[1;96m | Cyan   |\n| \\e[1;97m | White  |\n\n## High Intensity backgrounds\n\n| Value     | Color  |\n| --------- | ------ |\n| \\e[0;100m | Black  |\n| \\e[0;101m | Red    |\n| \\e[0;102m | Green  |\n| \\e[0;103m | Yellow |\n| \\e[0;104m | Blue   |\n| \\e[0;105m | Purple |\n| \\e[0;106m | Cyan   |\n| \\e[0;107m | White  |\n\n## Reset\n\n| Value | Color |\n| ----- | ----- |\n| \\e[0m | Reset |\n\n## other styles\n\n```bash\necho -e \"\\e[1mbold\\e[0m\"\necho -e \"\\e[3mitalic\\e[0m\"\necho -e \"\\e[3m\\e[1mbold italic\\e[0m\"\necho -e \"\\e[4munderline\\e[0m\"\necho -e \"\\e[9mstrikethrough\\e[0m\"\necho -e \"\\e[31mHello World\\e[0m\"\necho -e \"\\x1B[31mHello World\\e[0m\"\n```\n\n- [src]: https://gist.github.com/JBlond/2fea43a3049b38287e5e9cefc87b2124\n","wordCount":429,"tags":[],"metadata":{},"created":"2024-12-09T05:43:18.848925946Z","modified":"2024-12-09T07:29:42.531841212Z","checksum":"e03b78d8b3ce59e2fe0a063621ed2f34306bd01521ec805571f46cde41e6ee02"},
    {"filename":"4vysjbn9.md","filenameStem":"4vysjbn9","path":"4vysjbn9.md","absPath":"/home/khadd/mynotes/4vysjbn9.md","title":"Abolishing Hierarchy for Flexibility","link":"[[4vysjbn9]]","lead":"A meta-concept found in many domains.","body":"A meta-concept found in many domains.\n\n- Capability-based security [[c4icaua4]]\n- OOP: Prefer composition to inheritance\n- Zettlekasten style of note linking vs. fixed directory structures\n- Distributed systems","snippets":["A meta-concept found in many domains."],"rawContent":"# Abolishing Hierarchy for Flexibility\n\nA meta-concept found in many domains.\n\n- Capability-based security [[c4icaua4]]\n- OOP: Prefer composition to inheritance\n- Zettlekasten style of note linking vs. fixed directory structures\n- Distributed systems\n","wordCount":34,"tags":[],"metadata":{},"created":"2024-12-12T05:00:53.194828077Z","modified":"2024-12-23T05:36:24.683254515Z","checksum":"cb56d716d6550504fbbe79a1e5b968f5e0bef20f52e1519bf7d90a9d7c0f958b"},
    {"filename":"64zyhko0.md","filenameStem":"64zyhko0","path":"64zyhko0.md","absPath":"/home/khadd/mynotes/64zyhko0.md","title":"Academic vocabularies (security)","link":"[[64zyhko0]]","lead":"#writing","body":"#writing\n\n- Curtail (verb): To impose restrictions on. \n  - E.g., Our proposed design curtailed the attacker's ability to hijack the control flow.","snippets":["#writing"],"rawContent":"# Academic vocabularies (security)\n#writing\n\n- Curtail (verb): To impose restrictions on. \n  - E.g., Our proposed design curtailed the attacker's ability to hijack the control flow.\n\n\n","wordCount":26,"tags":["writing"],"metadata":{},"created":"2023-08-30T08:03:57.104771544Z","modified":"2024-05-20T11:00:55.665146783Z","checksum":"6b63d5088e9d39cc6996ecd0d29ab34f32dde56fb308205564bb034f668d13ac"},
    {"filename":"2xsjor1o.md","filenameStem":"2xsjor1o","path":"2xsjor1o.md","absPath":"/home/khadd/mynotes/2xsjor1o.md","title":"Accessing user memory from Kernel","link":"[[2xsjor1o]]","lead":"#linux","body":"#linux\n\nLinux provides `__user` annotation to mark userspace pointers. _Transfer\nfunctions_ such as `copy_from_user` can only operate on those pointers. User\npointers are always compared against userspace address space to avoid kernel\npointers. An example of `get_user`:\n\n```assembly\n.text\nENTRY(__get_user_1)\n    mov PER_CPU_VAR(current_task), %_ASM_DX\n    cmp TASK_addr_limit(%_ASM_DX),%_ASM_AX\n    jae bad_get_user\n    ASM_STAC\n1:  movzbl (%_ASM_AX),%edx\n    xor %eax,%eax\n    ASM_CLAC\n    ret\nENDPROC(__get_user_1)\n\nbad_get_user:\n    xor %edx,%edx\n    mov $(-EFAULT),%_ASM_AX\n    ASM_CLAC\n    ret\nEND(bad_get_user)\n\n_ASM_EXTABLE(1b,bad_get_user)\n```\n\nThe first two instructions check the pointer against the process descriptor to\nmake sure it's not pointer from usersapce. Then it disable SMAP (ASM_STAC) and\naccess userspace memory (at 1: block)","snippets":["#linux"],"rawContent":"# Accessing user memory from Kernel\n\n#linux\n\nLinux provides `__user` annotation to mark userspace pointers. _Transfer\nfunctions_ such as `copy_from_user` can only operate on those pointers. User\npointers are always compared against userspace address space to avoid kernel\npointers. An example of `get_user`:\n\n```assembly\n.text\nENTRY(__get_user_1)\n    mov PER_CPU_VAR(current_task), %_ASM_DX\n    cmp TASK_addr_limit(%_ASM_DX),%_ASM_AX\n    jae bad_get_user\n    ASM_STAC\n1:  movzbl (%_ASM_AX),%edx\n    xor %eax,%eax\n    ASM_CLAC\n    ret\nENDPROC(__get_user_1)\n\nbad_get_user:\n    xor %edx,%edx\n    mov $(-EFAULT),%_ASM_AX\n    ASM_CLAC\n    ret\nEND(bad_get_user)\n\n_ASM_EXTABLE(1b,bad_get_user)\n```\n\nThe first two instructions check the pointer against the process descriptor to\nmake sure it's not pointer from usersapce. Then it disable SMAP (ASM_STAC) and\naccess userspace memory (at 1: block)\n","wordCount":103,"tags":["linux"],"metadata":{},"created":"2023-05-23T09:02:05.544541174Z","modified":"2024-09-14T11:09:07.79362046Z","checksum":"0bf5dea504ebe60e0e79239d6b43a04c004efeae5f0d4d64424ecf4588762d42"},
    {"filename":"nhovug1d.md","filenameStem":"nhovug1d","path":"nhovug1d.md","absPath":"/home/khadd/mynotes/nhovug1d.md","title":"Address translation / virtual memory overheads","link":"[[nhovug1d]]","lead":"#os #architecture","body":"#os #architecture\n\nVirtual memory abstraction [[eqbigndi]] enable easy programming model through\nMMU support and address translation.\n\nHOwever, Address address translation creates non-trivials overheads\n[@yan2019translation] that came from two main sources:\n\n- The OS needs to handle page faults in the software.\n- The CPU's MMU needs to walk the page table, which requires multiple memory\n  accesses (in case of TLB miss) of up to 5 page table levels.\n\n## Increasing TLB size\n\nModern architectures cope with this overhead by increasing the TLB size.\nHowever, this approach is not be scalable. Even with thousands of entries, they\nare still three magnitude less than required [@gupta2021rebooting].\n\n## Huge pages\n\nUsing huge pages copes with address translation is by increasing memory ranges\ncovered by the TLB entries.\n\n- Using huge pages requires continuous physical memory that requires the OS to\n  spend significant effort to defragment.\n- Huge page are difficult to use without internal fragmentation\n  [@gupta2021rebooting].\n- Is a leaky abstraction. It is costly / difficult to provide huge page\n  transparently so program is required to explicitly request them .\n\n## Hardware changes\n\nChanges in hardware are proposed to reduce address translation overheads\n[@gupta2021rebooting, @yan2019translation].\n\n## Software Replacement\n\nCARAT [@suchy2022carat] proposed using compiler-inserted checks to replace the\nMMU-provided access control.","snippets":["#os #architecture"],"rawContent":"# Address translation / virtual memory overheads\n\n#os #architecture\n\nVirtual memory abstraction [[eqbigndi]] enable easy programming model through\nMMU support and address translation.\n\nHOwever, Address address translation creates non-trivials overheads\n[@yan2019translation] that came from two main sources:\n\n- The OS needs to handle page faults in the software.\n- The CPU's MMU needs to walk the page table, which requires multiple memory\n  accesses (in case of TLB miss) of up to 5 page table levels.\n\n## Increasing TLB size\n\nModern architectures cope with this overhead by increasing the TLB size.\nHowever, this approach is not be scalable. Even with thousands of entries, they\nare still three magnitude less than required [@gupta2021rebooting].\n\n## Huge pages\n\nUsing huge pages copes with address translation is by increasing memory ranges\ncovered by the TLB entries.\n\n- Using huge pages requires continuous physical memory that requires the OS to\n  spend significant effort to defragment.\n- Huge page are difficult to use without internal fragmentation\n  [@gupta2021rebooting].\n- Is a leaky abstraction. It is costly / difficult to provide huge page\n  transparently so program is required to explicitly request them .\n\n## Hardware changes\n\nChanges in hardware are proposed to reduce address translation overheads\n[@gupta2021rebooting, @yan2019translation].\n\n## Software Replacement\n\nCARAT [@suchy2022carat] proposed using compiler-inserted checks to replace the\nMMU-provided access control.\n","wordCount":214,"tags":["os","architecture"],"metadata":{},"created":"2024-12-09T04:15:21.681612081Z","modified":"2024-12-09T04:15:06.172051626Z","checksum":"39f033b4974e6d7e587696413ce4c33c24223b845838fde32cee516d182f284b"},
    {"filename":"p5k8t7io.md","filenameStem":"p5k8t7io","path":"p5k8t7io.md","absPath":"/home/khadd/mynotes/p5k8t7io.md","title":"Adrenaline helps remembering","link":"[[p5k8t7io]]","lead":"#cognitive","body":"#cognitive\n\nEmotionally significants experiences tend to be remembered well.\n\nStudies [@mcintyre2007adrenal] has shown hormones (epinephrine, glucocorticoids)\nreleased by the adrenal gland enhance memory consodilation and object\nrecognition training (rats and human). However, it is not only the hormones by\nthemself causing this effect, but there have to be emotional arousal\n[@mcintyre2007adrenal].\n\nBecause of this, it might be a good advice to spike your adrenaline after\nlearning something to boost long-term retention. This can be achieved through\ncold shock or exercises.","snippets":["#cognitive"],"rawContent":"# Adrenaline helps remembering\n\n#cognitive\n\nEmotionally significants experiences tend to be remembered well.\n\nStudies [@mcintyre2007adrenal] has shown hormones (epinephrine, glucocorticoids)\nreleased by the adrenal gland enhance memory consodilation and object\nrecognition training (rats and human). However, it is not only the hormones by\nthemself causing this effect, but there have to be emotional arousal\n[@mcintyre2007adrenal].\n\nBecause of this, it might be a good advice to spike your adrenaline after\nlearning something to boost long-term retention. This can be achieved through\ncold shock or exercises.\n","wordCount":84,"tags":["cognitive"],"metadata":{},"created":"2024-12-09T07:53:16.561724578Z","modified":"2024-12-09T08:05:41.398133018Z","checksum":"d94172496ee25265d597a8995ca23fa1598579f48c92e05cfef248ce46701f1c"},
    {"filename":"u2rtuz36.md","filenameStem":"u2rtuz36","path":"u2rtuz36.md","absPath":"/home/khadd/mynotes/u2rtuz36.md","title":"All Ideologies Inevitably have Contradictions","link":"[[u2rtuz36]]","lead":"Everyone's world view is influenced by certain ideologies. Ideologies are\ncollection of symbols that a person use to make sense of the world.","body":"Everyone's world view is influenced by certain ideologies. Ideologies are\ncollection of symbols that a person use to make sense of the world.\n\nContradictions in the way of thinking are signs of an underlying ideology.\n\n- \u003chttps://www.philosophizethis.org/podcast/anarchism-part-one-26l4k-pj5c2-yehbw-jebes\u003e","snippets":["Everyone's world view is influenced by certain ideologies. Ideologies are\ncollection of symbols that a person use to make sense of the world."],"rawContent":"# All Ideologies Inevitably have Contradictions\n\nEveryone's world view is influenced by certain ideologies. Ideologies are\ncollection of symbols that a person use to make sense of the world.\n\nContradictions in the way of thinking are signs of an underlying ideology.\n\n- \u003chttps://www.philosophizethis.org/podcast/anarchism-part-one-26l4k-pj5c2-yehbw-jebes\u003e\n","wordCount":43,"tags":[],"metadata":{},"created":"2024-07-25T04:59:30.925101648Z","modified":"2024-11-26T13:31:13.491799356Z","checksum":"087baccc9a0e57e80d1dfd3e879dc48ddeb7089eb028c5531a3dc6e5ece449a2"},
    {"filename":"vjmpqh7z.md","filenameStem":"vjmpqh7z","path":"vjmpqh7z.md","absPath":"/home/khadd/mynotes/vjmpqh7z.md","title":"Asynchronous vs synchronous IPC","link":"[[vjmpqh7z]]","lead":"Commonly Inter Process Communication primitives comes in the form of synchronous\nand asynchronous.","body":"Commonly Inter Process Communication primitives comes in the form of synchronous\nand asynchronous.\n\nIn Linux, IPC primitives allows implementing both, with blocking and\nnon-blocking FD operations. When you call `read` on a file descriptor that is\nblocking (`O_NONBLOCKING` not set), the the calling thread will be blocked (the\nthread is de-scheduled) until there is data inside the FD. For non-blocking\ncalls, `read` will simply return `EAGAIN`.\n\n## In Microkernels\n\nOn IPC-heavy system like microkenrels, the choice matters a lot. An IPC in the\nmicrokernel require a synchronous system call to switch to the microkernel,\nwhere the microkernel can schedule the target service [[i2blyo37]].\n\nSynchronous IPC are also better for the security, they may be made resistant to\nDOS attacks.\n\nHowever, the costs of synchronous IPC becomes a bottleneck in modern computing\nwith emphasis multiprocessing, which motivates modern optimization techniques\n[[i2blyo37]].","snippets":["Commonly Inter Process Communication primitives comes in the form of synchronous\nand asynchronous."],"rawContent":"# Asynchronous vs synchronous IPC\n\nCommonly Inter Process Communication primitives comes in the form of synchronous\nand asynchronous.\n\nIn Linux, IPC primitives allows implementing both, with blocking and\nnon-blocking FD operations. When you call `read` on a file descriptor that is\nblocking (`O_NONBLOCKING` not set), the the calling thread will be blocked (the\nthread is de-scheduled) until there is data inside the FD. For non-blocking\ncalls, `read` will simply return `EAGAIN`.\n\n## In Microkernels\n\nOn IPC-heavy system like microkenrels, the choice matters a lot. An IPC in the\nmicrokernel require a synchronous system call to switch to the microkernel,\nwhere the microkernel can schedule the target service [[i2blyo37]].\n\nSynchronous IPC are also better for the security, they may be made resistant to\nDOS attacks.\n\nHowever, the costs of synchronous IPC becomes a bottleneck in modern computing\nwith emphasis multiprocessing, which motivates modern optimization techniques\n[[i2blyo37]].\n","wordCount":145,"tags":[],"metadata":{},"created":"2024-12-16T03:56:49.135187363Z","modified":"2024-12-16T03:56:38.552223511Z","checksum":"a13d689e5331f7280b3c60043073a85ed4e4b2dc797e3ef1c98ce4225b2aff47"},
    {"filename":"36d79g1n.md","filenameStem":"36d79g1n","path":"36d79g1n.md","absPath":"/home/khadd/mynotes/36d79g1n.md","title":"Autarky: Closing controlled channels with self-paging enclaves","link":"[[36d79g1n]]","lead":"#literature #sgx #controlled-channel","body":"#literature #sgx #controlled-channel\n\n@orenbach2020autarky\n\n# Positioning\n\nThe paper's main argument against the previous work is that a _practical_\nsolution for the control channels for SGX must be backward compatible with\nexisting x86 software, and also the OS. Hence, solutions that employ two\nseparate page tables, such as [@aga2019invisipage], and [@costan2016sanctum] are\nnot practical as they require changes to even the host OS. On the other hand,\nother software-only defenses (at the time of the paper, there are @shih2017tsgx,\nand [@oleksenko2018varys]) restrict the usability as forbid demand paging, have\nhuge overheads, and are also susceptible to non-page-fault attacks that use the\ndirty bits [[1yhmh234]].\n\n## Non-intrusive hardware changes\n\nWhile introducing hardware changes, the work aims to do it in the least\nintrusive manner. It tries to _change only the same path that SGX's mechanisms\nchange in x86 architectures_. This includes (1) SGX-specific checks that are\nperformed after PTE checks during enclave mode, and (2) AEX page fault procedure\n([[taztx2mo]]).\n\nFor the above reason, the paper also argues against using separated enclave page\ntables, as used in many clean-slate designs for TEEs ([@costan2016sanctum]).\nSuch mechanisms (1) require complex collaborative page management between the\nhost OS and the enclave ([@aga2019invisipage]), (2) requires new protection to\nprevent the enclave from mapping arbitrary host memory, and (3) require\nsignificant changes to the performance-critical portions of the MMU (e.g., the\nMMU need to be changed to differentiate between normal state and enclave states,\nand use different page tables).\n\nThe paper suggests three small changes to the current SGX scheme. First, instead\nof just masking the page offset in AEX page faults, the entire address is masked\nso that it is invisible to the host.\n\nSecond, an additional flag is introduced in the TCS called the _pending\nexception flag_. The bit is set when there is a page fault occurs. `ERESUME`\nwill fail when this flag is set, and `EENTER` clears the flag. Hence, the OS is\nforced to use `EENTER` as a trusted enclave entry point that handles page\nfaults. This handler can use the SSA frame to determine if an exception has\noccurred, and take appropriate actions defined by the software, such as\nORAM-based paging. After, `EEXIT` passes the control back the the OS page fault\nhandler, which can now use `ERESUME`, since the pending exception flag is\ncleared. On the OS side, the EPC paging ISA (`EWB`, `ELDU`) can be used to\nperform enclave paging as normal.\n\n```\n  ┌────────────────────────────┐ ┌─────────────────────────────────┐\n  │ Set pending exception flag │ │ Check SSA frame to detect fault │\n  └────────────────────────────┘ └─────────────────────────────────┘\n                ▲                             ▲\n                │                             │\nEnclave      Page fault     ┌──────► Self-paging Runtime ────────┐       Fault handled\n                 │  AEX     │EENTER         │ ▲ Paging syscalls  │            ▲\n                 ▼          │  │            ▼ │                  │ EEXIT      │ ERESUME\nOS      Page fault handler ─┘  │    Autarky-aware syscalls       └─► Page fault handler\n                               ▼\n                  ┌─────────────────────────┐\n                  │ Unset pending exception │\n                  └─────────────────────────┘\n\n```\n\nThe paper also suggested a _fast path_ to omit the expensive context switching\nbetween enclave and OS (that includes TLB flushing): on a page fault, the CPU\nsaves the context to the SSA, increments the SSA stack, and automatically\nperforms enclave entry to the entry point.\n\nThird, to prevent the OS from using the dirty bit to infer page accesses, by\nadding a security check to _SGX-specific checks_ the PTE is fetched. The check\nsimply enforces that the access and dirty bit must be already set. This\nessentially renders these bits useless.\n\n_SUMMARY_: Together, these changes enable three properties: first, with the\nfaulting address hidden, all-natural page faults are hidden from the host.\nSecond, with the pending exception flag, all paging-related events must be\nnotified to the enclave, so that there are no unexpected page faults. Third, the\ndirty/access bit in the PTE is irrelevant to an enclave's memory access pattern.\n\n## Software components\n\nWith the above changes, page faults on the EPC pages are hidden from the host.\nHowever, it renders demand-paging impossible, since the host does not know about\nfaulting address. Autarky implements a _self-paging_ runtime on top of the\nGraphine-SGX library OS so that the enclave can directly request the host OS for\npaging operations.\n\nFirst, Autarky split pages into OS-managed pages and enclave-managed pages.\n\nFor the first type, the access patterns are not considered sensitive, so the\nmanagement of these pages is up to the OS. While it is not specified in the\npaper, maybe the paging runtime just forwards the faulting addresses of those\npages to the OS's page fault handler, so that the OS can use `EWB`/`ELDU` to\nswap these pages in/out.\n\nFor the second type, page faults on these pages are considered hostile (except\nfor the clustering and bounded leakage policiese), and the enclave may terminate\nthe execution when there are faults. Hence, the OS must make sure that these\npages are _memory-resident while the enclave is executing_. To reclaim these\npages, the only option for the OS is to _swap the entire enclave out_.\n\nOn enclave-managed pages, the enclave may perform _self-paging_ with the added\nsystem called `ay_fetch_pages` and `ay_evict_pages` that require the OS to\nfetch/evict a list of pages from/to the EPC memory.\n\nThree different policies are introduced that make use of the self-paging.\n\n### ORAM\n\nORAM policy enhanced the ORAM instrumentations used in [@orenbach2019cosmix]. In\nthe original, ever memory instruction is instrumented to perform an ORAM access.\nSince enclave-managed pages are protected from the host, the paper uses those\npages as a cache for ORAM. Hence, the new instrumentation looks for the page in\nthe cache first, before requesting expensive ORAM accesses.\n\nThis policy requires program instrumentations on memory access to perform ORAM\naccesses.\n\n### Clustering\n\nThe second policy clusters pages together so that a group of pages is always\nfetched and evicted together. On a fault, the runtime requests all pages in a\ncluster together. Clustering a group of pages hides the access pattern within a\ncluster.\n\nThis policy requires changes to the application to identify code/data pages that\nbelong to a cluster.\n\n### Rate-limiting\n\nThe final policy aims to support unmodified applications. It clusters the code\npages and introduces a page fault rate. Since there is no trusted clock inside\nthe enclave, the rate is calculated using other events instead. The authors\nsuggest using different rate metrics for each application; for example, page\nfault per socket received, or page fault per memory allocations.","snippets":["#literature #sgx #controlled-channel"],"rawContent":"# Autarky: Closing controlled channels with self-paging enclaves\n\n#literature #sgx #controlled-channel\n\n@orenbach2020autarky\n\n# Positioning\n\nThe paper's main argument against the previous work is that a _practical_\nsolution for the control channels for SGX must be backward compatible with\nexisting x86 software, and also the OS. Hence, solutions that employ two\nseparate page tables, such as [@aga2019invisipage], and [@costan2016sanctum] are\nnot practical as they require changes to even the host OS. On the other hand,\nother software-only defenses (at the time of the paper, there are @shih2017tsgx,\nand [@oleksenko2018varys]) restrict the usability as forbid demand paging, have\nhuge overheads, and are also susceptible to non-page-fault attacks that use the\ndirty bits [[1yhmh234]].\n\n## Non-intrusive hardware changes\n\nWhile introducing hardware changes, the work aims to do it in the least\nintrusive manner. It tries to _change only the same path that SGX's mechanisms\nchange in x86 architectures_. This includes (1) SGX-specific checks that are\nperformed after PTE checks during enclave mode, and (2) AEX page fault procedure\n([[taztx2mo]]).\n\nFor the above reason, the paper also argues against using separated enclave page\ntables, as used in many clean-slate designs for TEEs ([@costan2016sanctum]).\nSuch mechanisms (1) require complex collaborative page management between the\nhost OS and the enclave ([@aga2019invisipage]), (2) requires new protection to\nprevent the enclave from mapping arbitrary host memory, and (3) require\nsignificant changes to the performance-critical portions of the MMU (e.g., the\nMMU need to be changed to differentiate between normal state and enclave states,\nand use different page tables).\n\nThe paper suggests three small changes to the current SGX scheme. First, instead\nof just masking the page offset in AEX page faults, the entire address is masked\nso that it is invisible to the host.\n\nSecond, an additional flag is introduced in the TCS called the _pending\nexception flag_. The bit is set when there is a page fault occurs. `ERESUME`\nwill fail when this flag is set, and `EENTER` clears the flag. Hence, the OS is\nforced to use `EENTER` as a trusted enclave entry point that handles page\nfaults. This handler can use the SSA frame to determine if an exception has\noccurred, and take appropriate actions defined by the software, such as\nORAM-based paging. After, `EEXIT` passes the control back the the OS page fault\nhandler, which can now use `ERESUME`, since the pending exception flag is\ncleared. On the OS side, the EPC paging ISA (`EWB`, `ELDU`) can be used to\nperform enclave paging as normal.\n\n```\n  ┌────────────────────────────┐ ┌─────────────────────────────────┐\n  │ Set pending exception flag │ │ Check SSA frame to detect fault │\n  └────────────────────────────┘ └─────────────────────────────────┘\n                ▲                             ▲\n                │                             │\nEnclave      Page fault     ┌──────► Self-paging Runtime ────────┐       Fault handled\n                 │  AEX     │EENTER         │ ▲ Paging syscalls  │            ▲\n                 ▼          │  │            ▼ │                  │ EEXIT      │ ERESUME\nOS      Page fault handler ─┘  │    Autarky-aware syscalls       └─► Page fault handler\n                               ▼\n                  ┌─────────────────────────┐\n                  │ Unset pending exception │\n                  └─────────────────────────┘\n\n```\n\nThe paper also suggested a _fast path_ to omit the expensive context switching\nbetween enclave and OS (that includes TLB flushing): on a page fault, the CPU\nsaves the context to the SSA, increments the SSA stack, and automatically\nperforms enclave entry to the entry point.\n\nThird, to prevent the OS from using the dirty bit to infer page accesses, by\nadding a security check to _SGX-specific checks_ the PTE is fetched. The check\nsimply enforces that the access and dirty bit must be already set. This\nessentially renders these bits useless.\n\n_SUMMARY_: Together, these changes enable three properties: first, with the\nfaulting address hidden, all-natural page faults are hidden from the host.\nSecond, with the pending exception flag, all paging-related events must be\nnotified to the enclave, so that there are no unexpected page faults. Third, the\ndirty/access bit in the PTE is irrelevant to an enclave's memory access pattern.\n\n## Software components\n\nWith the above changes, page faults on the EPC pages are hidden from the host.\nHowever, it renders demand-paging impossible, since the host does not know about\nfaulting address. Autarky implements a _self-paging_ runtime on top of the\nGraphine-SGX library OS so that the enclave can directly request the host OS for\npaging operations.\n\nFirst, Autarky split pages into OS-managed pages and enclave-managed pages.\n\nFor the first type, the access patterns are not considered sensitive, so the\nmanagement of these pages is up to the OS. While it is not specified in the\npaper, maybe the paging runtime just forwards the faulting addresses of those\npages to the OS's page fault handler, so that the OS can use `EWB`/`ELDU` to\nswap these pages in/out.\n\nFor the second type, page faults on these pages are considered hostile (except\nfor the clustering and bounded leakage policiese), and the enclave may terminate\nthe execution when there are faults. Hence, the OS must make sure that these\npages are _memory-resident while the enclave is executing_. To reclaim these\npages, the only option for the OS is to _swap the entire enclave out_.\n\nOn enclave-managed pages, the enclave may perform _self-paging_ with the added\nsystem called `ay_fetch_pages` and `ay_evict_pages` that require the OS to\nfetch/evict a list of pages from/to the EPC memory.\n\nThree different policies are introduced that make use of the self-paging.\n\n### ORAM\n\nORAM policy enhanced the ORAM instrumentations used in [@orenbach2019cosmix]. In\nthe original, ever memory instruction is instrumented to perform an ORAM access.\nSince enclave-managed pages are protected from the host, the paper uses those\npages as a cache for ORAM. Hence, the new instrumentation looks for the page in\nthe cache first, before requesting expensive ORAM accesses.\n\nThis policy requires program instrumentations on memory access to perform ORAM\naccesses.\n\n### Clustering\n\nThe second policy clusters pages together so that a group of pages is always\nfetched and evicted together. On a fault, the runtime requests all pages in a\ncluster together. Clustering a group of pages hides the access pattern within a\ncluster.\n\nThis policy requires changes to the application to identify code/data pages that\nbelong to a cluster.\n\n### Rate-limiting\n\nThe final policy aims to support unmodified applications. It clusters the code\npages and introduces a page fault rate. Since there is no trusted clock inside\nthe enclave, the rate is calculated using other events instead. The authors\nsuggest using different rate metrics for each application; for example, page\nfault per socket received, or page fault per memory allocations.\n","wordCount":1057,"tags":["literature","sgx","controlled-channel"],"metadata":{},"created":"2024-05-22T08:24:03.226667589Z","modified":"2024-06-24T13:58:25.637801699Z","checksum":"172e5ab4ac65a28e75a19e6cbad74610ea93b34c741743e9e304e7aa1c2333cc"},
    {"filename":"mqnreqwk.md","filenameStem":"mqnreqwk","path":"mqnreqwk.md","absPath":"/home/khadd/mynotes/mqnreqwk.md","title":"Avoiding Failure in ORAM","link":"[[mqnreqwk]]","lead":"#oram","body":"#oram\n\nIn most ORAM algorithms, there is a chance of failure, due to the stash\noverflowing.\n\n## Reversed path eviction\n\nIn the eviction phase (Path ORAM and Ring ORAM), blocks are pushed to the tree\nin the reversed order, starting from the leaves, and ending at the root. The\nreason for intuition is that blocks at higher levels are more likely to\nintersect with another path, leading to higher chance the block is pushed to the\ntree.\n\nFor example, in a tree with 3 levels, nodes on the last level (leaf nodes)\ncorrespond to only one path. Nodes on the second level can be evicted on 2 paths\n(1 can be evicted on paths 0 and 1). Nodes on the first level can be evicted on\nany path.\n\n```none\n              0\n          1       2\n      3       4       5\n---------------------------\npath: 0       1       2\n```\n\n## Background Eviction\n\n[@ren2013design] proposed _background eviction_, which happens when the free\nslots in the stash becomes smaller than $Height*BucketSize$, i.e., the minimum\nfree blocks required in an ORAM access.\n\nDummy accesses are performed on random a path that read blocks into the stash,\nand opportunistically place blocks back into the tree. At worst, if the path is\nalready filled, or no blocks can be evicted from the stash, the path is simply\nwritten back to the tree.\n\nBackground eviction access pattern is identical to an ORAM access, so attackers\ncannot know when background eviction happens.","snippets":["#oram"],"rawContent":"# Avoiding Failure in ORAM\n\n#oram\n\nIn most ORAM algorithms, there is a chance of failure, due to the stash\noverflowing.\n\n## Reversed path eviction\n\nIn the eviction phase (Path ORAM and Ring ORAM), blocks are pushed to the tree\nin the reversed order, starting from the leaves, and ending at the root. The\nreason for intuition is that blocks at higher levels are more likely to\nintersect with another path, leading to higher chance the block is pushed to the\ntree.\n\nFor example, in a tree with 3 levels, nodes on the last level (leaf nodes)\ncorrespond to only one path. Nodes on the second level can be evicted on 2 paths\n(1 can be evicted on paths 0 and 1). Nodes on the first level can be evicted on\nany path.\n\n```none\n              0\n          1       2\n      3       4       5\n---------------------------\npath: 0       1       2\n```\n\n## Background Eviction\n\n[@ren2013design] proposed _background eviction_, which happens when the free\nslots in the stash becomes smaller than $Height*BucketSize$, i.e., the minimum\nfree blocks required in an ORAM access.\n\nDummy accesses are performed on random a path that read blocks into the stash,\nand opportunistically place blocks back into the tree. At worst, if the path is\nalready filled, or no blocks can be evicted from the stash, the path is simply\nwritten back to the tree.\n\nBackground eviction access pattern is identical to an ORAM access, so attackers\ncannot know when background eviction happens.\n","wordCount":242,"tags":["oram"],"metadata":{},"created":"2023-07-19T02:45:03.353432335Z","modified":"2024-06-28T08:09:16.359872121Z","checksum":"7ea11acdd980af22f11e852ae0b4937f20f0c32bcf7eeda7dfbfd45c607eea8d"},
    {"filename":"7y9mztkv.md","filenameStem":"7y9mztkv","path":"7y9mztkv.md","absPath":"/home/khadd/mynotes/7y9mztkv.md","title":"Bash cheatsheet","link":"[[7y9mztkv]]","lead":"## Working with paths","body":"## Working with paths\n\nA good practice is to always use absolute paths. Relative paths is messy and\nshould be avoided.\n\nThis can be achieved by having a common environment file set up before hand.\n\nAnother approach or to use a source ground truth that is always correct for the\ncurrent file.\n\n### Obtaining ground truth paths\n\nTo get location of current executing script\n\nGit location is another useful ground truth.\n\n```bash\nPROJ_ROOT=$(git rev-parse --show-toplevel)\n```\n\n## Functions\n\n### Arugments\n\nSpecial bash variable is used for some useful argument\n\n- Get all arguments as one: `${@}` or `${*}`\n- Number of arguments: `@{#}`\n\n## Conditions\n\n## Working with Processes\n\n### Tacking pid of background jobs\n\n`${!}` gives the ID of just-executed background process","snippets":["## Working with paths"],"rawContent":"# Bash cheatsheet\n\n## Working with paths\n\nA good practice is to always use absolute paths. Relative paths is messy and\nshould be avoided.\n\nThis can be achieved by having a common environment file set up before hand.\n\nAnother approach or to use a source ground truth that is always correct for the\ncurrent file.\n\n### Obtaining ground truth paths\n\nTo get location of current executing script\n\nGit location is another useful ground truth.\n\n```bash\nPROJ_ROOT=$(git rev-parse --show-toplevel)\n```\n\n## Functions\n\n### Arugments\n\nSpecial bash variable is used for some useful argument\n\n- Get all arguments as one: `${@}` or `${*}`\n- Number of arguments: `@{#}`\n\n## Conditions\n\n## Working with Processes\n\n### Tacking pid of background jobs\n\n`${!}` gives the ID of just-executed background process\n","wordCount":126,"tags":[],"metadata":{},"created":"2024-08-05T10:15:49.311152743Z","modified":"2024-08-05T10:22:28.710781626Z","checksum":"76e877bfaf0899547d6da34e8dc7813eaff13e239bdde469de4c05a3b43c3165"},
    {"filename":"doffw381.md","filenameStem":"doffw381","path":"doffw381.md","absPath":"/home/khadd/mynotes/doffw381.md","title":"Be a better writer","link":"[[doffw381]]","lead":"#area","body":"#area\n\n- [Tips about writing systems papers](https://www.linzhong.org/opinions/writing.html)\n  - General tips on writing system papers:\n    - Use structure and abstractions\n    - Be specific \u0026 concise","snippets":["#area"],"rawContent":"# Be a better writer\n\n#area\n\n- [Tips about writing systems papers](https://www.linzhong.org/opinions/writing.html)\n  - General tips on writing system papers:\n    - Use structure and abstractions\n    - Be specific \u0026 concise\n","wordCount":29,"tags":["area"],"metadata":{},"created":"2024-05-22T08:24:03.244431537Z","modified":"2024-12-24T06:51:53.33865749Z","checksum":"19bee2a21f2cb9a6683d64809b235e8fae253f90db9f7575e341aaae7b2fe09f"},
    {"filename":"n43kyyfh.md","filenameStem":"n43kyyfh","path":"n43kyyfh.md","absPath":"/home/khadd/mynotes/n43kyyfh.md","title":"Binary Rewriting is Hard","link":"[[n43kyyfh]]","lead":"Rewriting binaries is useful for security instrumentations, like CFI\n[@zhang2013control], randomization [@koo2018compilerassisted].","body":"Rewriting binaries is useful for security instrumentations, like CFI\n[@zhang2013control], randomization [@koo2018compilerassisted].\n\nTwo issues when modifying a compiled binary.\n\n- **Unintended instructions**: First, it might mess up the instruction\n  boundaries and lead to unintended instructions.\n- **Addressing**: If you insert additional code, the instruction address now\n  changes, which mess up existing IP-relative code.\n\n## Reassembling\n\nFor correct rewriting, a common approach is _reassembling_\n[@wang2015reassembleable]: perform rewriting on an intermediate representation,\nthan compile it back into a fresh binary/basic block. Still it is an error-prone\nprocess [@kim2023reassembly].\n\n## Control flow reconstruction\n\nYou may modify the binary layout for more flexible rewriting policies. However,\nnow you must also perform control-flow recovery, to cope with the changes in the\naddress space. This is a difficult problem in binary analysis [[fps6sygk]].\n\nMany techniques avoid this by leveraging probes-based binary rewriting\n[[4yeegysq]].\n\n## Probing\n\nRewriting that _poke_ / probe the binary code with other code does not change\nthe address layout, so is safe with PC-relative code. For example, Kprobes\n[[1mhpx5ds]] insert `int3` and `jmp` insertion to probe parts of the kernel.\n\nAlso, simple rewrite, e.g., absolute address replacement in absolute jumps\n[@ren2022dynamic], where target instruction has the same size and semantics of\nthe replaced instruction, are safe to be performed. Another example is to\nrewrite syscall instructions for hooking syscall [@yasukata2023zpoline].\nOccasions for simple rewrite are hard to come by and require expert analysis.\n\nTwo issues:\n\n1. **Overheads**: `int3` probes are slow, so `jmp` are much more desired.\n   However, `jmp` are 5-bytes, which may overwrite more instructions if the\n   probe target is smaller than 5. Instruction punning [[jejw1spb]] is a\n   technique to maximize the `jmp` probes.\n2. **Preserving original execution:** We must ensure that the probed (replaced)\n   instruction is correctly executed:\n   - If possible, the instruction should be single-stepped\n   - Certain instructions must be emulated if they cannot be single-stepped\n     properly.\n   - Other relative-addressing must have their PC relative adjusted\n3. **Multi-threading**: Probing on one thread leads to invalid execution on\n   other threads if they access partially-modified code. Stop-the-world is not\n   scalable, and dynamically probing code on-the-fly require careful\n   considerations [@chamith2016living].","snippets":["Rewriting binaries is useful for security instrumentations, like CFI\n[@zhang2013control], randomization [@koo2018compilerassisted]."],"rawContent":"# Binary Rewriting is Hard\n\nRewriting binaries is useful for security instrumentations, like CFI\n[@zhang2013control], randomization [@koo2018compilerassisted].\n\nTwo issues when modifying a compiled binary.\n\n- **Unintended instructions**: First, it might mess up the instruction\n  boundaries and lead to unintended instructions.\n- **Addressing**: If you insert additional code, the instruction address now\n  changes, which mess up existing IP-relative code.\n\n## Reassembling\n\nFor correct rewriting, a common approach is _reassembling_\n[@wang2015reassembleable]: perform rewriting on an intermediate representation,\nthan compile it back into a fresh binary/basic block. Still it is an error-prone\nprocess [@kim2023reassembly].\n\n## Control flow reconstruction\n\nYou may modify the binary layout for more flexible rewriting policies. However,\nnow you must also perform control-flow recovery, to cope with the changes in the\naddress space. This is a difficult problem in binary analysis [[fps6sygk]].\n\nMany techniques avoid this by leveraging probes-based binary rewriting\n[[4yeegysq]].\n\n## Probing\n\nRewriting that _poke_ / probe the binary code with other code does not change\nthe address layout, so is safe with PC-relative code. For example, Kprobes\n[[1mhpx5ds]] insert `int3` and `jmp` insertion to probe parts of the kernel.\n\nAlso, simple rewrite, e.g., absolute address replacement in absolute jumps\n[@ren2022dynamic], where target instruction has the same size and semantics of\nthe replaced instruction, are safe to be performed. Another example is to\nrewrite syscall instructions for hooking syscall [@yasukata2023zpoline].\nOccasions for simple rewrite are hard to come by and require expert analysis.\n\nTwo issues:\n\n1. **Overheads**: `int3` probes are slow, so `jmp` are much more desired.\n   However, `jmp` are 5-bytes, which may overwrite more instructions if the\n   probe target is smaller than 5. Instruction punning [[jejw1spb]] is a\n   technique to maximize the `jmp` probes.\n2. **Preserving original execution:** We must ensure that the probed (replaced)\n   instruction is correctly executed:\n   - If possible, the instruction should be single-stepped\n   - Certain instructions must be emulated if they cannot be single-stepped\n     properly.\n   - Other relative-addressing must have their PC relative adjusted\n3. **Multi-threading**: Probing on one thread leads to invalid execution on\n   other threads if they access partially-modified code. Stop-the-world is not\n   scalable, and dynamically probing code on-the-fly require careful\n   considerations [@chamith2016living].\n","wordCount":352,"tags":[],"metadata":{},"created":"2024-07-12T05:58:45.301890337Z","modified":"2024-07-12T08:00:38.632715231Z","checksum":"a8d5a8df7b038fd9630ee678841ef8063d6243bbf06c3602d3bcd9c591f2a0f6"},
    {"filename":"4yeegysq.md","filenameStem":"4yeegysq","path":"4yeegysq.md","absPath":"/home/khadd/mynotes/4yeegysq.md","title":"Binary Rewriting without Control-flow Recovery","link":"[[4yeegysq]]","lead":"#binary-analysis","body":"#binary-analysis\n\nMany rewriting approaches requires control-flow recovery to that they can\nrelocate RIP-relative code [[n43kyyfh]] to different locations. However, these\napproaches are not robust and require heuristics and assumptions. However,\ncontrol-flow recovery is generally undecidable [[fps6sygk]].\n\nA class of binary rewriting techniques focus on not using control-flow (sub\nfunction) recovery techniques for more robustness\n[@chamith2017instruction,@duck2020binary]. To this end, probe-based techniques,\nespecially instruction punning [[jejw1spb]] does not requires fine-grained\ncontrol-flow recovery since they do not modify the binary layout.","snippets":["#binary-analysis"],"rawContent":"# Binary Rewriting without Control-flow Recovery\n\n#binary-analysis\n\nMany rewriting approaches requires control-flow recovery to that they can\nrelocate RIP-relative code [[n43kyyfh]] to different locations. However, these\napproaches are not robust and require heuristics and assumptions. However,\ncontrol-flow recovery is generally undecidable [[fps6sygk]].\n\nA class of binary rewriting techniques focus on not using control-flow (sub\nfunction) recovery techniques for more robustness\n[@chamith2017instruction,@duck2020binary]. To this end, probe-based techniques,\nespecially instruction punning [[jejw1spb]] does not requires fine-grained\ncontrol-flow recovery since they do not modify the binary layout.\n","wordCount":84,"tags":["binary-analysis"],"metadata":{},"created":"2024-07-12T07:41:09.277528642Z","modified":"2024-07-22T01:59:58.377472883Z","checksum":"4be87aa91f48da5b57d2c6f66ce5555aa959d067061c9aac31c7df3d2a01b61c"},
    {"filename":"hxoovt97.md","filenameStem":"hxoovt97","path":"hxoovt97.md","absPath":"/home/khadd/mynotes/hxoovt97.md","title":"Binary disassembly","link":"[[hxoovt97]]","lead":"#binary","body":"#binary\n\nDisassembly is the process of analyzing a compiled binary, which consists of\nsequences of opcodes, into a list of known instructions with known semantics.\n\n## Techniques\n\nDisassembly may be performed through two techniques: (1) linear scan through the\ntext section of the program, or by (2) recursively disassembling while\nconstructing the control flow.\n\n### Linear scan\n\nLinear scan may be confused by _gaps_ in the program, e.g., paddings for\nalignment, [@zhang2013control], which it may incorrectly treat as instructions\n(e.g., unintended instruction problem [[kskzr2l4]]).\n\n### Recursive disassembly\n\nRecursive disassembly tries to reconstruct the control flow graph of the\nbinaries. On each new control flow transfer instructions, e.g., `call foo`, it\nadds the target (`foo`) to the list of identified entry list, and disassemble\nthe target.\n\nCaveats includes how to accurately determine indirect jump targets, and\nnon-explicit control flow transfers like interrupts [[kskzr2l4]].","snippets":["#binary"],"rawContent":"# Binary disassembly\n\n#binary\n\nDisassembly is the process of analyzing a compiled binary, which consists of\nsequences of opcodes, into a list of known instructions with known semantics.\n\n## Techniques\n\nDisassembly may be performed through two techniques: (1) linear scan through the\ntext section of the program, or by (2) recursively disassembling while\nconstructing the control flow.\n\n### Linear scan\n\nLinear scan may be confused by _gaps_ in the program, e.g., paddings for\nalignment, [@zhang2013control], which it may incorrectly treat as instructions\n(e.g., unintended instruction problem [[kskzr2l4]]).\n\n### Recursive disassembly\n\nRecursive disassembly tries to reconstruct the control flow graph of the\nbinaries. On each new control flow transfer instructions, e.g., `call foo`, it\nadds the target (`foo`) to the list of identified entry list, and disassemble\nthe target.\n\nCaveats includes how to accurately determine indirect jump targets, and\nnon-explicit control flow transfers like interrupts [[kskzr2l4]].\n","wordCount":145,"tags":["binary"],"metadata":{},"created":"2024-06-28T05:21:44.029921768Z","modified":"2024-12-13T08:46:06.420241342Z","checksum":"372747eb8bde5a8d747eca4fb070ff3d78741323404271cfb5d7ac235ff3ea7b"},
    {"filename":"lfyjdfv4.md","filenameStem":"lfyjdfv4","path":"lfyjdfv4.md","absPath":"/home/khadd/mynotes/lfyjdfv4.md","title":"Bit manipulation tricks","link":"[[lfyjdfv4]]","lead":"#programming #kernel #c #cxx","body":"#programming #kernel #c #cxx\n\n\n\n# Creating a mask with all N bit set\n```c\n#define mask(N) (1UL \u003c\u003c N) - 1\n```\nFor example, if N = 3, then the first shift will create ` 1000`. When subtracted by 1 bit, the result will be `111`\n\n# Checking if the Nth bit is set in a word\n\n```c\n#define check(word, N) (word \u0026 (1UL \u003c\u003c N))\n```\n# Clearing the Nth bit\n```c\n#define clear(word, N) (word \u0026 ~(1UL \u003c\u003c N))\n```\n# Check if a number is power of 2 \nThe key property is that if the number is the power of 2, it only has m bit set in the leftmost bit.\n```c\n#define is_power_of_2(n) ((n \u0026 (n - 1)) == 0)\n```","snippets":["#programming #kernel #c #cxx"],"rawContent":"# Bit manipulation tricks\n#programming #kernel #c #cxx\n\n\n\n# Creating a mask with all N bit set\n```c\n#define mask(N) (1UL \u003c\u003c N) - 1\n```\nFor example, if N = 3, then the first shift will create ` 1000`. When subtracted by 1 bit, the result will be `111`\n\n# Checking if the Nth bit is set in a word\n\n```c\n#define check(word, N) (word \u0026 (1UL \u003c\u003c N))\n```\n# Clearing the Nth bit\n```c\n#define clear(word, N) (word \u0026 ~(1UL \u003c\u003c N))\n```\n# Check if a number is power of 2 \nThe key property is that if the number is the power of 2, it only has m bit set in the leftmost bit.\n```c\n#define is_power_of_2(n) ((n \u0026 (n - 1)) == 0)\n```\n","wordCount":129,"tags":["programming","kernel","c","cxx"],"metadata":{},"created":"2023-07-07T04:18:00.556339409Z","modified":"2023-07-18T04:25:32.195948678Z","checksum":"4313c218c0b7504db9c206d496b2311930104e9d3632f7ac9e88f49247d3d54c"},
    {"filename":"1rqx4xia.md","filenameStem":"1rqx4xia","path":"1rqx4xia.md","absPath":"/home/khadd/mynotes/1rqx4xia.md","title":"Bits in page table entries","link":"[[1rqx4xia]]","lead":"#os #architecture","body":"#os #architecture\n\n\n# Present flag\nThe *present* flag indicates that there exists a backing physical frame for this page table entry. If the present bit is not set, a page fault will be triggered.\n\n\n# Access and dirty flags\nOn x86, bit 5 is the *accessed* flag, and bit 6 is the *dirty* flag.\n\nThe _accessed_ flag is set when a page is accessed by the CPU during address translation. The *dirty* flag is set when a page is written by the CPU. \n\nAfter being set, these flags need to be cleared by the software.\n\nThe dirty bit indicates that page must be written to the disk before the frame can be reused for other pages. Else, the page content is unchanged, so it is safe to reuse the page [standford-paging].\n\n# References\n- @2023intel\n- [standford-paging](https://web.stanford.edu/~ouster/cgi-bin/cs140-winter16/lecture.php?topic=paging)","snippets":["#os #architecture"],"rawContent":"# Bits in page table entries\n#os #architecture\n\n\n# Present flag\nThe *present* flag indicates that there exists a backing physical frame for this page table entry. If the present bit is not set, a page fault will be triggered.\n\n\n# Access and dirty flags\nOn x86, bit 5 is the *accessed* flag, and bit 6 is the *dirty* flag.\n\nThe _accessed_ flag is set when a page is accessed by the CPU during address translation. The *dirty* flag is set when a page is written by the CPU. \n\nAfter being set, these flags need to be cleared by the software.\n\nThe dirty bit indicates that page must be written to the disk before the frame can be reused for other pages. Else, the page content is unchanged, so it is safe to reuse the page [standford-paging].\n\n# References\n- @2023intel\n- [standford-paging](https://web.stanford.edu/~ouster/cgi-bin/cs140-winter16/lecture.php?topic=paging)\n","wordCount":143,"tags":["os","architecture"],"metadata":{},"created":"2023-07-20T08:50:44.822063007Z","modified":"2023-07-20T09:20:05.786649266Z","checksum":"d72e515f4683595e686ffd79b9de17de60fc9da1ecde62ce05d9883bbaaaa04d"},
    {"filename":"jj89s7vj.md","filenameStem":"jj89s7vj","path":"jj89s7vj.md","absPath":"/home/khadd/mynotes/jj89s7vj.md","title":"Bounce buffers","link":"[[jj89s7vj]]","lead":"Bounce buffers are buffers for bouncing data, e.g., containing parts of data\nthat must be isolated, commonly for security purposes.","body":"Bounce buffers are buffers for bouncing data, e.g., containing parts of data\nthat must be isolated, commonly for security purposes.\n\n## Confidential I/O\n\nIn CVMs, the host cannot freely access the guest memory, so the guest must\ncooperate in sharing I/O data. It achieve this by maintaining a region of shared\n(public) memory for bounce buffers (or SWIOTLB), to be used for shared data\nstructures, such as virtio descriptors/rings.\n\nThe guest's networking stack copies memory from its internal buffers into this\nbounce buffers's shared memory, and the host must map this memory into the\nhardware for DMA.\n\n## Containing untrusted devices\n\nCertain devices are commonly considered untrusted, e.g., USB. in the case of\nvirtualization, devices may also be configured to perform illegal actions by the\nVM [[3eot91og]].\n\nWhile IOMMU [[hxm4jt6e]] is useful in containing untrusted memory, it is\npage-granular ([@markuze2016true]), so the shared page with the device might\ncontain other kernel memory.\n\nThe solution is to create a temporary buffer and to share data with the device.\nOnly the necessary portion of the data is copied to this bounce buffer.\n\nMore:\n\n- \u003chttps://lore.kernel.org/linux-iommu/f416c0dc-a82b-f608-4c6a-c2441b417bfb@linux.intel.com/T/\u003e\n- \u003chttps://lwn.net/Articles/786558/\u003e\n- \u003chttps://docs.kernel.org/core-api/swiotlb.html\u003e\n\n## Overheads\n\nBounce buffering create redundant memory copies that reduce I/O performance.\nThis contributes to overheads in confidetial I/O [[68nms906]] and also\nvirtualized I/O [[3eot91og]].","snippets":["Bounce buffers are buffers for bouncing data, e.g., containing parts of data\nthat must be isolated, commonly for security purposes."],"rawContent":"# Bounce buffers\n\nBounce buffers are buffers for bouncing data, e.g., containing parts of data\nthat must be isolated, commonly for security purposes.\n\n## Confidential I/O\n\nIn CVMs, the host cannot freely access the guest memory, so the guest must\ncooperate in sharing I/O data. It achieve this by maintaining a region of shared\n(public) memory for bounce buffers (or SWIOTLB), to be used for shared data\nstructures, such as virtio descriptors/rings.\n\nThe guest's networking stack copies memory from its internal buffers into this\nbounce buffers's shared memory, and the host must map this memory into the\nhardware for DMA.\n\n## Containing untrusted devices\n\nCertain devices are commonly considered untrusted, e.g., USB. in the case of\nvirtualization, devices may also be configured to perform illegal actions by the\nVM [[3eot91og]].\n\nWhile IOMMU [[hxm4jt6e]] is useful in containing untrusted memory, it is\npage-granular ([@markuze2016true]), so the shared page with the device might\ncontain other kernel memory.\n\nThe solution is to create a temporary buffer and to share data with the device.\nOnly the necessary portion of the data is copied to this bounce buffer.\n\nMore:\n\n- \u003chttps://lore.kernel.org/linux-iommu/f416c0dc-a82b-f608-4c6a-c2441b417bfb@linux.intel.com/T/\u003e\n- \u003chttps://lwn.net/Articles/786558/\u003e\n- \u003chttps://docs.kernel.org/core-api/swiotlb.html\u003e\n\n## Overheads\n\nBounce buffering create redundant memory copies that reduce I/O performance.\nThis contributes to overheads in confidetial I/O [[68nms906]] and also\nvirtualized I/O [[3eot91og]].\n","wordCount":215,"tags":[],"metadata":{},"created":"2024-12-02T08:49:23.931428811Z","modified":"2024-12-11T10:25:49.596201431Z","checksum":"e066d1fbf9554e4b6315377ba974e57ce2c342134e1f3318993997168b1e8389"},
    {"filename":"q06rtkof.md","filenameStem":"q06rtkof","path":"q06rtkof.md","absPath":"/home/khadd/mynotes/q06rtkof.md","title":"Branch Prediction","link":"[[q06rtkof]]","lead":"#architecture","body":"#architecture\n\nIn CPU architectures, branch prediction is an optimization that allows the CPU\nto skip the instruction pipeline on certain indirect/conditional jumps\ninstructions. It does so by predicting the likely outcome of the jump target\nusing data from the previous execution.\n\nModern processor uses a Branch Target Buffer (BTB) structure to cache the recent\njump results for prediction.\n\n```asm\n                           Branch Target Buffer\n                                                                       correct\n                           | IP    | Target |                            ┌─► commit\n0xa00: jmp [eax] ┬────────►| 0xa00 | 0xd00  |── speculative execution ───┤   results\n                 │         | 0xd00 | 0xf00  |           ▲                │\n                 │                                      │                └─► revert\n                 │                                      │ actual       incorrect\n                 └───►  CPU pipeline (slow) ────────────┘ target\n\n\n```\n\nReturn instruction is also a type of indirect jump, as its target reles on the\ninstruction on the stack. The CPU keeps a separated mechanism called the Return\nStack Buffer (RSB) that is similar to the BTB to track the target of return\nvalues.\n\nThe above naive BTB implementation probably cause a lot of misprediction since\nit does not care about certain branch patterns, e.g., if taken vs. not taken\npattern is 0101, it would always mispredict. Modern CPUs additionally includes\nsome ways to make up for program patterns.\n\nEarly processors like the P1 [@fog2016microarchitecture] includes a Saturating\nCounter in the BTB.\n\nLater processors use a more complecated method of pattern matching. They\nadditionally keep a Pattern History Table that map certain branching pattern to\nthe next likely outcome. For example, the BTB might maintain a branch's history\nas 0101. The branch prediction unit use this pattern to look up the pattern\nhistory table to predict the likely conditional results, e.g., 1. This result is\ncombined with the target value in the BTB to predict the next instruction (the\nfollowing instruction or the one in the BTB).\n\n```asm\n| IP   | Target | Branch History |\n| ---- | ------ | -------------- |\n| 0xab | 0xcd   | 1100           |\n| 0xcd | 0xef   | 0101           |\n         │         │\n         └─────────┼───────────────────────────┬──► Prediction\n                   │                           │\n                   │    | Pattern | Output |   │\n                   │    | ------- | ------ |   │\n                   └───►| 0101    | 0      |───┘\n                        | 1100    | 1      |\n```\n\n## Security Issues\n\nSpectre attacks shows that branch predictor might be mistrained such that\nspeculative execution is performed incorrectly [@kocher2019spectre","snippets":["#architecture"],"rawContent":"# Branch Prediction\n\n#architecture\n\nIn CPU architectures, branch prediction is an optimization that allows the CPU\nto skip the instruction pipeline on certain indirect/conditional jumps\ninstructions. It does so by predicting the likely outcome of the jump target\nusing data from the previous execution.\n\nModern processor uses a Branch Target Buffer (BTB) structure to cache the recent\njump results for prediction.\n\n```asm\n                           Branch Target Buffer\n                                                                       correct\n                           | IP    | Target |                            ┌─► commit\n0xa00: jmp [eax] ┬────────►| 0xa00 | 0xd00  |── speculative execution ───┤   results\n                 │         | 0xd00 | 0xf00  |           ▲                │\n                 │                                      │                └─► revert\n                 │                                      │ actual       incorrect\n                 └───►  CPU pipeline (slow) ────────────┘ target\n\n\n```\n\nReturn instruction is also a type of indirect jump, as its target reles on the\ninstruction on the stack. The CPU keeps a separated mechanism called the Return\nStack Buffer (RSB) that is similar to the BTB to track the target of return\nvalues.\n\nThe above naive BTB implementation probably cause a lot of misprediction since\nit does not care about certain branch patterns, e.g., if taken vs. not taken\npattern is 0101, it would always mispredict. Modern CPUs additionally includes\nsome ways to make up for program patterns.\n\nEarly processors like the P1 [@fog2016microarchitecture] includes a Saturating\nCounter in the BTB.\n\nLater processors use a more complecated method of pattern matching. They\nadditionally keep a Pattern History Table that map certain branching pattern to\nthe next likely outcome. For example, the BTB might maintain a branch's history\nas 0101. The branch prediction unit use this pattern to look up the pattern\nhistory table to predict the likely conditional results, e.g., 1. This result is\ncombined with the target value in the BTB to predict the next instruction (the\nfollowing instruction or the one in the BTB).\n\n```asm\n| IP   | Target | Branch History |\n| ---- | ------ | -------------- |\n| 0xab | 0xcd   | 1100           |\n| 0xcd | 0xef   | 0101           |\n         │         │\n         └─────────┼───────────────────────────┬──► Prediction\n                   │                           │\n                   │    | Pattern | Output |   │\n                   │    | ------- | ------ |   │\n                   └───►| 0101    | 0      |───┘\n                        | 1100    | 1      |\n```\n\n## Security Issues\n\nSpectre attacks shows that branch predictor might be mistrained such that\nspeculative execution is performed incorrectly [@kocher2019spectre\n","wordCount":376,"tags":["architecture"],"metadata":{},"created":"2024-07-22T04:47:56.66188191Z","modified":"2024-07-23T06:54:00.239867197Z","checksum":"0e9e6c35410b37e7af8f5ca507ba4f9c427fff60bbef8ab649d5afef05947a4c"},
    {"filename":"fhvrh4ka.md","filenameStem":"fhvrh4ka","path":"fhvrh4ka.md","absPath":"/home/khadd/mynotes/fhvrh4ka.md","title":"Branch space randomization","link":"[[fhvrh4ka]]","lead":"#project","body":"#project\n\nThe idea is to randomize the space of branch expressions at every program launch\nto make attack relying on bypassing authorization checks (e.g., is_admin) much\nharder.\n\nExample 1:\n\n```c\nif (flag | IS_ADMIN /* != 0 */) {\n  // allow something\n} else {\n  // authorization failure\n}\n```\n\nExample 2:\n\n```c\nif (is_admin /* != 0 */) {\n  // allow something\n} else { /* is_admin == 0 */\n  // authorization failure\n}\n```\n\nNow, imagine 0 is randomized\n\n```c\n/* Keeping the original condition, just changing the static. */\nif (is_admin /* != -1337 */) {\n  // allow something\n} else { /* is_addmin == -1337 */\n  // authorization failure\n}\n```\n\nBefore, the attacker only needs to overwrite it with a random value (not 0).\nNow, the attacker need to make a guess of what 0 is mapped to, then choose a\nvalue that is not this value. Though, selecting a value that bypass this\ncondition is not hard.\n\nIt is evidence that we must also change the _branch condition_ too.\n\n```c\n/* Changing both condition and the static value.*/\nif (is_admin /* == -1337 */) {\n  // allow something\n} else { /* is_addmin != -1337 */\n  // authorization failure\n}\n```\n\nGuideline 1:\n\n1. Use exact comparison (deny-first) instead of bitwise.\n\nNow, it is much more challenging to the attacker. He must make a guess 1 out of\nall possible integer values. Let's call this process \"branch narrowing\". The\ncondition for branch narrowing while preserving program semantic:\n\n- Simple branch: Branch can be resolved through a simple static value.\n\n- How do we know which branch should be narrowed?\n  - Maybe through a set of heuristics, e.g., syscall access, libc calls.\n\n## Challenges\n\nThe two main challenges:\n\n- Entropy. The constant value space is often limited (e.g., the integer range\n  from 0-100). Applying a simple mapping of `0-\u003e1337` throughout program\n  execution probably provide limited benefits, e.g., the attacker only need to\n  make one guess to break the entire system.\n\n  - Fine-grained specialization techniques might is needed.\n  - Another approach is to have runtime rerandomization.\n\n- Handling random arithmetic.\n\n```\n\n```","snippets":["#project"],"rawContent":"# Branch space randomization\n\n#project\n\nThe idea is to randomize the space of branch expressions at every program launch\nto make attack relying on bypassing authorization checks (e.g., is_admin) much\nharder.\n\nExample 1:\n\n```c\nif (flag | IS_ADMIN /* != 0 */) {\n  // allow something\n} else {\n  // authorization failure\n}\n```\n\nExample 2:\n\n```c\nif (is_admin /* != 0 */) {\n  // allow something\n} else { /* is_admin == 0 */\n  // authorization failure\n}\n```\n\nNow, imagine 0 is randomized\n\n```c\n/* Keeping the original condition, just changing the static. */\nif (is_admin /* != -1337 */) {\n  // allow something\n} else { /* is_addmin == -1337 */\n  // authorization failure\n}\n```\n\nBefore, the attacker only needs to overwrite it with a random value (not 0).\nNow, the attacker need to make a guess of what 0 is mapped to, then choose a\nvalue that is not this value. Though, selecting a value that bypass this\ncondition is not hard.\n\nIt is evidence that we must also change the _branch condition_ too.\n\n```c\n/* Changing both condition and the static value.*/\nif (is_admin /* == -1337 */) {\n  // allow something\n} else { /* is_addmin != -1337 */\n  // authorization failure\n}\n```\n\nGuideline 1:\n\n1. Use exact comparison (deny-first) instead of bitwise.\n\nNow, it is much more challenging to the attacker. He must make a guess 1 out of\nall possible integer values. Let's call this process \"branch narrowing\". The\ncondition for branch narrowing while preserving program semantic:\n\n- Simple branch: Branch can be resolved through a simple static value.\n\n- How do we know which branch should be narrowed?\n  - Maybe through a set of heuristics, e.g., syscall access, libc calls.\n\n## Challenges\n\nThe two main challenges:\n\n- Entropy. The constant value space is often limited (e.g., the integer range\n  from 0-100). Applying a simple mapping of `0-\u003e1337` throughout program\n  execution probably provide limited benefits, e.g., the attacker only need to\n  make one guess to break the entire system.\n\n  - Fine-grained specialization techniques might is needed.\n  - Another approach is to have runtime rerandomization.\n\n- Handling random arithmetic.\n\n```\n\n```\n","wordCount":360,"tags":["project"],"metadata":{},"created":"2024-12-16T06:23:46.10688405Z","modified":"2024-12-16T07:32:57.025583106Z","checksum":"fd18381c5c4a7105d41fd1fcde48d447b3216c8f813a7d4eaeb939a4ea6d2903"},
    {"filename":"mwf41frv.md","filenameStem":"mwf41frv","path":"mwf41frv.md","absPath":"/home/khadd/mynotes/mwf41frv.md","title":"C programming notes","link":"[[mwf41frv]]","lead":"#programming #c #cxx","body":"#programming #c #cxx\n\n- [[lfyjdfv4]]","snippets":["#programming #c #cxx"],"rawContent":"# C programming notes\n#programming #c #cxx\n\n- [[lfyjdfv4]]\n\n\n","wordCount":9,"tags":["programming","c","cxx"],"metadata":{},"created":"2023-07-12T06:13:13.195027243Z","modified":"2024-05-22T08:23:40.666608407Z","checksum":"86db599502391877a0b4a39849b1e6be03ebc69b624a877d5e3fc2583940870f"},
    {"filename":"zw0lj520.md","filenameStem":"zw0lj520","path":"zw0lj520.md","absPath":"/home/khadd/mynotes/zw0lj520.md","title":"CAP-VMs: Capability-Based Isolation and Sharing in the Cloud","link":"[[zw0lj520]]","lead":"#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]","body":"#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]\n\n## One sentence summary\n\nThe paper built a container-like isolation abstraction on top of CHERI\narchitecture for efficient sharing on and isolation.\n\n## Context\n\n### Containers vs. Virtual machines\n\nContainers and Virtual machines both have disadvantages for implementing\nisolation and sharing. See [[h3manv25]].\n\n### Capabilities\n\nCheri capabilities enable in-process compartmentalization with the hybrid\ncapability model.\n\n### Contributions\n\nThis paper proposed the best of both world with CHERI capabilities: _cVM_, new\nVM-like abstraction for cloud isolation with efficient, single-address space\nsharing.\n\n- Communication between cVMs bypass the OS with new in-process capabilities\n  abstractions for trusted safe ipc.\n- Compatible with existing applications with the _hybrid_ capability model. Only\n  a subset of libC, the library OS, and the intravisor need to be\n  capability-aware.\n- No namespace isolation is required, since the isolation boundary is in-process\n  through capabilities. The OS is only needed for I/O, synchronization,\n  execution context (similar to a VM).\n\n## System overview\n\nThe system introduces 2 layers of isolation. A _library OS_ provides namespace\nisolation for and provides OS primitives for the cVMs. An _intravisor_ manage\ncVMs instances, enable cross-communication and other primitives.\n\nThe program interacts with the libOS through the syscall interface provided by\nthe musl libc. LibOS interact with intravisor through hostcall interface. Both\ninterfaces are capability-ware.\n\n## APIs\n\nA set of APIs is provided to manage cVM and facilitate their communications.\n\nCP_FILE-based interfaces enable file-like access to other cVM memory through\ncapability invocation. A cVM registers shared memory to be shared across other\ncVMs with a key. Other cVMs read and write into the CP-FILE obtained with the\nsame key.\n\nCP_CALL-based interfaces allows for capability-based registration and invocation\nof external functions.\n\n## Capability management\n\nThe system revoke CAP_STORE from capabilities, preventing them from being stored\ninto memory outside of the intra.","snippets":["#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]"],"rawContent":"# CAP-VMs: Capability-Based Isolation and Sharing in the Cloud\n\n#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]\n\n## One sentence summary\n\nThe paper built a container-like isolation abstraction on top of CHERI\narchitecture for efficient sharing on and isolation.\n\n## Context\n\n### Containers vs. Virtual machines\n\nContainers and Virtual machines both have disadvantages for implementing\nisolation and sharing. See [[h3manv25]].\n\n### Capabilities\n\nCheri capabilities enable in-process compartmentalization with the hybrid\ncapability model.\n\n### Contributions\n\nThis paper proposed the best of both world with CHERI capabilities: _cVM_, new\nVM-like abstraction for cloud isolation with efficient, single-address space\nsharing.\n\n- Communication between cVMs bypass the OS with new in-process capabilities\n  abstractions for trusted safe ipc.\n- Compatible with existing applications with the _hybrid_ capability model. Only\n  a subset of libC, the library OS, and the intravisor need to be\n  capability-aware.\n- No namespace isolation is required, since the isolation boundary is in-process\n  through capabilities. The OS is only needed for I/O, synchronization,\n  execution context (similar to a VM).\n\n## System overview\n\nThe system introduces 2 layers of isolation. A _library OS_ provides namespace\nisolation for and provides OS primitives for the cVMs. An _intravisor_ manage\ncVMs instances, enable cross-communication and other primitives.\n\nThe program interacts with the libOS through the syscall interface provided by\nthe musl libc. LibOS interact with intravisor through hostcall interface. Both\ninterfaces are capability-ware.\n\n## APIs\n\nA set of APIs is provided to manage cVM and facilitate their communications.\n\nCP_FILE-based interfaces enable file-like access to other cVM memory through\ncapability invocation. A cVM registers shared memory to be shared across other\ncVMs with a key. Other cVMs read and write into the CP-FILE obtained with the\nsame key.\n\nCP_CALL-based interfaces allows for capability-based registration and invocation\nof external functions.\n\n## Capability management\n\nThe system revoke CAP_STORE from capabilities, preventing them from being stored\ninto memory outside of the intra.\n","wordCount":312,"tags":["literature","ipc","capabilities","vm","container","os","cheri","libos"],"metadata":{},"created":"2024-05-22T08:24:03.315807763Z","modified":"2024-06-18T10:20:12.785302166Z","checksum":"12af0359fbee28f55d3539cc0ae8df016d12b271fbe9e38d459292f5efbf01bb"},
    {"filename":"khi9ihj9.md","filenameStem":"khi9ihj9","path":"khi9ihj9.md","absPath":"/home/khadd/mynotes/khi9ihj9.md","title":"Capabilities","link":"[[khi9ihj9]]","lead":"Capabilities","body":"Capabilities\n\n## Why capabilities exists\n\nThe capability model enable two properties in systems\n\n- Flexibility of systems policies [[c4icaua4]] through separation of mechanism\n  and policies [[8113ygxd]]. That is, the reference monitor only needs to\n  validate the references using simple mechanisms. The policies themselves are\n  embedded in the capabilities.\n- Avoid the problem of confused deputy [[y9wu5ut7]]. In a capability system, all\n  subjects must be explicitly given the access rights, so that there is no\n  _ambient authorities_.\n\n## More\n\n- [Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes\n  of capabilities by [[j19hdkto]] himself.\n- Eros [@shapiro1999eros] is one of the first application of capability for\n  kernel access control, which laid the foundation for modern microkernels\n  [@klein2009sel4]\n- [[y0z8fhtd]]","snippets":["Capabilities"],"rawContent":"# Capabilities\n\nCapabilities\n\n## Why capabilities exists\n\nThe capability model enable two properties in systems\n\n- Flexibility of systems policies [[c4icaua4]] through separation of mechanism\n  and policies [[8113ygxd]]. That is, the reference monitor only needs to\n  validate the references using simple mechanisms. The policies themselves are\n  embedded in the capabilities.\n- Avoid the problem of confused deputy [[y9wu5ut7]]. In a capability system, all\n  subjects must be explicitly given the access rights, so that there is no\n  _ambient authorities_.\n\n## More\n\n- [Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes\n  of capabilities by [[j19hdkto]] himself.\n- Eros [@shapiro1999eros] is one of the first application of capability for\n  kernel access control, which laid the foundation for modern microkernels\n  [@klein2009sel4]\n- [[y0z8fhtd]]\n","wordCount":117,"tags":[],"metadata":{},"created":"2024-12-12T05:40:10.526778569Z","modified":"2024-12-23T05:39:08.113846619Z","checksum":"c59698393cd1da4ddcc52840a7eccbe3d8b3d425a0508f092c63edb20f608300"},
    {"filename":"kskzr2l4.md","filenameStem":"kskzr2l4","path":"kskzr2l4.md","absPath":"/home/khadd/mynotes/kskzr2l4.md","title":"Challenges in binary analysis","link":"[[kskzr2l4]]","lead":"#binary-analysis","body":"#binary-analysis\n\n## What is hard?\n\n- Binary code is not easy [@meng2016binary]\n- Ground truth for binary disassembly is not easy [@pang2022ground]\n- Reassembly is hard [@kim2023reassembly]\n- Binary rewriting is hard [[n43kyyfh]]\n- Disassembly is hard [[fps6sygk]]\n\n## References\n\n- [@zhang2013control], [@priyadarshan2023safer], [@sang2024airtaint]\n- [@pang2021sok,@shoshitaishvili2016sok]","snippets":["#binary-analysis"],"rawContent":"# Challenges in binary analysis\n\n#binary-analysis\n\n## What is hard?\n\n- Binary code is not easy [@meng2016binary]\n- Ground truth for binary disassembly is not easy [@pang2022ground]\n- Reassembly is hard [@kim2023reassembly]\n- Binary rewriting is hard [[n43kyyfh]]\n- Disassembly is hard [[fps6sygk]]\n\n## References\n\n- [@zhang2013control], [@priyadarshan2023safer], [@sang2024airtaint]\n- [@pang2021sok,@shoshitaishvili2016sok]\n","wordCount":51,"tags":["binary-analysis"],"metadata":{},"created":"2024-06-22T13:43:58.744364116Z","modified":"2024-12-13T08:46:27.28364682Z","checksum":"d92b033ea41c2b562e0957f39100921ea25b7c0e5b4a3d3ba2d97be652fd8732"},
    {"filename":"3npwjx2c.md","filenameStem":"3npwjx2c","path":"3npwjx2c.md","absPath":"/home/khadd/mynotes/3npwjx2c.md","title":"Changing Linux build flags","link":"[[3npwjx2c]]","lead":"#area #linux","body":"#area #linux\n\nBuild errors are probably from using a newer GCC version than intended.\n\nErrors can be shut up by changing kernel build flag inside\n`tools/lib/subcmd/Makefile`\n\n```\nCFLAGS := -ggdb3 -Wall -Wextra -std=gnu99 -fPIC\n```\n\n\u003chttps://unix.stackexchange.com/questions/709671/linux-kernel-5-15-54-compilation-errors-with-gcc-12-1\u003e","snippets":["#area #linux"],"rawContent":"# Changing Linux build flags\n\n#area #linux\n\nBuild errors are probably from using a newer GCC version than intended.\n\nErrors can be shut up by changing kernel build flag inside\n`tools/lib/subcmd/Makefile`\n\n```\nCFLAGS := -ggdb3 -Wall -Wextra -std=gnu99 -fPIC\n```\n\n\u003chttps://unix.stackexchange.com/questions/709671/linux-kernel-5-15-54-compilation-errors-with-gcc-12-1\u003e\n","wordCount":41,"tags":["linux","area"],"metadata":{},"created":"2024-05-21T12:08:22.43336346Z","modified":"2024-06-20T08:59:53.936164422Z","checksum":"13cbd37d666ed793330481ef6b73ce9a0aa62a57b38b1d6d3d6ac1ece2d36088"},
    {"filename":"x9zetwej.md","filenameStem":"x9zetwej","path":"x9zetwej.md","absPath":"/home/khadd/mynotes/x9zetwej.md","title":"Code-centric vs. Data-centric Compartmentalization","link":"[[x9zetwej]]","lead":"#compartmentalization","body":"#compartmentalization\n\nFor the selection of compartmentalization subjects (a part of defining\ncompartmentalization policy [[7r5okim8]]), the strategies can be broadly\nclassified into three types, _data-centric_ and _code-centric_ and _hybrid_\n[@lefeuvre2024sok].\n\n- Code-centric approaches treat the code (instructions, functions) as the\n  subject of compartmentalization. Any input data results in the policies. E.g.,\n  libjpeg is known to be buggy, so all of its code must be in a separated\n  compartment\n- Data-centric approaches starts from the data (resource) and select code unit\n  that interacts with such data as the subject. Since pieces of data have\n  _lifetime_ (e.g., network packets), this results in the selection of subject\n  having _temporal_ property. E.g., the code that interacts with network packets\n  must be isolated.\n  - [@lefeuvre2024sok] noted that this model blends well with the process/thread\n    model, e.g., isolated threads are spawned to process a specific packet.\n- Hybrid approaches combine the two, akin to object-oriented programming. E.g.,\n  capability systems like CHERI allows the subject of isolation to be both data\n  and code.\n\n## When to use which\n\n- Code-centric is better when the source of distrust can be directed toward a\n  specific piece of code.\n- Data-centric is better on programs that either\n  - Handle multiple information flows, e.g., same code accessing both trusted\n    and untrusted components.lefeuvre2024sok\n  - Source of distrust can be directed toward a source of input (i.e., network\n    packets, stdin).\n- Hybrid approach, well, achieves a the mix of the two.","snippets":["#compartmentalization"],"rawContent":"# Code-centric vs. Data-centric Compartmentalization\n\n#compartmentalization\n\nFor the selection of compartmentalization subjects (a part of defining\ncompartmentalization policy [[7r5okim8]]), the strategies can be broadly\nclassified into three types, _data-centric_ and _code-centric_ and _hybrid_\n[@lefeuvre2024sok].\n\n- Code-centric approaches treat the code (instructions, functions) as the\n  subject of compartmentalization. Any input data results in the policies. E.g.,\n  libjpeg is known to be buggy, so all of its code must be in a separated\n  compartment\n- Data-centric approaches starts from the data (resource) and select code unit\n  that interacts with such data as the subject. Since pieces of data have\n  _lifetime_ (e.g., network packets), this results in the selection of subject\n  having _temporal_ property. E.g., the code that interacts with network packets\n  must be isolated.\n  - [@lefeuvre2024sok] noted that this model blends well with the process/thread\n    model, e.g., isolated threads are spawned to process a specific packet.\n- Hybrid approaches combine the two, akin to object-oriented programming. E.g.,\n  capability systems like CHERI allows the subject of isolation to be both data\n  and code.\n\n## When to use which\n\n- Code-centric is better when the source of distrust can be directed toward a\n  specific piece of code.\n- Data-centric is better on programs that either\n  - Handle multiple information flows, e.g., same code accessing both trusted\n    and untrusted components.lefeuvre2024sok\n  - Source of distrust can be directed toward a source of input (i.e., network\n    packets, stdin).\n- Hybrid approach, well, achieves a the mix of the two.\n","wordCount":242,"tags":["compartmentalization"],"metadata":{},"created":"2024-11-22T05:20:06.159745295Z","modified":"2024-12-16T03:56:38.552223511Z","checksum":"ff81bd762ebc1f88398f5cbc9b386a469a417681484e1241c037b781ba925ca3"},
    {"filename":"lqni89fq.md","filenameStem":"lqni89fq","path":"lqni89fq.md","absPath":"/home/khadd/mynotes/lqni89fq.md","title":"Commonplace notebook","link":"[[lqni89fq]]","lead":"A commonplace notebook is a notebook used to collect _external_ sources. This\ncontrasts with a diary, or a journal where you log your _internal_ thinking.","body":"A commonplace notebook is a notebook used to collect _external_ sources. This\ncontrasts with a diary, or a journal where you log your _internal_ thinking.\n\nMost of what you want to log in the commonplace note are quotations [[amyz6o6h]]","snippets":["A commonplace notebook is a notebook used to collect _external_ sources. This\ncontrasts with a diary, or a journal where you log your _internal_ thinking."],"rawContent":"# Commonplace notebook\n\nA commonplace notebook is a notebook used to collect _external_ sources. This\ncontrasts with a diary, or a journal where you log your _internal_ thinking.\n\nMost of what you want to log in the commonplace note are quotations [[amyz6o6h]]\n","wordCount":42,"tags":[],"metadata":{},"created":"2024-12-04T05:37:50.966683597Z","modified":"2024-12-04T05:39:40.385727158Z","checksum":"3ff69320adfa958a258ab50c550fbe0bcf43699eb6762494c8ce22dad60a3cbc"},
    {"filename":"douswvq0.md","filenameStem":"douswvq0","path":"douswvq0.md","absPath":"/home/khadd/mynotes/douswvq0.md","title":"Compartment-aware hardening","link":"[[douswvq0]]","lead":"#fleeting #idea","body":"#fleeting #idea\n\n## Background\n\nSoftware defenses such as DFI/CPI/CFI see the program at one unit.\n\nEfforts in compartmentalization brings the boundary to within the program.\n\n## Main arguments\n\nExisting software hardening techniques are not compartment-aware, so they miss\nclasses of attacks on compartment interfaces.\n\nMaking them compartment-aware requires some static / runtime analysis at the\nboundary.\n\n## Compartment-aware CFI\n\nCFI type matching + compartment-aware narrowing for cross-compartment indirect\ncalls e.g., A site can only call type B from compartment X.\n\n## Compartment-aware DFI\n\nAssuming data isolation between domains. DFI only for cross-domain objects.\n\n- Use static analysis to determine subset of sensitive objects.\n- We enforce DFI on them.\n\nThis has sanitizing effect, remove CIV.","snippets":["#fleeting #idea"],"rawContent":"# Compartment-aware hardening\n\n#fleeting #idea\n\n## Background\n\nSoftware defenses such as DFI/CPI/CFI see the program at one unit.\n\nEfforts in compartmentalization brings the boundary to within the program.\n\n## Main arguments\n\nExisting software hardening techniques are not compartment-aware, so they miss\nclasses of attacks on compartment interfaces.\n\nMaking them compartment-aware requires some static / runtime analysis at the\nboundary.\n\n## Compartment-aware CFI\n\nCFI type matching + compartment-aware narrowing for cross-compartment indirect\ncalls e.g., A site can only call type B from compartment X.\n\n## Compartment-aware DFI\n\nAssuming data isolation between domains. DFI only for cross-domain objects.\n\n- Use static analysis to determine subset of sensitive objects.\n- We enforce DFI on them.\n\nThis has sanitizing effect, remove CIV.\n","wordCount":118,"tags":["fleeting","idea"],"metadata":{},"created":"2024-05-23T06:27:21.347230161Z","modified":"2024-06-28T08:18:34.552272542Z","checksum":"dd0909d8fb8eb137903b4fc3c779823faae5b118a5547c6bd98fae1187bbf9e4"},
    {"filename":"68nms906.md","filenameStem":"68nms906","path":"68nms906.md","absPath":"/home/khadd/mynotes/68nms906.md","title":"Confidential I/O Taxes","link":"[[68nms906]]","lead":"#tee #os #io","body":"#tee #os #io\n\nThere are overheads for using I/O in TEEs due to several factors.\n\n## CVMs\n\nI/O in CVMs are predominantly performed through the `virtio` paravirtualized\ndrivers due to its performance [@li2023bifrost].\n\nEven then, there are certain \"taxes\" that slow down the I/O performance in CVMs.\n\n### Bounce buffering\n\nSince the host cannot directly access the private memory of the CVM, bounce\nbuffers located in shared memory [[jj89s7vj]] must be maintained by the _guest_.\nTo send any packets to the hardware, the guest must copy the data from its\nprivate memory into the bounce buffer, and the host must maps the bounce buffer\ninto the device (NIC) for it to perform DMA. The reversed direction is the\nsimilar. This contributes 19.45% of CPU cycles [@li2023bifrost]\n\n[@li2023bifrost] noticed that TLS itself must perform memory copies during\nencryption and decryption, and requiring private memory and decryption at the\nsame time is not optimal. An optimization that directly decrypt data into shared\nmemory and encrypt data from shared memory into private is added.\n\n### VMExits\n\nVMExits is known to be more expensive on CVMs compared to normal VMs\n[[eczmc02q]], since it have to encrypt VM states and perform security checks.\nAsynchronous interrupt posting mechansisms supported by hardware kind of make\nthis less of an issue [@li2023bifrost].\n\n### Packet processing\n\nPacket processing is another major cost, but this is not unique to confidential\nI/O. Still, one optimization can be made to _reassemble packets_ in the\nhost-side backend driver into larger packets [@li2023bifrost].\n\n### Non-CVM costs\n\nMore: [[471vf8vr]].","snippets":["#tee #os #io"],"rawContent":"# Confidential I/O Taxes\n\n#tee #os #io\n\nThere are overheads for using I/O in TEEs due to several factors.\n\n## CVMs\n\nI/O in CVMs are predominantly performed through the `virtio` paravirtualized\ndrivers due to its performance [@li2023bifrost].\n\nEven then, there are certain \"taxes\" that slow down the I/O performance in CVMs.\n\n### Bounce buffering\n\nSince the host cannot directly access the private memory of the CVM, bounce\nbuffers located in shared memory [[jj89s7vj]] must be maintained by the _guest_.\nTo send any packets to the hardware, the guest must copy the data from its\nprivate memory into the bounce buffer, and the host must maps the bounce buffer\ninto the device (NIC) for it to perform DMA. The reversed direction is the\nsimilar. This contributes 19.45% of CPU cycles [@li2023bifrost]\n\n[@li2023bifrost] noticed that TLS itself must perform memory copies during\nencryption and decryption, and requiring private memory and decryption at the\nsame time is not optimal. An optimization that directly decrypt data into shared\nmemory and encrypt data from shared memory into private is added.\n\n### VMExits\n\nVMExits is known to be more expensive on CVMs compared to normal VMs\n[[eczmc02q]], since it have to encrypt VM states and perform security checks.\nAsynchronous interrupt posting mechansisms supported by hardware kind of make\nthis less of an issue [@li2023bifrost].\n\n### Packet processing\n\nPacket processing is another major cost, but this is not unique to confidential\nI/O. Still, one optimization can be made to _reassemble packets_ in the\nhost-side backend driver into larger packets [@li2023bifrost].\n\n### Non-CVM costs\n\nMore: [[471vf8vr]].\n","wordCount":258,"tags":["os","tee","io"],"metadata":{},"created":"2024-12-02T08:43:57.562802344Z","modified":"2024-12-09T04:15:06.172051626Z","checksum":"007304609fd9d04000dbe606c2db58e4c06156626fee49b665f7bb68e3f0eb13"},
    {"filename":"s7kof4mh.md","filenameStem":"s7kof4mh","path":"s7kof4mh.md","absPath":"/home/khadd/mynotes/s7kof4mh.md","title":"Confidential IO Reading","link":"[[s7kof4mh]]","lead":"","body":"","snippets":[],"rawContent":"# Confidential IO Reading\n","wordCount":4,"tags":[],"metadata":{},"created":"2024-12-23T04:13:07.212813348Z","modified":"2024-12-23T04:29:49.024273662Z","checksum":"16b367f4b994d8e8f4ec7bdf36a39eaa2141790faaed6bd979452bf384731d1a"},
    {"filename":"oktf2gql.md","filenameStem":"oktf2gql","path":"oktf2gql.md","absPath":"/home/khadd/mynotes/oktf2gql.md","title":"Conflict of security interest in cloud services","link":"[[oktf2gql]]","lead":"Modern cloud service models provide services where the clients can","body":"Modern cloud service models provide services where the clients can\n\n- Send their data and code to be executed on the cloud (e.g.,\n  Infrastructure-as-a-Service, Function-as-a-Service)\n- send their data to be processed by an external services and receive the\n  results. Examples of this can be seen in can be AI prediction services, LLM\n  chatbots, NaaS [[ijh22i54]]\n\nA more detail threat model analysis reveal that there is a conflict in security\ninterest between the parties. Considering the cloud users and the cloud are\nmutually distrusting.\n\n- The clients want to keep their data and code secret from the cloud service\n- The cloud want to isolate the client code so that they cannot attack the\n  system\n- a more complex scenarios can be seen in multi-party AI computation:\n  - one party provide code\n  - one party provide data\n  - one party provide execution environment\n\nTrusted execution technologies","snippets":["Modern cloud service models provide services where the clients can"],"rawContent":"# Conflict of security interest in cloud services\n\nModern cloud service models provide services where the clients can\n\n- Send their data and code to be executed on the cloud (e.g.,\n  Infrastructure-as-a-Service, Function-as-a-Service)\n- send their data to be processed by an external services and receive the\n  results. Examples of this can be seen in can be AI prediction services, LLM\n  chatbots, NaaS [[ijh22i54]]\n\nA more detail threat model analysis reveal that there is a conflict in security\ninterest between the parties. Considering the cloud users and the cloud are\nmutually distrusting.\n\n- The clients want to keep their data and code secret from the cloud service\n- The cloud want to isolate the client code so that they cannot attack the\n  system\n- a more complex scenarios can be seen in multi-party AI computation:\n  - one party provide code\n  - one party provide data\n  - one party provide execution environment\n\nTrusted execution technologies\n","wordCount":154,"tags":[],"metadata":{},"created":"2024-12-18T03:29:29.975693176Z","modified":"2024-12-18T04:08:00.68839924Z","checksum":"4bab893b9c8f18cb262a617e9ec26bcb75ff38d023b7f149a045eb6f34eb70c6"},
    {"filename":"y9wu5ut7.md","filenameStem":"y9wu5ut7","path":"y9wu5ut7.md","absPath":"/home/khadd/mynotes/y9wu5ut7.md","title":"Confused deputy","link":"[[y9wu5ut7]]","lead":"#capabilities #compartmentalization","body":"#capabilities #compartmentalization\n\nIn securing any system, it is inevitable that there are some components that\nhave higher privilege than others. A confused deputy happens when a\nhigh-privilege system is tricked into performing a certain action on behalf of a\nlower-privilege system.\n\nThe confused deputy problem requires rethinking about access control, and leads\nto development of capabilities-based access control models, where access through\nresources are given to each user through _capabilities_ [[khi9ihj9]].\n\n## An example\n\nThe example used in the original paper [@hardy1988confused] is a compiler\nprogram. A user invoke the compiler with the name of the input file to compile a\nprogram, and also an output file to receive statistics. The compiler is given\nthe authority to write into its home directory. Let's say there is another file\nin the home directory of the compiler that contains the billing information. A\nmalicious user of the compiler can invoke it to trick the compiler into writing\ninto the billing file since it is within the authority of the compiler.\n\nIn a sense, confused deputy happens due to the _ambient authority_. In the\ncompiler case, the compiler user obtains more authority than needed (access to\nthe whole home directory) to perform it job (read input, write output).\n\nTo solve this problem, a naive solution would be to switch the authority of the\ncompiler (through some system call) to that of the invoked. However, such a\nsystem would lead to complexity when there is a high amount of authorities, and\nalso hard to generalize.\n\n## Interface vulnerabilities\n\nInterface vulnerabilities is a manifestation of confused deputy problem, where\ndifferent mutually distrusting entities interacts with each other through\nexposed interfaces [@lefeuvre2023assessing]. More: [[yef2w9yc]].","snippets":["#capabilities #compartmentalization"],"rawContent":"# Confused deputy\n\n#capabilities #compartmentalization\n\nIn securing any system, it is inevitable that there are some components that\nhave higher privilege than others. A confused deputy happens when a\nhigh-privilege system is tricked into performing a certain action on behalf of a\nlower-privilege system.\n\nThe confused deputy problem requires rethinking about access control, and leads\nto development of capabilities-based access control models, where access through\nresources are given to each user through _capabilities_ [[khi9ihj9]].\n\n## An example\n\nThe example used in the original paper [@hardy1988confused] is a compiler\nprogram. A user invoke the compiler with the name of the input file to compile a\nprogram, and also an output file to receive statistics. The compiler is given\nthe authority to write into its home directory. Let's say there is another file\nin the home directory of the compiler that contains the billing information. A\nmalicious user of the compiler can invoke it to trick the compiler into writing\ninto the billing file since it is within the authority of the compiler.\n\nIn a sense, confused deputy happens due to the _ambient authority_. In the\ncompiler case, the compiler user obtains more authority than needed (access to\nthe whole home directory) to perform it job (read input, write output).\n\nTo solve this problem, a naive solution would be to switch the authority of the\ncompiler (through some system call) to that of the invoked. However, such a\nsystem would lead to complexity when there is a high amount of authorities, and\nalso hard to generalize.\n\n## Interface vulnerabilities\n\nInterface vulnerabilities is a manifestation of confused deputy problem, where\ndifferent mutually distrusting entities interacts with each other through\nexposed interfaces [@lefeuvre2023assessing]. More: [[yef2w9yc]].\n","wordCount":281,"tags":["capabilities","compartmentalization"],"metadata":{},"created":"2024-05-20T09:23:11.423316875Z","modified":"2024-12-23T05:33:06.612544883Z","checksum":"8b958ba5d508efabb1fd74e0c88e5e34a0cfea5259db8aa61e99389d3010fb04"},
    {"filename":"rlcg39bj.md","filenameStem":"rlcg39bj","path":"rlcg39bj.md","absPath":"/home/khadd/mynotes/rlcg39bj.md","title":"Connecting to BMC","link":"[[rlcg39bj]]","lead":"#project","body":"#project\n\n### SSSEV\n\n- IP: 115.145.154.187]\n- Port: 3321\n- admin credentials: sssev-admin / s3cure-ctF!\n\n### BMC for SSSEV\n\n- IP: \u003chttps://115.145.173.192/#login\u003e\n- admin credentials: admin / s3cure-ctF!\n- You can remote control it with “Remote Control” \u003e “H5Viewer”","snippets":["#project"],"rawContent":"# Connecting to BMC\n\n#project\n\n### SSSEV\n\n- IP: 115.145.154.187]\n- Port: 3321\n- admin credentials: sssev-admin / s3cure-ctF!\n\n### BMC for SSSEV\n\n- IP: \u003chttps://115.145.173.192/#login\u003e\n- admin credentials: admin / s3cure-ctF!\n- You can remote control it with “Remote Control” \u003e “H5Viewer”\n","wordCount":43,"tags":["project"],"metadata":{},"created":"2024-06-25T07:15:47.537758932Z","modified":"2024-07-31T07:45:53.340760188Z","checksum":"2e9e46beafab5f04cf3551c3efdd351f9591f94eb1b658c2b4b98204b1be2c28"},
    {"filename":"h3manv25.md","filenameStem":"h3manv25","path":"h3manv25.md","absPath":"/home/khadd/mynotes/h3manv25.md","title":"Containers vs. Virtual machines","link":"[[h3manv25]]","lead":"#vm #container #cloud #ipc #os #virtualization","body":"#vm #container #cloud #ipc #os #virtualization\n\nContainers and virtual machines ([[s16ct1rj]]) are two main isolation primitives\nwhen it come to cloud isolation.\n\nVirtual machines provides strong isolation between application components with a\nsmall TCB: a small hypervisor need to be trusted. However, data sharing between\nVMs is challenging and commonly have high overheads [@yasukata2023exitless].\n\nOn the other hand, containers allows application components to share the\nunderlying OS. This enable richer OS-backed IPC mechanisms for better data\nsharing. This comes at the cost of larger TCB: a shared OS have to implement\nnamespace isolation and complex IPC primitives [@sartakov2022capvms].","snippets":["#vm #container #cloud #ipc #os #virtualization"],"rawContent":"# Containers vs. Virtual machines\n\n#vm #container #cloud #ipc #os #virtualization\n\nContainers and virtual machines ([[s16ct1rj]]) are two main isolation primitives\nwhen it come to cloud isolation.\n\nVirtual machines provides strong isolation between application components with a\nsmall TCB: a small hypervisor need to be trusted. However, data sharing between\nVMs is challenging and commonly have high overheads [@yasukata2023exitless].\n\nOn the other hand, containers allows application components to share the\nunderlying OS. This enable richer OS-backed IPC mechanisms for better data\nsharing. This comes at the cost of larger TCB: a shared OS have to implement\nnamespace isolation and complex IPC primitives [@sartakov2022capvms].\n","wordCount":103,"tags":["ipc","vm","cloud","container","os","virtualization"],"metadata":{},"created":"2023-05-10T06:48:13.569982345Z","modified":"2024-06-22T13:20:50.682732288Z","checksum":"df9f62867e1f7ef381057ed68aa3256cd12cdd9ad7fb13ee1cbe730b193c1bf9"},
    {"filename":"1yhmh234.md","filenameStem":"1yhmh234","path":"1yhmh234.md","absPath":"/home/khadd/mynotes/1yhmh234.md","title":"Controlled-channel Attacks","link":"[[1yhmh234]]","lead":"#attack #tee #sgx","body":"#attack #tee #sgx\n\nControlled-channel attack refers to attacks launched by the higher-privilege system against the lower-privilege one. The confidential lower-privilege system (SGX, VM) lacks capabilities (e.g., paging, file access), and needs to request the higher-privilege system (OS, hypervisor) for resources. The higher-privilege can use this controlled channel to monitor the lower-privilege one. This scenario happens especially in a confidential execution environment, where the protected program does not trust the underlying infrastructure, or cloud service provider (CSP).","snippets":["#attack #tee #sgx"],"rawContent":"# Controlled-channel Attacks\n#attack #tee #sgx\n\nControlled-channel attack refers to attacks launched by the higher-privilege system against the lower-privilege one. The confidential lower-privilege system (SGX, VM) lacks capabilities (e.g., paging, file access), and needs to request the higher-privilege system (OS, hypervisor) for resources. The higher-privilege can use this controlled channel to monitor the lower-privilege one. This scenario happens especially in a confidential execution environment, where the protected program does not trust the underlying infrastructure, or cloud service provider (CSP).\n\n","wordCount":79,"tags":["sgx","tee","attack"],"metadata":{},"created":"2023-05-25T09:32:00.071940821Z","modified":"2024-05-20T11:00:55.665146783Z","checksum":"eb13b907208744cb3f652a0945829b7243c22e12cec2d4fb3d44f931ed4ba17c"},
    {"filename":"qq4qcbos.md","filenameStem":"qq4qcbos","path":"qq4qcbos.md","absPath":"/home/khadd/mynotes/qq4qcbos.md","title":"Controlled-channel attacks against SEV","link":"[[qq4qcbos]]","lead":"#controlled-channel #side-channel #sev #tee","body":"#controlled-channel #side-channel #sev #tee\n\n# Nested page fault side-channels\nVirtualization hardware enables two-stage translation process from gVA to gPA, and from gPA to hPA through the nested page table (NPT) ([[d3nt6uix]]). This is the same in SEV. Although there is no official documentation, many paper indicate that hypervisor cannot intercept guest page faults (gPF) and look for faulting address.\n\nPage fault attacks in SEV is similar to the controlled-channel attacks on SGX @xu2015controlledchannel. \nThe hypervisor can unset the present bit (`P` bit) in the NPT for particular physical pages, such that nested page fault (NPF) will be generated when the page is accessed by the VM, which the hypervisor can capture and analyze.\n\n# IO events\nSome applications requiring I/O events can leak certain behaviors of the program. For instance, @morbitzer2019extracting, @li2019exploiting use network packets to determine the start/end of a TLS connection, and disk I/O to determine disk encryption operation.\n\n\n# Related notes\n- @li2019exploiting: [[literature/ncfh611p]]","snippets":["#controlled-channel #side-channel #sev #tee"],"rawContent":"# Controlled-channel attacks against SEV\n#controlled-channel #side-channel #sev #tee\n\n# Nested page fault side-channels\nVirtualization hardware enables two-stage translation process from gVA to gPA, and from gPA to hPA through the nested page table (NPT) ([[d3nt6uix]]). This is the same in SEV. Although there is no official documentation, many paper indicate that hypervisor cannot intercept guest page faults (gPF) and look for faulting address.\n\nPage fault attacks in SEV is similar to the controlled-channel attacks on SGX @xu2015controlledchannel. \nThe hypervisor can unset the present bit (`P` bit) in the NPT for particular physical pages, such that nested page fault (NPF) will be generated when the page is accessed by the VM, which the hypervisor can capture and analyze.\n\n# IO events\nSome applications requiring I/O events can leak certain behaviors of the program. For instance, @morbitzer2019extracting, @li2019exploiting use network packets to determine the start/end of a TLS connection, and disk I/O to determine disk encryption operation.\n\n\n# Related notes\n- @li2019exploiting: [[literature/ncfh611p]]\n","wordCount":162,"tags":["tee","sev","controlled-channel","side-channel"],"metadata":{},"created":"2023-06-19T06:44:04.882184776Z","modified":"2023-07-04T04:09:27.095621492Z","checksum":"e3d7b4385bb89907a20faf04b9ffb37bf87bb5b6db63a8ed5f544fc66d2654a7"},
    {"filename":"i2blyo37.md","filenameStem":"i2blyo37","path":"i2blyo37.md","absPath":"/home/khadd/mynotes/i2blyo37.md","title":"Cost of IPC in microkernels and Optimizations","link":"[[i2blyo37]]","lead":"#microkernel #sel4 #ipc #kpti #os","body":"#microkernel #sel4 #ipc #kpti #os\n\nIn microkernels such as sel4, kernel code is kept to the minimum, and most of\nthe system services such as file system, and networking are moved into the\nuserspace as a _system server_. Applications that use those services need to\ninvoke them through _IPC_. Since those services are in the userspace in\ndifferent address spaces, an IPC would consist of:\n\n1. Privilege switch to from application the kernel\n2. Process switch to the callee process\n3. Privilege switch to the callee\n4. Process switch back to the caller process\n5. Privilege switch from kernel to the caller\n\n## Overhead analysis\n\n[@gu2020harmonizing] (see [[2a7l7odo]]) performed a study of the source of\noverheads of such IPC. SQLite3 is run on Zircon and seL4 microkernels. It is\nfound that total IPC time is 79% the time on Zircon and 44% of the time on seL4\n(with KPTI).\n\nThe overheads of each component are also studied in the following table.\n\n| Parts            | w/o KPTI | w/ KPTI        |\n| ---------------- | -------- | -------------- |\n| Privilege switch | 158      | 690            |\n| Process switch   | 295      | included above |\n| Others           | 277      | 320            |\n| Total            | 730      | 1010           |\n\n_Privilege switch_ is the overhead of a syscall instruction. _Process switch_ is\nmostly changing the page table by writing into the CR3 register (about 270\ncycles). With KPTI enabled, an additional page table switch needs to be added to\nevery user-to-kernel privilege switch, which adds another layer of overheads.\nAdditionally, there are also other types of overheads such as permission checks,\nand capabilities checks.\n\n## Optimizations\n\nOne way to reduce this cost is to leverage fast in-process switching to isolate\nthe process from the microkernel. [@mi2019skybridge] uses VMFUNC and Underbridge\nuses intel PKU [@gu2020harmonizing].\n\nThe other trend is to leverage the power of multicore with asynchronous IPC\nmechanisms [@soares2010flexsc], that run each process in a separated thread and\nuse pooling. This lead to better per-core locality and also get rid of the\ncontext switching costs.","snippets":["#microkernel #sel4 #ipc #kpti #os"],"rawContent":"# Cost of IPC in microkernels and Optimizations\n\n#microkernel #sel4 #ipc #kpti #os\n\nIn microkernels such as sel4, kernel code is kept to the minimum, and most of\nthe system services such as file system, and networking are moved into the\nuserspace as a _system server_. Applications that use those services need to\ninvoke them through _IPC_. Since those services are in the userspace in\ndifferent address spaces, an IPC would consist of:\n\n1. Privilege switch to from application the kernel\n2. Process switch to the callee process\n3. Privilege switch to the callee\n4. Process switch back to the caller process\n5. Privilege switch from kernel to the caller\n\n## Overhead analysis\n\n[@gu2020harmonizing] (see [[2a7l7odo]]) performed a study of the source of\noverheads of such IPC. SQLite3 is run on Zircon and seL4 microkernels. It is\nfound that total IPC time is 79% the time on Zircon and 44% of the time on seL4\n(with KPTI).\n\nThe overheads of each component are also studied in the following table.\n\n| Parts            | w/o KPTI | w/ KPTI        |\n| ---------------- | -------- | -------------- |\n| Privilege switch | 158      | 690            |\n| Process switch   | 295      | included above |\n| Others           | 277      | 320            |\n| Total            | 730      | 1010           |\n\n_Privilege switch_ is the overhead of a syscall instruction. _Process switch_ is\nmostly changing the page table by writing into the CR3 register (about 270\ncycles). With KPTI enabled, an additional page table switch needs to be added to\nevery user-to-kernel privilege switch, which adds another layer of overheads.\nAdditionally, there are also other types of overheads such as permission checks,\nand capabilities checks.\n\n## Optimizations\n\nOne way to reduce this cost is to leverage fast in-process switching to isolate\nthe process from the microkernel. [@mi2019skybridge] uses VMFUNC and Underbridge\nuses intel PKU [@gu2020harmonizing].\n\nThe other trend is to leverage the power of multicore with asynchronous IPC\nmechanisms [@soares2010flexsc], that run each process in a separated thread and\nuse pooling. This lead to better per-core locality and also get rid of the\ncontext switching costs.\n","wordCount":351,"tags":["microkernel","sel4","ipc","kpti","os"],"metadata":{},"created":"2023-05-08T04:00:25.410180908Z","modified":"2024-12-17T04:35:02.234942951Z","checksum":"d3143b2367d0ee847c5b8e0787777c603c072c84786bb182e566f7b07625dc58"},
    {"filename":"415db476.md","filenameStem":"415db476","path":"415db476.md","absPath":"/home/khadd/mynotes/415db476.md","title":"Courage is not the absence of fear, but rather the assessment that something else is more important than fear.","link":"[[415db476]]","lead":"#quote","body":"#quote\n\nFranklin D. Roosevelt","snippets":["#quote"],"rawContent":"---\ncreated: 2024-12-08T20:06:51+09:00\nmodified: 2024-12-08T20:09:08+09:00\n---\n\n# Courage is not the absence of fear, but rather the assessment that something else is more important than fear.\n\n#quote\n\nFranklin D. Roosevelt\n","wordCount":30,"tags":["quote"],"metadata":{"created":"2024-12-08T20:06:51+09:00","modified":"2024-12-08T20:09:08+09:00"},"created":"2024-12-09T04:21:46.898462796Z","modified":"2024-12-09T04:18:11.669411243Z","checksum":"4b6a0acb3d89ef748a84a1be242ee434c548678221217b9510020dd790f0a107"},
    {"filename":"bkdcd5nv.md","filenameStem":"bkdcd5nv","path":"bkdcd5nv.md","absPath":"/home/khadd/mynotes/bkdcd5nv.md","title":"DPDK vs. io_uring","link":"[[bkdcd5nv]]","lead":"#os #io","body":"#os #io\n\nDPDK (Data Plane Development Kit) [[qctx04tc]] and `io_uring` are both\ntechniques to improve I/O performance in Linux by reducing the amount of context\nswitches. `io_uring` implements new syscalls for asynchronous I/O in the kernel.\n\n## Performance\n\nGenerally DPDK outperforms `io_uring` and traditional networking thanks to its\nkernel bypass [@vorbrodt2023analyzing].\n\nHowever, `io_uring` and traditional networking stack perform better under when\nthe requests exceed the maximum capabilities, potentially due to having access\nto kernel resouces [@vorbrodt2023analyzing].\n\n## Security\n\nDPDK sacrifies safety, requiring it to trust other users of the devices, or\nexpecting some safe multiplexor [@hedayati2019hodor]. ([[qctx04tc]])\n\n`io_uring` and traditional networking stack let the kernel be the sole user of\nthe networking devices, allowing safe multiplexing across users.","snippets":["#os #io"],"rawContent":"# DPDK vs. io_uring\n\n#os #io\n\nDPDK (Data Plane Development Kit) [[qctx04tc]] and `io_uring` are both\ntechniques to improve I/O performance in Linux by reducing the amount of context\nswitches. `io_uring` implements new syscalls for asynchronous I/O in the kernel.\n\n## Performance\n\nGenerally DPDK outperforms `io_uring` and traditional networking thanks to its\nkernel bypass [@vorbrodt2023analyzing].\n\nHowever, `io_uring` and traditional networking stack perform better under when\nthe requests exceed the maximum capabilities, potentially due to having access\nto kernel resouces [@vorbrodt2023analyzing].\n\n## Security\n\nDPDK sacrifies safety, requiring it to trust other users of the devices, or\nexpecting some safe multiplexor [@hedayati2019hodor]. ([[qctx04tc]])\n\n`io_uring` and traditional networking stack let the kernel be the sole user of\nthe networking devices, allowing safe multiplexing across users.\n","wordCount":122,"tags":["os","io"],"metadata":{},"created":"2024-12-03T06:47:18.167856594Z","modified":"2024-12-03T07:04:12.738805611Z","checksum":"8c33231f5696cad7fa6b3441710cf7bb9481dae50994630506dddaeaff77f22d"},
    {"filename":"s1icecys.md","filenameStem":"s1icecys","path":"s1icecys.md","absPath":"/home/khadd/mynotes/s1icecys.md","title":"Danish conference Visa from Korea","link":"[[s1icecys]]","lead":"#visa","body":"#visa\n\n\n\nYou have to go through the Swedish embassy in Korea. The process is the same as applying for a Swedish visa.\n\n\n# Documents\n\n- have a passport that is valid for at least three months after the visa has expired, was issued in the last ten years and has at least two empty pages\n- be able to describe the purpose of your visit\n- have an invitation from the company or the person that is arranging the conference\n- have money to support yourself and for the return trip home (Sweden also requires you to have 450 SEK for each day you stay in Sweden, which can also be paid for by the company that has invited you)\n- have an individual medical travel insurance that covers all costs that may arise in connection with emergency medical treatment, urgent medical care or transportation to your home country for medical reasons (the insurance must cover costs of at least 30,000 EUR and be valid for all Schengen countries)\n- show that you intend to leave Sweden and the Schengen area on the last day before the visa expires\n- a photograph that is in passport format and taken with you facing the camera and which is not older than six months\n- other documents that the embassy may require.\n\n\n# Process\n1. Apply online at https://www.migrationsverket.se/\n2. Wait for result\n\n# References\n- https://www.migrationsverket.se/English/Private-individuals/Visiting-Sweden/Visit-Sweden-for-less-than-90-days---apply-for-a-visa.html","snippets":["#visa"],"rawContent":"# Danish conference Visa from Korea\n#visa\n\n\n\nYou have to go through the Swedish embassy in Korea. The process is the same as applying for a Swedish visa.\n\n\n# Documents\n\n- have a passport that is valid for at least three months after the visa has expired, was issued in the last ten years and has at least two empty pages\n- be able to describe the purpose of your visit\n- have an invitation from the company or the person that is arranging the conference\n- have money to support yourself and for the return trip home (Sweden also requires you to have 450 SEK for each day you stay in Sweden, which can also be paid for by the company that has invited you)\n- have an individual medical travel insurance that covers all costs that may arise in connection with emergency medical treatment, urgent medical care or transportation to your home country for medical reasons (the insurance must cover costs of at least 30,000 EUR and be valid for all Schengen countries)\n- show that you intend to leave Sweden and the Schengen area on the last day before the visa expires\n- a photograph that is in passport format and taken with you facing the camera and which is not older than six months\n- other documents that the embassy may require.\n\n\n# Process\n1. Apply online at https://www.migrationsverket.se/\n2. Wait for result\n\n# References\n- https://www.migrationsverket.se/English/Private-individuals/Visiting-Sweden/Visit-Sweden-for-less-than-90-days---apply-for-a-visa.html\n","wordCount":241,"tags":["visa"],"metadata":{},"created":"2023-08-21T04:30:49.689187197Z","modified":"2023-08-21T04:34:39.477270251Z","checksum":"a1285c40bf52fc80a4fa49311c435933d277894421d205575923c32c42a69bcd"},
    {"filename":"b5bm8g0p.md","filenameStem":"b5bm8g0p","path":"b5bm8g0p.md","absPath":"/home/khadd/mynotes/b5bm8g0p.md","title":"Data binary representation","link":"[[b5bm8g0p]]","lead":"In the age of internet, data must be transferred as efficiently as possible.\nWhile text-based format dominated the web, e.g., RESTful APIs, it is not best\nknown for efficiency.","body":"In the age of internet, data must be transferred as efficiently as possible.\nWhile text-based format dominated the web, e.g., RESTful APIs, it is not best\nknown for efficiency.\n\n- Plain text is space in-efficient. E.g., ASCII uses 7 bits to encode\n  characters, while UTF-8 uses 1 to 4 bytes. Moreover, encoding long numbers\n  like `10000000` is more compact in binary (1/4/8 bytes), while in text, it\n  requires one byte for each character.\n- Parsing text is inefficient (compared to parsing binary data). Parsing text\n  require you to decode each character, then parse the character into data\n  format.\n\nThere has been specifications to encode data directly into the binary format.\n\nUseful data usually has _structures_, e.g., C `struct`, Rust `Vec`, so there\nmust be ways to encode them into binary while preserving structures and a way to\ndecode the binary blob into structures on the receiving end. Encoding\nprogramming language data structures into binary is called _serializing_ , and\nthe other direction is called _deserializing_.\n\n## Examples\n\n- **cbor** is a compact binary representation for JSON.\n- **Protocol Buffer (protobuf)** is Google's proposal for language-neutral,\n  platform-neutral to structured data serialization/deserialization.\n- **Flat Buffers** allow deserializing parts of the binary.","snippets":["In the age of internet, data must be transferred as efficiently as possible.\nWhile text-based format dominated the web, e.g., RESTful APIs, it is not best\nknown for efficiency."],"rawContent":"# Data binary representation\n\nIn the age of internet, data must be transferred as efficiently as possible.\nWhile text-based format dominated the web, e.g., RESTful APIs, it is not best\nknown for efficiency.\n\n- Plain text is space in-efficient. E.g., ASCII uses 7 bits to encode\n  characters, while UTF-8 uses 1 to 4 bytes. Moreover, encoding long numbers\n  like `10000000` is more compact in binary (1/4/8 bytes), while in text, it\n  requires one byte for each character.\n- Parsing text is inefficient (compared to parsing binary data). Parsing text\n  require you to decode each character, then parse the character into data\n  format.\n\nThere has been specifications to encode data directly into the binary format.\n\nUseful data usually has _structures_, e.g., C `struct`, Rust `Vec`, so there\nmust be ways to encode them into binary while preserving structures and a way to\ndecode the binary blob into structures on the receiving end. Encoding\nprogramming language data structures into binary is called _serializing_ , and\nthe other direction is called _deserializing_.\n\n## Examples\n\n- **cbor** is a compact binary representation for JSON.\n- **Protocol Buffer (protobuf)** is Google's proposal for language-neutral,\n  platform-neutral to structured data serialization/deserialization.\n- **Flat Buffers** allow deserializing parts of the binary.\n","wordCount":203,"tags":[],"metadata":{},"created":"2024-12-17T03:08:59.895344897Z","modified":"2024-12-17T03:30:34.395049757Z","checksum":"26e834f9bc3171294872c4dbb439f57b077051ecfc73fe610132bf520b2dac44"},
    {"filename":"x13kncyi.md","filenameStem":"x13kncyi","path":"x13kncyi.md","absPath":"/home/khadd/mynotes/x13kncyi.md","title":"Data sharing in VMs","link":"[[x13kncyi]]","lead":"#os #virtualization","body":"#os #virtualization\n\nThere are two main methods for sharing data across VMs: using (1) shared memory\nmappings or (2) hypervisor delegation. Shared memory mappings is considered\ninsecure, as both party can freely access the underlying data. On the other\nhand, hypervisor delegation provides controlled access to shared data, but\nrequires costly VMEXITs. With a exitless mechanism that enforce isolation like\nVMFUNC, (2) can provide both efficiency and isolation [@yasukata2023exitless].\n\nOther issues with Cross-VM sharing the significant different between the\nprogramming model of VM sharing and existing process-based IPC interfaces.\nHence, VM programs must be specifically adapted to use the low-level shared\nmemory mappings and hypervisor delegation. A common research pattern is to\nprovides an POSIX environment (unikernels/library OSes/containers\n[@sartakov2022capvms],[@belay2012dune]) with support for rich IPC interfaces,\nwhile keeping isolation boundaries of VMs.","snippets":["#os #virtualization"],"rawContent":"# Data sharing in VMs\n\n#os #virtualization\n\nThere are two main methods for sharing data across VMs: using (1) shared memory\nmappings or (2) hypervisor delegation. Shared memory mappings is considered\ninsecure, as both party can freely access the underlying data. On the other\nhand, hypervisor delegation provides controlled access to shared data, but\nrequires costly VMEXITs. With a exitless mechanism that enforce isolation like\nVMFUNC, (2) can provide both efficiency and isolation [@yasukata2023exitless].\n\nOther issues with Cross-VM sharing the significant different between the\nprogramming model of VM sharing and existing process-based IPC interfaces.\nHence, VM programs must be specifically adapted to use the low-level shared\nmemory mappings and hypervisor delegation. A common research pattern is to\nprovides an POSIX environment (unikernels/library OSes/containers\n[@sartakov2022capvms],[@belay2012dune]) with support for rich IPC interfaces,\nwhile keeping isolation boundaries of VMs.\n","wordCount":136,"tags":["os","virtualization"],"metadata":{},"created":"2024-06-18T10:06:08.448189416Z","modified":"2024-06-22T14:11:21.285000978Z","checksum":"2cb1a6f6688c9b3fed5d785cb9a20e89780a11f13b5bb64ea034c31c7dd3cb98"},
    {"filename":"mk2qs4yt.md","filenameStem":"mk2qs4yt","path":"mk2qs4yt.md","absPath":"/home/khadd/mynotes/mk2qs4yt.md","title":"Debug support in SEV","link":"[[mk2qs4yt]]","lead":"AMD SEV-ES supports hardware debug breakpoints. To set the debug breakpoint, the\nVM writes to DR0-3, then DR7 (debug control reg.). Normally, write to DR7 is\ntrapped by the hypervisor, and the behavior is emulated. However, when SWAP TYPE\nB is enabled,","body":"AMD SEV-ES supports hardware debug breakpoints. To set the debug breakpoint, the\nVM writes to DR0-3, then DR7 (debug control reg.). Normally, write to DR7 is\ntrapped by the hypervisor, and the behavior is emulated. However, when SWAP TYPE\nB is enabled,\n\n## Linux implementaiton\n\n[This patch](https://lore.kernel.org/lkml/20230615063757.3039121-1-aik@amd.com/)\nadd supports for DebugSwap.\n\n\u003e Add support for \"DebugSwap for SEV-ES guests\", which provides support for\n\u003e swapping DR[0-3] and DR[0-3]_ADDR_MASK on VMRUN and VMEXIT, i.e. allows KVM to\n\u003e expose debug capabilities to SEV-ES guests. Without DebugSwap support, the CPU\n\u003e doesn't save/load most \\_guest_ debug registers (except DR6/7), and KVM cannot\n\u003e manually context switch guest DRs due the VMSA being encrypted.\n\u003e\n\u003e Enable DebugSwap if and only if the CPU also supports NoNestedDataBp, which\n\u003e causes the CPU to ignore nested #DBs, i.e. #DBs that occur when vectoring a\n\u003e #DB. Without NoNestedDataBp, a malicious guest can DoS the host by putting the\n\u003e CPU into an infinite loop of vectoring #DBs (see\n\u003e \u003chttps://bugzilla.redhat.com/show_bug.cgi?id=1278496\u003e)\n\u003e\n\u003e Set the features bit in sev*es_sync_vmsa() which is the last point when VMSA\n\u003e is not encrypted yet as sev*(es\\_)init_vmcb() (where the most init happens) is\n\u003e called not only when VCPU is initialised but also on intrahost migration when\n\u003e VMSA is encrypted. Eliminate DR7 intercepts as KVM can't modify guest DR7, and\n\u003e intercepting DR7 would completely defeat the purpose of enabling DebugSwap.\n\u003e\n\u003e Make X86_FEATURE_DEBUG_SWAP appear in /proc/cpuinfo (by not adding \"\") to let\n\u003e the operator know if the VM can debug.\n\n[This patch](https://lore.kernel.org/lkml/20240404121327.3107131-1-pbonzini@redhat.com/)\nadds a patch that allows flexible VM creation that can enable VM features like\nDebugSwap","snippets":["AMD SEV-ES supports hardware debug breakpoints. To set the debug breakpoint, the\nVM writes to DR0-3, then DR7 (debug control reg.). Normally, write to DR7 is\ntrapped by the hypervisor, and the behavior is emulated. However, when SWAP TYPE\nB is enabled,"],"rawContent":"# Debug support in SEV\n\nAMD SEV-ES supports hardware debug breakpoints. To set the debug breakpoint, the\nVM writes to DR0-3, then DR7 (debug control reg.). Normally, write to DR7 is\ntrapped by the hypervisor, and the behavior is emulated. However, when SWAP TYPE\nB is enabled,\n\n## Linux implementaiton\n\n[This patch](https://lore.kernel.org/lkml/20230615063757.3039121-1-aik@amd.com/)\nadd supports for DebugSwap.\n\n\u003e Add support for \"DebugSwap for SEV-ES guests\", which provides support for\n\u003e swapping DR[0-3] and DR[0-3]_ADDR_MASK on VMRUN and VMEXIT, i.e. allows KVM to\n\u003e expose debug capabilities to SEV-ES guests. Without DebugSwap support, the CPU\n\u003e doesn't save/load most \\_guest_ debug registers (except DR6/7), and KVM cannot\n\u003e manually context switch guest DRs due the VMSA being encrypted.\n\u003e\n\u003e Enable DebugSwap if and only if the CPU also supports NoNestedDataBp, which\n\u003e causes the CPU to ignore nested #DBs, i.e. #DBs that occur when vectoring a\n\u003e #DB. Without NoNestedDataBp, a malicious guest can DoS the host by putting the\n\u003e CPU into an infinite loop of vectoring #DBs (see\n\u003e \u003chttps://bugzilla.redhat.com/show_bug.cgi?id=1278496\u003e)\n\u003e\n\u003e Set the features bit in sev*es_sync_vmsa() which is the last point when VMSA\n\u003e is not encrypted yet as sev*(es\\_)init_vmcb() (where the most init happens) is\n\u003e called not only when VCPU is initialised but also on intrahost migration when\n\u003e VMSA is encrypted. Eliminate DR7 intercepts as KVM can't modify guest DR7, and\n\u003e intercepting DR7 would completely defeat the purpose of enabling DebugSwap.\n\u003e\n\u003e Make X86_FEATURE_DEBUG_SWAP appear in /proc/cpuinfo (by not adding \"\") to let\n\u003e the operator know if the VM can debug.\n\n[This patch](https://lore.kernel.org/lkml/20240404121327.3107131-1-pbonzini@redhat.com/)\nadds a patch that allows flexible VM creation that can enable VM features like\nDebugSwap\n","wordCount":277,"tags":["DBs","DB"],"metadata":{},"created":"2024-05-29T04:45:56.74318779Z","modified":"2024-06-28T07:53:37.598908722Z","checksum":"97ab17d4aa2a0040bd2d5af06fed5e3e10592cdf94906985b51c3a7a3dd37354"},
    {"filename":"azyquhm6.md","filenameStem":"azyquhm6","path":"azyquhm6.md","absPath":"/home/khadd/mynotes/azyquhm6.md","title":"Debugging e9patch rewriter","link":"[[azyquhm6]]","lead":"## Bruteforce way","body":"## Bruteforce way\n\nIf all does not work, we may exclude certain function as a last resort. You may\nget function size by the `nm` command [[j111e16c]].\n\nNext, use the `--exclude` flag\n\n```\ne9tool --exclude func_name..func_name+size\n```","snippets":["## Bruteforce way"],"rawContent":"# Debugging e9patch rewriter\n\n## Bruteforce way\n\nIf all does not work, we may exclude certain function as a last resort. You may\nget function size by the `nm` command [[j111e16c]].\n\nNext, use the `--exclude` flag\n\n```\ne9tool --exclude func_name..func_name+size\n```\n","wordCount":41,"tags":[],"metadata":{},"created":"2024-09-05T08:46:00.17729303Z","modified":"2024-09-19T03:40:32.852847995Z","checksum":"36e64532e46e6b05e15be91e71bd12bc82480c0c70d8d7bd6885d033fb4f9cd5"},
    {"filename":"7r5okim8.md","filenameStem":"7r5okim8","path":"7r5okim8.md","absPath":"/home/khadd/mynotes/7r5okim8.md","title":"Deconstructing Software Compartmentalization","link":"[[7r5okim8]]","lead":"#compartmentalization","body":"#compartmentalization\n\nSoftware compartmentalization is a common research goal, but usually each of the\npaper propose a new compartmentalization models (e.g., two-level, capabilities),\nor new methods, new automation, new mechanisms, which makes it difficult to\nevaluate their impact in the grand picture.\n\n[@lefeuvre2024sok] introduced a taxonomy model to classify them. A\ncompartmentalization model need to resolve three challenges:\n\n- **Policy definition methods (PDM)**. How to determine what is the policy to\n  enforce. This reflect the methodology for selecting the subject and resources\n  (e.g., see [[x9zetwej]]) for isolation, which may be performed manually or\n  automatically.\n- **Compartmentalization abstractions**. How to represent compartmentalization\n  as a programming abstraction. This deals with how the programmer interact with\n  the compartmentalization model (through config files, program annotations,\n  etc.).\n- **Compartmentalization mechanism**. How compartmentalization is enforced at\n  runtime.\n\nThe model allow comparision of some seemingly unrelated approaches and also\nreveal the missing pieces in these models.","snippets":["#compartmentalization"],"rawContent":"# Deconstructing Software Compartmentalization\n\n#compartmentalization\n\nSoftware compartmentalization is a common research goal, but usually each of the\npaper propose a new compartmentalization models (e.g., two-level, capabilities),\nor new methods, new automation, new mechanisms, which makes it difficult to\nevaluate their impact in the grand picture.\n\n[@lefeuvre2024sok] introduced a taxonomy model to classify them. A\ncompartmentalization model need to resolve three challenges:\n\n- **Policy definition methods (PDM)**. How to determine what is the policy to\n  enforce. This reflect the methodology for selecting the subject and resources\n  (e.g., see [[x9zetwej]]) for isolation, which may be performed manually or\n  automatically.\n- **Compartmentalization abstractions**. How to represent compartmentalization\n  as a programming abstraction. This deals with how the programmer interact with\n  the compartmentalization model (through config files, program annotations,\n  etc.).\n- **Compartmentalization mechanism**. How compartmentalization is enforced at\n  runtime.\n\nThe model allow comparision of some seemingly unrelated approaches and also\nreveal the missing pieces in these models.\n","wordCount":152,"tags":["compartmentalization"],"metadata":{},"created":"2024-12-16T03:56:49.101884168Z","modified":"2024-12-16T03:56:38.548890167Z","checksum":"a2e639be627317e132151c4ec57a35bc60d6b16716fc22a42fc8fbd74e42c6be"},
    {"filename":"dgdvhu1e.md","filenameStem":"dgdvhu1e","path":"dgdvhu1e.md","absPath":"/home/khadd/mynotes/dgdvhu1e.md","title":"Dependence analysis","link":"[[dgdvhu1e]]","lead":"#analysis #compartmentalization","body":"#analysis #compartmentalization\n\nDependence analysis find dependencies between programs points, such that\nsecurity policies can be enforced.\n\nOne common use case is to split programs, where all code blocks that related to\nparticular variables are moved to another program. To do this, there must be a\ndependence analysis to find all code dependencies.\n\nAnother use case is to enforce valid data flow between program points to prevent\ndata-only attacks [[gbkc1fhy]]. For instance, defenses such as DFI and WIT use\ndependence analysis to find all valid writer to a variable.\n\n## Data-flow-based\n\nProgram compartmentalization techniques such as [@liu2017ptrsplit] often relies\non dependence analysis to determine the data flow between code locations, then\nseparate the program based code dependency. Commonly it is done by first\nidentify all _control dependencies_ of instructions, which form a reachable\ncontrol-flow graph.\n\nThen, on the reachable control-flow graph, data-flow analysis is performed to\nfind data dependencies.\n\n### Limitations\n\n[@lu2023practical] ([[4zdjxws6]]) notes several limitations with such an\napproach:\n\nFirst, control dependencies does not reflect all data dependencies.\n\n- System calls and interrupt handlers is invoked at arbitrary time, and don't\n  have a control-flow edge on the CFG.\n- Two control-independent functions can still pass data through global variables\n  or shared memory. Second, data-flow analysis requires points-to analysis\n  - Points-to analysis is expensive can cannot scale to large programs\n  - Points-to analysis produces a large amount of false positive\n\n## Module-based and type-based\n\n[@lu2023practical] describes a more simplified version of dependence analysis,\nwhere only the dependence between modules (program source files) are analyzed. A\ncoarse-grained data-flow graph between modules can be analyzed based on data\nflow observed in (1) cross-module function calls and (2) access to global\nvariables.\n\nIt uses construct type dependencies between modules to limit the possible data\nflows. E.g., an object from module M1 of type A is able to flow to to module M2.","snippets":["#analysis #compartmentalization"],"rawContent":"# Dependence analysis\n\n#analysis #compartmentalization\n\nDependence analysis find dependencies between programs points, such that\nsecurity policies can be enforced.\n\nOne common use case is to split programs, where all code blocks that related to\nparticular variables are moved to another program. To do this, there must be a\ndependence analysis to find all code dependencies.\n\nAnother use case is to enforce valid data flow between program points to prevent\ndata-only attacks [[gbkc1fhy]]. For instance, defenses such as DFI and WIT use\ndependence analysis to find all valid writer to a variable.\n\n## Data-flow-based\n\nProgram compartmentalization techniques such as [@liu2017ptrsplit] often relies\non dependence analysis to determine the data flow between code locations, then\nseparate the program based code dependency. Commonly it is done by first\nidentify all _control dependencies_ of instructions, which form a reachable\ncontrol-flow graph.\n\nThen, on the reachable control-flow graph, data-flow analysis is performed to\nfind data dependencies.\n\n### Limitations\n\n[@lu2023practical] ([[4zdjxws6]]) notes several limitations with such an\napproach:\n\nFirst, control dependencies does not reflect all data dependencies.\n\n- System calls and interrupt handlers is invoked at arbitrary time, and don't\n  have a control-flow edge on the CFG.\n- Two control-independent functions can still pass data through global variables\n  or shared memory. Second, data-flow analysis requires points-to analysis\n  - Points-to analysis is expensive can cannot scale to large programs\n  - Points-to analysis produces a large amount of false positive\n\n## Module-based and type-based\n\n[@lu2023practical] describes a more simplified version of dependence analysis,\nwhere only the dependence between modules (program source files) are analyzed. A\ncoarse-grained data-flow graph between modules can be analyzed based on data\nflow observed in (1) cross-module function calls and (2) access to global\nvariables.\n\nIt uses construct type dependencies between modules to limit the possible data\nflows. E.g., an object from module M1 of type A is able to flow to to module M2.\n","wordCount":311,"tags":["analysis","compartmentalization"],"metadata":{},"created":"2023-05-22T02:06:14.451358792Z","modified":"2024-06-28T08:37:41.187296691Z","checksum":"b80f91b928e9e48ddaa64c7b8c4eaa7166e7141c5e6772bf6dc88591a9580362"},
    {"filename":"slides.md","filenameStem":"slides","path":"presentations/kaleidoscope/slides.md","absPath":"/home/khadd/mynotes/presentations/kaleidoscope/slides.md","title":"Design","link":"[[presentations/kaleidoscope/slides]]","lead":"---","body":"---\n\n## How to find likely invariants?\n\n- Place probes into SVF\n  - record constraints and their derivations\n  - when the points-to sets are updated\n- Heuristics: trigger alerts in snowballing scenarios\n  - Too many objects added to points-to set (100~1000)\n  - Too many types added to points-to set (10~50)\n- Perform analysis on NGINX webserver and minimal linux kernel\n- Manually inspect the alerts\n\n---\n\n## Likely invariants summary\n\n- Arbitrary pointer arithmetic (cleanly deal with pointer arithmetics)\n  \u003e _Assumes pointer arithmetic only points to array_\n- Positive weight cycles (prevent loss of field sensitivity)\n  \u003e _Assumes PWC does not occur at runtime_\n- Context sensitivity (selective context senstivity)\n  \u003e _Assumes certain pointer arguments are not updated_\n\n---\n\n## Arbitrary pointer arithmetics\n\n![w:720 center](./pointerarith.png)\n\n---\n\n## Context sensitivity\n\n![w:720 center](./contextsensitivity.png)\n\n---\n\n# Kd-powered CFI\n\n![center](./cfi.png)\n\n---\n\n## Memory view switch integrity\n\n- Must prevent attacker from arbitrarily switch memory view\n- Use secure gates to switch between memory views\n- On legitimate switch sites, push a secret value to the stack\n- Validate the value in the call gate\n\n---\n\n## Security\n\n- Reduce indirect call targets through IGO\n- Attacker now have to\n  1. Use restricted CFI version\n  2. Bypass the monitor to enable more permissive CFI (i.e., data only-attack)\n  - \\\u003e Maybe hard to do because the conditions are not directly related to the\n    target function pointer\n\n---\n\n# Evaluation\n\n- How Kaleidoscope impacts PTA precision?\n- How much each of the likely invariant contribute?\n- Runtime overheads of runtime monitoring?\n- Are the likely invariants valid?\n\n---\n\n## Setup\n\n- 10 _small_ applications: MbedTLS, Lighttpd, Memcached, LibPNG, ...\n\n---\n\n## Precision improvement\n\n- Point-to set sizes distribution\n\n![center](./pts-eval.png)\n\n\u003e $13.15 \\times$ reduction in average PTS size.\n\n---\n\n## Impact on CFI\n\n![center](./cfi-eval.png)\n\n---\n\n## Performance overheads\n\n- Throughput evaluations\n\n![center](./throughput-eval.png)\n\n\u003e $5.45\\%$ throughput reduction on average.\n\n---\n\n## Likely invariant validation through fuzzing\n\n- Use AFL++ to fuzz target applications\n- In 24 hours, none of likely invariants are violated\n\n---\n\n## Discussion\n\n- More fine-grained memory views?\n- Improving static analysis with dynamic analysis\n- Add efforts to attackers: now must bypass runtime monitor AND CFI\n  - Data-only attack prevention becomes even more important\n- How is this approach related to data-only attacks?","snippets":["---"],"rawContent":"---\n---\n\n\u003cstyle\u003e\n\timg[alt~=\"center\"] {\n\t\tdisplay: block;\n\t\tmargin: 0 auto;\n\t}\n\tsection.lead {\n\t\ttext-align: center;\n\t}\n\t/* Use instead of footnote */\n\tblockquote {\n\t\t/* border-top: 0.1em dashed #555; */\n\t\t/* font-size: 60%; */\n\t\t/* margin-top: auto; */\n\t}\n\n\tblockquote {\n\t\tbackground-color: lightgray;\n\t\tcolor: black;\n\t\t/* border-top: 0.1em dashed #555; */\n\t\t/* font-size: 60%; */\n\t\t/* margin-top: auto; */\n\t}\n\u003c/style\u003e\n\n![](title.png)\n\n\u003c!-- _class: lead --\u003e\n\nASPLOS 2024\n\n---\n\n## Content\n\n- Background: Points-to analysis and challenges\n- Key observations\n- Kaleidoscope's approach\n- Kaleidoscope's design\n- Kaleidoscope-powered CFI\n- Evaluations\n\n---\n\n## Pointer analysis\n\n```c\nint o1, o2, o3;\nint *p1, *p2, *p3;\np1 = \u0026o1;\np3 = \u0026o3;\n*o2 = o3;\np2 = \u0026o3;\n```\n\n![w:350 center](pta.png)\n\n---\n\n## Andersen-style analysis\n\n- Based on solving **constraints**\n- e.g., `p = \u0026x` $\\rightarrow x \\in pts(p)$ (Addr-Of constraint)\n- e.g., `p = q` $\\rightarrow pts(p) = pts (p) \\cup pts(q)$ (Copy constraint)\n\n![w:720 center](constraints.png)\n\n---\n\n## Precision challenges in PTA\n\n- Scalability vs. Precisions\n- Directly affect security applications like CFI\n- Why: Imprecision\n  - Context sensitivity: Distinguish each calling context.\n    - e.g., `p1 = malloc(512);` vs. `p2 = malloc(256);`\n  - Field sensitivity: Distinguishing fields of struct objects\n    - e.g., `p = \u0026(obj-\u003efield);`\n  - Flow sensitivity: Distinguish order of execution\n  - Path sensitivity: Distinguish branch conditions\n\n\u003e \\\u003e _Statically_ improving precision is usually too expensive\n\n---\n\n## Key observations\n\n1. Imprecisions have a _snowballing effect_\n\n![w:720 center](./mbedtls.png)\n\n---\n\n## Key observations\n\n1. Imprecisions have a _snowballing effect_\n\n   - \\\u003e It is important to detect and stop these imprecision early\n\n2. The process of constraint solving provide hints about these imprecisions.\n   E.g., _points-to set increases 10-fold after adding a constraint_.\n   - Making certain assumptions about the program makes our life easier\n   - E.g., pointer `p` is unlikely to point a certain object `obj`\n   - \\\u003e I.e., **Likely invariants**\n\n---\n\n## How do we exploit these likely invariants?\n\n- Choice of invariant:\n  - Should significantly impact PTS\n  - Should be limited in number\n- Soundness guarantee:\n  - Should preserve soundness of original PTS\n\n---\n\n## Kaleidoscope approach\n\n- Enhance PTS-based security applications\n- Employ different **Memory views** (i.e., different instrumented binary\n  versions) based on different PTAs\n- Switch memory view when invariant is violated\n\n![center](./overview.png)\n\n---\n\n# Design\n\n---\n\n## How to find likely invariants?\n\n- Place probes into SVF\n  - record constraints and their derivations\n  - when the points-to sets are updated\n- Heuristics: trigger alerts in snowballing scenarios\n  - Too many objects added to points-to set (100~1000)\n  - Too many types added to points-to set (10~50)\n- Perform analysis on NGINX webserver and minimal linux kernel\n- Manually inspect the alerts\n\n---\n\n## Likely invariants summary\n\n- Arbitrary pointer arithmetic (cleanly deal with pointer arithmetics)\n  \u003e _Assumes pointer arithmetic only points to array_\n- Positive weight cycles (prevent loss of field sensitivity)\n  \u003e _Assumes PWC does not occur at runtime_\n- Context sensitivity (selective context senstivity)\n  \u003e _Assumes certain pointer arguments are not updated_\n\n---\n\n## Arbitrary pointer arithmetics\n\n![w:720 center](./pointerarith.png)\n\n---\n\n## Context sensitivity\n\n![w:720 center](./contextsensitivity.png)\n\n---\n\n# Kd-powered CFI\n\n![center](./cfi.png)\n\n---\n\n## Memory view switch integrity\n\n- Must prevent attacker from arbitrarily switch memory view\n- Use secure gates to switch between memory views\n- On legitimate switch sites, push a secret value to the stack\n- Validate the value in the call gate\n\n---\n\n## Security\n\n- Reduce indirect call targets through IGO\n- Attacker now have to\n  1. Use restricted CFI version\n  2. Bypass the monitor to enable more permissive CFI (i.e., data only-attack)\n  - \\\u003e Maybe hard to do because the conditions are not directly related to the\n    target function pointer\n\n---\n\n# Evaluation\n\n- How Kaleidoscope impacts PTA precision?\n- How much each of the likely invariant contribute?\n- Runtime overheads of runtime monitoring?\n- Are the likely invariants valid?\n\n---\n\n## Setup\n\n- 10 _small_ applications: MbedTLS, Lighttpd, Memcached, LibPNG, ...\n\n---\n\n## Precision improvement\n\n- Point-to set sizes distribution\n\n![center](./pts-eval.png)\n\n\u003e $13.15 \\times$ reduction in average PTS size.\n\n---\n\n## Impact on CFI\n\n![center](./cfi-eval.png)\n\n---\n\n## Performance overheads\n\n- Throughput evaluations\n\n![center](./throughput-eval.png)\n\n\u003e $5.45\\%$ throughput reduction on average.\n\n---\n\n## Likely invariant validation through fuzzing\n\n- Use AFL++ to fuzz target applications\n- In 24 hours, none of likely invariants are violated\n\n---\n\n## Discussion\n\n- More fine-grained memory views?\n- Improving static analysis with dynamic analysis\n- Add efforts to attackers: now must bypass runtime monitor AND CFI\n  - Data-only attack prevention becomes even more important\n- How is this approach related to data-only attacks?\n","wordCount":755,"tags":[],"metadata":{},"created":"2024-09-13T03:05:45.750264696Z","modified":"2024-09-13T05:50:06.859354121Z","checksum":"63dc10b056d519a3a8e8a0ea715f010db0b1e85b5a46aa2d6f13af8c875175c9"},
    {"filename":"idff94ne.md","filenameStem":"idff94ne","path":"idff94ne.md","absPath":"/home/khadd/mynotes/idff94ne.md","title":"Designing Capability-based Interfaces","link":"[[idff94ne]]","lead":"When designing interfaces from the ground up for safety, capabilities\n[[khi9ihj9]] is a good choice.","body":"When designing interfaces from the ground up for safety, capabilities\n[[khi9ihj9]] is a good choice.\n\n- Nova [@nova] is a \"micro-hypervisor\" inspired by capabilities in microkernels.\n\nTo redesign an interface to use capabilities, how the system handle resources\nmust be redesigned from the ground up.\n\nThe most difficult part is to **encapsulate** (1) resources and (2) resources\noperations into types of **objects**. Here, an **object** both identifies the\nresource to access (e.g., file), and the authorization (e.g., R/W/X). Think\nobject-oriented programming, where a class definition define both data and the\noperation that can be performed on the data.\n\n\u003e [!example] UNIX File descriptors\n\u003e\n\u003e For example, in Unix, a file in the file system is encapsulated into a **file\n\u003e object**. Each process is given control to the file descriptors (capability\n\u003e token) that both identify the file object and represent authority over it.\n\u003e Operations performed on the file descriptor only require the file descriptor\n\u003e itself for authorization.\n\nNow, the decision of which resources to encapsulate is highly dependent on the\ngoal of the system.\n\n\u003e [!example] Microkernels\n\u003e\n\u003e For example, microkernels [[sn99wrm0]] goals is to provide a safe time-sharing\n\u003e environment. They encapsulate types of objects for scheduling (time resource),\n\u003e virtual address space (memory resource) and IPC (communication). Providing an\n\u003e IPC abstraction allow highly composable systems and also allow flexible\n\u003e policies. E.g., the right to perform IPC may be passed from processes to\n\u003e another.\n\n\u003e [!example] NOVA\n\u003e\n\u003e NOVA [@steinberg2010nova] is a _microhypervisor_ to that tried to minimize TCB\n\u003e of hypervisor. It offloads most of VMM functionalities into userspace in lieu\n\u003e of a microkernel-like architecture for the hypervisor. The objects of\n\u003e encapsulation are:\n\u003e\n\u003e - **Protection domains**: abstraction from processes and VMs, for managing\n\u003e   memory, I/O permissions, and capabilities\n\u003e - **Execution context**: abstraction from vCPU and threads.\n\u003e - **Scheduling context**: the time slice given to a VM execution context\n\u003e - **Portal**: Gateways for communication between VM and VMMs\n\u003e - **Semaphore**: Synchronization between execution contexts\n\nThe object handles are then given to the subjects (threads, processes,\ncompartments). There must be a security monitor that validate the **capability\ninvocations** to check for permissions and also allowing access to the resource.\nFor more on implementation: [[y0z8fhtd]].","snippets":["When designing interfaces from the ground up for safety, capabilities\n[[khi9ihj9]] is a good choice."],"rawContent":"# Designing Capability-based Interfaces\n\nWhen designing interfaces from the ground up for safety, capabilities\n[[khi9ihj9]] is a good choice.\n\n- Nova [@nova] is a \"micro-hypervisor\" inspired by capabilities in microkernels.\n\nTo redesign an interface to use capabilities, how the system handle resources\nmust be redesigned from the ground up.\n\nThe most difficult part is to **encapsulate** (1) resources and (2) resources\noperations into types of **objects**. Here, an **object** both identifies the\nresource to access (e.g., file), and the authorization (e.g., R/W/X). Think\nobject-oriented programming, where a class definition define both data and the\noperation that can be performed on the data.\n\n\u003e [!example] UNIX File descriptors\n\u003e\n\u003e For example, in Unix, a file in the file system is encapsulated into a **file\n\u003e object**. Each process is given control to the file descriptors (capability\n\u003e token) that both identify the file object and represent authority over it.\n\u003e Operations performed on the file descriptor only require the file descriptor\n\u003e itself for authorization.\n\nNow, the decision of which resources to encapsulate is highly dependent on the\ngoal of the system.\n\n\u003e [!example] Microkernels\n\u003e\n\u003e For example, microkernels [[sn99wrm0]] goals is to provide a safe time-sharing\n\u003e environment. They encapsulate types of objects for scheduling (time resource),\n\u003e virtual address space (memory resource) and IPC (communication). Providing an\n\u003e IPC abstraction allow highly composable systems and also allow flexible\n\u003e policies. E.g., the right to perform IPC may be passed from processes to\n\u003e another.\n\n\u003e [!example] NOVA\n\u003e\n\u003e NOVA [@steinberg2010nova] is a _microhypervisor_ to that tried to minimize TCB\n\u003e of hypervisor. It offloads most of VMM functionalities into userspace in lieu\n\u003e of a microkernel-like architecture for the hypervisor. The objects of\n\u003e encapsulation are:\n\u003e\n\u003e - **Protection domains**: abstraction from processes and VMs, for managing\n\u003e   memory, I/O permissions, and capabilities\n\u003e - **Execution context**: abstraction from vCPU and threads.\n\u003e - **Scheduling context**: the time slice given to a VM execution context\n\u003e - **Portal**: Gateways for communication between VM and VMMs\n\u003e - **Semaphore**: Synchronization between execution contexts\n\nThe object handles are then given to the subjects (threads, processes,\ncompartments). There must be a security monitor that validate the **capability\ninvocations** to check for permissions and also allowing access to the resource.\nFor more on implementation: [[y0z8fhtd]].\n","wordCount":386,"tags":[],"metadata":{},"created":"2024-12-17T04:50:45.002683958Z","modified":"2024-12-17T10:10:00.911179144Z","checksum":"735e8ef9db70e4ca03196470d765ef7af7e207df17036e289af0e261c1e86408"},
    {"filename":"zzq5zy5v.md","filenameStem":"zzq5zy5v","path":"zzq5zy5v.md","absPath":"/home/khadd/mynotes/zzq5zy5v.md","title":"Detecting bugs in Rust","link":"[[zzq5zy5v]]","lead":"#area #rust","body":"#area #rust\n\n## Rudra\n\nRudra [@bae2021rudra] analyzes Rust HIR and MIR to have a _generic type-aware_\nanalysis. Generic type-awareness is necessary because certain bugs only happen\nfor the implementation of specific types.\n\n```rust\nfn double_drop\u003cT\u003e (mut val: T){\n  unsafe {ptr::drop_in_place(\u0026mut val);}\n  drop(val);\n}\ndouble_drop(123); // no violation since drop on an integer is no-op\ndouble_drop(vec![1, 2, 3]); // double-free happens\n```\n\nMore specifically, Rudra considers a generic function having bugs, if any of the\ninstantiation has a safety bug.\n\n## Unsafe Dataflow Checker\n\nThis checker simply find if their exists a dataflow from the start of lifetime\nbypass to a suspicious function call. The hope is to find dataflwo from unsafe\ninto functions that might `panic`, or functions that might implicitly requires\nsome higher-order invariants (but not upholded by the unsafe caller).\n\nIt is suprising that this simple heuristic helps finds a lot of bugs. On the\nother hand, it has very high false positive rate (53.3% precision on highest\nprecision). Moreover, this kind of heuristic is coarse-grained, it does not try\nto identify the _root cause_ of the bug, but instead finds pattern that commonly\nhave bugs,and rely on the programmer instead instead to filter out the bugs.\n\nThere are two heuristics used by this checker, to determine the lifetime bypass\nlocations, and to determine suspicious function calls.\n\n### Suspicious function calls\n\nThis check marks all _unresolvable generic function call_ as suspicious.\nUnresolvable functions are functions that their definitions cannot be found\nwithout precise type parameters. An example was:\n\n```rust\nfn foo\u003cT\u003e(reader: T)\n  where T: Reader {\n  reader::read();\n}\n\n```\n\nIn this case, to know the definition of `read()`, the type of `reader` must be\nknown, but it is available at runtime. On the other hand, `Vec\u003cT\u003e::push()` has\nimplementation of `push()` implemeted for all possible type `T`.\n\nThe author finds that those unresolable function are where programmers usually\nmake mistake, since they have to _speculate_ about the function behaviors.\n\n### Lifetime bypass locations\n\nThere are six classes of lifetime bypasses:\n\n- Unintialized value (created by extending `Vec` with `Vec::set_len()`)\n- Duplicating lifetime (e.g., `mem::read()`)\n- Overwriting memory (e.g., `mem::write`)\n- Copying values (e.g., buffer copy) (this has the effect of duplicating and\n  overwriting)\n- Transmuting a type and its lifetime\n- Converting a pointer to a reference\n\nRudra uses three precision settings:\n\n- High precision only detect uninitialized values (e.g., `Vec::set_len()`)\n- Medium precision setting additionally find lifetime bypass using `read()`,\n  `write()`, `copy()`.\n- Low precision setting find all `transmute()`a and raw pointer casting.","snippets":["#area #rust"],"rawContent":"# Detecting bugs in Rust\n\n#area #rust\n\n## Rudra\n\nRudra [@bae2021rudra] analyzes Rust HIR and MIR to have a _generic type-aware_\nanalysis. Generic type-awareness is necessary because certain bugs only happen\nfor the implementation of specific types.\n\n```rust\nfn double_drop\u003cT\u003e (mut val: T){\n  unsafe {ptr::drop_in_place(\u0026mut val);}\n  drop(val);\n}\ndouble_drop(123); // no violation since drop on an integer is no-op\ndouble_drop(vec![1, 2, 3]); // double-free happens\n```\n\nMore specifically, Rudra considers a generic function having bugs, if any of the\ninstantiation has a safety bug.\n\n## Unsafe Dataflow Checker\n\nThis checker simply find if their exists a dataflow from the start of lifetime\nbypass to a suspicious function call. The hope is to find dataflwo from unsafe\ninto functions that might `panic`, or functions that might implicitly requires\nsome higher-order invariants (but not upholded by the unsafe caller).\n\nIt is suprising that this simple heuristic helps finds a lot of bugs. On the\nother hand, it has very high false positive rate (53.3% precision on highest\nprecision). Moreover, this kind of heuristic is coarse-grained, it does not try\nto identify the _root cause_ of the bug, but instead finds pattern that commonly\nhave bugs,and rely on the programmer instead instead to filter out the bugs.\n\nThere are two heuristics used by this checker, to determine the lifetime bypass\nlocations, and to determine suspicious function calls.\n\n### Suspicious function calls\n\nThis check marks all _unresolvable generic function call_ as suspicious.\nUnresolvable functions are functions that their definitions cannot be found\nwithout precise type parameters. An example was:\n\n```rust\nfn foo\u003cT\u003e(reader: T)\n  where T: Reader {\n  reader::read();\n}\n\n```\n\nIn this case, to know the definition of `read()`, the type of `reader` must be\nknown, but it is available at runtime. On the other hand, `Vec\u003cT\u003e::push()` has\nimplementation of `push()` implemeted for all possible type `T`.\n\nThe author finds that those unresolable function are where programmers usually\nmake mistake, since they have to _speculate_ about the function behaviors.\n\n### Lifetime bypass locations\n\nThere are six classes of lifetime bypasses:\n\n- Unintialized value (created by extending `Vec` with `Vec::set_len()`)\n- Duplicating lifetime (e.g., `mem::read()`)\n- Overwriting memory (e.g., `mem::write`)\n- Copying values (e.g., buffer copy) (this has the effect of duplicating and\n  overwriting)\n- Transmuting a type and its lifetime\n- Converting a pointer to a reference\n\nRudra uses three precision settings:\n\n- High precision only detect uninitialized values (e.g., `Vec::set_len()`)\n- Medium precision setting additionally find lifetime bypass using `read()`,\n  `write()`, `copy()`.\n- Low precision setting find all `transmute()`a and raw pointer casting.\n","wordCount":420,"tags":["rust","area"],"metadata":{},"created":"2024-05-20T09:23:13.179473981Z","modified":"2024-06-28T08:13:29.720967159Z","checksum":"c67b804d4ba50a4cd4d16c67f6e66cf8d6609a2f2dee457a2d06368db831a3bb"},
    {"filename":"f864w92q.md","filenameStem":"f864w92q","path":"f864w92q.md","absPath":"/home/khadd/mynotes/f864w92q.md","title":"Determine Cache Size","link":"[[f864w92q]]","lead":"`cat /proc/cpuinfo` returns general information about CPU, which includes\nper-code L1 cache.","body":"`cat /proc/cpuinfo` returns general information about CPU, which includes\nper-code L1 cache.\n\n`sudo dmidecode -t cache` returns information about cache. E.g.,\n\n```shell\nHandle 0x003D, DMI type 7, 27 bytes\nCache Information\n        Socket Designation: L1 - Cache\n        Configuration: Enabled, Not Socketed, Level 1\n        Operational Mode: Write Back\n        Location: Internal\n        Installed Size: 2048 kB\n        Maximum Size: 2048 kB\n        Supported SRAM Types:\n                Pipeline Burst\n        Installed SRAM Type: Pipeline Burst\n        Speed: 1 ns\n        Error Correction Type: Multi-bit ECC\n        System Type: Unified\n        Associativity: 8-way Set-associative\n\nHandle 0x003E, DMI type 7, 27 bytes\nCache Information\n        Socket Designation: L2 - Cache\n        Configuration: Enabled, Not Socketed, Level 2\n        Operational Mode: Write Back\n        Location: Internal\n        Installed Size: 16384 kB\n        Maximum Size: 16384 kB\n        Supported SRAM Types:\n                Pipeline Burst\n        Installed SRAM Type: Pipeline Burst\n        Speed: 1 ns\n        Error Correction Type: Multi-bit ECC\n        System Type: Unified\n        Associativity: 8-way Set-associative\n\nHandle 0x003F, DMI type 7, 27 bytes\nCache Information\n        Socket Designation: L3 - Cache\n        Configuration: Enabled, Not Socketed, Level 3\n        Operational Mode: Write Back\n        Location: Internal\n        Installed Size: 131072 kB\n        Maximum Size: 131072 kB\n        Supported SRAM Types:\n                Pipeline Burst\n        Installed SRAM Type: Pipeline Burst\n        Speed: 1 ns\n        Error Correction Type: Multi-bit ECC\n        System Type: Unified\n        Associativity: 16-way Set-associative\n\n```","snippets":["`cat /proc/cpuinfo` returns general information about CPU, which includes\nper-code L1 cache."],"rawContent":"# Determine Cache Size\n\n`cat /proc/cpuinfo` returns general information about CPU, which includes\nper-code L1 cache.\n\n`sudo dmidecode -t cache` returns information about cache. E.g.,\n\n```shell\nHandle 0x003D, DMI type 7, 27 bytes\nCache Information\n        Socket Designation: L1 - Cache\n        Configuration: Enabled, Not Socketed, Level 1\n        Operational Mode: Write Back\n        Location: Internal\n        Installed Size: 2048 kB\n        Maximum Size: 2048 kB\n        Supported SRAM Types:\n                Pipeline Burst\n        Installed SRAM Type: Pipeline Burst\n        Speed: 1 ns\n        Error Correction Type: Multi-bit ECC\n        System Type: Unified\n        Associativity: 8-way Set-associative\n\nHandle 0x003E, DMI type 7, 27 bytes\nCache Information\n        Socket Designation: L2 - Cache\n        Configuration: Enabled, Not Socketed, Level 2\n        Operational Mode: Write Back\n        Location: Internal\n        Installed Size: 16384 kB\n        Maximum Size: 16384 kB\n        Supported SRAM Types:\n                Pipeline Burst\n        Installed SRAM Type: Pipeline Burst\n        Speed: 1 ns\n        Error Correction Type: Multi-bit ECC\n        System Type: Unified\n        Associativity: 8-way Set-associative\n\nHandle 0x003F, DMI type 7, 27 bytes\nCache Information\n        Socket Designation: L3 - Cache\n        Configuration: Enabled, Not Socketed, Level 3\n        Operational Mode: Write Back\n        Location: Internal\n        Installed Size: 131072 kB\n        Maximum Size: 131072 kB\n        Supported SRAM Types:\n                Pipeline Burst\n        Installed SRAM Type: Pipeline Burst\n        Speed: 1 ns\n        Error Correction Type: Multi-bit ECC\n        System Type: Unified\n        Associativity: 16-way Set-associative\n\n```\n","wordCount":201,"tags":[],"metadata":{},"created":"2024-06-04T10:04:33.829153604Z","modified":"2024-06-04T10:06:51.750014459Z","checksum":"140cc76ef951badb8825a8406d0b94235781a1d1d4a1dec4c1310abb3eec3381"},
    {"filename":"fps6sygk.md","filenameStem":"fps6sygk","path":"fps6sygk.md","absPath":"/home/khadd/mynotes/fps6sygk.md","title":"Disassembly is hard","link":"[[fps6sygk]]","lead":"More on disassembly techniques [[hxoovt97]].","body":"More on disassembly techniques [[hxoovt97]].\n\n## Why is it hard?\n\nIt needs to reliably recover control flow for any useful rewriting/reassembly.\nNote that some form of rewriting does not need this [[4yeegysq]].\n\nIt is hard because of the unintended instruction problem [[njh7pnzn]].","snippets":["More on disassembly techniques [[hxoovt97]]."],"rawContent":"# Disassembly is hard\n\nMore on disassembly techniques [[hxoovt97]].\n\n## Why is it hard?\n\nIt needs to reliably recover control flow for any useful rewriting/reassembly.\nNote that some form of rewriting does not need this [[4yeegysq]].\n\nIt is hard because of the unintended instruction problem [[njh7pnzn]].\n","wordCount":46,"tags":[],"metadata":{},"created":"2024-07-12T05:59:46.297464552Z","modified":"2024-12-13T08:46:20.960291601Z","checksum":"d5e743dd9ac6a805652e1163f291443b3e4add823e119e619ae24ebac89913ec"},
    {"filename":"utefektn.md","filenameStem":"utefektn","path":"utefektn.md","absPath":"/home/khadd/mynotes/utefektn.md","title":"Djstra notes","link":"[[utefektn]]","lead":"","body":"","snippets":[],"rawContent":"# Djstra notes\n\n\n","wordCount":3,"tags":[],"metadata":{},"created":"2024-12-09T04:15:21.692510489Z","modified":"2024-12-09T04:15:06.172051626Z","checksum":"eafbaa51dcb9c39d6e95428ef8692273ee59483bf057b389a1ffccb5d652e04f"},
    {"filename":"f25v3txq.md","filenameStem":"f25v3txq","path":"f25v3txq.md","absPath":"/home/khadd/mynotes/f25v3txq.md","title":"Do only what only you can do","link":"[[f25v3txq]]","lead":"The advice is given by Dijkstra when asked how to select a research topic.","body":"The advice is given by Dijkstra when asked how to select a research topic.","snippets":["The advice is given by Dijkstra when asked how to select a research topic."],"rawContent":"# Do only what only you can do\n\nThe advice is given by Dijkstra when asked how to select a research topic.\n","wordCount":22,"tags":[],"metadata":{},"created":"2023-05-26T02:17:58.496798368Z","modified":"2024-07-28T07:41:51.193272729Z","checksum":"f8837dc5fcdc9e88df4835e4452dbb3d3e1462c2f50282d1126b864cb67a1001"},
    {"filename":"xnhumnfb.md","filenameStem":"xnhumnfb","path":"xnhumnfb.md","absPath":"/home/khadd/mynotes/xnhumnfb.md","title":"Dynamic Loader as OS extension","link":"[[xnhumnfb]]","lead":"#os","body":"#os\n\nModern software are mostly delivered as dynamically linked code (up to 99% of\nbinaries in Ubuntu). Dynamic libraries are chosen due to their easy of\nmaintenance, and also to the of the fear of \"license contamination\" where some\nlicenses like GPL force statically linked code to also have the same license.\n\nAt the same time, if is often that the dynamic loader need to be modified, for\ninstance, to automatically harden binaries [@zhang2013control] and enforce\nsecurity policies like isolation [@ghosn2021enclosure,@sartakov2021cubicleos],\ndebloating [@quach2018debloating,@porter2020blankit] and rerandomization\n[@williams-king2016shuffler]. Adapting these modifications into the official\nloader is unlikely due to maintenance costs.\n\nAt the same time, the OS dynamic linker govern the operating system\n[@castes2023dynamic]. In dynamic program, the dynamic loader (pointed to by\n`.interp` section in the ELF) is always executed before the program (e.g., on\n`execve` system call). It has control over all program execution on the OS, and\ncan serve as a \"narrow waist\" to extend the OS.\n\nGiven these premise, a recent trend is to introduce extensible interfaces to the\nOS dynamic loader/linker [@castes2023dynamic,@ren2022dynamic]. iFed\n[@castes2023dynamic] adds a pass-based framework based on glibc loader\n([[26npf1xb]]) to implement transformations on the library. Spindl\n[@castes2023dynamic] reimagine the OS dynamic linker with facilities to\nimplement extensions.","snippets":["#os"],"rawContent":"# Dynamic Loader as OS extension\n\n#os\n\nModern software are mostly delivered as dynamically linked code (up to 99% of\nbinaries in Ubuntu). Dynamic libraries are chosen due to their easy of\nmaintenance, and also to the of the fear of \"license contamination\" where some\nlicenses like GPL force statically linked code to also have the same license.\n\nAt the same time, if is often that the dynamic loader need to be modified, for\ninstance, to automatically harden binaries [@zhang2013control] and enforce\nsecurity policies like isolation [@ghosn2021enclosure,@sartakov2021cubicleos],\ndebloating [@quach2018debloating,@porter2020blankit] and rerandomization\n[@williams-king2016shuffler]. Adapting these modifications into the official\nloader is unlikely due to maintenance costs.\n\nAt the same time, the OS dynamic linker govern the operating system\n[@castes2023dynamic]. In dynamic program, the dynamic loader (pointed to by\n`.interp` section in the ELF) is always executed before the program (e.g., on\n`execve` system call). It has control over all program execution on the OS, and\ncan serve as a \"narrow waist\" to extend the OS.\n\nGiven these premise, a recent trend is to introduce extensible interfaces to the\nOS dynamic loader/linker [@castes2023dynamic,@ren2022dynamic]. iFed\n[@castes2023dynamic] adds a pass-based framework based on glibc loader\n([[26npf1xb]]) to implement transformations on the library. Spindl\n[@castes2023dynamic] reimagine the OS dynamic linker with facilities to\nimplement extensions.\n","wordCount":210,"tags":["os"],"metadata":{},"created":"2024-07-23T07:05:00.509368454Z","modified":"2024-07-23T11:03:46.872331017Z","checksum":"3bc9889156769fa3902d9b046cf1f0bf38f9c6b93b3b231d053fc0df01736459"},
    {"filename":"nr81p506.md","filenameStem":"nr81p506","path":"nr81p506.md","absPath":"/home/khadd/mynotes/nr81p506.md","title":"EFI Stuff","link":"[[nr81p506]]","lead":"## Add boot order in UEFI shell\n```\n# List boot entries\nbcfg boot dump -b \n# Remove entry 0\nbcfg boot rm 0\nbcfg boot mv 2 3\n// Harcoding this to \nbcfg boot add 0 FS0:\\EFI\\BOOT\\BOOTX64.EFI \"unikraft\"\n```","body":"## Add boot order in UEFI shell\n```\n# List boot entries\nbcfg boot dump -b \n# Remove entry 0\nbcfg boot rm 0\nbcfg boot mv 2 3\n// Harcoding this to \nbcfg boot add 0 FS0:\\EFI\\BOOT\\BOOTX64.EFI \"unikraft\"\n```","snippets":["## Add boot order in UEFI shell\n```\n# List boot entries\nbcfg boot dump -b \n# Remove entry 0\nbcfg boot rm 0\nbcfg boot mv 2 3\n// Harcoding this to \nbcfg boot add 0 FS0:\\EFI\\BOOT\\BOOTX64.EFI \"unikraft\"\n```"],"rawContent":"# EFI Stuff\n\n## Add boot order in UEFI shell\n```\n# List boot entries\nbcfg boot dump -b \n# Remove entry 0\nbcfg boot rm 0\nbcfg boot mv 2 3\n// Harcoding this to \nbcfg boot add 0 FS0:\\EFI\\BOOT\\BOOTX64.EFI \"unikraft\"\n```\n\n\n","wordCount":43,"tags":[],"metadata":{},"created":"2023-09-22T11:04:45.490497794Z","modified":"2024-05-20T11:00:29.301946541Z","checksum":"edf9870fec31fe83a1ce5f23bec60f219d9ec0b992f5c57a93c56e1f102e5408"},
    {"filename":"9zudb41g.md","filenameStem":"9zudb41g","path":"9zudb41g.md","absPath":"/home/khadd/mynotes/9zudb41g.md","title":"Emulating x86 push and pop on ARM","link":"[[9zudb41g]]","lead":"#assembly #arm","body":"#assembly #arm\n\nAlthough there is no push and pop instructions, Arm support addressing modes\nthat can both update and address memory. This can be used to implement stack\npush and pop More concretely, post-indexing is used for push, and pre-indexing\nis used for pop\n\nPre-indexing update the address register _before_ the store, which is\nessentially the same as x86 push instruction that decrease the stack pointer,\nthen store the value.\n\n```asm\nstr x1, [sp, -#16]!\n```\n\nPre-index addressing update the address register after the store.\n\n```asm\nldr x1, [sp] #16\n```\n\nSource:\n\n- [Addressing Lab](https://www.cs.uregina.ca/Links/class-info/301/ARM-addressing/lecture.html)","snippets":["#assembly #arm"],"rawContent":"# Emulating x86 push and pop on ARM\n\n#assembly #arm\n\nAlthough there is no push and pop instructions, Arm support addressing modes\nthat can both update and address memory. This can be used to implement stack\npush and pop More concretely, post-indexing is used for push, and pre-indexing\nis used for pop\n\nPre-indexing update the address register _before_ the store, which is\nessentially the same as x86 push instruction that decrease the stack pointer,\nthen store the value.\n\n```asm\nstr x1, [sp, -#16]!\n```\n\nPre-index addressing update the address register after the store.\n\n```asm\nldr x1, [sp] #16\n```\n\nSource:\n\n- [Addressing Lab](https://www.cs.uregina.ca/Links/class-info/301/ARM-addressing/lecture.html)\n","wordCount":103,"tags":["assembly","arm"],"metadata":{},"created":"2023-05-23T08:55:30.365968581Z","modified":"2024-07-01T03:50:48.720290557Z","checksum":"be1263f52195228ce6e30b5ccdc8313ea4ad0693283be3b51114fa0735c808c2"},
    {"filename":"iemlvip1.md","filenameStem":"iemlvip1","path":"iemlvip1.md","absPath":"/home/khadd/mynotes/iemlvip1.md","title":"Enable Swap storage Arch","link":"[[iemlvip1]]","lead":"#resource #linux #arch","body":"#resource #linux #arch\n\n## Showing swap storages\n\n```bash\nswapon --show\n```\n\n## Creating swap\n\n### 1. Create a swap partition\n\nTools like gparted can be used to create a new partition.\n\n### 2. Enable it at swap\n\n```bash\nmkswap /dev/{swap partition}\n```\n\n## Enabling swap\n\n```bash\nswapon /dev/{swap partition}\n```","snippets":["#resource #linux #arch"],"rawContent":"# Enable Swap storage Arch\n\n#resource #linux #arch\n\n## Showing swap storages\n\n```bash\nswapon --show\n```\n\n## Creating swap\n\n### 1. Create a swap partition\n\nTools like gparted can be used to create a new partition.\n\n### 2. Enable it at swap\n\n```bash\nmkswap /dev/{swap partition}\n```\n\n## Enabling swap\n\n```bash\nswapon /dev/{swap partition}\n```\n","wordCount":55,"tags":["linux","resource","arch"],"metadata":{},"created":"2024-06-11T04:36:22.10179123Z","modified":"2024-06-11T04:40:04.582122041Z","checksum":"67588d21b2d121c43bb6a2df14fcb47797588270da2c44e730754a3262c1f592"},
    {"filename":"jcoxpgnk.md","filenameStem":"jcoxpgnk","path":"jcoxpgnk.md","absPath":"/home/khadd/mynotes/jcoxpgnk.md","title":"Exitless system calls for SGX","link":"[[jcoxpgnk]]","lead":"#sgx #tee #system-call #performance #rpc","body":"#sgx #tee #system-call #performance #rpc\n\nTo perform system calls in SGX, the enclave must perform enclave exit and enter through `EEXIT`, `EENTER`. It is found that these two instructions have heavy overheads of about 3,300 and 3,800 cycles @orenbach2017eleos. This is much higher than the overheads of a normal system call, about 250 cycles.\n\nAnother cost of SGX is due to page fault, since in an enclave exit also need to be triggered.\n\n# Elos\n## RPC for system calls\n@orenbach2017eleos proposed using RPC instead to serve system calls on an enclave. The system employs a separated thread in the untrusted part of the application to serve system call. Ocalls in SGX for serving system call is then replaced with RPC to the system call-serving threads. \n\nMoreover, the system uses Intel Cache Allocation Technology (CAT) to allocate only 25% of the cache to the worker thread, while keeping 75% cache. This avoids LLC pollution.\n\n@orenbach2020autarky, @orenbach2019cosmix also adapts this.\n\n## User-managed virtual memory \nElos also includes a fine-grained page management system to avoid enclave exit on page faults. The idea is to cache the commonly used pages in the untrusted memory, and serve from it first, instead of relying on the OS.\n\n## Related note\n[[taztx2mo]]","snippets":["#sgx #tee #system-call #performance #rpc"],"rawContent":"# Exitless system calls for SGX\n#sgx #tee #system-call #performance #rpc\n\nTo perform system calls in SGX, the enclave must perform enclave exit and enter through `EEXIT`, `EENTER`. It is found that these two instructions have heavy overheads of about 3,300 and 3,800 cycles @orenbach2017eleos. This is much higher than the overheads of a normal system call, about 250 cycles.\n\nAnother cost of SGX is due to page fault, since in an enclave exit also need to be triggered.\n\n# Elos\n## RPC for system calls\n@orenbach2017eleos proposed using RPC instead to serve system calls on an enclave. The system employs a separated thread in the untrusted part of the application to serve system call. Ocalls in SGX for serving system call is then replaced with RPC to the system call-serving threads. \n\nMoreover, the system uses Intel Cache Allocation Technology (CAT) to allocate only 25% of the cache to the worker thread, while keeping 75% cache. This avoids LLC pollution.\n\n@orenbach2020autarky, @orenbach2019cosmix also adapts this.\n\n## User-managed virtual memory \nElos also includes a fine-grained page management system to avoid enclave exit on page faults. The idea is to cache the commonly used pages in the untrusted memory, and serve from it first, instead of relying on the OS.\n\n## Related note\n[[taztx2mo]]\n","wordCount":212,"tags":["sgx","tee","system-call","performance","rpc"],"metadata":{},"created":"2023-06-12T04:34:51.342439815Z","modified":"2024-05-20T11:00:55.665146783Z","checksum":"acfe3b5b48d7f9f2629755a2c88707f9e110964bcf220ce3896847af9928a8d0"},
    {"filename":"07bi6une.md","filenameStem":"07bi6une","path":"07bi6une.md","absPath":"/home/khadd/mynotes/07bi6une.md","title":"Exokernel","link":"[[07bi6une]]","lead":"Exokernel is a kernel architecture that maximize application direct access to\nthe hardware, while removing all the cost of kernel abstractions. In this model,\napplication are implemented as **library operating systems** that implement all\nthe abstractions. The exokernel tasks is to ensure safe multiplexing of hardware\nresources by allocating resources to the applications.","body":"Exokernel is a kernel architecture that maximize application direct access to\nthe hardware, while removing all the cost of kernel abstractions. In this model,\napplication are implemented as **library operating systems** that implement all\nthe abstractions. The exokernel tasks is to ensure safe multiplexing of hardware\nresources by allocating resources to the applications.\n\nThe original exokernel paper [@exokernel] describes a _secure binding_ mechanism\nthat bind the application to an instance of resource, such that the resource may\nbe accessed at runtime without checking costs. This mechanism is highly\nresource-specific and is unlikely generalizable.\n\n- For memory, a binding may be made by caching the address translation inside\n  the TLB/page table.\n- For networking, the exokernel proposed using packet filtering to deliver\n  packets to the correct applications.\n- File system might be exposed as in-memory pages.\n- Some specific hardware provide binding between the owner and the resource,\n  e.g., frame buffer hardware.\n\nThis concept is different from microkernels [[sn99wrm0]] in that there is almost\nno abstractions in exokernels. However, implementation of the secure binding\nmechanisms is very dependent on the type of resource. It is unclear if the\napproach results in a smaller TCB compared to microkernels. E.g., a network\nfilter is required in the kernel for multiplexing of networking.","snippets":["Exokernel is a kernel architecture that maximize application direct access to\nthe hardware, while removing all the cost of kernel abstractions. In this model,\napplication are implemented as **library operating systems** that implement all\nthe abstractions. The exokernel tasks is to ensure safe multiplexing of hardware\nresources by allocating resources to the applications."],"rawContent":"# Exokernel\n\nExokernel is a kernel architecture that maximize application direct access to\nthe hardware, while removing all the cost of kernel abstractions. In this model,\napplication are implemented as **library operating systems** that implement all\nthe abstractions. The exokernel tasks is to ensure safe multiplexing of hardware\nresources by allocating resources to the applications.\n\nThe original exokernel paper [@exokernel] describes a _secure binding_ mechanism\nthat bind the application to an instance of resource, such that the resource may\nbe accessed at runtime without checking costs. This mechanism is highly\nresource-specific and is unlikely generalizable.\n\n- For memory, a binding may be made by caching the address translation inside\n  the TLB/page table.\n- For networking, the exokernel proposed using packet filtering to deliver\n  packets to the correct applications.\n- File system might be exposed as in-memory pages.\n- Some specific hardware provide binding between the owner and the resource,\n  e.g., frame buffer hardware.\n\nThis concept is different from microkernels [[sn99wrm0]] in that there is almost\nno abstractions in exokernels. However, implementation of the secure binding\nmechanisms is very dependent on the type of resource. It is unclear if the\napproach results in a smaller TCB compared to microkernels. E.g., a network\nfilter is required in the kernel for multiplexing of networking.\n","wordCount":211,"tags":[],"metadata":{},"created":"2024-12-23T06:05:07.164137174Z","modified":"2024-12-23T06:18:13.283370393Z","checksum":"c0a02a8e8c9a7b5bdc167bbd7bd61d0490da26d039885eeed690993594b97905"},
    {"filename":"ncfh611p.md","filenameStem":"ncfh611p","path":"ncfh611p.md","absPath":"/home/khadd/mynotes/ncfh611p.md","title":"Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization","link":"[[ncfh611p]]","lead":"#literature #side-channel #sev @li2019exploiting","body":"#literature #side-channel #sev @li2019exploiting\n\n# Summary\n\nThe paper proposes an attack method that exploits the unprotected I/O operations\nin AMD SEV. Here, _unprotected_ means that the I/O operations (MMIO and DMA)\nmust be performed on unencrypted memory that is visible by the hypervisor. The\npaper shows that by replacing ciphertext blocks in the VM memory, the hypervisor\ncan create trick the VM into encrypting and decrypting arbitrary data, hence\nencryption/decryption oracles.\n\n# Attack overview\n\n## Encryption oracle\n\nThe target of the attack is an SSH service running inside a cVM. While the ssh\npackets are encrypted, due to unprotected I/O [[zmt276jl]], the hypervisor can\nobserve and modify the TCP and IP headers.\n\nBriefly, the attack finds the _encrypted_ page that contains the packet to be\nsent over the I/O channel. It then replaces the encrypted header (16B) with\nanother encrypted block of data, right before the packet is copied into the\nunencrypted I/O memory observable by the hypervisor. Using this method, a\ndecryption oracle is built that allows the decryption of any memory block.\n\nThe attack is performed in three steps: pattern matching, ciphertext\nreplacement, and packet recovery.\n\n### Pattern matching\n\nPattern matching stage uses the nested page fault side-channel [[qq4qcbos]] to\ndetermine which pages are being accessed when the VM serves the SSH packet. The\nhypervisor first sends an SSH packet to the VM, then clears the present bits in\nthe NPT PTEs. It collects the sequences of page fault accesses to build a\n_signature_ of the page accessed from the time of receiving the request, to the\ntime right before sending the packet. It then uses this signature to determine\nthe page containing the `sk_buff` structure that contains the packet.\n\n### Ciphertext replacement\n\nCiphertext replacement replaces the ciphertext inside the header of the SSH\npacket and recovers the plaintext result. Since SEV's memory encryption applies\na teak function based on the physical address, steps need to be done to recover\nplaintext: Assuming the ciphertext $c$ is copied from the address $P_c$.\nPlaintext must be obtained by:\n\n$m = d \\oplus  T(hPA((P_{priv}+16))/16*16) \\oplus T(P_c)$\n\nWhere $d$ is the decrypted text of $c$, T is the tweak function. Essentially,\nthis negates the effect of the teak of the current address and applies the teak\nof the target location.\n\n### Plaintext recovery\n\nThe original plaintext must be recovered so that the attack is stealthy. Since\nthe attack only modifies the header of the SSH packet, which is public, it only\nneeds to predict the content of the current header (replaced by the attack).\nHere, the ID of the packet is increased by 1 after each response, so it adds\nthat to the response's header.\n\n# Mitigation\n\nThe attack in this paper is mitigated by SEV-SNP since the hypervisor cannot\nwrite into encrypted memory anymore.\n\nSince SNP did not exist at the time, the paper also suggests other mitigations.\nOne of them is to make the VM encrypts the _entire_ packets, and use a trusted\nproxy server to decrypt the packets, before forwarding them to the client.","snippets":["#literature #side-channel #sev @li2019exploiting"],"rawContent":"# Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization\n\n#literature #side-channel #sev @li2019exploiting\n\n# Summary\n\nThe paper proposes an attack method that exploits the unprotected I/O operations\nin AMD SEV. Here, _unprotected_ means that the I/O operations (MMIO and DMA)\nmust be performed on unencrypted memory that is visible by the hypervisor. The\npaper shows that by replacing ciphertext blocks in the VM memory, the hypervisor\ncan create trick the VM into encrypting and decrypting arbitrary data, hence\nencryption/decryption oracles.\n\n# Attack overview\n\n## Encryption oracle\n\nThe target of the attack is an SSH service running inside a cVM. While the ssh\npackets are encrypted, due to unprotected I/O [[zmt276jl]], the hypervisor can\nobserve and modify the TCP and IP headers.\n\nBriefly, the attack finds the _encrypted_ page that contains the packet to be\nsent over the I/O channel. It then replaces the encrypted header (16B) with\nanother encrypted block of data, right before the packet is copied into the\nunencrypted I/O memory observable by the hypervisor. Using this method, a\ndecryption oracle is built that allows the decryption of any memory block.\n\nThe attack is performed in three steps: pattern matching, ciphertext\nreplacement, and packet recovery.\n\n### Pattern matching\n\nPattern matching stage uses the nested page fault side-channel [[qq4qcbos]] to\ndetermine which pages are being accessed when the VM serves the SSH packet. The\nhypervisor first sends an SSH packet to the VM, then clears the present bits in\nthe NPT PTEs. It collects the sequences of page fault accesses to build a\n_signature_ of the page accessed from the time of receiving the request, to the\ntime right before sending the packet. It then uses this signature to determine\nthe page containing the `sk_buff` structure that contains the packet.\n\n### Ciphertext replacement\n\nCiphertext replacement replaces the ciphertext inside the header of the SSH\npacket and recovers the plaintext result. Since SEV's memory encryption applies\na teak function based on the physical address, steps need to be done to recover\nplaintext: Assuming the ciphertext $c$ is copied from the address $P_c$.\nPlaintext must be obtained by:\n\n$m = d \\oplus  T(hPA((P_{priv}+16))/16*16) \\oplus T(P_c)$\n\nWhere $d$ is the decrypted text of $c$, T is the tweak function. Essentially,\nthis negates the effect of the teak of the current address and applies the teak\nof the target location.\n\n### Plaintext recovery\n\nThe original plaintext must be recovered so that the attack is stealthy. Since\nthe attack only modifies the header of the SSH packet, which is public, it only\nneeds to predict the content of the current header (replaced by the attack).\nHere, the ID of the packet is increased by 1 after each response, so it adds\nthat to the response's header.\n\n# Mitigation\n\nThe attack in this paper is mitigated by SEV-SNP since the hypervisor cannot\nwrite into encrypted memory anymore.\n\nSince SNP did not exist at the time, the paper also suggests other mitigations.\nOne of them is to make the VM encrypts the _entire_ packets, and use a trusted\nproxy server to decrypt the packets, before forwarding them to the client.\n","wordCount":515,"tags":["literature","sev","side-channel"],"metadata":{},"created":"2024-05-22T08:24:03.286904042Z","modified":"2024-06-20T09:18:47.577849095Z","checksum":"4a9d642f4770641a88da32fdc2d6d0a1ac2e4c5224b183c7ec057bd92f93beb7"},
    {"filename":"a6uh87al.md","filenameStem":"a6uh87al","path":"a6uh87al.md","absPath":"/home/khadd/mynotes/a6uh87al.md","title":"Extending on an idea","link":"[[a6uh87al]]","lead":"#writing","body":"#writing\n\nSometimes it is hard to *determine what to write* for a particular idea. Using *frameworks* would helps in such cases. \n\nGenerally, following prompts helps: \n- Answering What, why, how\n- Give an example\n- What is this idea similar to\n- What contradicts this idea\n\nKeep in mind:\n- Why is this an important issue\n- Why reader has to know about this\n\n\n\n\nOther note taking frameworks might helps, such as: \n- [[dyx2t4oz]]\n- [[zz3cedu0]]","snippets":["#writing"],"rawContent":"# Extending on an idea\n#writing\n\nSometimes it is hard to *determine what to write* for a particular idea. Using *frameworks* would helps in such cases. \n\nGenerally, following prompts helps: \n- Answering What, why, how\n- Give an example\n- What is this idea similar to\n- What contradicts this idea\n\nKeep in mind:\n- Why is this an important issue\n- Why reader has to know about this\n\n\n\n\nOther note taking frameworks might helps, such as: \n- [[dyx2t4oz]]\n- [[zz3cedu0]]\n\n\n","wordCount":81,"tags":["writing"],"metadata":{},"created":"2023-05-22T02:06:14.449520757Z","modified":"2023-05-19T04:07:16.005118828Z","checksum":"7e51df8c7dabc81cf1bd782e69245187c898bf067f8079d8dfc18b4dc2a08764"},
    {"filename":"b8dhhxft.md","filenameStem":"b8dhhxft","path":"b8dhhxft.md","absPath":"/home/khadd/mynotes/b8dhhxft.md","title":"Flat vs. hierarchical notes","link":"[[b8dhhxft]]","lead":"#fleeting","body":"#fleeting\n\n# Flat notes\nFlat notes make use of hashtag and linking for navigation\n\n## Arguments for flat notes\nFlat notes make every notes equally important.\n\nFlat notes is easier for linking.\n\nEasy to maintain. You can create a a grouping of concepts by just inserting a new hashtag.\n\n## Argument agaisnt\nHashtags can be cluttering.\n\nThis is related to a good hashtag system.\n\n# Hierarchical notes\nHierarchical notes group notes using folders/directories. It is great when you use a file system to maintain your zettel.\n\nHierarchical notes is good when the content within the directory is \n(1) well-maintained, \n(2) well-separated: though, this kind of go against the linking your thinking ideologies. \n(3) you need multiple \n\n## Argument for hierarchical notes\nVisually separated in the file system.\n\nEasy to move around. Though, you rarely need to move your notes.\n\nSupport multiple layers of grouping.\n\n```\n- Group A\n  - Note a.1  \n  - Note a.2\n  - Group A.1\n    - note A.1.1 \n- Group B\n  - Note b.1\n```\n\n## Arguments against\nYour conceptual grouping of notes might change over time.\n\nLinking requires an extra indirection (`\\[\\[directory/note\\]\\]`). This might be dependent on the note manager you are using.\n\n\n\n# Conclusion\n\nIf you are sure the grouping of notes is permanent, and you want to clearly and visually separate those notes from the rest, using a directory is fine. For instance, generally Zettlekasten gurus recommends you to separate fleeting, literature, and permanent notes.\n\nFor notes where their grouping might change overtime, it is best to use flat notes plus hashtags.","snippets":["#fleeting"],"rawContent":"# Flat vs. hierarchical notes\n#fleeting\n\n# Flat notes\nFlat notes make use of hashtag and linking for navigation\n\n## Arguments for flat notes\nFlat notes make every notes equally important.\n\nFlat notes is easier for linking.\n\nEasy to maintain. You can create a a grouping of concepts by just inserting a new hashtag.\n\n## Argument agaisnt\nHashtags can be cluttering.\n\nThis is related to a good hashtag system.\n\n# Hierarchical notes\nHierarchical notes group notes using folders/directories. It is great when you use a file system to maintain your zettel.\n\nHierarchical notes is good when the content within the directory is \n(1) well-maintained, \n(2) well-separated: though, this kind of go against the linking your thinking ideologies. \n(3) you need multiple \n\n## Argument for hierarchical notes\nVisually separated in the file system.\n\nEasy to move around. Though, you rarely need to move your notes.\n\nSupport multiple layers of grouping.\n\n```\n- Group A\n  - Note a.1  \n  - Note a.2\n  - Group A.1\n    - note A.1.1 \n- Group B\n  - Note b.1\n```\n\n## Arguments against\nYour conceptual grouping of notes might change over time.\n\nLinking requires an extra indirection (`\\[\\[directory/note\\]\\]`). This might be dependent on the note manager you are using.\n\n\n\n# Conclusion\n\nIf you are sure the grouping of notes is permanent, and you want to clearly and visually separate those notes from the rest, using a directory is fine. For instance, generally Zettlekasten gurus recommends you to separate fleeting, literature, and permanent notes.\n\nFor notes where their grouping might change overtime, it is best to use flat notes plus hashtags. \n\n\n","wordCount":262,"tags":["fleeting"],"metadata":{},"created":"2024-05-23T06:27:21.345093568Z","modified":"2023-05-26T03:24:45.528578304Z","checksum":"1fe224eda1d1b71c80dbdd67ed9111497e5f5120d18e3e6f7770d72d4ef9343b"},
    {"filename":"nitymocd.md","filenameStem":"nitymocd","path":"nitymocd.md","absPath":"/home/khadd/mynotes/nitymocd.md","title":"Force function inline in LLVM","link":"[[nitymocd]]","lead":"#llvm #compiler","body":"#llvm #compiler\n\nInlining with attributes, e.g., `__attribute__((__always_inline__))` is more\nlike a _suggestion_ to the compiler and does not always work.\n\n`Lib/Transform/Utils/Cloning.h` provide a function call\n`InlineFunction(CallInst, ...)` when invoked it would try to inline the call\ninstruction. This way, a function call site may be reliably inlined.","snippets":["#llvm #compiler"],"rawContent":"# Force function inline in LLVM\n\n#llvm #compiler\n\nInlining with attributes, e.g., `__attribute__((__always_inline__))` is more\nlike a _suggestion_ to the compiler and does not always work.\n\n`Lib/Transform/Utils/Cloning.h` provide a function call\n`InlineFunction(CallInst, ...)` when invoked it would try to inline the call\ninstruction. This way, a function call site may be reliably inlined.\n","wordCount":53,"tags":["llvm","compiler"],"metadata":{},"created":"2023-05-23T08:51:18.357019284Z","modified":"2024-06-28T08:35:28.890052916Z","checksum":"d5af1424b44be3b35543958900b155af2b8d8f0acce3ccc70bc160e6c901fe99"},
    {"filename":"l56og3zt.md","filenameStem":"l56og3zt","path":"l56og3zt.md","absPath":"/home/khadd/mynotes/l56og3zt.md","title":"Foreach pattern in C macro","link":"[[l56og3zt]]","lead":"#c #programming","body":"#c #programming\n\nYou can define a foreach macro like this. Useful when iterating over custom\nstructures.\n\n```c\n\n#define FOREACH(var) for (var = 0; var \u003c PREDEFINED_LEN; var++)\n\n#define FOREACH(var, len) for (var = 0; var \u003c len; var++)\n\n#define FOREACH_TYPE_T(ptr)                                                    \\\n  for (ptr = begin(); ptr != end(); ptr = get_next_ptr(ptr))\n```","snippets":["#c #programming"],"rawContent":"# Foreach pattern in C macro\n\n#c #programming\n\nYou can define a foreach macro like this. Useful when iterating over custom\nstructures.\n\n```c\n\n#define FOREACH(var) for (var = 0; var \u003c PREDEFINED_LEN; var++)\n\n#define FOREACH(var, len) for (var = 0; var \u003c len; var++)\n\n#define FOREACH_TYPE_T(ptr)                                                    \\\n  for (ptr = begin(); ptr != end(); ptr = get_next_ptr(ptr))\n```\n","wordCount":58,"tags":["programming","c"],"metadata":{},"created":"2023-07-12T06:13:13.191076529Z","modified":"2024-06-28T07:53:27.08218946Z","checksum":"7eda6450eea15cb64139e97fc991357bbc45908a83b2dac0c8eccb586b5e9b09"},
    {"filename":"28uzj27u.md","filenameStem":"28uzj27u","path":"28uzj27u.md","absPath":"/home/khadd/mynotes/28uzj27u.md","title":"Fork is an outdated OS abstraction","link":"[[28uzj27u]]","lead":"#os","body":"#os\n\nThe `fork` system call clone the context of a process. In the past, `fork` is\nuseful to quickly setup isolated processes.\n\nA recent opinion is that providing `fork()` as a first-class abstraction in OSes\nis more harmful than good [@baumann2019fork] due to its bad\nscalability/efficiency and difficulty in supporting single-address-space OSes.\n\nScalability: Fork is wasteful in its resource useage.\n\nNecessity: `fork()` is not even really essential, since most modern applications\nthat use fork (Apache, Chrome, PostgreSQL) have Windows port that does not use\nfork [@baumann2019fork].\n\nStill, some workloads, nginx, Redis, greatly benefits from it\n[@lupu2023nephele].","snippets":["#os"],"rawContent":"# Fork is an outdated OS abstraction\n\n#os\n\nThe `fork` system call clone the context of a process. In the past, `fork` is\nuseful to quickly setup isolated processes.\n\nA recent opinion is that providing `fork()` as a first-class abstraction in OSes\nis more harmful than good [@baumann2019fork] due to its bad\nscalability/efficiency and difficulty in supporting single-address-space OSes.\n\nScalability: Fork is wasteful in its resource useage.\n\nNecessity: `fork()` is not even really essential, since most modern applications\nthat use fork (Apache, Chrome, PostgreSQL) have Windows port that does not use\nfork [@baumann2019fork].\n\nStill, some workloads, nginx, Redis, greatly benefits from it\n[@lupu2023nephele].\n","wordCount":103,"tags":["os"],"metadata":{},"created":"2024-06-18T09:42:27.023814684Z","modified":"2024-11-08T12:23:34.94837231Z","checksum":"2d09817488919048acd555551becd90f67f62b595791a7b1a101bc591c132ce4"},
    {"filename":"833m9lxc.md","filenameStem":"833m9lxc","path":"833m9lxc.md","absPath":"/home/khadd/mynotes/833m9lxc.md","title":"From reading to notes","link":"[[833m9lxc]]","lead":"#reading #notes","body":"#reading #notes\n\n[evergreen] describes a 5-step iterative process.\n\n1. Write broad notes, capturing the big idea\n2. Write finer-grained notes\n3. Connect. Find previous notes and link them together\n4. Revisit the broad notes with improved understanding from detailed notes\n5. Repeat\n\n## Zettelkasten style\n\nFrom [zettel]:\n\n- Taking note: Write short, atomic notes during the reading.\n- Processing notes:\n  1. Pull notes from the book\n  2. Cluster notes, let overview emerges\n  3. Write notes from clusters\n     1. General note per cluster\n     2. Detailed notes\n     3. Improve general notes with detail notes\n\n## References\n\n[evergreen]:\n\thttps://notes.andymatuschak.org/How_to_process_reading_annotations_into_evergreen_notes\n[zettel]: https://zettelkasten.de/posts/create-zettel-from-reading-notes/","snippets":["#reading #notes"],"rawContent":"# From reading to notes\n\n#reading #notes\n\n[evergreen] describes a 5-step iterative process.\n\n1. Write broad notes, capturing the big idea\n2. Write finer-grained notes\n3. Connect. Find previous notes and link them together\n4. Revisit the broad notes with improved understanding from detailed notes\n5. Repeat\n\n## Zettelkasten style\n\nFrom [zettel]:\n\n- Taking note: Write short, atomic notes during the reading.\n- Processing notes:\n  1. Pull notes from the book\n  2. Cluster notes, let overview emerges\n  3. Write notes from clusters\n     1. General note per cluster\n     2. Detailed notes\n     3. Improve general notes with detail notes\n\n## References\n\n[evergreen]:\n\thttps://notes.andymatuschak.org/How_to_process_reading_annotations_into_evergreen_notes\n[zettel]: https://zettelkasten.de/posts/create-zettel-from-reading-notes/\n","wordCount":103,"tags":["reading","notes"],"metadata":{},"created":"2024-07-03T07:19:31.636914268Z","modified":"2024-07-03T07:30:37.940288315Z","checksum":"40f769ef9d256a8c567d973c1a475b624351a3d78009f6b3e4cd14cc383cb7e9"},
    {"filename":"j111e16c.md","filenameStem":"j111e16c","path":"j111e16c.md","absPath":"/home/khadd/mynotes/j111e16c.md","title":"Getting binary function size","link":"[[j111e16c]]","lead":"For some reason gettting the function size from a ELF is not as straightfoward\nas it seems. You may use the `nm` tool with the `--print-size` option (`-S`).","body":"For some reason gettting the function size from a ELF is not as straightfoward\nas it seems. You may use the `nm` tool with the `--print-size` option (`-S`).\n\nAdditionally, you may use `-t d` (print in decimal) to show decimal values.\n\n```\nnm -S -t d path/to/elf\n```","snippets":["For some reason gettting the function size from a ELF is not as straightfoward\nas it seems. You may use the `nm` tool with the `--print-size` option (`-S`)."],"rawContent":"# Getting binary function size\n\nFor some reason gettting the function size from a ELF is not as straightfoward\nas it seems. You may use the `nm` tool with the `--print-size` option (`-S`).\n\nAdditionally, you may use `-t d` (print in decimal) to show decimal values.\n\n```\nnm -S -t d path/to/elf\n```\n","wordCount":53,"tags":[],"metadata":{},"created":"2024-09-05T08:53:33.564753132Z","modified":"2024-09-06T04:08:07.000042757Z","checksum":"986de0f3940f2ca7268acf51d364e6d116f8c5f7daa7aa1b51c595d92c7c2125"},
    {"filename":"xrcwotlz.md","filenameStem":"xrcwotlz","path":"xrcwotlz.md","absPath":"/home/khadd/mynotes/xrcwotlz.md","title":"Git Commit Log is a Manual","link":"[[xrcwotlz]]","lead":"#git #programming","body":"#git #programming\n\nThe commit log is not only a history into the project. It can be seen as a\nmanual of how to do something.\n\n- **PR**: How to do X. E.g., X = \"implementing a virtio driver\".\n- **Commit titles**: the steps must be taken. E.g.,\n  - \u003e virtio_bus: Add header for `virtio` rings definitions\n  - \u003e virtio: Implement PCI capabilities bus discovering\n  - \u003e virtio_pci: Implement `virtio_pci` driver\n- **Detailed commit text**: Detailed explanations.\n- **Code diff**: How it is done.\n\nSo, keep your git log clean.\n\n## Implications\n\n- AI models can leverage this for better in-context learning ([Shawn]).\n- Also, segmenting your git commits into PRs achieve this goal better.\n\n## Reference\n\n- [Shawn]:\n  \thttps://x.com/narphorium/status/1806778340323512472?s=09\u0026t=NBsImYx9vO2InQpJtca9zQ","snippets":["#git #programming"],"rawContent":"# Git Commit Log is a Manual\n\n#git #programming\n\nThe commit log is not only a history into the project. It can be seen as a\nmanual of how to do something.\n\n- **PR**: How to do X. E.g., X = \"implementing a virtio driver\".\n- **Commit titles**: the steps must be taken. E.g.,\n  - \u003e virtio_bus: Add header for `virtio` rings definitions\n  - \u003e virtio: Implement PCI capabilities bus discovering\n  - \u003e virtio_pci: Implement `virtio_pci` driver\n- **Detailed commit text**: Detailed explanations.\n- **Code diff**: How it is done.\n\nSo, keep your git log clean.\n\n## Implications\n\n- AI models can leverage this for better in-context learning ([Shawn]).\n- Also, segmenting your git commits into PRs achieve this goal better.\n\n## Reference\n\n- [Shawn]:\n  \thttps://x.com/narphorium/status/1806778340323512472?s=09\u0026t=NBsImYx9vO2InQpJtca9zQ\n","wordCount":126,"tags":["programming","git"],"metadata":{},"created":"2024-07-01T01:05:38.876747981Z","modified":"2024-07-23T06:54:21.43995099Z","checksum":"e6dab0a142c7c8058daca0d38186e07f9db1a6d3c2870123c0c1d98f3c9766ca"},
    {"filename":"jgb6g5qx.md","filenameStem":"jgb6g5qx","path":"jgb6g5qx.md","absPath":"/home/khadd/mynotes/jgb6g5qx.md","title":"GitJournal: The missing piece to my note taking workflow","link":"[[jgb6g5qx]]","lead":"#blog","body":"#blog\n\n## Some Background\n\nI have been using [zk](https://github.com/zk-org/zk) for taking notes in plain\nmarkdown. While it lacks features compared to the well-known Obsidian, I prefer\nit over tools like Obsidian for the following reasons:\n\n- Using your preferred editor is possible. I am an avid\n  [Neovim](https://neovim.io/) user and would prefer to do all of my writing\n  with Vim key bindings if possible. I like it so much that I even created a\n  [language server](https://github.com/kha-dinh/bibli-ls) to support BibTeX\n  citations in my notes.\n\n- Terminal-first workflow. zk's nice [fzf](https://github.com/junegunn/fzf)\n  integration allows me to access my notes with just a single keyboard shortcut.\n  This enables me to avoid using a mouse in general.\n\n- Lightweight design. I like that zk provides the bare minimum tools for looking\n  up your notes and providing editor-agnostic diagnostics highlighting through\n  its LSP protocol. This enables me to quickly set up the note-taking workflow\n  on any new desktop.\n\nFor maintaining my notes, I have a private GitHub repo that I regularly push to.\nI prefer this to cloud synchronization due to its simplicity.\n\n## Complaints\n\nOne of the pet peeves I have with the terminal + git workflow is that it is\nfundamentally difficult to **synchronize** and **access** your notes on mobile\ndevices. All available options are not ideal.\n\nFor synchronization:\n\n- Upload your notes to a cloud service and use\n  [syncthing](https://syncthing.net/) to automatically synchronize. This means\n  you must keep your notes in two places.\n\nFor reading/editing:\n\n- Using a terminal emulator like [termux](https://termux.dev/en/). A keyboard is\n  required which is only sometimes available on the go, and setting up is still\n  a hassle.\n- Directly accessing your notes through GitHub's web interface. This results in\n  a terrible editing experience.\n\nIn contrast, Obsidian has a dedicated [mobile app](https://obsidian.md/mobile)\nthat streamlines the experience on both desktop and mobile phones. Obsidian\nusers might use Obsidian's cloud service or the Obsidian git plugin to maintain\ntheir notes.\n\n## GitJournal\n\nRecently, I encountered the\n[GitJournal](https://github.com/GitJournal/GitJournal) mobile application that\nsolves the aforementioned issues. It simplifies notes synchronization and\nediting into a single mobile app:\n\n- Markdown preview/editing support. The app prioritizes support for markdown\n  notes in plaintext.\n- Simplified git synchronization at the push of a button.\n- _Links between notes work_! I can just press on a link, e.g., `[[AkgiO4ax]]`,\n  to visit the note. This is partly thanks to zk's use of the file name (a\n  random UUID) as notes link.\n\nWhile there are still a few minor issues, I can live with them:\n\n- The pricing for pro features is a bit steep, so I need some time to decide if\n  it's worth it.\n- Note UUID generation scheme doesn't match with my zk's note ID system. Still,\n  I can edit them when I get to my desktop.\n\n## Conclusion\n\nGitJournal has filled a crucial gap in my note-taking system, allowing me to\nmaintain the terminal-first, git-based workflow I love on the desktop while\ngaining seamless mobile access. It proves that we don't always need to\ncompromise between power-user preferences and mobile convenience. For those who\nprefer lightweight, text-based note-taking tools like zk but want better mobile\nintegration, GitJournal offers an elegant solution that respects the simplicity\nand flexibility of plain markdown files while making them accessible on the go.","snippets":["#blog"],"rawContent":"---\ndate:\n---\n\n# GitJournal: The missing piece to my note taking workflow\n\n#blog\n\n## Some Background\n\nI have been using [zk](https://github.com/zk-org/zk) for taking notes in plain\nmarkdown. While it lacks features compared to the well-known Obsidian, I prefer\nit over tools like Obsidian for the following reasons:\n\n- Using your preferred editor is possible. I am an avid\n  [Neovim](https://neovim.io/) user and would prefer to do all of my writing\n  with Vim key bindings if possible. I like it so much that I even created a\n  [language server](https://github.com/kha-dinh/bibli-ls) to support BibTeX\n  citations in my notes.\n\n- Terminal-first workflow. zk's nice [fzf](https://github.com/junegunn/fzf)\n  integration allows me to access my notes with just a single keyboard shortcut.\n  This enables me to avoid using a mouse in general.\n\n- Lightweight design. I like that zk provides the bare minimum tools for looking\n  up your notes and providing editor-agnostic diagnostics highlighting through\n  its LSP protocol. This enables me to quickly set up the note-taking workflow\n  on any new desktop.\n\nFor maintaining my notes, I have a private GitHub repo that I regularly push to.\nI prefer this to cloud synchronization due to its simplicity.\n\n## Complaints\n\nOne of the pet peeves I have with the terminal + git workflow is that it is\nfundamentally difficult to **synchronize** and **access** your notes on mobile\ndevices. All available options are not ideal.\n\nFor synchronization:\n\n- Upload your notes to a cloud service and use\n  [syncthing](https://syncthing.net/) to automatically synchronize. This means\n  you must keep your notes in two places.\n\nFor reading/editing:\n\n- Using a terminal emulator like [termux](https://termux.dev/en/). A keyboard is\n  required which is only sometimes available on the go, and setting up is still\n  a hassle.\n- Directly accessing your notes through GitHub's web interface. This results in\n  a terrible editing experience.\n\nIn contrast, Obsidian has a dedicated [mobile app](https://obsidian.md/mobile)\nthat streamlines the experience on both desktop and mobile phones. Obsidian\nusers might use Obsidian's cloud service or the Obsidian git plugin to maintain\ntheir notes.\n\n## GitJournal\n\nRecently, I encountered the\n[GitJournal](https://github.com/GitJournal/GitJournal) mobile application that\nsolves the aforementioned issues. It simplifies notes synchronization and\nediting into a single mobile app:\n\n- Markdown preview/editing support. The app prioritizes support for markdown\n  notes in plaintext.\n- Simplified git synchronization at the push of a button.\n- _Links between notes work_! I can just press on a link, e.g., `[[AkgiO4ax]]`,\n  to visit the note. This is partly thanks to zk's use of the file name (a\n  random UUID) as notes link.\n\nWhile there are still a few minor issues, I can live with them:\n\n- The pricing for pro features is a bit steep, so I need some time to decide if\n  it's worth it.\n- Note UUID generation scheme doesn't match with my zk's note ID system. Still,\n  I can edit them when I get to my desktop.\n\n## Conclusion\n\nGitJournal has filled a crucial gap in my note-taking system, allowing me to\nmaintain the terminal-first, git-based workflow I love on the desktop while\ngaining seamless mobile access. It proves that we don't always need to\ncompromise between power-user preferences and mobile convenience. For those who\nprefer lightweight, text-based note-taking tools like zk but want better mobile\nintegration, GitJournal offers an elegant solution that respects the simplicity\nand flexibility of plain markdown files while making them accessible on the go.\n","wordCount":552,"tags":["blog"],"metadata":{"date":null},"created":"2024-12-09T04:15:21.678120926Z","modified":"2024-12-09T04:15:06.172051626Z","checksum":"fdb5187c19d6cf673e5999851ecc2f8e2aef6e0399efa06063b20fadf031950d"},
    {"filename":"26npf1xb.md","filenameStem":"26npf1xb","path":"26npf1xb.md","absPath":"/home/khadd/mynotes/26npf1xb.md","title":"Glibc Dynamic Linker","link":"[[26npf1xb]]","lead":"#glibc #libc #dynamic-linking #elf","body":"#glibc #libc #dynamic-linking #elf\n\n## Launching\n\nWhen the program with dynamic linking is loaded by the kernel, the kernel looks\nin the `.interp` section for the program interpreter (dynamic loader) to be use.\nWithin `interp` is a path, e.g., `/lib64/ld-linux-x86-64.so.2`, which it will\nalso loads into the address space.\n\n```bash\n❯ objdump -s -j .interp fs0/helloworld\n\nfs0/helloworld:     file format elf64-x86-64\n\nContents of section .interp:\n 0318 2f6c6962 36342f6c 642d6c69 6e75782d  /lib64/ld-linux-\n 0328 7838362d 36342e73 6f2e3200           x86-64.so.2.\n```\n\nThe kernel then setup the stack and registers, following system V ABI, then\ntransfer the control flow to the entry function inside the dynamic linker\n(contained in the program header of the dynamic linker).\n\n```bash\n❯ readelf -h lib/ld-linux-x86-64.so.2\n\nELF Header:\n  ...\n  Entry point address:               0x1100\n  ...\n```\n\nIf you look at the function att address 0x1100, you will see glibc's entry\nfunction for the dynamic loader that immediately call `_dl_start`\n(`glibc-2.31/elf/rtld.c`).\n\n```bash\n❯ objdump -S --start-address=0x1100  --stop-address=0x1200 lib/ld-2.31.so\n\nlib/ld-2.31.so:     file format elf64-x86-64\n\n\nDisassembly of section .text:\n\n0000000000001100 \u003c_start\u003e:\n    1100:       48 89 e7                mov    %rsp,%rdi\n    1103:       e8 28 0c 00 00          callq  1d30 \u003c_dl_start\u003e\n...\n```\n\n### Setting up\n\nThe setting up process is quite complicated. Here is a simplified list.\n\nPrepare the execution environment for `dl_main` (`_dl_start`):\n\n- Relocate the dynamic loader itself\n- OS-dependent initialization (`_dl_sysdep_start`)\n\nIn `dl_main`:\n\n- Check the environment variables for DL-related configs, e.g., `DL_DEBUG`,\n  `DL_BIND_NOW`, which determine the behavior (`process_envars`).\n- Load all the `DT_NEEDED` libraries into memory and also all of their\n  dependencies (`_dl_map_object_deps`)\n  - I.e., open the libraries files (`open`), parse the headers, map the content\n    into memory (`mmap`), change page permissions appropriately (`mprotect`)\n- Relocate all objects now if lazy binding is not enabled.\n- Setting up runtime resolving\n\n## Runtime resolving\n\nRuntime resolving is kicked started by the dynamic linker writing information\ninto `GOT[1]` and `GOT[2]` of the shared object.\n\n```c\n// elf/rtld.c\nstatic ElfW(Addr) __attribute_used__ _dl_start(void *arg) {\n  // ...\n  if (bootstrap_map.l_addr || !bootstrap_map.l_info[VALIDX(DT_GNU_PRELINKED)]) {\n    /* Relocate ourselves so we can do normal function calls and\n       data access using the global offset table.  */\n\n    ELF_DYNAMIC_RELOCATE(\u0026bootstrap_map, 0, 0, 0);\n  }\n  bootstrap_map.l_relocated = 1;\n  // ...\n}\n\n// dynamic-link.h\n/* This can't just be an inline function because GCC is too dumb\n   to inline functions containing inlines themselves.  */\n#define ELF_DYNAMIC_RELOCATE(map, lazy, consider_profile, skip_ifunc)          \\\n  do {                                                                         \\\n    int edr_lazy =                                                             \\\n        elf_machine_runtime_setup((map), (lazy), (consider_profile));          \\\n    ELF_DYNAMIC_DO_REL((map), edr_lazy, skip_ifunc);                           \\\n    ELF_DYNAMIC_DO_RELA((map), edr_lazy, skip_ifunc);                          \\\n  } while (0)\n```\n\n`elf_machine_runtime_setup` does the actual setting up of runtime resolving. The\ngeneric version is pretty simple.\n\n```c\n// sysdeps/x86_64/dl-machine.h\n/* Set up the loaded object described by L so its unrelocated PLT\n   entries will jump to the on-demand fixup code in dl-runtime.c.  */\n\nstatic inline int elf_machine_runtime_setup(struct link_map *l, int lazy) {\n  extern void _dl_runtime_resolve(Elf32_Word);\n\n  if (lazy) {\n    /* The GOT entries for functions in the PLT have not yet been filled\n       in.  Their initial contents will arrange when called to push an\n       offset into the .rel.plt section, push _GLOBAL_OFFSET_TABLE_[1],\n       and then jump to _GLOBAL_OFFSET_TABLE[2].  */\n    Elf32_Addr *got = (Elf32_Addr *)D_PTR(l, l_info[DT_PLTGOT]);\n    got[1] = (Elf32_Addr)l; /* Identify this shared object.  */\n\n    /* This function will get called to fix up the GOT entry indicated by\n       the offset on the stack, and then jump to the resolved address.  */\n    got[2] = (Elf32_Addr)\u0026_dl_runtime_resolve;\n  }\n\n  return lazy;\n}\n```\n\nThe `x86_64` version is more complicated, which also support profiling.\n\n```c\n// sysdeps/x86_64/dl-machine.h\nstatic inline int __attribute__((unused, always_inline))\nelf_machine_runtime_setup(struct link_map *l, int lazy, int profile) {\n  Elf64_Addr *got;\n  extern void _dl_runtime_resolve_fxsave(ElfW(Word)) attribute_hidden;\n  extern void _dl_runtime_resolve_xsave(ElfW(Word)) attribute_hidden;\n  extern void _dl_runtime_resolve_xsavec(ElfW(Word)) attribute_hidden;\n  extern void _dl_runtime_profile_sse(ElfW(Word)) attribute_hidden;\n  extern void _dl_runtime_profile_avx(ElfW(Word)) attribute_hidden;\n  extern void _dl_runtime_profile_avx512(ElfW(Word)) attribute_hidden;\n\n  if (l-\u003el_info[DT_JMPREL] \u0026\u0026 lazy) {\n    /* The GOT entries for functions in the PLT have not yet been filled\n       in.  Their initial contents will arrange when called to push an\n       offset into the .rel.plt section, push _GLOBAL_OFFSET_TABLE_[1],\n       and then jump to _GLOBAL_OFFSET_TABLE_[2].  */\n    got = (Elf64_Addr *)D_PTR(l, l_info[DT_PLTGOT]);\n    /* If a library is prelinked but we have to relocate anyway,\n       we have to be able to undo the prelinking of .got.plt.\n       The prelinker saved us here address of .plt + 0x16.  */\n    if (got[1]) {\n      l-\u003el_mach.plt = got[1] + l-\u003el_addr;\n      l-\u003el_mach.gotplt = (ElfW(Addr)) \u0026 got[3];\n    }\n    /* Identify this shared object.  */\n    *(ElfW(Addr) *)(got + 1) = (ElfW(Addr))l;\n\n    /* The got[2] entry contains the address of a function which gets\n       called to get the address of a so far unresolved function and\n       jump to it.  The profiling extension of the dynamic linker allows\n       to intercept the calls to collect information.  In this case we\n       don't store the address in the GOT so that all future calls also\n       end in this function.  */\n    if (__glibc_unlikely(profile)) {\n      if (HAS_ARCH_FEATURE(AVX512F_Usable))\n        *(ElfW(Addr) *)(got + 2) = (ElfW(Addr)) \u0026 _dl_runtime_profile_avx512;\n      else if (HAS_ARCH_FEATURE(AVX_Usable))\n        *(ElfW(Addr) *)(got + 2) = (ElfW(Addr)) \u0026 _dl_runtime_profile_avx;\n      else\n        *(ElfW(Addr) *)(got + 2) = (ElfW(Addr)) \u0026 _dl_runtime_profile_sse;\n\n      if (GLRO(dl_profile) != NULL \u0026\u0026 _dl_name_match_p(GLRO(dl_profile), l))\n        /* This is the object we are looking for.  Say that we really\n           want profiling and the timers are started.  */\n        GL(dl_profile_map) = l;\n    } else {\n      /* This function will get called to fix up the GOT entry\n         indicated by the offset on the stack, and then jump to\n         the resolved address.  */\n      if (GLRO(dl_x86_cpu_features).xsave_state_size != 0)\n        *(ElfW(Addr) *)(got + 2) =\n            (HAS_ARCH_FEATURE(XSAVEC_Usable)\n                 ? (ElfW(Addr)) \u0026 _dl_runtime_resolve_xsavec\n                 : (ElfW(Addr)) \u0026 _dl_runtime_resolve_xsave);\n      else\n        *(ElfW(Addr) *)(got + 2) = (ElfW(Addr)) \u0026 _dl_runtime_resolve_fxsave;\n    }\n  }\n\n  if (l-\u003el_info[ADDRIDX(DT_TLSDESC_GOT)] \u0026\u0026 lazy)\n    *(ElfW(Addr) *)(D_PTR(l, l_info[ADDRIDX(DT_TLSDESC_GOT)]) + l-\u003el_addr) =\n        (ElfW(Addr)) \u0026 _dl_tlsdesc_resolve_rela;\n\n  return lazy;\n}\n```\n\n## Linkmap data structure\n\n## Loading objects\n\n```language\n_dl_map_object\n      │\n      └──► _dl_map_object_from_fd\n                    │\n                    └───► _dl_map_segments\n\n```\n\n## More references\n\n- [source-glibc]: https://github.com/lastweek/source-glibc","snippets":["#glibc #libc #dynamic-linking #elf"],"rawContent":"# Glibc Dynamic Linker\n\n#glibc #libc #dynamic-linking #elf\n\n## Launching\n\nWhen the program with dynamic linking is loaded by the kernel, the kernel looks\nin the `.interp` section for the program interpreter (dynamic loader) to be use.\nWithin `interp` is a path, e.g., `/lib64/ld-linux-x86-64.so.2`, which it will\nalso loads into the address space.\n\n```bash\n❯ objdump -s -j .interp fs0/helloworld\n\nfs0/helloworld:     file format elf64-x86-64\n\nContents of section .interp:\n 0318 2f6c6962 36342f6c 642d6c69 6e75782d  /lib64/ld-linux-\n 0328 7838362d 36342e73 6f2e3200           x86-64.so.2.\n```\n\nThe kernel then setup the stack and registers, following system V ABI, then\ntransfer the control flow to the entry function inside the dynamic linker\n(contained in the program header of the dynamic linker).\n\n```bash\n❯ readelf -h lib/ld-linux-x86-64.so.2\n\nELF Header:\n  ...\n  Entry point address:               0x1100\n  ...\n```\n\nIf you look at the function att address 0x1100, you will see glibc's entry\nfunction for the dynamic loader that immediately call `_dl_start`\n(`glibc-2.31/elf/rtld.c`).\n\n```bash\n❯ objdump -S --start-address=0x1100  --stop-address=0x1200 lib/ld-2.31.so\n\nlib/ld-2.31.so:     file format elf64-x86-64\n\n\nDisassembly of section .text:\n\n0000000000001100 \u003c_start\u003e:\n    1100:       48 89 e7                mov    %rsp,%rdi\n    1103:       e8 28 0c 00 00          callq  1d30 \u003c_dl_start\u003e\n...\n```\n\n### Setting up\n\nThe setting up process is quite complicated. Here is a simplified list.\n\nPrepare the execution environment for `dl_main` (`_dl_start`):\n\n- Relocate the dynamic loader itself\n- OS-dependent initialization (`_dl_sysdep_start`)\n\nIn `dl_main`:\n\n- Check the environment variables for DL-related configs, e.g., `DL_DEBUG`,\n  `DL_BIND_NOW`, which determine the behavior (`process_envars`).\n- Load all the `DT_NEEDED` libraries into memory and also all of their\n  dependencies (`_dl_map_object_deps`)\n  - I.e., open the libraries files (`open`), parse the headers, map the content\n    into memory (`mmap`), change page permissions appropriately (`mprotect`)\n- Relocate all objects now if lazy binding is not enabled.\n- Setting up runtime resolving\n\n## Runtime resolving\n\nRuntime resolving is kicked started by the dynamic linker writing information\ninto `GOT[1]` and `GOT[2]` of the shared object.\n\n```c\n// elf/rtld.c\nstatic ElfW(Addr) __attribute_used__ _dl_start(void *arg) {\n  // ...\n  if (bootstrap_map.l_addr || !bootstrap_map.l_info[VALIDX(DT_GNU_PRELINKED)]) {\n    /* Relocate ourselves so we can do normal function calls and\n       data access using the global offset table.  */\n\n    ELF_DYNAMIC_RELOCATE(\u0026bootstrap_map, 0, 0, 0);\n  }\n  bootstrap_map.l_relocated = 1;\n  // ...\n}\n\n// dynamic-link.h\n/* This can't just be an inline function because GCC is too dumb\n   to inline functions containing inlines themselves.  */\n#define ELF_DYNAMIC_RELOCATE(map, lazy, consider_profile, skip_ifunc)          \\\n  do {                                                                         \\\n    int edr_lazy =                                                             \\\n        elf_machine_runtime_setup((map), (lazy), (consider_profile));          \\\n    ELF_DYNAMIC_DO_REL((map), edr_lazy, skip_ifunc);                           \\\n    ELF_DYNAMIC_DO_RELA((map), edr_lazy, skip_ifunc);                          \\\n  } while (0)\n```\n\n`elf_machine_runtime_setup` does the actual setting up of runtime resolving. The\ngeneric version is pretty simple.\n\n```c\n// sysdeps/x86_64/dl-machine.h\n/* Set up the loaded object described by L so its unrelocated PLT\n   entries will jump to the on-demand fixup code in dl-runtime.c.  */\n\nstatic inline int elf_machine_runtime_setup(struct link_map *l, int lazy) {\n  extern void _dl_runtime_resolve(Elf32_Word);\n\n  if (lazy) {\n    /* The GOT entries for functions in the PLT have not yet been filled\n       in.  Their initial contents will arrange when called to push an\n       offset into the .rel.plt section, push _GLOBAL_OFFSET_TABLE_[1],\n       and then jump to _GLOBAL_OFFSET_TABLE[2].  */\n    Elf32_Addr *got = (Elf32_Addr *)D_PTR(l, l_info[DT_PLTGOT]);\n    got[1] = (Elf32_Addr)l; /* Identify this shared object.  */\n\n    /* This function will get called to fix up the GOT entry indicated by\n       the offset on the stack, and then jump to the resolved address.  */\n    got[2] = (Elf32_Addr)\u0026_dl_runtime_resolve;\n  }\n\n  return lazy;\n}\n```\n\nThe `x86_64` version is more complicated, which also support profiling.\n\n```c\n// sysdeps/x86_64/dl-machine.h\nstatic inline int __attribute__((unused, always_inline))\nelf_machine_runtime_setup(struct link_map *l, int lazy, int profile) {\n  Elf64_Addr *got;\n  extern void _dl_runtime_resolve_fxsave(ElfW(Word)) attribute_hidden;\n  extern void _dl_runtime_resolve_xsave(ElfW(Word)) attribute_hidden;\n  extern void _dl_runtime_resolve_xsavec(ElfW(Word)) attribute_hidden;\n  extern void _dl_runtime_profile_sse(ElfW(Word)) attribute_hidden;\n  extern void _dl_runtime_profile_avx(ElfW(Word)) attribute_hidden;\n  extern void _dl_runtime_profile_avx512(ElfW(Word)) attribute_hidden;\n\n  if (l-\u003el_info[DT_JMPREL] \u0026\u0026 lazy) {\n    /* The GOT entries for functions in the PLT have not yet been filled\n       in.  Their initial contents will arrange when called to push an\n       offset into the .rel.plt section, push _GLOBAL_OFFSET_TABLE_[1],\n       and then jump to _GLOBAL_OFFSET_TABLE_[2].  */\n    got = (Elf64_Addr *)D_PTR(l, l_info[DT_PLTGOT]);\n    /* If a library is prelinked but we have to relocate anyway,\n       we have to be able to undo the prelinking of .got.plt.\n       The prelinker saved us here address of .plt + 0x16.  */\n    if (got[1]) {\n      l-\u003el_mach.plt = got[1] + l-\u003el_addr;\n      l-\u003el_mach.gotplt = (ElfW(Addr)) \u0026 got[3];\n    }\n    /* Identify this shared object.  */\n    *(ElfW(Addr) *)(got + 1) = (ElfW(Addr))l;\n\n    /* The got[2] entry contains the address of a function which gets\n       called to get the address of a so far unresolved function and\n       jump to it.  The profiling extension of the dynamic linker allows\n       to intercept the calls to collect information.  In this case we\n       don't store the address in the GOT so that all future calls also\n       end in this function.  */\n    if (__glibc_unlikely(profile)) {\n      if (HAS_ARCH_FEATURE(AVX512F_Usable))\n        *(ElfW(Addr) *)(got + 2) = (ElfW(Addr)) \u0026 _dl_runtime_profile_avx512;\n      else if (HAS_ARCH_FEATURE(AVX_Usable))\n        *(ElfW(Addr) *)(got + 2) = (ElfW(Addr)) \u0026 _dl_runtime_profile_avx;\n      else\n        *(ElfW(Addr) *)(got + 2) = (ElfW(Addr)) \u0026 _dl_runtime_profile_sse;\n\n      if (GLRO(dl_profile) != NULL \u0026\u0026 _dl_name_match_p(GLRO(dl_profile), l))\n        /* This is the object we are looking for.  Say that we really\n           want profiling and the timers are started.  */\n        GL(dl_profile_map) = l;\n    } else {\n      /* This function will get called to fix up the GOT entry\n         indicated by the offset on the stack, and then jump to\n         the resolved address.  */\n      if (GLRO(dl_x86_cpu_features).xsave_state_size != 0)\n        *(ElfW(Addr) *)(got + 2) =\n            (HAS_ARCH_FEATURE(XSAVEC_Usable)\n                 ? (ElfW(Addr)) \u0026 _dl_runtime_resolve_xsavec\n                 : (ElfW(Addr)) \u0026 _dl_runtime_resolve_xsave);\n      else\n        *(ElfW(Addr) *)(got + 2) = (ElfW(Addr)) \u0026 _dl_runtime_resolve_fxsave;\n    }\n  }\n\n  if (l-\u003el_info[ADDRIDX(DT_TLSDESC_GOT)] \u0026\u0026 lazy)\n    *(ElfW(Addr) *)(D_PTR(l, l_info[ADDRIDX(DT_TLSDESC_GOT)]) + l-\u003el_addr) =\n        (ElfW(Addr)) \u0026 _dl_tlsdesc_resolve_rela;\n\n  return lazy;\n}\n```\n\n## Linkmap data structure\n\n## Loading objects\n\n```language\n_dl_map_object\n      │\n      └──► _dl_map_object_from_fd\n                    │\n                    └───► _dl_map_segments\n\n```\n\n## More references\n\n- [source-glibc]: https://github.com/lastweek/source-glibc\n","wordCount":938,"tags":["elf","glibc","libc","dynamic-linking"],"metadata":{},"created":"2024-07-03T03:34:13.931777071Z","modified":"2024-07-23T07:43:04.830067708Z","checksum":"e98d4aa3cc8c2d3b621b4e5d371bf7772e863d18ca9c86b0aba2cd6156f1f9e0"},
    {"filename":"kfs6h55d.md","filenameStem":"kfs6h55d","path":"kfs6h55d.md","absPath":"/home/khadd/mynotes/kfs6h55d.md","title":"Good ideas can be systematically generated","link":"[[kfs6h55d]]","lead":"Many people believe that coming up with good ideas is either pure luck or by\npure stroke of intelligence. This is simply not true.","body":"Many people believe that coming up with good ideas is either pure luck or by\npure stroke of intelligence. This is simply not true.\n\nIdeas considered genius are simply clever/unexpected solution to a specific\nproblem. Now, given that the solution space for a problem may seems infinite,\ncominig up with such a clever idea may seems to be luck/intelligence.\n\nMore specifically, all ideas resolves a contradiction that may seem impossible\nat first.\n\nIf we generalize even more, we can see that every technological innovation\nfollows certain abstract principles and patterns that may be reused to solve\nproblem in other domains. TRIZ methodology develop the _law of technical systems\nevolution_, that categorize these patterns into more abstracted forms.","snippets":["Many people believe that coming up with good ideas is either pure luck or by\npure stroke of intelligence. This is simply not true."],"rawContent":"# Good ideas can be systematically generated\n\nMany people believe that coming up with good ideas is either pure luck or by\npure stroke of intelligence. This is simply not true.\n\nIdeas considered genius are simply clever/unexpected solution to a specific\nproblem. Now, given that the solution space for a problem may seems infinite,\ncominig up with such a clever idea may seems to be luck/intelligence.\n\nMore specifically, all ideas resolves a contradiction that may seem impossible\nat first.\n\nIf we generalize even more, we can see that every technological innovation\nfollows certain abstract principles and patterns that may be reused to solve\nproblem in other domains. TRIZ methodology develop the _law of technical systems\nevolution_, that categorize these patterns into more abstracted forms.\n","wordCount":124,"tags":[],"metadata":{},"created":"2024-07-05T05:00:10.621235282Z","modified":"2024-07-28T07:41:51.193272729Z","checksum":"8a51af5d59ad8e085c973ae40e38d19a890cf91ee01a6360a0b5cca250a7807a"},
    {"filename":"dc9r8veg.md","filenameStem":"dc9r8veg","path":"dc9r8veg.md","absPath":"/home/khadd/mynotes/dc9r8veg.md","title":"Gramine-TDX Slides","link":"[[dc9r8veg]]","lead":"#slides","body":"#slides\n\n## Intro\n\n- Confidential computing \u0026 CVMs\n- Memory encryption \u0026 access control prevent direct access\n- Now the attack surfaces come the interfaces with the hosts.\n\n## What are the Attack surfaces\n\n- Shared memory. virtio.\n- PORT I/O \u0026 MMIO.\n- CPUID leaves \u0026 MSRs.\n- Hypercalls. Iago attacks.\n- Interrupts. Heckler attacks\n\n## Just harden the interfaces!\n\n- Fuzzing the kernel is time-consuming, best-effort and inconclusive\n- A lot of manual effort for hardening\n- Huge TCB; 20 M line of code 15,000 configurations\n\n## Solution: Minimizing TCB and attack surfaces\n\n- Minimize TCB size (LoC)\n  - Offload non-security operations if possible\n  - Reimplement functionalities with security in mind\n- Minimize attack surfaces.\n  - Turn off unnecessary features\n  - Filter out notifications\n  - Sanitize inputs\n\n## Approach: Lightweight LibOS\n\n- LibOS: specialized image that contain only the necessary to maintain POSIX\n  compatibility\n  - Enable running unmodified POSIX applications in SGX\n- Gramine (Graphene) \u0026 Gramine-SGX\n\n![]https://av.tib.eu/media/61466","snippets":["#slides"],"rawContent":"# Gramine-TDX Slides\n\n#slides\n\n## Intro\n\n- Confidential computing \u0026 CVMs\n- Memory encryption \u0026 access control prevent direct access\n- Now the attack surfaces come the interfaces with the hosts.\n\n## What are the Attack surfaces\n\n- Shared memory. virtio.\n- PORT I/O \u0026 MMIO.\n- CPUID leaves \u0026 MSRs.\n- Hypercalls. Iago attacks.\n- Interrupts. Heckler attacks\n\n## Just harden the interfaces!\n\n- Fuzzing the kernel is time-consuming, best-effort and inconclusive\n- A lot of manual effort for hardening\n- Huge TCB; 20 M line of code 15,000 configurations\n\n## Solution: Minimizing TCB and attack surfaces\n\n- Minimize TCB size (LoC)\n  - Offload non-security operations if possible\n  - Reimplement functionalities with security in mind\n- Minimize attack surfaces.\n  - Turn off unnecessary features\n  - Filter out notifications\n  - Sanitize inputs\n\n## Approach: Lightweight LibOS\n\n- LibOS: specialized image that contain only the necessary to maintain POSIX\n  compatibility\n  - Enable running unmodified POSIX applications in SGX\n- Gramine (Graphene) \u0026 Gramine-SGX\n\n![]https://av.tib.eu/media/61466\n","wordCount":163,"tags":["slides"],"metadata":{},"created":"2024-12-12T08:45:48.477273756Z","modified":"2024-12-12T09:07:10.949795301Z","checksum":"7d8e28c3c6a76d297a38cb0ac298ca88bd53f95578cfeaadb53a7be99e818e69"},
    {"filename":"eaf8df05.md","filenameStem":"eaf8df05","path":"eaf8df05.md","absPath":"/home/khadd/mynotes/eaf8df05.md","title":"Grammar for your concepts note","link":"[[eaf8df05]]","lead":"Ideas like atomic notes insists that your notes should focus on a single idea,\nbut often not clearly define what is an \"idea\" here.","body":"Ideas like atomic notes insists that your notes should focus on a single idea,\nbut often not clearly define what is an \"idea\" here.\n\nIt seems that what constitute as an idea can be formally defined like how you\ndefine programming language syntaxes.\n\n```bnf\nconcept = concept relationship concept\n        | concept implications\n        | idea;\nidea    = single\n        | composite;\ncomposite = idea vs. idea;\n```\n\nFor example:\n\n```\nMemory encryption vs. Access control\n         v        v         v\n\tidea      vs.      idea\n```\n\n## Edited AI generated stuff\n\nExtended Grammar for Conceptual Notes\n\n```c\n\n/* Basic concept structure */\nconcept     = concept relationship (concept | statement)\n            | idea\n            ;\n\n/* Relationships - ways concepts connect to other concepts */\nrelationship    = \"connects_to\"\n                | \"depends_on\"\n                | \"leads_to\"\n                | \"influences\"\n                | \"correlates_with\"\n                | \"causes\"\n                | \"contradicts\"\n                | \"exemplifies\"    // Concrete example\n                | \"illustrates\"    // Abstract example\n                ;\n\n/* Simple statements */\nstatement   = value_judgment      // e.g., \"is bad\"\n            | factual_claim       // e.g., \"increases risk\"\n            | recommendation      // e.g., \"should be avoided\"\n            ;\n\n/* Core idea representations */\nidea        = single_idea\n            | composite_idea\n            ;\n\n/* Idea types */\nsingle_idea     = statement;\ncomposite_idea  = comparison\n                | synthesis\n                | categorization\n                ;\n\ncomparison      = idea \"vs.\" idea;\nsynthesis       = idea \"combined_with\" idea;\n\n/* Hierarchical structures */\ncategorization  = category        // contains subcategories\n                | whole          // consists of parts\n                | general        // specializes to specifics\n                ;\n\n```\n\ntest cases:\n\n```\n// Basic single ideas\nsmoking                                              // single_idea\nexercise                                             // single_idea\n\n// Simple concept -\u003e statement relationships\nsmoking implies \"is harmful\"                         // concept relationship statement\nexercise suggests \"improves mood\"                    // concept relationship statement\n\n// Concept -\u003e concept relationships\nsmoking causes cancer                                // concept relationship concept\nexercise enhances \"sleep quality\"                    // concept relationship concept\n\n// Chained relationships\nsmoking causes cancer implies \"requires treatment\"   // (concept relationship concept) relationship statement\n\n// Composite ideas - comparisons\ncardio vs. strength_training                        // comparison\nasync vs. sync_programming                          // comparison\n\n// Composite ideas - synthesis\nfrontend combined_with backend                      // synthesis\n\n// Composite ideas - categorization\nprogramming_languages                               // category\n  - interpreted_languages                           // subcategory\n  - compiled_languages                             // subcategory\n\nhuman_body                                         // whole\n  - cardiovascular_system                          // part\n  - nervous_system                                 // part\n\nanimal                                            // general\n  - mammal                                        // specific\n  - reptile                                       // specific\n\n// Complex nested examples\n(cardio vs. strength_training) implies \"different benefits\"    // (comparison) relationship statement\n\nprogramming_languages influences\n  (interpreted_languages vs. compiled_languages)              // concept relationship comparison\n\n(frontend combined_with backend) suggests \"full-stack development\"  // (synthesis) relationship statement\n\n// Multiple relationships chain\nsmoking causes cancer contradicts healthy_lifestyle implies \"needs change\"\n  // (concept relationship concept) relationship concept relationship statement\n```","snippets":["Ideas like atomic notes insists that your notes should focus on a single idea,\nbut often not clearly define what is an \"idea\" here."],"rawContent":"# Grammar for your concepts note\n\nIdeas like atomic notes insists that your notes should focus on a single idea,\nbut often not clearly define what is an \"idea\" here.\n\nIt seems that what constitute as an idea can be formally defined like how you\ndefine programming language syntaxes.\n\n```bnf\nconcept = concept relationship concept\n        | concept implications\n        | idea;\nidea    = single\n        | composite;\ncomposite = idea vs. idea;\n```\n\nFor example:\n\n```\nMemory encryption vs. Access control\n         v        v         v\n\tidea      vs.      idea\n```\n\n## Edited AI generated stuff\n\nExtended Grammar for Conceptual Notes\n\n```c\n\n/* Basic concept structure */\nconcept     = concept relationship (concept | statement)\n            | idea\n            ;\n\n/* Relationships - ways concepts connect to other concepts */\nrelationship    = \"connects_to\"\n                | \"depends_on\"\n                | \"leads_to\"\n                | \"influences\"\n                | \"correlates_with\"\n                | \"causes\"\n                | \"contradicts\"\n                | \"exemplifies\"    // Concrete example\n                | \"illustrates\"    // Abstract example\n                ;\n\n/* Simple statements */\nstatement   = value_judgment      // e.g., \"is bad\"\n            | factual_claim       // e.g., \"increases risk\"\n            | recommendation      // e.g., \"should be avoided\"\n            ;\n\n/* Core idea representations */\nidea        = single_idea\n            | composite_idea\n            ;\n\n/* Idea types */\nsingle_idea     = statement;\ncomposite_idea  = comparison\n                | synthesis\n                | categorization\n                ;\n\ncomparison      = idea \"vs.\" idea;\nsynthesis       = idea \"combined_with\" idea;\n\n/* Hierarchical structures */\ncategorization  = category        // contains subcategories\n                | whole          // consists of parts\n                | general        // specializes to specifics\n                ;\n\n```\n\ntest cases:\n\n```\n// Basic single ideas\nsmoking                                              // single_idea\nexercise                                             // single_idea\n\n// Simple concept -\u003e statement relationships\nsmoking implies \"is harmful\"                         // concept relationship statement\nexercise suggests \"improves mood\"                    // concept relationship statement\n\n// Concept -\u003e concept relationships\nsmoking causes cancer                                // concept relationship concept\nexercise enhances \"sleep quality\"                    // concept relationship concept\n\n// Chained relationships\nsmoking causes cancer implies \"requires treatment\"   // (concept relationship concept) relationship statement\n\n// Composite ideas - comparisons\ncardio vs. strength_training                        // comparison\nasync vs. sync_programming                          // comparison\n\n// Composite ideas - synthesis\nfrontend combined_with backend                      // synthesis\n\n// Composite ideas - categorization\nprogramming_languages                               // category\n  - interpreted_languages                           // subcategory\n  - compiled_languages                             // subcategory\n\nhuman_body                                         // whole\n  - cardiovascular_system                          // part\n  - nervous_system                                 // part\n\nanimal                                            // general\n  - mammal                                        // specific\n  - reptile                                       // specific\n\n// Complex nested examples\n(cardio vs. strength_training) implies \"different benefits\"    // (comparison) relationship statement\n\nprogramming_languages influences\n  (interpreted_languages vs. compiled_languages)              // concept relationship comparison\n\n(frontend combined_with backend) suggests \"full-stack development\"  // (synthesis) relationship statement\n\n// Multiple relationships chain\nsmoking causes cancer contradicts healthy_lifestyle implies \"needs change\"\n  // (concept relationship concept) relationship concept relationship statement\n```\n","wordCount":420,"tags":[],"metadata":{},"created":"2024-12-16T04:04:44.354368349Z","modified":"2024-12-16T05:00:56.022788276Z","checksum":"f1089ff319404a4b9caa72609455db1f27e4e151f5debe25eb285ab0066f2fd2"},
    {"filename":"zecj938z.md","filenameStem":"zecj938z","path":"zecj938z.md","absPath":"/home/khadd/mynotes/zecj938z.md","title":"HYDRA:The Kernel of a Multiprocessor Operating System","link":"[[zecj938z]]","lead":"#literature #os #capabilities\n@wulf1974hydra","body":"#literature #os #capabilities\n@wulf1974hydra\n\n\n\n## Noteworthy arguments\n### Hierarchical layering limits flexibility: See [[c4icaua4]].\nHowever, maintaining order in a non-hierarchical manner is challenging in traditional systems. HYDRA's capability model enable flexibility by rejecting hierarchical structuring. In HYDRA, a *template* define the security checking mechanism of a procedure, and allows a procedure to *derive* higher capabilities from the argument capabilities (belong to the caller). This way, a callee function might have greater capabilities than the caller, but the caller have no way of obtaining those capabilities by itself. This enable invocation of procedures in any orders, as long as the callee adhere to the rules defined by the system designer.\n\nAs a downside, such a system must have the support from the kernel. HYDRA uses a kernel-assisted CALL mechanism. The kernel checks for the parameter capabilities with the according to the security requirements. It then derives new capabilities and place it in the callee's environment. Finally, the kernel transfer the control to the callee function.\n\n### Protection (mechanism) should be separated from security (policy)\nThe paper argue that the protection mechanism does not necessary grant security. Take password for example, the password checking mechanism does not guarantee that the user will use a strong enough password.\n\nHence, HYDRA aims to provides primitives (mechanisms) to implements the policy (security), but not to provide  the security by itself.","snippets":["#literature #os #capabilities\n@wulf1974hydra"],"rawContent":"# HYDRA:The Kernel of a Multiprocessor Operating System\n#literature #os #capabilities\n@wulf1974hydra\n\n\n\n## Noteworthy arguments\n### Hierarchical layering limits flexibility: See [[c4icaua4]].\nHowever, maintaining order in a non-hierarchical manner is challenging in traditional systems. HYDRA's capability model enable flexibility by rejecting hierarchical structuring. In HYDRA, a *template* define the security checking mechanism of a procedure, and allows a procedure to *derive* higher capabilities from the argument capabilities (belong to the caller). This way, a callee function might have greater capabilities than the caller, but the caller have no way of obtaining those capabilities by itself. This enable invocation of procedures in any orders, as long as the callee adhere to the rules defined by the system designer.\n\nAs a downside, such a system must have the support from the kernel. HYDRA uses a kernel-assisted CALL mechanism. The kernel checks for the parameter capabilities with the according to the security requirements. It then derives new capabilities and place it in the callee's environment. Finally, the kernel transfer the control to the callee function.\n\n### Protection (mechanism) should be separated from security (policy)\nThe paper argue that the protection mechanism does not necessary grant security. Take password for example, the password checking mechanism does not guarantee that the user will use a strong enough password.\n\nHence, HYDRA aims to provides primitives (mechanisms) to implements the policy (security), but not to provide  the security by itself.\n","wordCount":233,"tags":["literature","capabilities","os"],"metadata":{},"created":"2024-05-22T08:24:03.312747594Z","modified":"2024-05-22T08:23:40.666608407Z","checksum":"ef8d49672048a3a1fffb41b086f8d21d4f2cc910b21f2024b789e977377c3b9e"},
    {"filename":"bedsukcc.md","filenameStem":"bedsukcc","path":"bedsukcc.md","absPath":"/home/khadd/mynotes/bedsukcc.md","title":"Hardware breakpoint in Linux","link":"[[bedsukcc]]","lead":"#area #linux","body":"#area #linux\n\nThe source for the x86 HW breakpoints is in `arch/x86/kernel/hw_breakpoint.c`.\nThe function `arch_install_hw_breakpoint` installs the actual breakpoint.","snippets":["#area #linux"],"rawContent":"# Hardware breakpoint in Linux\n\n#area #linux\n\nThe source for the x86 HW breakpoints is in `arch/x86/kernel/hw_breakpoint.c`.\nThe function `arch_install_hw_breakpoint` installs the actual breakpoint.\n","wordCount":24,"tags":["linux","area"],"metadata":{},"created":"2024-05-28T09:41:37.484315079Z","modified":"2024-06-20T07:50:22.426341567Z","checksum":"e3a97175e189c579fd696fbff19225635138b9497608d7a3ebef91bef22b95bf"},
    {"filename":"27le2qfj.md","filenameStem":"27le2qfj","path":"27le2qfj.md","absPath":"/home/khadd/mynotes/27le2qfj.md","title":"Hardware in OSI networking","link":"[[27le2qfj]]","lead":"Hardware are commonly located the lowest in the stack (L2, before physical\nlayer), but sometimes they provide features that belong to higher levels (L3,\nnetworking). Moreover, for flexibility, many hardware functionalities are\nimplemented in software as a dedicated service, i.e., [[szlwwqsj]]","body":"Hardware are commonly located the lowest in the stack (L2, before physical\nlayer), but sometimes they provide features that belong to higher levels (L3,\nnetworking). Moreover, for flexibility, many hardware functionalities are\nimplemented in software as a dedicated service, i.e., [[szlwwqsj]]\n\n- **Switches** are located at L2 (Data link), which connect devices within a\n  local area network (LAN). Switches uses MAC addressing, to route packets\n  directly from one machine to another, which put it at L2.\n- **Router** is located at L3 (Networking), which connect different networks to\n  each other. Since it's at L3, it is aware of IP addresses of source\n  destinations. The router determine the most optimal path for the packet to\n  travel.\n- **Hardware NIC** are at L2 (Data link). This means it is only aware of device\n  MAC. The delivering of correct packets into the NIC is handled by the router.\n  Through, some NIC is aware of headers of higher layers for better packet\n  balancing.","snippets":["Hardware are commonly located the lowest in the stack (L2, before physical\nlayer), but sometimes they provide features that belong to higher levels (L3,\nnetworking). Moreover, for flexibility, many hardware functionalities are\nimplemented in software as a dedicated service, i.e., [[szlwwqsj]]"],"rawContent":"# Hardware in OSI networking\n\nHardware are commonly located the lowest in the stack (L2, before physical\nlayer), but sometimes they provide features that belong to higher levels (L3,\nnetworking). Moreover, for flexibility, many hardware functionalities are\nimplemented in software as a dedicated service, i.e., [[szlwwqsj]]\n\n- **Switches** are located at L2 (Data link), which connect devices within a\n  local area network (LAN). Switches uses MAC addressing, to route packets\n  directly from one machine to another, which put it at L2.\n- **Router** is located at L3 (Networking), which connect different networks to\n  each other. Since it's at L3, it is aware of IP addresses of source\n  destinations. The router determine the most optimal path for the packet to\n  travel.\n- **Hardware NIC** are at L2 (Data link). This means it is only aware of device\n  MAC. The delivering of correct packets into the NIC is handled by the router.\n  Through, some NIC is aware of headers of higher layers for better packet\n  balancing.\n","wordCount":164,"tags":[],"metadata":{},"created":"2024-12-18T02:44:59.51375347Z","modified":"2024-12-18T03:03:26.902485419Z","checksum":"9f75d3de1945e84cd05710f2ffc6585dabe2682af53a8ba088e2310e332e6a5f"},
    {"filename":"2a7l7odo.md","filenameStem":"2a7l7odo","path":"2a7l7odo.md","absPath":"/home/khadd/mynotes/2a7l7odo.md","title":"Harmonizing Performance and Isolation in Microkernels with Efficient Intra-kernel Isolation and Communication","link":"[[2a7l7odo]]","lead":"#literature #mpk #microkernel #sel4 #os [@gu2020harmonizing]","body":"#literature #mpk #microkernel #sel4 #os [@gu2020harmonizing]\n\n## Context\n\nThe paper argues that the cost of IPC in microkernels are too high, and proposed\nusing MPK-based domains to reduce the number of context switches during IPCs.\nThe paper provides a motivation study by profiling the overheads of IPC in\ncommon microkernels (see [[i2blyo37#Overhead analysis]]).\n\n### Background\n\nPrevious systems use MPK for single address-space isolation.\n\nPrevious state-of-the-art [@mi2019skybridge] enables fast IPC by retrofitting\nVMFUNC., but still have high overheads due to Page table switching\n\n### Contributions\n\nThe proposed system tackles three main challenges in the context of microkernels\nthat previous work did not solve.\n\n- The first is to prevent illegal IPC calls, since intel MPK does not check for\n  permission before executing code. This is solved by secure IPC gates for the\n  specific connections between two specific servers (a _system server_ is an\n  application that provides system-level services) in the trusted domain (core\n  kernel).\n- Second is the limited number of domains. The paper designs a _server\n  migration_ technique that allows a server to be migrated between userspace\n  (same as normal microkernel) and kernel space.\n- Third, due to the server executing in the privileged space, the system needs\n  to prevent it from executing privileged instructions.","snippets":["#literature #mpk #microkernel #sel4 #os [@gu2020harmonizing]"],"rawContent":"# Harmonizing Performance and Isolation in Microkernels with Efficient Intra-kernel Isolation and Communication\n\n#literature #mpk #microkernel #sel4 #os [@gu2020harmonizing]\n\n## Context\n\nThe paper argues that the cost of IPC in microkernels are too high, and proposed\nusing MPK-based domains to reduce the number of context switches during IPCs.\nThe paper provides a motivation study by profiling the overheads of IPC in\ncommon microkernels (see [[i2blyo37#Overhead analysis]]).\n\n### Background\n\nPrevious systems use MPK for single address-space isolation.\n\nPrevious state-of-the-art [@mi2019skybridge] enables fast IPC by retrofitting\nVMFUNC., but still have high overheads due to Page table switching\n\n### Contributions\n\nThe proposed system tackles three main challenges in the context of microkernels\nthat previous work did not solve.\n\n- The first is to prevent illegal IPC calls, since intel MPK does not check for\n  permission before executing code. This is solved by secure IPC gates for the\n  specific connections between two specific servers (a _system server_ is an\n  application that provides system-level services) in the trusted domain (core\n  kernel).\n- Second is the limited number of domains. The paper designs a _server\n  migration_ technique that allows a server to be migrated between userspace\n  (same as normal microkernel) and kernel space.\n- Third, due to the server executing in the privileged space, the system needs\n  to prevent it from executing privileged instructions.\n","wordCount":218,"tags":["literature","mpk","microkernel","sel4","os"],"metadata":{},"created":"2024-05-22T08:24:03.220426769Z","modified":"2024-06-19T05:57:31.656856712Z","checksum":"11e771c9d836e2f98158535daa8d308a76226b9e939bfc04160a64dcf82f6e3b"},
    {"filename":"c6cpkdl9.md","filenameStem":"c6cpkdl9","path":"c6cpkdl9.md","absPath":"/home/khadd/mynotes/c6cpkdl9.md","title":"Heap modeling in points-to analysis","link":"[[c6cpkdl9]]","lead":"#analysis #points-to-analysis","body":"#analysis #points-to-analysis\n\nPoints-to analysis often require heap modeling, which is essentially tracking\nwhich functions can allocate pointers (`malloc`) such that their call-site can\nbe identified as a unique pointer.\n\n## Issues with allocation wrappers\n\nCommonly, you would hard-code the allocation function name (e.g., `malloc`), and\nassume that the function returns a heap object. However, things get complicated\nwhen allocator wrappers are used. This is troublesome for automated analysis in\ncertain cases. Consider the following code. Something like this is commonly seen\nin C libraries.\n\n```c\nkey_t* key_alloc(){\n  return malloc(sizeof(key_t));\n}\nvoid fee(){\n  void* buf = malloc(512);\n  unsafe_access(buf);\n}\nvoid foo(){\n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\n\nLet say we want to replace all object touched by `unsafe_access` with a\ndifferent allocator. Points-to analysis is needed for this case. For `fee`, it\nis straightforward, since the analysis can immediately find the allocation\nfunction. However, for `foo`, there is a complication.\n\nIf we perform a _context-insensitive_ points-to analysis on on the key access,\nthe result will contains _all_ pointers that are allocated using `key_alloc()`.\nE.g., all `fee`, `foo`, `bar` would be aliases. Hence, a _context-sensitve_\nanalysis is needed for modeling the heap in these cases to avoid serve\nover-approximation.\n\nIn Rust, there are also similar cases. `Box\u003cT\u003e` abstracts away the malloc call.\n\n## Context sensitivity\n\nThere are two methods to achieve context sensitivity.\n\n### Context-sensitive analysis\n\nThe first is to just use a _context-senstive_ variant of points-to analysis. A\nContext-sensitive analysis explore all possible code paths, which may be very\nexpensive.\n\n### Function cloning\n\nThe second, more practical approach used in some research papers\n[@bang2023trust], [@borrello2021constantine] is to perform cloning to introduce\ncontext sensitivity. This achieve the same effect as exploring possible code\npaths; where there are two variants that points to the same heap object, the\nentire call tree is cloned so that there are two different functions.\n\nIn the above example, cloning key_alloc into `unsafe_key_alloc` and\n`key_alloc_safe` , and replace the key_alloc call would differentiate the heap\ncontext between foo and bar.\n\n```c\nvoid foo(){\n  key_t* key = key_alloc_unsafe();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc_safe();\n  safe_access(key);\n}\n```\n\nAnother challenge here is to identify which _depth_ to clone to achieve the\ndesired accuracy.\n\n```c\nkey_t* special_key_alloc(){\n  key_t *key = key_alloc();\n  key-\u003etype = SPECIAL;\n  return key;\n}\nvoid fez(){\n  key_t  *key = special_key_alloc();\n  unsafe_access(key);\n}\nvoid fiz(){\n  key_t  *key = special_key_alloc();\n  safe_access(key);\n}\nvoid foo(){\n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\n\nIn the above example, we need to clone the contexts for all 4 functions.","snippets":["#analysis #points-to-analysis"],"rawContent":"# Heap modeling in points-to analysis\n\n#analysis #points-to-analysis\n\nPoints-to analysis often require heap modeling, which is essentially tracking\nwhich functions can allocate pointers (`malloc`) such that their call-site can\nbe identified as a unique pointer.\n\n## Issues with allocation wrappers\n\nCommonly, you would hard-code the allocation function name (e.g., `malloc`), and\nassume that the function returns a heap object. However, things get complicated\nwhen allocator wrappers are used. This is troublesome for automated analysis in\ncertain cases. Consider the following code. Something like this is commonly seen\nin C libraries.\n\n```c\nkey_t* key_alloc(){\n  return malloc(sizeof(key_t));\n}\nvoid fee(){\n  void* buf = malloc(512);\n  unsafe_access(buf);\n}\nvoid foo(){\n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\n\nLet say we want to replace all object touched by `unsafe_access` with a\ndifferent allocator. Points-to analysis is needed for this case. For `fee`, it\nis straightforward, since the analysis can immediately find the allocation\nfunction. However, for `foo`, there is a complication.\n\nIf we perform a _context-insensitive_ points-to analysis on on the key access,\nthe result will contains _all_ pointers that are allocated using `key_alloc()`.\nE.g., all `fee`, `foo`, `bar` would be aliases. Hence, a _context-sensitve_\nanalysis is needed for modeling the heap in these cases to avoid serve\nover-approximation.\n\nIn Rust, there are also similar cases. `Box\u003cT\u003e` abstracts away the malloc call.\n\n## Context sensitivity\n\nThere are two methods to achieve context sensitivity.\n\n### Context-sensitive analysis\n\nThe first is to just use a _context-senstive_ variant of points-to analysis. A\nContext-sensitive analysis explore all possible code paths, which may be very\nexpensive.\n\n### Function cloning\n\nThe second, more practical approach used in some research papers\n[@bang2023trust], [@borrello2021constantine] is to perform cloning to introduce\ncontext sensitivity. This achieve the same effect as exploring possible code\npaths; where there are two variants that points to the same heap object, the\nentire call tree is cloned so that there are two different functions.\n\nIn the above example, cloning key_alloc into `unsafe_key_alloc` and\n`key_alloc_safe` , and replace the key_alloc call would differentiate the heap\ncontext between foo and bar.\n\n```c\nvoid foo(){\n  key_t* key = key_alloc_unsafe();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc_safe();\n  safe_access(key);\n}\n```\n\nAnother challenge here is to identify which _depth_ to clone to achieve the\ndesired accuracy.\n\n```c\nkey_t* special_key_alloc(){\n  key_t *key = key_alloc();\n  key-\u003etype = SPECIAL;\n  return key;\n}\nvoid fez(){\n  key_t  *key = special_key_alloc();\n  unsafe_access(key);\n}\nvoid fiz(){\n  key_t  *key = special_key_alloc();\n  safe_access(key);\n}\nvoid foo(){\n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\n\nIn the above example, we need to clone the contexts for all 4 functions.\n","wordCount":440,"tags":["analysis","points-to-analysis"],"metadata":{},"created":"2023-06-01T02:38:33.806452991Z","modified":"2024-06-20T08:57:38.052254505Z","checksum":"3b702d8da416afbb294099c073384d106a378ccd60ef51e232ab067faffdf71c"},
    {"filename":"c4icaua4.md","filenameStem":"c4icaua4","path":"c4icaua4.md","absPath":"/home/khadd/mynotes/c4icaua4.md","title":"Hierarchical layering limits flexibility","link":"[[c4icaua4]]","lead":"#capabilities #os","body":"#capabilities #os\n\nMany systems use the strict hierarchical layering for resource allocation. In\nthose systems, the rules enforced by the kernel is that\n\n1. A process can only allocate resources that it own to its children,\n2. Can only start/stop/remove its own children's, and\n3. A process's resources must be returned to its parent when it terminates.\n\nThese rules can be seen in modern UNIX system.\n\nHowever, [@wulf1974hydra] argued that hierarchical layering of a system limits\nits flexibility.\n\n- While resource allocation might contain hierarchical layering (one component\n  allocate for the other), as shown above, the _control_ (e.g.,\n  starting/stopping subprocesses) need not have the same hierarchical.\n- Strict hierarchical system leads to increasingly privileged system components,\n  and therefore leads to a component that have the \"most privileged\" only\n  because it manages other subsystems. This leads to confused deputy problems\n  ([[y9wu5ut7]]) in those components.\n\nCapabilities [[khi9ihj9]] systems naturally remove hierarchies by centralizing\naccess control decision to a reference monitor.\n\n## Related\n\n- State spills hinders flexibility in systems similarly by creating implicit\n  dependencies [[2j6s9zpm]].\n- [[8113ygxd]]\n- [[4vysjbn9]].","snippets":["#capabilities #os"],"rawContent":"# Hierarchical layering limits flexibility\n\n#capabilities #os\n\nMany systems use the strict hierarchical layering for resource allocation. In\nthose systems, the rules enforced by the kernel is that\n\n1. A process can only allocate resources that it own to its children,\n2. Can only start/stop/remove its own children's, and\n3. A process's resources must be returned to its parent when it terminates.\n\nThese rules can be seen in modern UNIX system.\n\nHowever, [@wulf1974hydra] argued that hierarchical layering of a system limits\nits flexibility.\n\n- While resource allocation might contain hierarchical layering (one component\n  allocate for the other), as shown above, the _control_ (e.g.,\n  starting/stopping subprocesses) need not have the same hierarchical.\n- Strict hierarchical system leads to increasingly privileged system components,\n  and therefore leads to a component that have the \"most privileged\" only\n  because it manages other subsystems. This leads to confused deputy problems\n  ([[y9wu5ut7]]) in those components.\n\nCapabilities [[khi9ihj9]] systems naturally remove hierarchies by centralizing\naccess control decision to a reference monitor.\n\n## Related\n\n- State spills hinders flexibility in systems similarly by creating implicit\n  dependencies [[2j6s9zpm]].\n- [[8113ygxd]]\n- [[4vysjbn9]].\n","wordCount":182,"tags":["capabilities","os"],"metadata":{},"created":"2023-05-24T01:48:35.84434459Z","modified":"2024-12-23T05:40:40.784184316Z","checksum":"cb7e5477db2d825a542272d4931a4331e0139a5d88c1b3221e52d48777d99196"},
    {"filename":"b740rhio.md","filenameStem":"b740rhio","path":"b740rhio.md","absPath":"/home/khadd/mynotes/b740rhio.md","title":"Hourglass structure of information","link":"[[b740rhio]]","lead":"#reading #learning","body":"#reading #learning\n\nIn most forms of writing, information is usually structured in an hourglass\nstructure. Usually high-level (easier to get) and most important information at\nthe beginning and the end, More specific information and less important in the\nmiddle.\n\nHence, during reading, more time should be spent on the beginning and the end of\nthe chapter/sections/paragraph.\n\n## References\n\n- \u003chttps://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf\u003e","snippets":["#reading #learning"],"rawContent":"# Hourglass structure of information\n\n#reading #learning\n\nIn most forms of writing, information is usually structured in an hourglass\nstructure. Usually high-level (easier to get) and most important information at\nthe beginning and the end, More specific information and less important in the\nmiddle.\n\nHence, during reading, more time should be spent on the beginning and the end of\nthe chapter/sections/paragraph.\n\n## References\n\n- \u003chttps://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf\u003e\n","wordCount":65,"tags":["reading","learning"],"metadata":{},"created":"2023-05-05T06:54:52.6054501Z","modified":"2024-06-28T08:04:31.405287993Z","checksum":"1eb125277992ba7f5bebaaff2e136ad3ab837b47ccbf4039ec08858e4bf56450"},
    {"filename":"7isqcppd.md","filenameStem":"7isqcppd","path":"7isqcppd.md","absPath":"/home/khadd/mynotes/7isqcppd.md","title":"How to Speak","link":"[[7isqcppd]]","lead":"#communication","body":"#communication\n\n## Slides\n\n- The less text, the better. Cut out headers, footer, unnecessary visual\n  cluttering (e.g., bullet points).\n- Figures should be simple.\n\n## Crimes\n\n- Hands in pocket\n- Pointers to the slide\n\n## How to get your work recognized\n\n[How-to-Speak] mentioned 5 pillars:\n\n1. Symbol: A symbol helps\n2. Slogan\n3. Surprise\n4. Salient\n5. Story\n\n## References\n\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s)","snippets":["#communication"],"rawContent":"# How to Speak\n\n#communication\n\n## Slides\n\n- The less text, the better. Cut out headers, footer, unnecessary visual\n  cluttering (e.g., bullet points).\n- Figures should be simple.\n\n## Crimes\n\n- Hands in pocket\n- Pointers to the slide\n\n## How to get your work recognized\n\n[How-to-Speak] mentioned 5 pillars:\n\n1. Symbol: A symbol helps\n2. Slogan\n3. Surprise\n4. Salient\n5. Story\n\n## References\n\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s)\n","wordCount":67,"tags":["communication"],"metadata":{},"created":"2023-07-03T02:43:48.499639362Z","modified":"2024-06-28T07:56:51.779853264Z","checksum":"bcab714d9849f47b252a935fd11afea8692b777be810549bd0d5eee908b6d51d"},
    {"filename":"gmp22r4e.md","filenameStem":"gmp22r4e","path":"gmp22r4e.md","absPath":"/home/khadd/mynotes/gmp22r4e.md","title":"How to do research","link":"[[gmp22r4e]]","lead":"#resource","body":"#resource\n\n# References\n- [How to look for ideas in Computer Science Research](https://medium.com/digital-diplomacy/how-to-look-for-ideas-in-computer-science-research-7a3fa6f4696f)","snippets":["#resource"],"rawContent":"# How to do research\n#resource\n\n# References\n- [How to look for ideas in Computer Science Research](https://medium.com/digital-diplomacy/how-to-look-for-ideas-in-computer-science-research-7a3fa6f4696f)\n","wordCount":18,"tags":["resource"],"metadata":{},"created":"2023-06-09T07:37:26.870843698Z","modified":"2024-05-22T08:23:40.663275058Z","checksum":"29acb67c6fdb418b4825847d95a6d639985e62fce7d900af801826574c5fd332"},
    {"filename":"zy68i5ym.md","filenameStem":"zy68i5ym","path":"zy68i5ym.md","absPath":"/home/khadd/mynotes/zy68i5ym.md","title":"How to explain an idea","link":"[[zy68i5ym]]","lead":"#communication","body":"#communication\n\n## Heuristics\n\n1. _Cycling_: If something is important, it is worth revisiting at least _3_\n   times.\n2. _Build a fence_: Clearly differentiate the idea and other may-similar ideas.\n\n## References\n\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s)\n- [[7isqcppd]]","snippets":["#communication"],"rawContent":"# How to explain an idea\n\n#communication\n\n## Heuristics\n\n1. _Cycling_: If something is important, it is worth revisiting at least _3_\n   times.\n2. _Build a fence_: Clearly differentiate the idea and other may-similar ideas.\n\n## References\n\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s)\n- [[7isqcppd]]\n","wordCount":41,"tags":["communication"],"metadata":{},"created":"2024-05-20T09:23:13.152630533Z","modified":"2024-06-28T07:57:26.520017696Z","checksum":"913dd3d1dd6df8fe5a5840a86a0b73dc87f3fcc5d7143d88205f70373c6d66db"},
    {"filename":"8v4evysc.md","filenameStem":"8v4evysc","path":"8v4evysc.md","absPath":"/home/khadd/mynotes/8v4evysc.md","title":"How to handle quotes in my zk","link":"[[8v4evysc]]","lead":"#quote #note-taking #zettelkasten","body":"#quote #note-taking #zettelkasten\n\nMaintaining/collecting quotes is important, so I try to somehow incorporate them\ninto my notes.\n\n- [[msjmb62t]]\n- [[amyz6o6h]]\n\n## Goals\n\nWhat I want in my quotes:\n\n- R1. Easily searchable. Should be able to find quotes for the appropriate\n  context.\n- R2. Metadata: Relevatant info (author, pages in the book, what context) should\n  be maintained.\n- R3. Non-redundancy: Repeating occurances of the same quote should pointed to a\n  single entry.\n- R4. Linkable. Should be easy to pull out a quote and put them in the\n  appropriate context.\n\n## My system\n\nR1. First, the title of the note contains the quote itself. This will make the\nentire quote a first-class content. It will shows up in zk, for example. A\n`#quote` tag is attached to the note. This allows for better indexing.\n\nR2. The note should contains description of the note. For instance, who is it\nfrom, in what context.\n\nThe remaining problem is left is to maintain authors of quotes to avoid\nredundancy. There are two approaches, linking to the (may empty) note about\nauthor, or use hash tag, both of which have trade-off. Linking force you to\ncreate a note on the author, which may not be populated. using hashtags kind of\nclutter you tags. Searching using hashtags may not be ideal (I might change my\nmind later).\n\nR3, R4. Now, to reference a quote, you link to the quote in the appropriate\ncontext. Since the title is the quote it self, it can be searched easily.","snippets":["#quote #note-taking #zettelkasten"],"rawContent":"# How to handle quotes in my zk\n\n#quote #note-taking #zettelkasten\n\nMaintaining/collecting quotes is important, so I try to somehow incorporate them\ninto my notes.\n\n- [[msjmb62t]]\n- [[amyz6o6h]]\n\n## Goals\n\nWhat I want in my quotes:\n\n- R1. Easily searchable. Should be able to find quotes for the appropriate\n  context.\n- R2. Metadata: Relevatant info (author, pages in the book, what context) should\n  be maintained.\n- R3. Non-redundancy: Repeating occurances of the same quote should pointed to a\n  single entry.\n- R4. Linkable. Should be easy to pull out a quote and put them in the\n  appropriate context.\n\n## My system\n\nR1. First, the title of the note contains the quote itself. This will make the\nentire quote a first-class content. It will shows up in zk, for example. A\n`#quote` tag is attached to the note. This allows for better indexing.\n\nR2. The note should contains description of the note. For instance, who is it\nfrom, in what context.\n\nThe remaining problem is left is to maintain authors of quotes to avoid\nredundancy. There are two approaches, linking to the (may empty) note about\nauthor, or use hash tag, both of which have trade-off. Linking force you to\ncreate a note on the author, which may not be populated. using hashtags kind of\nclutter you tags. Searching using hashtags may not be ideal (I might change my\nmind later).\n\nR3, R4. Now, to reference a quote, you link to the quote in the appropriate\ncontext. Since the title is the quote it self, it can be searched easily.\n","wordCount":260,"tags":["zettelkasten","note-taking","quote"],"metadata":{},"created":"2023-05-26T02:29:00.70063893Z","modified":"2024-12-10T02:15:45.681470934Z","checksum":"36e4e23d961efde2b8dc067348ec37f283f681fceb13a99d5d378d3fa509f393"},
    {"filename":"cemsxh4n.md","filenameStem":"cemsxh4n","path":"cemsxh4n.md","absPath":"/home/khadd/mynotes/cemsxh4n.md","title":"How to write a note","link":"[[cemsxh4n]]","lead":"#zettelkasten #note-taking","body":"#zettelkasten #note-taking\n\n#todo: Need more research \n\nThe note content should have three main parts:\n- The idea \n- The observation\n- The conclusion\nThis is which is also similar to how academic papers are structured.\n\nUsing frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.","snippets":["#zettelkasten #note-taking"],"rawContent":"# How to write a note\n#zettelkasten #note-taking\n\n#todo: Need more research \n\nThe note content should have three main parts:\n- The idea \n- The observation\n- The conclusion\nThis is which is also similar to how academic papers are structured.\n\nUsing frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.\n","wordCount":58,"tags":["zettelkasten","todo:","note-taking"],"metadata":{},"created":"2023-05-03T03:47:47.578591088Z","modified":"2023-07-04T05:14:43.082758247Z","checksum":"fb21dbe626763343fe640738e06778e42719a3dd4f747c3865f65081e369afeb"},
    {"filename":"d3nt6uix.md","filenameStem":"d3nt6uix","path":"d3nt6uix.md","absPath":"/home/khadd/mynotes/d3nt6uix.md","title":"Hypervisor (VMM)","link":"[[d3nt6uix]]","lead":"#virtualization #os","body":"#virtualization #os\n\nA hypervisor, also known as virtual machine monitor (VMM) manage virtual\nmachines.\n\nIt performs interposition ([[s16ct1rj#interposition]]) on a certain\n_interesting_ instructions to _emulate_ then, hence _trap-and-emulate_. Those\ninteresting instruction can be:\n\n- Access to hardware devices\n- Special instructions (e.g., CPUID)\n- Access to important and dangerous registers that have global effect\n\nHypervisor works by exploiting modern hardware supports that allows trapping of\nthose important instructions.\n\n## Launching VM\n\nProcessor state of the VM is stored in a Virtual Machine Control structure/block\n(VMCS/VMCB) (see [VMCS](https://shhoya.github.io/hv_vmcsdata.html)). VMCS is a\ncomplex structure containing informations related to a VM's state. A pointer to\nthe current VMCS is stored in a dedicated register, loaded with `VMPTRLD`\ninstruction ([VMPTR](https://www.felixcloutier.com/x86/vmptrld.)).\n\nThe hypervisor is required to setup the VMCS correctly with necessary\ninformation.\n\nThe `VMLAUNCH\\VMRESUME` instruction is then used to lanch the VM based on the\ncurrent VMCS.\n\n## Memory management\n\n### Legacy\n\nPreviously, all access to physical memory in the Guest need to be interposed and\nemulated, which causes a lot of overheads. Address translation and paging need\nto be perform twice.\n\n### Shadow Page Table\n\nTo avoid this, Shadow page table (SPT) is a per-VM page table used by the\nhypervisor to translate guest virtual memory to host physical memory. It\nmaintain a copy of the guest page table in a _shadow_ page table, and mirror\nevery page table update from the guest.\n\nThis shadow page table is pointed to by CR3, and contains the actual mapping.\n\nUpon a guest page fault (aka, shadow page fault):\n\n- The hypervisor trap it, then forward it to the guest for it to update its page\n  table since there is no entry yet.\n- The guest update its page table (which will not be used by hardware\n  translation). This may trigger a real page fault if guest page table is set at\n  Read-only. Here the hypervisor can intercept and update the shadow page table.\n- The guest then access the memory. Since the mapping is now contained in the\n  shadow page table, it can access it.\n\nNote that this process bypass the two-time address translation.\n\nStill, this is expensive when there is a lot of paging in the guest VM, since\nevery page fault in the guest is forwarded to the host.\n\nNowaday it is still used in nested virtualization.\n\n### EPT/NPT\n\nExtended page table (EPT), aka Nested page table (NPT), is a hardware extension\nimplementing second-level address translation (SLAT). Each VM will have an\nadditional extended page table translate from guest physical address (gPAddr)\ninto host physical address (hPAddr). This extended page table is stored in the\nVMCS. In virtualization mode, the MMU now walk the guest VM page table first to\ntranslate gVAddr to gPAddr. Then the MMU, without stopping, translate the second\npage table in the host. Hence, host page table is _nested_ within the guest page\ntable to translate (gPAddr-\u003ehVAddr-\u003ehPAddr). If there is a page fault, the host\nOS simply update the nested table with the mapping. This allows more efficient\ntranslation.\n\nWith the technology, when there is on guest's page fault, there is no exit to\nthe hypervisor; the CPU automatically wals both page table.\n\nFor more implementation details of the feature, see\n[bhyve](https://people.freebsd.org/~neel/bhyve/bhyve_nested_paging.pdf)'s\nimplementation.\n\n## More resources\n\n- [High-level introduction to the Low-Level virtualization](http://haifux.org/lectures/312/High-Level%20Introduction%20to%20the%20Low-Level%20of%20Virtualization.pdf)\n- Intel manual?","snippets":["#virtualization #os"],"rawContent":"# Hypervisor (VMM)\n\n#virtualization #os\n\nA hypervisor, also known as virtual machine monitor (VMM) manage virtual\nmachines.\n\nIt performs interposition ([[s16ct1rj#interposition]]) on a certain\n_interesting_ instructions to _emulate_ then, hence _trap-and-emulate_. Those\ninteresting instruction can be:\n\n- Access to hardware devices\n- Special instructions (e.g., CPUID)\n- Access to important and dangerous registers that have global effect\n\nHypervisor works by exploiting modern hardware supports that allows trapping of\nthose important instructions.\n\n## Launching VM\n\nProcessor state of the VM is stored in a Virtual Machine Control structure/block\n(VMCS/VMCB) (see [VMCS](https://shhoya.github.io/hv_vmcsdata.html)). VMCS is a\ncomplex structure containing informations related to a VM's state. A pointer to\nthe current VMCS is stored in a dedicated register, loaded with `VMPTRLD`\ninstruction ([VMPTR](https://www.felixcloutier.com/x86/vmptrld.)).\n\nThe hypervisor is required to setup the VMCS correctly with necessary\ninformation.\n\nThe `VMLAUNCH\\VMRESUME` instruction is then used to lanch the VM based on the\ncurrent VMCS.\n\n## Memory management\n\n### Legacy\n\nPreviously, all access to physical memory in the Guest need to be interposed and\nemulated, which causes a lot of overheads. Address translation and paging need\nto be perform twice.\n\n### Shadow Page Table\n\nTo avoid this, Shadow page table (SPT) is a per-VM page table used by the\nhypervisor to translate guest virtual memory to host physical memory. It\nmaintain a copy of the guest page table in a _shadow_ page table, and mirror\nevery page table update from the guest.\n\nThis shadow page table is pointed to by CR3, and contains the actual mapping.\n\nUpon a guest page fault (aka, shadow page fault):\n\n- The hypervisor trap it, then forward it to the guest for it to update its page\n  table since there is no entry yet.\n- The guest update its page table (which will not be used by hardware\n  translation). This may trigger a real page fault if guest page table is set at\n  Read-only. Here the hypervisor can intercept and update the shadow page table.\n- The guest then access the memory. Since the mapping is now contained in the\n  shadow page table, it can access it.\n\nNote that this process bypass the two-time address translation.\n\nStill, this is expensive when there is a lot of paging in the guest VM, since\nevery page fault in the guest is forwarded to the host.\n\nNowaday it is still used in nested virtualization.\n\n### EPT/NPT\n\nExtended page table (EPT), aka Nested page table (NPT), is a hardware extension\nimplementing second-level address translation (SLAT). Each VM will have an\nadditional extended page table translate from guest physical address (gPAddr)\ninto host physical address (hPAddr). This extended page table is stored in the\nVMCS. In virtualization mode, the MMU now walk the guest VM page table first to\ntranslate gVAddr to gPAddr. Then the MMU, without stopping, translate the second\npage table in the host. Hence, host page table is _nested_ within the guest page\ntable to translate (gPAddr-\u003ehVAddr-\u003ehPAddr). If there is a page fault, the host\nOS simply update the nested table with the mapping. This allows more efficient\ntranslation.\n\nWith the technology, when there is on guest's page fault, there is no exit to\nthe hypervisor; the CPU automatically wals both page table.\n\nFor more implementation details of the feature, see\n[bhyve](https://people.freebsd.org/~neel/bhyve/bhyve_nested_paging.pdf)'s\nimplementation.\n\n## More resources\n\n- [High-level introduction to the Low-Level virtualization](http://haifux.org/lectures/312/High-Level%20Introduction%20to%20the%20Low-Level%20of%20Virtualization.pdf)\n- Intel manual?\n","wordCount":550,"tags":["os","virtualization"],"metadata":{},"created":"2023-05-24T08:20:59.378521317Z","modified":"2024-06-22T14:19:16.463563725Z","checksum":"249d98f7a6a6d0a8d3d2b019f178bf4dbabb16eee7edcf0d71bd919c54eb4c56"},
    {"filename":"1t3bkqpk.md","filenameStem":"1t3bkqpk","path":"1t3bkqpk.md","absPath":"/home/khadd/mynotes/1t3bkqpk.md","title":"I do not here speak of that perfection only which consists in power, but of that also which is founded in the conception of what is fit and beautiful. It is probable that a careful analysis of this question would conduct us to some such conclusion as the following, viz., that a perfect method should not only be an efficient one, as respects the accomplishment of the objects for which it is designed, but should in all its parts and processes manifest a certain unity and harmony","link":"[[1t3bkqpk]]","lead":"#quote","body":"#quote\n\n- By George Boole, in the book \"An Investigation of the Laws of Thought\"\n- Found in [src], where Djisktra is discussing about computer programs should\n  also be elegant.\n- [src]: https://www.cs.utexas.edu/~EWD/transcriptions/EWD01xx/EWD117.html","snippets":["#quote"],"rawContent":"# I do not here speak of that perfection only which consists in power, but of that also which is founded in the conception of what is fit and beautiful. It is probable that a careful analysis of this question would conduct us to some such conclusion as the following, viz., that a perfect method should not only be an efficient one, as respects the accomplishment of the objects for which it is designed, but should in all its parts and processes manifest a certain unity and harmony\n\n#quote\n\n- By George Boole, in the book \"An Investigation of the Laws of Thought\"\n- Found in [src], where Djisktra is discussing about computer programs should\n  also be elegant.\n- [src]: https://www.cs.utexas.edu/~EWD/transcriptions/EWD01xx/EWD117.html\n","wordCount":121,"tags":["quote"],"metadata":{},"created":"2024-12-09T04:15:21.654728296Z","modified":"2024-12-09T04:15:06.172051626Z","checksum":"8573df807f7bc4f0505f8bb4e549e6d058ffd8382ead6a60684e7569b41d6744"},
    {"filename":"zmt276jl.md","filenameStem":"zmt276jl","path":"zmt276jl.md","absPath":"/home/khadd/mynotes/zmt276jl.md","title":"I/O operations in AMD SEV","link":"[[zmt276jl]]","lead":"#sev #io #tee","body":"#sev #io #tee\n\nSEV VMs interacts with virtualized hardware through QEMU. More particularly,\nQEMU-KVM on the host side will serve I/O requests of the VM.\n\nSupported common I/O operations are PIO, MMIO, DMA.\n\n## DMA\n\nThe IOMMU maps DMA-capable I/O buses of hardware devices to the physical memory.\nBecause the IOMMU only supports memory encryption with ASID=0 (host ID), DMA\noperations must be done on pages that are shared between VM and host. Those\npages are called the Software I/O Translation Look-aside Buffer SWIOTLB.\n\nOn a read DMA request from the guest VM, QEMU-KVM instructs the IOMMU to perform\nDMA transfer from device into the SWIOTLB (e.g., swapping pages from the disk).\nThe guest VM then copy the pages inside SWIOTLB into its own memory.\n\nOn a write DMA request, the guest need to copy its data into the SWIOTLB first.\nQEMU-KVM then commands the IOMMU to transfer those pages to the devices.\n\n## Security\n\nBecause I/O is unencrypted, the cVM needs to encrypt the I/O data using the\nsoftware. However, certain types of data cannot be encrypted. For instance,\npackets for DHF key exchange are not encrypted.\n\n[@li2019exploiting] shows an example where a malicious hypervisor patches the\n`sshd` binaries to bypass the authentication.\n\n[@li2019exploiting] took a closer look at I/O operations that must not be\nencrypted:\n\n- In network I/O, the header of IP or TCP cannot be encrypted. Hence, the\n  attacker can forge the header.\n- In display I/O (e.g., VNC), QEMU-KVM redirects the VGA display from the guest\n  to the VNC protocol.\n- Disk I/O can be encrypted with a secret key provisioned by the cVM owner.\n  However, the key is stored in memory and can be extracted using the encryption\n  oracle described in the paper.\n\n## Related notes\n\n- [@li2019exploiting]: [[ncfh611p]]","snippets":["#sev #io #tee"],"rawContent":"# I/O operations in AMD SEV\n\n#sev #io #tee\n\nSEV VMs interacts with virtualized hardware through QEMU. More particularly,\nQEMU-KVM on the host side will serve I/O requests of the VM.\n\nSupported common I/O operations are PIO, MMIO, DMA.\n\n## DMA\n\nThe IOMMU maps DMA-capable I/O buses of hardware devices to the physical memory.\nBecause the IOMMU only supports memory encryption with ASID=0 (host ID), DMA\noperations must be done on pages that are shared between VM and host. Those\npages are called the Software I/O Translation Look-aside Buffer SWIOTLB.\n\nOn a read DMA request from the guest VM, QEMU-KVM instructs the IOMMU to perform\nDMA transfer from device into the SWIOTLB (e.g., swapping pages from the disk).\nThe guest VM then copy the pages inside SWIOTLB into its own memory.\n\nOn a write DMA request, the guest need to copy its data into the SWIOTLB first.\nQEMU-KVM then commands the IOMMU to transfer those pages to the devices.\n\n## Security\n\nBecause I/O is unencrypted, the cVM needs to encrypt the I/O data using the\nsoftware. However, certain types of data cannot be encrypted. For instance,\npackets for DHF key exchange are not encrypted.\n\n[@li2019exploiting] shows an example where a malicious hypervisor patches the\n`sshd` binaries to bypass the authentication.\n\n[@li2019exploiting] took a closer look at I/O operations that must not be\nencrypted:\n\n- In network I/O, the header of IP or TCP cannot be encrypted. Hence, the\n  attacker can forge the header.\n- In display I/O (e.g., VNC), QEMU-KVM redirects the VGA display from the guest\n  to the VNC protocol.\n- Disk I/O can be encrypted with a secret key provisioned by the cVM owner.\n  However, the key is stored in memory and can be extracted using the encryption\n  oracle described in the paper.\n\n## Related notes\n\n- [@li2019exploiting]: [[ncfh611p]]\n","wordCount":301,"tags":["tee","sev","io"],"metadata":{},"created":"2024-05-20T09:23:13.145941814Z","modified":"2024-06-20T10:33:59.689484774Z","checksum":"dac7f6527541a819435496dfe3da1500bdba6fe2f951bd440e5d85fd8937e066"},
    {"filename":"zm4xc4b9.md","filenameStem":"zm4xc4b9","path":"zm4xc4b9.md","absPath":"/home/khadd/mynotes/zm4xc4b9.md","title":"IITP","link":"[[zm4xc4b9]]","lead":"## Components","body":"## Components\n\n- Dynamic provenance tracking\n\n## Source APIs: Taint any value returned, depending on the privacy label of the argument\n\n- `torch.load(path)`\n\n## Model definition\n\n- `InceptionResnetV1()`\n\n## Propagation APIs: if any input is tainted, taint the return value\n\n- `Subset()`\n- `DataLoader()`\n- `x.to()`, x is an element of `DataLoader` type\n- `model(input)` is a model definition (i.e., `InceptionResnetV1`)\n- `criterion`\n\n## Sink API: Create artifact\n\n- torch.sink","snippets":["## Components"],"rawContent":"# IITP\n\n## Components\n\n- Dynamic provenance tracking\n\n## Source APIs: Taint any value returned, depending on the privacy label of the argument\n\n- `torch.load(path)`\n\n## Model definition\n\n- `InceptionResnetV1()`\n\n## Propagation APIs: if any input is tainted, taint the return value\n\n- `Subset()`\n- `DataLoader()`\n- `x.to()`, x is an element of `DataLoader` type\n- `model(input)` is a model definition (i.e., `InceptionResnetV1`)\n- `criterion`\n\n## Sink API: Create artifact\n\n- torch.sink\n","wordCount":72,"tags":[],"metadata":{},"created":"2024-10-28T09:34:26.359349523Z","modified":"2024-10-29T08:17:07.791947606Z","checksum":"6ff5114b1b61bbdd63fdce3a66dfe06f69c192627f8580dd2d0ccf9f5c9da955"},
    {"filename":"hxm4jt6e.md","filenameStem":"hxm4jt6e","path":"hxm4jt6e.md","absPath":"/home/khadd/mynotes/hxm4jt6e.md","title":"IOMMU, usage and considerations","link":"[[hxm4jt6e]]","lead":"The IOMMU enable a virtual memory subsystem for the hardware devices and enforce\npaging-like protection for each PCI device.","body":"The IOMMU enable a virtual memory subsystem for the hardware devices and enforce\npaging-like protection for each PCI device.\n\nThis is in response to threats of malicious DMA from devices [[3eot91og]].\n\nThe hypervisor can use the IOMMU to enforce intra-OS (isolating the buggy\ndevices from the kernel) and inter-Guest protection.\n\n## DMA isolation\n\nFor the most security, a transient mapping is created per transaction between\nthe VM and the hardware, and the mapping is destroyed right after. E.g., NIC\ndriver maps the VM packet buffers to hardware to the hardware NIC to receive\npackets, then unmap after packet is received.\n\nThis mechanism is refered to as **bounce buffering** [[jj89s7vj]] by Linux\ndevelopers and some modern papers.\n\nRelated:\n\n- [[asuoudgb]]\n\n## Overheads\n\nMaintaining transient IOMMU mappings this lead to high overheads, mostly due to\nIOTLB flushing and IO Virtual Addresses (IOVA) management. These mappings are\ncreated and destroyed millions of times per second [@peleg2015utilizing].\n\n- IOVA management taks up to 70% of cycles for IOMMU managment, due to the need\n  to aquire a global lock [@peleg2015utilizing] for each allocation.\n- For IOTLB flushing, it takes about 2000 cycles on Intel Sandy Bridge\n  [@markuze2016true].\n\n## IOTLB invalidation is (generally) more expensive than copying\n\nWhile it is a common knowledge that copying should be avoided, for most cases it\nis actually cheaper to copy the packets (~1500 bytes due to MTU). In stead of\ntemporarily allowing DMA to some kernel addresses, [@markuze2016true] propose to\ninstead maintain an always-mapped DMA buffer, and copy data from/to kernel\nmemory into it at every device transaction.\n\n## SWIOTLB\n\nSWIOTLB is kind of an emulation of hardware IOMMU [1]. In certain scenarios,\nlike confidential computing [[jj89s7vj]], DMA cannot be performed directly onto\nthe target memory buffer. SWIOTLB is an allocator that allocate memory that\nconform to the restriction for DMA (e.g., unencrypted memory). The CPU copy data\nto this bounce buffer, then data from the bounce buffer is DMA-ed by the device.\n\n## More\n\n- [1]: https://xillybus.com/tutorials/iommu-swiotlb-linux","snippets":["The IOMMU enable a virtual memory subsystem for the hardware devices and enforce\npaging-like protection for each PCI device."],"rawContent":"# IOMMU, usage and considerations\n\nThe IOMMU enable a virtual memory subsystem for the hardware devices and enforce\npaging-like protection for each PCI device.\n\nThis is in response to threats of malicious DMA from devices [[3eot91og]].\n\nThe hypervisor can use the IOMMU to enforce intra-OS (isolating the buggy\ndevices from the kernel) and inter-Guest protection.\n\n## DMA isolation\n\nFor the most security, a transient mapping is created per transaction between\nthe VM and the hardware, and the mapping is destroyed right after. E.g., NIC\ndriver maps the VM packet buffers to hardware to the hardware NIC to receive\npackets, then unmap after packet is received.\n\nThis mechanism is refered to as **bounce buffering** [[jj89s7vj]] by Linux\ndevelopers and some modern papers.\n\nRelated:\n\n- [[asuoudgb]]\n\n## Overheads\n\nMaintaining transient IOMMU mappings this lead to high overheads, mostly due to\nIOTLB flushing and IO Virtual Addresses (IOVA) management. These mappings are\ncreated and destroyed millions of times per second [@peleg2015utilizing].\n\n- IOVA management taks up to 70% of cycles for IOMMU managment, due to the need\n  to aquire a global lock [@peleg2015utilizing] for each allocation.\n- For IOTLB flushing, it takes about 2000 cycles on Intel Sandy Bridge\n  [@markuze2016true].\n\n## IOTLB invalidation is (generally) more expensive than copying\n\nWhile it is a common knowledge that copying should be avoided, for most cases it\nis actually cheaper to copy the packets (~1500 bytes due to MTU). In stead of\ntemporarily allowing DMA to some kernel addresses, [@markuze2016true] propose to\ninstead maintain an always-mapped DMA buffer, and copy data from/to kernel\nmemory into it at every device transaction.\n\n## SWIOTLB\n\nSWIOTLB is kind of an emulation of hardware IOMMU [1]. In certain scenarios,\nlike confidential computing [[jj89s7vj]], DMA cannot be performed directly onto\nthe target memory buffer. SWIOTLB is an allocator that allocate memory that\nconform to the restriction for DMA (e.g., unencrypted memory). The CPU copy data\nto this bounce buffer, then data from the bounce buffer is DMA-ed by the device.\n\n## More\n\n- [1]: https://xillybus.com/tutorials/iommu-swiotlb-linux\n","wordCount":334,"tags":[],"metadata":{},"created":"2024-12-10T04:37:32.228981321Z","modified":"2024-12-11T10:25:28.676129591Z","checksum":"624fe6d3904234646bc1f5f29c9484efc575c0c6da9e35e5039b9571b91cc38e"},
    {"filename":"syn2yulc.md","filenameStem":"syn2yulc","path":"syn2yulc.md","absPath":"/home/khadd/mynotes/syn2yulc.md","title":"IP configuration in Linux distributions","link":"[[syn2yulc]]","lead":"#admin #linux","body":"#admin #linux\n\n## Ubuntu\n\nUbuntu uses `netplan` for network configurations\n(\u003chttps://ubuntu.com/server/docs/network-configuration\u003e). To create a network\nconfiguration, create a file named `/etc/netplan/99_config.yaml` (or change the\nexisting config file.).\n\n```yaml\nnetwork:\n        version: 2\n        renderer: networkd\n        ethernets:\n                eth0:\n                        addresses:\n                                - 10.10.10.2/24\n                        routes:\n                                - to: default\n                                  via: 10.10.10.1\n                        nameservers:\n                                search: [mydomain, otherdomain]\n                                addresses: [10.10.10.1, 1.1.1.1]\n```\n\nAfter, runs `sudo netplan apply` to apply the configuration.","snippets":["#admin #linux"],"rawContent":"# IP configuration in Linux distributions\n\n#admin #linux\n\n## Ubuntu\n\nUbuntu uses `netplan` for network configurations\n(\u003chttps://ubuntu.com/server/docs/network-configuration\u003e). To create a network\nconfiguration, create a file named `/etc/netplan/99_config.yaml` (or change the\nexisting config file.).\n\n```yaml\nnetwork:\n        version: 2\n        renderer: networkd\n        ethernets:\n                eth0:\n                        addresses:\n                                - 10.10.10.2/24\n                        routes:\n                                - to: default\n                                  via: 10.10.10.1\n                        nameservers:\n                                search: [mydomain, otherdomain]\n                                addresses: [10.10.10.1, 1.1.1.1]\n```\n\nAfter, runs `sudo netplan apply` to apply the configuration.\n","wordCount":67,"tags":["linux","admin"],"metadata":{},"created":"2023-09-01T03:11:58.119340057Z","modified":"2024-06-28T07:57:32.770047153Z","checksum":"bd881cd316413863acf91ec1249354f19cb6351dda0b1ca81cb8a3ad4ffb4edc"},
    {"filename":"zz3cedu0.md","filenameStem":"zz3cedu0","path":"zz3cedu0.md","absPath":"/home/khadd/mynotes/zz3cedu0.md","title":"Idea Compass","link":"[[zz3cedu0]]","lead":"#zettelkasten #note-taking","body":"#zettelkasten #note-taking\n\nIdea Compass is a thinking tool that helps define how to think about a\nparticular idea. In particular, it is described in\n[Compass of Zettelkasten Thinking](https://feeei.substack.com/i/48707291/the-compass-of-zettelkasten-thinking)\nas follows:\n\n\u003e\n\n1. take one idea (X) and put it in the centre\n2. imagine the four compass directions. each direction helps give definition to\n   the idea in different ways.\n\n- NORTH: _“Where does X come from?”_ what are its origin? what group/category\n  does X belong to? what exists an order of magnitude higher? zoom out. what\n  gave birth to X? what causes X\n- WEST: _“What is similar to X?”_ what other disciplines could X already exist\n  in? what other disciplines could benefit from X? what are other ways to say/do\n  X?\n- SOUTH: _“Where can X lead to?”_ what does X contribute to? what group/category\n  could X be the headline of? what exists an order of magnitude lower? zoom in.\n  what does X nurture?\n- EAST: _“What competes with X?”_ what is the opposite of X? what is X missing?\n  its disadvantage? what could supercharge X?\n\n3. The Zettelkasten structure created around the idea could look something like\n   this:\n\n- NORTH\n  - The Idea\n    - SOUTH\n    - EAST\n    - WEST\n\nTakes the idea of the _idea compass_ itself for example. We can start from the\nNORTH:\n\n- NORTH: _\"Where does X come from?\"_\n  - This idea comes from the lack of clear instructions for using the\n       zettelkasten method. For instance, what should an idea contain? How do\n       you connect it with other ideas?\n  - Hence, the author introduces a framework for finding the _context_ of an\n       idea.\n  - SOUTH: _What can X leads to?_\n    - This idea helps to discover the context of a Zettelkasten note. More\n            importantly, helps writing notes easier [[cemsxh4n]]\n  - EAST: _“What competes with X?”_\n  - WEST: \\*“What is similar to _X?”_\n  - [This](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/)\n       introduces another technique called the _knowledge flower_ [[dyx2t4oz]]\n       that is more open for interpretation.","snippets":["#zettelkasten #note-taking"],"rawContent":"# Idea Compass\n\n#zettelkasten #note-taking\n\nIdea Compass is a thinking tool that helps define how to think about a\nparticular idea. In particular, it is described in\n[Compass of Zettelkasten Thinking](https://feeei.substack.com/i/48707291/the-compass-of-zettelkasten-thinking)\nas follows:\n\n\u003e\n\n1. take one idea (X) and put it in the centre\n2. imagine the four compass directions. each direction helps give definition to\n   the idea in different ways.\n\n- NORTH: _“Where does X come from?”_ what are its origin? what group/category\n  does X belong to? what exists an order of magnitude higher? zoom out. what\n  gave birth to X? what causes X\n- WEST: _“What is similar to X?”_ what other disciplines could X already exist\n  in? what other disciplines could benefit from X? what are other ways to say/do\n  X?\n- SOUTH: _“Where can X lead to?”_ what does X contribute to? what group/category\n  could X be the headline of? what exists an order of magnitude lower? zoom in.\n  what does X nurture?\n- EAST: _“What competes with X?”_ what is the opposite of X? what is X missing?\n  its disadvantage? what could supercharge X?\n\n3. The Zettelkasten structure created around the idea could look something like\n   this:\n\n- NORTH\n  - The Idea\n    - SOUTH\n    - EAST\n    - WEST\n\nTakes the idea of the _idea compass_ itself for example. We can start from the\nNORTH:\n\n- NORTH: _\"Where does X come from?\"_\n  - This idea comes from the lack of clear instructions for using the\n       zettelkasten method. For instance, what should an idea contain? How do\n       you connect it with other ideas?\n  - Hence, the author introduces a framework for finding the _context_ of an\n       idea.\n  - SOUTH: _What can X leads to?_\n    - This idea helps to discover the context of a Zettelkasten note. More\n            importantly, helps writing notes easier [[cemsxh4n]]\n  - EAST: _“What competes with X?”_\n  - WEST: \\*“What is similar to _X?”_\n  - [This](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/)\n       introduces another technique called the _knowledge flower_ [[dyx2t4oz]]\n       that is more open for interpretation.\n","wordCount":326,"tags":["zettelkasten","note-taking"],"metadata":{},"created":"2024-05-20T09:23:13.162600914Z","modified":"2024-06-20T07:51:41.330114144Z","checksum":"70d8a5f3b6c83a8c5a355e9d99439c967cf336d0530655d23e3571e1c56cef8a"},
    {"filename":"qypdxa5v.md","filenameStem":"qypdxa5v","path":"qypdxa5v.md","absPath":"/home/khadd/mynotes/qypdxa5v.md","title":"Immediate Novelty","link":"[[qypdxa5v]]","lead":"#research","body":"#research\n\nA type of research novelty I usually see is the novelty when directly compared\nagainst a limited set of previous work, usually only in the scope of a problem.\n\nFor instance, [@bang2023trust] proposes a new compiler framework for isolating\nunsafe Rust components. Its immediate comparison targets are only 3 papers, each\ntackle a different parts of the problem in Rust (only Unsafe Rust, or only\nexternal libraries).\n\nNow, this paper's individual novelty is judged one by one, it is not very\ninteresting. The idea of improving points-to analysis with cloning exist before.\nMoreover, automatic isolation using compiler is hardly a new thing, as there has\nbeen a numbers of previous works for C.\n\nHowever, as the comparison target is only its immediate predecessor in the scope\nof Rust, the paper has clear advantages over these works and is considered (at\nleast by the reviewers [[itd1o3ic]]).","snippets":["#research"],"rawContent":"# Immediate Novelty\n\n#research\n\nA type of research novelty I usually see is the novelty when directly compared\nagainst a limited set of previous work, usually only in the scope of a problem.\n\nFor instance, [@bang2023trust] proposes a new compiler framework for isolating\nunsafe Rust components. Its immediate comparison targets are only 3 papers, each\ntackle a different parts of the problem in Rust (only Unsafe Rust, or only\nexternal libraries).\n\nNow, this paper's individual novelty is judged one by one, it is not very\ninteresting. The idea of improving points-to analysis with cloning exist before.\nMoreover, automatic isolation using compiler is hardly a new thing, as there has\nbeen a numbers of previous works for C.\n\nHowever, as the comparison target is only its immediate predecessor in the scope\nof Rust, the paper has clear advantages over these works and is considered (at\nleast by the reviewers [[itd1o3ic]]).\n","wordCount":149,"tags":["research"],"metadata":{},"created":"2024-07-05T05:17:34.96744646Z","modified":"2024-07-05T05:27:14.743308704Z","checksum":"dcef6c12ba4a605a06bb65de0513005cc051b93b091378940b320d6406370b46"},
    {"filename":"y0z8fhtd.md","filenameStem":"y0z8fhtd","path":"y0z8fhtd.md","absPath":"/home/khadd/mynotes/y0z8fhtd.md","title":"Implementing capability systems","link":"[[y0z8fhtd]]","lead":"#capabilities","body":"#capabilities\n\nCapability concepts are simple enough to understand, but implementing them is a\ndifferent story.\n\n## Unforgeability of token\n\nA fundamental challenge is how to make the capability tokens _unforgeable_,\nwhile also allowing the user (subjects) to keep them. For example, plain\npointers are not capabilities token, as they may be easily modified by the\nuntrusted program.\n\nImplementing a storage for capability token requires maintaining their\nintegrity, which have two classical solutions: (1) access control and (2)\ncryptographic hash. This can be also phrased as (a) protected storage vs. (b)\nunprotected storage.\n\n- OSes use the access control model for simplicity, speed, and making use of\n  hardware assisted isolation (ring levels).\n  - For example, Linux maintains a per-process file descriptor table, and give\n    the index to the userspace. The userspace can use FD from the table, but\n    cannot obtain more privileges.\n- Hardware capabilities systems uses both approaches.\n  - CHERI-type system enforces access control. They store capability tokens in\n    write-protected memory regions.\n  - Cryptographic capabilities systems combines pointer encryption.\n- In distributed systems, cryptographic hash is used since network\n  communications already take most of the overheads, this implementation omits\n  the need for a centralized capability storage.\n\nFor access control type, it requires a centralized storage of capability tokens.\n\n## Invocation\n\nThere must be a security monitor that serves **capability invocations**. Usually\nin OSes capabilities are given as an opaque handle that are index to a\nkernel-maintained capability table [@steinberg2010nova,@klein2009sel4]\n([[sn99wrm0]]), which cannot be used directly, but must be _invoked_ through the\nprivileged software through system calls.\n\nAn alternative design is to let capabilities be invoked directly, e.g., pointer\naccess, but somehow enforce all invocation are checked (complete mediation).\nThis can be done through\n\n- Fault handler [@shapiro1999eros]\n- Compiler checks [@dinhduy2023capacity, @framer] (not common)\n- CPU automatic checks [@watson2015cheri]\n\n## Implementing delegation and revocation\n\nRealizing delegation and revocation is another headache. Most capability systems\noften do not support revocation.\n\nIdeally capability tokens should be freely given by a subject to other subjects.\nIn a centralized capability system, Delegation is easy enough. When receiving a\ndelegation request, you simply copy the capability (permissions) over to the\ntarget.\n\n### Revocation require tracking delegation\n\nHowever, enabling revocation is non-trivial and require complex state\nmanagements. It requires the enforcement to keep track of the flow of the\ncapability tokens across different subjects. For example if\n`A - delegate -\u003e B - delegate -\u003e C`, and A want to revoke the A to B delegation,\nthe delegated token for B and C must be revoked.\n\nThis complexity is often too much for hardware implementation, as they not only\nneed to keep track of where capabilities are, but also\n\n1. The chain of delegation of the capability\n2. All the copies of this capability in memory (i.e., runtime information flow\n   tracking).\n\n### Single-ownership\n\nEnforcing single-ownership is another way to simplify revocation. In fact, there\nis no need revocation in the first place, as the capability token is basically\ntransferred to the target.\n\nStill, the challenge is to \"revoke\" the existing capability of the delegating\nsubject. Doing so also require tracking where this capability has been, e.g.,\nwhat if the subject make copies of the capability before delegation.\n\nSingle-ownership can be enforced with programming language invariants\n[@narayanan2020redleaf,@boos2020theseus].\n\n## Retrofitting interfaces for capabilities\n\nOne must decompose existing interfaces into a set of capability objects and the\nset of operations that may be invoked on them.","snippets":["#capabilities"],"rawContent":"# Implementing capability systems\n\n#capabilities\n\nCapability concepts are simple enough to understand, but implementing them is a\ndifferent story.\n\n## Unforgeability of token\n\nA fundamental challenge is how to make the capability tokens _unforgeable_,\nwhile also allowing the user (subjects) to keep them. For example, plain\npointers are not capabilities token, as they may be easily modified by the\nuntrusted program.\n\nImplementing a storage for capability token requires maintaining their\nintegrity, which have two classical solutions: (1) access control and (2)\ncryptographic hash. This can be also phrased as (a) protected storage vs. (b)\nunprotected storage.\n\n- OSes use the access control model for simplicity, speed, and making use of\n  hardware assisted isolation (ring levels).\n  - For example, Linux maintains a per-process file descriptor table, and give\n    the index to the userspace. The userspace can use FD from the table, but\n    cannot obtain more privileges.\n- Hardware capabilities systems uses both approaches.\n  - CHERI-type system enforces access control. They store capability tokens in\n    write-protected memory regions.\n  - Cryptographic capabilities systems combines pointer encryption.\n- In distributed systems, cryptographic hash is used since network\n  communications already take most of the overheads, this implementation omits\n  the need for a centralized capability storage.\n\nFor access control type, it requires a centralized storage of capability tokens.\n\n## Invocation\n\nThere must be a security monitor that serves **capability invocations**. Usually\nin OSes capabilities are given as an opaque handle that are index to a\nkernel-maintained capability table [@steinberg2010nova,@klein2009sel4]\n([[sn99wrm0]]), which cannot be used directly, but must be _invoked_ through the\nprivileged software through system calls.\n\nAn alternative design is to let capabilities be invoked directly, e.g., pointer\naccess, but somehow enforce all invocation are checked (complete mediation).\nThis can be done through\n\n- Fault handler [@shapiro1999eros]\n- Compiler checks [@dinhduy2023capacity, @framer] (not common)\n- CPU automatic checks [@watson2015cheri]\n\n## Implementing delegation and revocation\n\nRealizing delegation and revocation is another headache. Most capability systems\noften do not support revocation.\n\nIdeally capability tokens should be freely given by a subject to other subjects.\nIn a centralized capability system, Delegation is easy enough. When receiving a\ndelegation request, you simply copy the capability (permissions) over to the\ntarget.\n\n### Revocation require tracking delegation\n\nHowever, enabling revocation is non-trivial and require complex state\nmanagements. It requires the enforcement to keep track of the flow of the\ncapability tokens across different subjects. For example if\n`A - delegate -\u003e B - delegate -\u003e C`, and A want to revoke the A to B delegation,\nthe delegated token for B and C must be revoked.\n\nThis complexity is often too much for hardware implementation, as they not only\nneed to keep track of where capabilities are, but also\n\n1. The chain of delegation of the capability\n2. All the copies of this capability in memory (i.e., runtime information flow\n   tracking).\n\n### Single-ownership\n\nEnforcing single-ownership is another way to simplify revocation. In fact, there\nis no need revocation in the first place, as the capability token is basically\ntransferred to the target.\n\nStill, the challenge is to \"revoke\" the existing capability of the delegating\nsubject. Doing so also require tracking where this capability has been, e.g.,\nwhat if the subject make copies of the capability before delegation.\n\nSingle-ownership can be enforced with programming language invariants\n[@narayanan2020redleaf,@boos2020theseus].\n\n## Retrofitting interfaces for capabilities\n\nOne must decompose existing interfaces into a set of capability objects and the\nset of operations that may be invoked on them.\n","wordCount":571,"tags":["capabilities"],"metadata":{},"created":"2024-12-12T05:46:16.539126009Z","modified":"2024-12-23T05:48:24.08921951Z","checksum":"311a7b500ee596e808164478b9b25cad571a3ae26146281ec34534da4fb744c2"},
    {"filename":"u1qgpjhe.md","filenameStem":"u1qgpjhe","path":"u1qgpjhe.md","absPath":"/home/khadd/mynotes/u1qgpjhe.md","title":"IncognitOS","link":"[[u1qgpjhe]]","lead":"#project","body":"#project\n\n## Notes\n\n- [[dpg049d1]]\n- [[baoqhski]]\n\n## Info\n\n- [[rlcg39bj]]","snippets":["#project"],"rawContent":"# IncognitOS\n\n#project\n\n## Notes\n\n- [[dpg049d1]]\n- [[baoqhski]]\n\n## Info\n\n- [[rlcg39bj]]\n","wordCount":13,"tags":["project"],"metadata":{},"created":"2024-05-23T06:28:26.294259469Z","modified":"2024-12-16T06:41:55.236314785Z","checksum":"3f433032cb5384d34ebeac88bddaf806e462ac7d502a3c00c7ec874043fee384"},
    {"filename":"7ld2zw1l.md","filenameStem":"7ld2zw1l","path":"7ld2zw1l.md","absPath":"/home/khadd/mynotes/7ld2zw1l.md","title":"IncognitOS archive","link":"[[7ld2zw1l]]","lead":"#archive","body":"#archive\n\n## 2024-07-25\n\n```bash\nBASELINE\nTEST                : Iterations/sec.  : Old Index   : New Index\n                    :                  : Pentium 90* : AMD K6/233*\n--------------------:------------------:-------------:------------\nNUMERIC SORT        :          2553.5  :      65.49  :      21.51\nSTRING SORT         :          2874.8  :    1284.53  :     198.82\nBITFIELD            :      1.1325e+09  :     194.26  :      40.58\nFP EMULATION        :          1134.5  :     544.39  :     125.62\nFOURIER             :      2.1469e+05  :     244.16  :     137.14\nASSIGNMENT          :          94.417  :     359.27  :      93.19\nIDEA                :           20703  :     316.64  :      94.01\nHUFFMAN             :          8929.9  :     247.63  :      79.07\nNEURAL NET          :\n\nCFR + O3\n\nmode                  = Linux ELF executable\ninput_binary          = ./nbench\noutput_binary         = a.out\nnum_patched           = 793 / 794 (99.87%)\nnum_patched_B2        = 15 / 794 (1.89%)\nnum_patched_T0        = 703 / 794 (88.54%)\nnum_patched_T1        = 14 / 794 (1.76%)\nnum_patched_T2        = 0 / 794 (0.00%)\nnum_patched_T3        = 1 / 794 (0.13%)\nnum_virtual_mappings  = 49\nnum_physical_mappings = 20 (40.82%)\nnum_virtual_bytes     = 200704\nnum_physical_bytes    = 81920 (40.82%)\ninput_file_size       = 73344\noutput_file_size      = 209130 (285.14%)\ntime_elapsed          = 11ms\nmemory_used           = 4812KB\n\nTEST                : Iterations/sec.  : Old Index   : New Index\n                    :                  : Pentium 90* : AMD K6/233*\n--------------------:------------------:-------------:------------\nNUMERIC SORT        :            1329  :      34.08  :      11.19\nSTRING SORT         :          1360.4  :     607.85  :      94.08\nBITFIELD            :      7.1621e+08  :     122.86  :      25.66\nFP EMULATION        :          852.94  :     409.28  :      94.44\nFOURIER             :      1.9182e+05  :     218.15  :     122.53\nASSIGNMENT          :          30.292  :     115.26  :      29.90\nIDEA                :          4766.1  :      72.90  :      21.64\nHUFFMAN             :          2588.7  :      71.79  :      22.92\n\nO3\n\nmode                  = Linux ELF executable\ninput_binary          = ./nbench\noutput_binary         = a.out\nnum_patched           = 793 / 794 (99.87%)\nnum_patched_B2        = 96 / 794 (12.09%)\nnum_patched_T1        = 28 / 794 (3.53%)\nnum_patched_T2        = 1 / 794 (0.13%)\nnum_patched_T3        = 3 / 794 (0.38%)\nnum_virtual_mappings  = 75\nnum_physical_mappings = 22 (29.33%)\nnum_virtual_bytes     = 307200\nnum_physical_bytes    = 90112 (29.33%)\ninput_file_size       = 73344\noutput_file_size      = 217634 (296.73%)\ntime_elapsed          = 11ms\nmemory_used           = 4812KB\n\nTEST                : Iterations/sec.  : Old Index   : New Index\n                    :                  : Pentium 90* : AMD K6/233*\n--------------------:------------------:-------------:------------\nNUMERIC SORT        :          1275.4  :      32.71  :      10.74\nSTRING SORT         :          1139.9  :     509.36  :      78.84\nBITFIELD            :      5.5403e+08  :      95.04  :      19.85\nFP EMULATION        :          840.37  :     403.25  :      93.05\nFOURIER             :      1.8739e+05  :     213.12  :     119.70\nASSIGNMENT          :           25.15  :      95.70  :      24.82\nIDEA                :          4872.7  :      74.53  :      22.13\nHUFFMAN             :            2497  :      69.24  :      22.11\n\n\nO2\n\nmode                  = Linux ELF executable\ninput_binary          = ./nbench\noutput_binary         = a.out\nnum_patched           = 793 / 794 (99.87%)\nnum_patched_B2        = 97 / 794 (12.22%)\nnum_patched_T1        = 27 / 794 (3.40%)\nnum_patched_T2        = 1 / 794 (0.13%)\nnum_patched_T3        = 3 / 794 (0.38%)\nnum_virtual_mappings  = 74\nnum_physical_mappings = 20 (27.03%)\nnum_virtual_bytes     = 303104\nnum_physical_bytes    = 81920 (27.03%)\ninput_file_size       = 73344\noutput_file_size      = 209430 (285.54%)\ntime_elapsed          = 10ms\nmemory_used           = 4428KB\n\n1284\n```\n\n## 2024-07-31\n\n```\nOK\nAT_NOTELF:            0\nAT_UCACHEBSIZE:       0x0\nAT_ICACHEBSIZE:       0x0\nAT_DCACHEBSIZE:       0x0\nAT_EXECFN:            nbench\nAT_SECURE:            0\nAT_EGID:              0\nAT_GID:               0\nAT_EUID:              0\nAT_UID:               0\nAT_ENTRY:             0x100001d8c0\nAT_FLAGS:             0x0\nAT_CLKTCK:            100\nAT_HWCAP:             0\nAT_PAGESZ:            4096\nAT_BASE:              0x1000060000\nAT_RANDOM:            0x11ec0\nAT_PHENT:             56\nAT_PHNUM:             13\nAT_PHDR:              0x100001a040\nAT_PLATFORM:          x86_64\n         2:\n\nFAIL\nAT_NOTELF:            0\nAT_UCACHEBSIZE:       0x0\nAT_ICACHEBSIZE:       0x0\nAT_DCACHEBSIZE:       0x0\nAT_EXECFN:            a.out\nAT_SECURE:            0\nAT_EGID:              0\nAT_GID:               0\nAT_EUID:              0\nAT_UID:               0\nAT_ENTRY:             0x120ea29688\nAT_FLAGS:             0x0\nAT_CLKTCK:            100\nAT_HWCAP:             0\nAT_PAGESZ:            4096\nAT_BASE:              0x1000057000\nAT_RANDOM:            0x11ec0\nAT_PHENT:             56\nAT_PHNUM:             13\nAT_PHDR:              0x1000040040\nAT_PLATFORM:          x86_64\n```\n\n```\n[    0.308951] dbg:  [appelfloader] \u003celf_load.c @  104\u003e a.out: ELF machine type: 62\n[    0.310271] dbg:  [appelfloader] \u003celf_load.c @  120\u003e a.out: ELF OS ABI: 0\n[    0.311515] dbg:  [appelfloader] \u003celf_load.c @  134\u003e a.out: ELF object type: 3\n[    0.312813] dbg:  [appelfloader] \u003celf_load.c @  177\u003e a.out: phdr[2]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 6912 B, memsz 6912 B, align: 4096 B\n[    0.314856] dbg:  [appelfloader] \u003celf_load.c @  188\u003e a.out: \\_ segment at pie + 0x0 (len: 0x1b00) from file @ 0x0 (len: 0x1b00)\n[    0.316631] dbg:  [appelfloader] \u003celf_load.c @  177\u003e a.out: phdr[3]: R-X, offset: 0x2000, vaddr: 0x2000, paddr: 0x2000, filesz: 47269 B, memsz 47269 B, align: 4096 B\n[    0.318792] dbg:  [appelfloader] \u003celf_load.c @  188\u003e a.out: \\_ segment at pie + 0x2000 (len: 0xb8a5) from file @ 0x2000 (len: 0xb8a5)\n[    0.320628] dbg:  [appelfloader] \u003celf_load.c @  177\u003e a.out: phdr[4]: R--, offset: 0xe000, vaddr: 0xe000, paddr: 0xe000, filesz: 9104 B, memsz 9104 B, align: 4096 B\n[    0.322764] dbg:  [appelfloader] \u003celf_load.c @  188\u003e a.out: \\_ segment at pie + 0xe000 (len: 0x2390) from file @ 0xe000 (len: 0x2390)\n[    0.324600] dbg:  [appelfloader] \u003celf_load.c @  177\u003e a.out: phdr[5]: RW-, offset: 0x10c78, vaddr: 0x11c78, paddr: 0x11c78, filesz: 2208 B, memsz 17456 B, align: 4096 B\n[    0.326775] dbg:  [appelfloader] \u003celf_load.c @  188\u003e a.out: \\_ segment at pie + 0x11c78 (len: 0x4430) from file @ 0x10c78 (len: 0x8a0)\n[    0.328620] dbg:  [appelfloader] \u003celf_load.c @  177\u003e a.out: phdr[8]: R-X, offset: 0x38000, vaddr: 0x20e9e9000, paddr: 0, filesz: 5313 B, memsz 5313 B, align: 4096 B\n[    0.330773] dbg:  [appelfloader] \u003celf_load.c @  188\u003e a.out: \\_ segment at pie + 0x0 (len: 0x14c1) from file @ 0x38000 (len: 0x14c1)\n[    0.332588] dbg:  [appelfloader] \u003celf_load.c @  211\u003e a.out: base: pie + 0x0, len: 0x160a8\n[    0.333993] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 98304 fd = 3\n[    0.335448] dbg:  [appelfloader] \u003celf_load.c @  442\u003e a.out: Memory mapped 0x0 - 0x1b00 to 0x1000040000 - 0x1000041b00\n[    0.337141] dbg:  [appelfloader] \u003celf_load.c @  464\u003e a.out: Program/Library memory region: 0x1000040000-0x1000057000\n[    0.338809] dbg:  [appelfloader] \u003celf_load.c @  349\u003e a.out: Zeroing 0x1000041b00 - 0x1000042000\n[    0.340269] dbg:  [appelfloader] \u003celf_load.c @  510\u003e a.out: Memory mapping 0x2000 - 0xd8a5 to 0x1000042000 - 0x100004d8a5\n[    0.341991] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000042000 len = 47269 fd = 3\n[    0.343545] dbg:  [appelfloader] \u003celf_load.c @  349\u003e a.out: Zeroing 0x100004d8a5 - 0x100004e000\n[    0.345010] dbg:  [appelfloader] \u003celf_load.c @  510\u003e a.out: Memory mapping 0xe000 - 0x10390 to 0x100004e000 - 0x1000050390\n[    0.346738] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100004e000 len = 9104 fd = 3\n[    0.348280] dbg:  [appelfloader] \u003celf_load.c @  349\u003e a.out: Zeroing 0x1000050390 - 0x1000051000\n[    0.349752] dbg:  [appelfloader] \u003celf_load.c @  510\u003e a.out: Memory mapping 0x10000 - 0x12190 to 0x1000051000 - 0x1000052518\n[    0.351602] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000051000 len = 5400 fd = 3\n[    0.353151] dbg:  [appelfloader] \u003celf_load.c @  349\u003e a.out: Zeroing 0x1000052518 - 0x1000057000\n[    0.354615] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000053000 len = 16384 fd = -1\n[    0.356184] dbg:  [appelfloader] \u003celf_load.c @  510\u003e a.out: Memory mapping 0x38000 - 0x394c1 to 0x1000040000 - 0x10000414c1\n[    0.357939] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000040000 len = 5313 fd = 3\n[    0.359488] dbg:  [appelfloader] \u003celf_load.c @  349\u003e a.out: Zeroing 0x10000414c1 - 0x1000042000\n[    0.360959] dbg:  [appelfloader] \u003celf_load.c @  781\u003e a.out: Protecting 0x1000040000 - 0x1000042000: R--\n[    0.362506] dbg:  [appelfloader] \u003celf_load.c @  781\u003e a.out: Protecting 0x1000042000 - 0x100004e000: R-X\n[    0.364054] dbg:  [appelfloader] \u003celf_load.c @  781\u003e a.out: Protecting 0x100004e000 - 0x1000051000: R--\n[    0.365613] dbg:  [appelfloader] \u003celf_load.c @  781\u003e a.out: Protecting 0x1000051000 - 0x1000057000: RW-\n[    0.367160] dbg:  [appelfloader] \u003celf_load.c @  781\u003e a.out: Protecting 0x1000040000 - 0x1000042000: R-X\n[    0.368714] dbg:  [appelfloader] \u003celf_load.c @ 1024\u003e a.out: Loading program interpreter /lib64/ld-linux-x86-64.so.2...\n[    0.370417] Info: [libvfscore] \u003csyscalls.c @  124\u003e sys_open: path=/lib64/ld-linux-x86-64.so.2 flags=0 mode=0\n[    0.372060] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 191504 fd = 3\n[    0.373536] dbg:  [appelfloader] \u003celf_load.c @  104\u003e \u003cinterp\u003e: ELF machine type: 62\n[    0.374885] dbg:  [appelfloader] \u003celf_load.c @  120\u003e \u003cinterp\u003e: ELF OS ABI: 0\n[    0.376165] dbg:  [appelfloader] \u003celf_load.c @  134\u003e \u003cinterp\u003e: ELF object type: 3\n[    0.377502] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[0]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 4040 B, memsz 4040 B, align: 4096 B\n[    0.379525] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x0 (len: 0xfc8) from file @ 0x0 (len: 0xfc8)\n[    0.381325] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[1]: R-X, offset: 0x1000, vaddr: 0x1000, paddr: 0x1000, filesz: 140932 B, memsz 140932 B, align: 4096 B\n[    0.383532] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x1000 (len: 0x22684) from file @ 0x1000 (len: 0x22684)\n[    0.385434] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[2]: R--, offset: 0x24000, vaddr: 0x24000, paddr: 0x24000, filesz: 31948 B, memsz 31948 B, align: 4096 B\n[    0.387654] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x24000 (len: 0x7ccc) from file @ 0x24000 (len: 0x7ccc)\n[    0.389549] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[3]: RW-, offset: 0x2c520, vaddr: 0x2d520, paddr: 0x2d520, filesz: 6872 B, memsz 7280 B, align: 4096 B\n[    0.391749] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x2d520 (len: 0x1c70) from file @ 0x2c520 (len: 0x1ad8)\n[    0.393647] dbg:  [appelfloader] \u003celf_load.c @  211\u003e \u003cinterp\u003e: base: pie + 0x0, len: 0x2f190\n[    0.395085] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 200704 fd = 3\n[    0.396568] dbg:  [appelfloader] \u003celf_load.c @  442\u003e \u003cinterp\u003e: Memory mapped 0x0 - 0xfc8 to 0x1000057000 - 0x1000057fc8\n[    0.398294] dbg:  [appelfloader] \u003celf_load.c @  464\u003e \u003cinterp\u003e: Program/Library memory region: 0x1000057000-0x1000087000\n[    0.399999] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x1000057fc8 - 0x1000058000\n[    0.401502] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x1000 - 0x23684 to 0x1000058000 - 0x100007a684\n[    0.403266] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000058000 len = 140932 fd = 3\n[    0.404854] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x100007a684 - 0x100007b000\n[    0.406353] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x24000 - 0x2bccc to 0x100007b000 - 0x1000082ccc\n[    0.408126] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100007b000 len = 31948 fd = 3\n[    0.409691] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x1000082ccc - 0x1000083000\n[    0.411189] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x2c000 - 0x2e518 to 0x1000084000 - 0x1000085ff8\n[    0.412968] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000084000 len = 8184 fd = 3\n[    0.414514] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x1000085ff8 - 0x1000087000\n[    0.416011] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000086000 len = 4096 fd = -1\n[    0.417580] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000057000 - 0x1000058000: R--\n[    0.419157] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000058000 - 0x100007b000: R-X\n[    0.420733] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x100007b000 - 0x1000083000: R--\n[    0.422316] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000084000 - 0x1000087000: RW-\n[    0.423904] Info: [appelfloader] \u003cmain.c @  213\u003e a.out: ELF program loaded to 0x1000040000-0x1000057000 (94208 B), entry at 0x120ea29688\n[    0.425832] dbg:  [appelfloader] \u003cmain.c @  231\u003e a.out: Prepare application thread...\n[    0.427202] dbg:  [appelfloader] \u003celf_ctx.c @  145\u003e a.out: image:          0x1000040000 - 0x1000057000\n[    0.428746] dbg:  [appelfloader] \u003celf_ctx.c @  148\u003e a.out: start:          0x1000040000\n[    0.430150] dbg:  [appelfloader] \u003celf_ctx.c @  150\u003e a.out: entry:          0x120ea29688\n[    0.431542] dbg:  [appelfloader] \u003celf_ctx.c @  152\u003e a.out: phdr.off:       0x40\n[    0.432858] dbg:  [appelfloader] \u003celf_ctx.c @  154\u003e a.out: phdr.num:       13\n[    0.434150] dbg:  [appelfloader] \u003celf_ctx.c @  156\u003e a.out: phdr.entsize:   0x38\n[    0.435466] dbg:  [appelfloader] \u003celf_ctx.c @  159\u003e a.out: interp:         0x1000057000 - 0x1000087000\n[    0.437007] dbg:  [appelfloader] \u003celf_ctx.c @  163\u003e a.out: interp.start:   0x1000057000\n[    0.438396] dbg:  [appelfloader] \u003celf_ctx.c @  165\u003e a.out: interp.entry:   0x1000058100\n[    0.439786] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[4]=\"LD_DEBUG=all\"\n[    0.441045] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[3]=\"LD_BIND_NOW=1\"\n[    0.442304] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[2]=\"LD_SHOW_AUXV=1\"\n[    0.443578] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[1]=\"LD_LIBRARY_PATH=/lib/x86_64-linux-gnu/\"\n[    0.445094] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[0]=\"PATH=/bin\"\n[    0.446314] dbg:  [appelfloader] \u003cmain.c @  240\u003e a.out: Application stack at 0x400380020 - 0x4003a0020, pointer: 0x40039fdd0\n[    0.448075] dbg:  [appelfloader] \u003cmain.c @  246\u003e a.out: Application entrance at 0x2d8230\n\n\n[    0.318200] dbg:  [appelfloader] \u003celf_load.c @  104\u003e nbench: ELF machine type: 62\n[    0.319588] dbg:  [appelfloader] \u003celf_load.c @  120\u003e nbench: ELF OS ABI: 0\n[    0.320904] dbg:  [appelfloader] \u003celf_load.c @  134\u003e nbench: ELF object type: 3\n[    0.322282] dbg:  [appelfloader] \u003celf_load.c @  177\u003e nbench: phdr[2]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 6912 B, memsz 6912 B, align: 4096 B\n[    0.324392] dbg:  [appelfloader] \u003celf_load.c @  188\u003e nbench: \\_ segment at pie + 0x0 (len: 0x1b00) from file @ 0x0 (len: 0x1b00)\n[    0.326247] dbg:  [appelfloader] \u003celf_load.c @  177\u003e nbench: phdr[3]: R-X, offset: 0x2000, vaddr: 0x2000, paddr: 0x2000, filesz: 47269 B, memsz 47269 B, align: 4096 B\n[    0.328490] dbg:  [appelfloader] \u003celf_load.c @  188\u003e nbench: \\_ segment at pie + 0x2000 (len: 0xb8a5) from file @ 0x2000 (len: 0xb8a5)\n[    0.330444] dbg:  [appelfloader] \u003celf_load.c @  177\u003e nbench: phdr[4]: R--, offset: 0xe000, vaddr: 0xe000, paddr: 0xe000, filesz: 9104 B, memsz 9104 B, align: 4096 B\n[    0.332701] dbg:  [appelfloader] \u003celf_load.c @  188\u003e nbench: \\_ segment at pie + 0xe000 (len: 0x2390) from file @ 0xe000 (len: 0x2390)\n[    0.334650] dbg:  [appelfloader] \u003celf_load.c @  177\u003e nbench: phdr[5]: RW-, offset: 0x10c78, vaddr: 0x11c78, paddr: 0x11c78, filesz: 2208 B, memsz 17456 B, align: 4096 B\n[    0.336963] dbg:  [appelfloader] \u003celf_load.c @  188\u003e nbench: \\_ segment at pie + 0x11c78 (len: 0x4430) from file @ 0x10c78 (len: 0x8a0)\n[    0.338911] dbg:  [appelfloader] \u003celf_load.c @  211\u003e nbench: base: pie + 0x0, len: 0x160a8\n[    0.340389] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 98304 fd = 3\n[    0.341924] dbg:  [appelfloader] \u003celf_load.c @  442\u003e nbench: Memory mapped 0x0 - 0x1b00 to 0x100001a000 - 0x100001bb00\n[    0.343708] dbg:  [appelfloader] \u003celf_load.c @  464\u003e nbench: Program/Library memory region: 0x100001a000-0x1000031000\n[    0.345487] dbg:  [appelfloader] \u003celf_load.c @  349\u003e nbench: Zeroing 0x100001bb00 - 0x100001c000\n[    0.347044] dbg:  [appelfloader] \u003celf_load.c @  510\u003e nbench: Memory mapping 0x2000 - 0xd8a5 to 0x100001c000 - 0x10000278a5\n[    0.348874] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100001c000 len = 47269 fd = 3\n[    0.350509] dbg:  [appelfloader] \u003celf_load.c @  349\u003e nbench: Zeroing 0x10000278a5 - 0x1000028000\n[    0.352025] dbg:  [appelfloader] \u003celf_load.c @  510\u003e nbench: Memory mapping 0xe000 - 0x10390 to 0x1000028000 - 0x100002a390\n[    0.353837] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000028000 len = 9104 fd = 3\n[    0.355418] dbg:  [appelfloader] \u003celf_load.c @  349\u003e nbench: Zeroing 0x100002a390 - 0x100002b000\n[    0.356948] dbg:  [appelfloader] \u003celf_load.c @  510\u003e nbench: Memory mapping 0x10000 - 0x12190 to 0x100002b000 - 0x100002c518\n[    0.358776] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100002b000 len = 5400 fd = 3\n[    0.360371] dbg:  [appelfloader] \u003celf_load.c @  349\u003e nbench: Zeroing 0x100002c518 - 0x1000031000\n[    0.361907] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100002d000 len = 16384 fd = -1\n[    0.363510] dbg:  [appelfloader] \u003celf_load.c @  781\u003e nbench: Protecting 0x100001a000 - 0x100001c000: R--\n[    0.365125] dbg:  [appelfloader] \u003celf_load.c @  781\u003e nbench: Protecting 0x100001c000 - 0x1000028000: R-X\n[    0.366722] dbg:  [appelfloader] \u003celf_load.c @  781\u003e nbench: Protecting 0x1000028000 - 0x100002b000: R--\n[    0.368326] dbg:  [appelfloader] \u003celf_load.c @  781\u003e nbench: Protecting 0x100002b000 - 0x1000031000: RW-\n[    0.369945] dbg:  [appelfloader] \u003celf_load.c @ 1024\u003e nbench: Loading program interpreter /lib64/ld-linux-x86-64.so.2...\n[    0.371685] Info: [libvfscore] \u003csyscalls.c @  124\u003e sys_open: path=/lib64/ld-linux-x86-64.so.2 flags=0 mode=0\n[    0.373399] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 191504 fd = 3\n[    0.374940] dbg:  [appelfloader] \u003celf_load.c @  104\u003e \u003cinterp\u003e: ELF machine type: 62\n[    0.376330] dbg:  [appelfloader] \u003celf_load.c @  120\u003e \u003cinterp\u003e: ELF OS ABI: 0\n[    0.377659] dbg:  [appelfloader] \u003celf_load.c @  134\u003e \u003cinterp\u003e: ELF object type: 3\n[    0.379048] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[0]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 4040 B, memsz 4040 B, align: 4096 B\n[    0.381169] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x0 (len: 0xfc8) from file @ 0x0 (len: 0xfc8)\n[    0.383032] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[1]: R-X, offset: 0x1000, vaddr: 0x1000, paddr: 0x1000, filesz: 140932 B, memsz 140932 B, align: 4096 B\n[    0.385336] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x1000 (len: 0x22684) from file @ 0x1000 (len: 0x22684)\n[    0.387270] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[2]: R--, offset: 0x24000, vaddr: 0x24000, paddr: 0x24000, filesz: 31948 B, memsz 31948 B, align: 4096 B\n[    0.389593] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x24000 (len: 0x7ccc) from file @ 0x24000 (len: 0x7ccc)\n[    0.391580] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[3]: RW-, offset: 0x2c520, vaddr: 0x2d520, paddr: 0x2d520, filesz: 6872 B, memsz 7280 B, align: 4096 B\n[    0.393870] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x2d520 (len: 0x1c70) from file @ 0x2c520 (len: 0x1ad8)\n[    0.395854] dbg:  [appelfloader] \u003celf_load.c @  211\u003e \u003cinterp\u003e: base: pie + 0x0, len: 0x2f190\n[    0.397338] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 200704 fd = 3\n[    0.398861] dbg:  [appelfloader] \u003celf_load.c @  442\u003e \u003cinterp\u003e: Memory mapped 0x0 - 0xfc8 to 0x1000060000 - 0x1000060fc8\n[    0.400631] dbg:  [appelfloader] \u003celf_load.c @  464\u003e \u003cinterp\u003e: Program/Library memory region: 0x1000060000-0x1000090000\n[    0.402407] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x1000060fc8 - 0x1000061000\n[    0.403934] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x1000 - 0x23684 to 0x1000061000 - 0x1000083684\n[    0.405760] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000061000 len = 140932 fd = 3\n[    0.407375] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x1000083684 - 0x1000084000\n[    0.408929] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x24000 - 0x2bccc to 0x1000084000 - 0x100008bccc\n[    0.410838] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000084000 len = 31948 fd = 3\n[    0.412438] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x100008bccc - 0x100008c000\n[    0.413967] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x2c000 - 0x2e518 to 0x100008d000 - 0x100008eff8\n[    0.415775] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100008d000 len = 8184 fd = 3\n[    0.417357] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x100008eff8 - 0x1000090000\n[    0.418882] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100008f000 len = 4096 fd = -1\n[    0.420482] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000060000 - 0x1000061000: R--\n[    0.422089] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000061000 - 0x1000084000: R-X\n[    0.423699] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000084000 - 0x100008c000: R--\n[    0.425313] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x100008d000 - 0x1000090000: RW-\n[    0.426930] Info: [appelfloader] \u003cmain.c @  213\u003e nbench: ELF program loaded to 0x100001a000-0x1000031000 (94208 B), entry at 0x100001d8c0\n[    0.428915] dbg:  [appelfloader] \u003cmain.c @  231\u003e nbench: Prepare application thread...\n[    0.430331] dbg:  [appelfloader] \u003celf_ctx.c @  145\u003e nbench: image:          0x100001a000 - 0x1000031000\n[    0.431942] dbg:  [appelfloader] \u003celf_ctx.c @  148\u003e nbench: start:          0x100001a000\n[    0.433399] dbg:  [appelfloader] \u003celf_ctx.c @  150\u003e nbench: entry:          0x100001d8c0\n[    0.434826] dbg:  [appelfloader] \u003celf_ctx.c @  152\u003e nbench: phdr.off:       0x40\n[    0.436177] dbg:  [appelfloader] \u003celf_ctx.c @  154\u003e nbench: phdr.num:       13\n[    0.437524] dbg:  [appelfloader] \u003celf_ctx.c @  156\u003e nbench: phdr.entsize:   0x38\n[    0.438867] dbg:  [appelfloader] \u003celf_ctx.c @  159\u003e nbench: interp:         0x1000060000 - 0x1000090000\n[    0.440446] dbg:  [appelfloader] \u003celf_ctx.c @  163\u003e nbench: interp.start:   0x1000060000\n[    0.441871] dbg:  [appelfloader] \u003celf_ctx.c @  165\u003e nbench: interp.entry:   0x1000061100\n[    0.443299] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[4]=\"LD_DEBUG=all\"\n[    0.444588] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[3]=\"LD_BIND_NOW=1\"\n[    0.445883] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[2]=\"LD_SHOW_AUXV=1\"\n[    0.447184] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[1]=\"LD_LIBRARY_PATH=/lib/x86_64-linux-gnu/\"\n[    0.448743] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[0]=\"PATH=/bin\"\n[    0.450003] dbg:  [appelfloader] \u003cmain.c @  240\u003e nbench: Application stack at 0x400380020 - 0x4003a0020, pointer: 0x40039fdd0\n[    0.451826] dbg:  [appelfloader] \u003cmain.c @  246\u003e nbench: Application entrance at 0x2d8230\n```\n\n### NOTE:\n\n- loader_base of e9patch is too high which prevent it from being mapped by\n  unikraft -remaining: e9init use /proc/self/map_files for some weird shit. must\n  fix in unikraft\n\n## 2024-08-01\n\n### Writing\n\n- Why adaptive reshuffling\n\n## 2024-08-08\n\n### Measure reliability of vmexit tracking\n\n- After 1s, record the number of exit tracked\n- Send the number to kvm, which it will uses to log an event\n- Use perf to count the mismatch\n\n- Perfect scenario: attacker interrupt after every instruction\n- To reliably detect, one might need twice the sampling rate 0.5 instruction,\n  which is infeasible.\n\n## 2024-08-09\n\nPACMEM\n\n- assume Assmume 8.6 crash behavior\n-\n- Overhead cannot be low\n-\n- should mark what you are talking about in the figure\n\n## 2024-08-17\n\ntest\n\n## 2024-08-19\n\n```\n[    3.820096] Info: [oblivium] \u003cvma_obliv_file.c @  188\u003e Creating new obliv file vma 0x60111000~x60113000\n[    3.822188] Info: [oblivium] \u003csyscall_hooks.c @   99\u003e    VAS layout:\n[    3.823804] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [00] 0x000060000000-0x000060003000 0x000000003000 rw- virtqueue\n[    3.826110] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [01] 0x000060003000-0x000060006000 0x000000003000 rw- virtqueue\n[    3.828419] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [02] 0x000060006000-0x000060007000 0x000000001000 r-- /lib/x86_64-linux-gnu/libdl.so.2\n[    3.831040] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [03] 0x000060007000-0x000060009000 0x000000002000 r-x /lib/x86_64-linux-gnu/libdl.so.2\n[    3.833636] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [04] 0x000060009000-0x00006000a000 0x000000001000 r-- /lib/x86_64-linux-gnu/libdl.so.2\n[    3.836237] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [05] 0x00006000a000-0x00006000c000 0x000000002000 rw- /lib/x86_64-linux-gnu/libdl.so.2\n[    3.838841] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [06] 0x00006000c000-0x00006000e000 0x000000002000 rw- oblivium_data_bss\n[    3.841242] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [07] 0x00006000e000-0x000060014000 0x000000006000 r-- /lib/x86_64-linux-gnu/libpthread.so.0\n[    3.843957] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [08] 0x000060014000-0x000060025000 0x000000011000 r-x /lib/x86_64-linux-gnu/libpthread.so.0\n[    3.846614] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [09] 0x000060025000-0x00006002b000 0x000000006000 r-- /lib/x86_64-linux-gnu/libpthread.so.0\n[    3.849266] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [10] 0x00006002b000-0x00006002d000 0x000000002000 rw- /lib/x86_64-linux-gnu/libpthread.so.0\n[    3.851930] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [11] 0x00006002d000-0x000060031000 0x000000004000 rw- oblivium_data_bss\n[    3.854338] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [12] 0x000060035000-0x000060036000 0x000000001000 r-- /lib64/ld-linux-x86-64.so.2\n[    3.856861] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [13] 0x000060036000-0x000060059000 0x000000023000 r-x /lib64/ld-linux-x86-64.so.2\n[    3.859387] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [14] 0x000060059000-0x000060061000 0x000000008000 r-- /lib64/ld-linux-x86-64.so.2\n[    3.861918] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [15] 0x000060062000-0x000060064000 0x000000002000 rw- /lib64/ld-linux-x86-64.so.2\n[    3.864450] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [16] 0x000060064000-0x000060065000 0x000000001000 rw- oblivium_code\n[    3.866796] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [17] 0x000060065000-0x000060067000 0x000000002000 r-- /lib/x86_64-linux-gnu/libcrypt.so.1\n[    3.869426] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [18] 0x000060067000-0x00006007c000 0x000000015000 r-x /lib/x86_64-linux-gnu/libcrypt.so.1\n[    3.872049] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [19] 0x00006007c000-0x000060096000 0x00000001a000 r-- /lib/x86_64-linux-gnu/libcrypt.so.1\n[    3.874681] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [20] 0x000060096000-0x000060098000 0x000000002000 rw- /lib/x86_64-linux-gnu/libcrypt.so.1\n\n[    3.877306] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [21] 0x000060098000-0x0000600a0000 0x000000008000 rw- oblivium_data_bss\n[    3.879702] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [22] 0x0000600a0000-0x0000600a2000 0x000000002000 r-- /lib/x86_64-linux-gnu/libpcre.so.3\n[    3.882330] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [23] 0x0000600a2000-0x0000600f3000 0x000000051000 r-x /lib/x86_64-linux-gnu/libpcre.so.3\n[    3.884951] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [24] 0x0000600f3000-0x000060111000 0x00000001e000 r-- /lib/x86_64-linux-gnu/libpcre.so.3\n[    3.887567] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [25] 0x000060111000-0x000060113000 0x000000002000 rw- /lib/x86_64-linux-gnu/libpcre.so.3\n[    3.890185] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [26] 0x000060135000-0x000060157000 0x000000022000 r-- /usr/local/nginx/sbin/nginx\n[    3.892709] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [27] 0x000060157000-0x000060213000 0x0000000bc000 r-x /usr/local/nginx/sbin/nginx\n[    3.895241] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [28] 0x000060213000-0x000060247000 0x000000034000 r-- /usr/local/nginx/sbin/nginx\n[    3.897766] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [29] 0x000060247000-0x000060264000 0x00000001d000 rw- /usr/local/nginx/sbin/nginx\n[    3.900287] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [30] 0x000060264000-0x000060284000 0x000000020000 rw- oblivium_code\n[    3.902633] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [31] 0x000400000000-0x000404040000 0x000004040000 rw- heap\n[    3.904861] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [32] 0x000450000000-0x000450080000 0x000000080000 rw- oblivium_internal_heap\n[    3.907328] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [33] 0x000480000000-0x000480200000 0x000000200000 rw- oblivium_stack\n```\n\n## 2024-08-25\n\n### Issues:\n\n- ramfs_vnops must use unsafe heap.\n  - Symptom: crash when thying to map new file\n- application stack must use unsafe heap\n\n  - Symptom: page fault when trying to tlbflush\n\n- Eval nginx\n  - Normal 3889.65\n  - Instrumented 3152.73\n  -\n\n### NAE\n\n```\n[    8.289434] Info: [oblivium] \u003coblivium.c @  425\u003e ------------- STATISTICS ------------\n[    8.291480] Info: [oblivium] \u003coblivium.c @  425\u003e oblivium_data_bss:\n[    8.293225] Info: [oblivium] \u003coblivium.c @  370\u003e     fault_handled: 33\n[    8.294815] Info: [oblivium] \u003coblivium.c @  372\u003e     block used: 49\n[    8.296372] Info: [oblivium] \u003coblivium.c @  373\u003e     rw_scratchpad: 44/512\n[    8.298008] Info: [oblivium] \u003coblivium.c @  369\u003e oblivium_rodata:\n[    8.299606] Info: [oblivium] \u003coblivium.c @  370\u003e     fault_handled: 15\n[    8.301239] Info: [oblivium] \u003coblivium.c @  372\u003e     block used: 882\n[    8.302801] Info: [oblivium] \u003coblivium.c @  373\u003e     rw_scratchpad: 44/512\n[    8.304488] Info: [oblivium] \u003coblivium.c @  369\u003e oblivium_pt:\n[    8.306032] Info: [oblivium] \u003coblivium.c @  370\u003e     fault_handled: 0\n[    8.307616] Info: [oblivium] \u003coblivium.c @  372\u003e     block used: 6\n[    8.309151] Info: [oblivium] \u003coblivium.c @  373\u003e     pt_scratchpad: 6/512\n[    8.310775] Info: [oblivium] \u003coblivium.c @  369\u003e oblivium_code:\n[    8.312317] Info: [oblivium] \u003coblivium.c @  370\u003e     fault_handled: 718\n[    8.313909] Info: [oblivium] \u003coblivium.c @  372\u003e     block used: 28298\n[    8.315497] Info: [oblivium] \u003coblivium.c @  373\u003e     code_scratchpad: 188/512\n[    8.317243] Info: [oblivium] \u003coblivium.c @  435\u003e ------------- GLOBAL STATS ------------\n[    8.319260] Info: [oblivium] \u003coblivium.c @  435\u003e     block used: 29235/65532\n[    8.321144] Info: [oblivium] \u003coblivium.c @  454\u003e     fault handled : 30000\n[    8.322773] Info: [oblivium] \u003coblivium.c @  455\u003e     nae_skipped: 0\n[    8.324325] Info: [oblivium] \u003coblivium.c @  456\u003e     exit_tracked: 301\n[    8.325905] Info: [oblivium] \u003coblivium.c @  457\u003e     rerandomization_performed: 3\n[    8.327629] Info: [oblivium] \u003coblivium.c @  459\u003e     block copied: 1283076\n[    8.329282] Info: [oblivium] \u003coblivium.c @  460\u003e     dummy accesses: 342944\n[    8.330925] Info: [oblivium] \u003coblivium.c @  465\u003e     background eviction performed: 10421\n[    8.332757] Info: [oblivium] \u003coblivium.c @  467\u003e     oram_access: 766\n[    8.334323] Info: [oblivium] \u003coblivium.c @  492\u003e     mem_used: 0\n[    8.335832] Info: [oblivium] \u003coblivium.c @  493\u003e validation perfomed: 0\n[    8.337463] Info: [oblivium] \u003coblivium.c @  506\u003e -------------------------------------\nRequests per second:    2193.14 [#/sec] (mean)\n```\n\n## 2024-09-05\n\n```\nset env LD_LIBRARY_PATH ./lib/x86_64-linux-gnu/\n\nrun -p  /home/khadd/projects/oblivium/experiments/nginx-exit-rates/workdir/fs0-app-elfloader-nginx-instrumented  -c /home/khadd/projects/oblivium/experiments/nginx-exit-rates/workdir/fs0-app-elfloader-nginx-instrumented/usr/local/nginx/conf/nginx.conf\n\n\n```\n\n## Today meeting\n\n### Main points\n\n- Optimization is not the main concern atm.\n- ORAM-back Paging: there is no ground-breaking contributions, so it should\n  consists of micro-contributions to look like a well-thought-out design\n- How to show our tick rate consistency: Show average, median, max, min of the\n  ticks.\n\n- N-step vs. Controlled-channel vs. singlestep\n\n  - Even controlled-channel attacks have very high exit rates, allowing us to\n    also detect them.\n\n- Ensuring ticks are executing in the kernel is important\n- Security analysis is important: Must compare safety against existing\n  solutions: obfuscuro and klotski.\n\n### TODO:\n\n- Kernel ticks analysis: Find out the hotspot in the kernel where there are long\n  execution without any ticks. This can be done by profiling the CVM and collect\n  events like syscalls. Based on the results we may manually place ticks into\n  the kernel code.\n- Security analysis: How do we argue for our defense's safety?\n  - 4K vs 2K paging (klotski)\n  - Impact of adaptive defense on fine-grained side-channels\n\n```\n\nsocketpair(0x1, 0x1, ...) = Address family not supported by protocol (-97)\ngettid() = pid:2\nwrite(fd:4, \"2024/11/05 20:20:48 [ale\"..., 100) = 100\nepoll_ctl(0x3, 0x1, ...) = 0x0\nepoll_ctl(0x3, 0x1, ...) = 0x0\ngettimeofday(0x4185df9e0, 0x0, ...) = 0x0\nepoll_wait(0x3, 0x40062d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=10, tv_nsec=113322252}) = OK\naccept4(0x6, 0x4185df850, ...) = 0x8\nepoll_ctl(0x3, 0x1, ...) = 0x0\nepoll_wait(0x3, 0x40062d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=10, tv_nsec=122914748}) = OK\nrecvfrom(0x8, 0x4185df8c0, ...) = 0x1\nsetsockopt(0x8, 0x6, ...) = 0x0\nread(fd:8, \u003cout\u003e\"\\x16\\x03\\x01\\x00\\xB7\\x01\\x00\\x00\\xB3\\x03\\x03(\\x07\\xA1\\xAD\\x94o3\\x8B\\xCB(\\x82\\xEF\\xA5\"..., 16709) = 188\ntime(0x0, 0x0, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40064beb8, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40064a0b0, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x400649bf0, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40065c6b0, ...) = 0x672a7e27\nwrite(fd:8, \"\\x16\\x03\\x03\\x00A\\x02\\x00\\x00=\\x03\\x03\\xA4E\\xBF\\xBA\\xF7\\xDDJ\\x0D,\\xF7\\xC0\u0026\\xD7\"..., 2218) = 2218\nread(fd:8, \u003cout\u003ebuf:0x40065eb43, 16709) = Resource temporarily unavailable (-11)\nepoll_wait(0x3, 0x40062d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=10, tv_nsec=212074748}) = OK\nread(fd:8, \u003cout\u003e\"\\x16\\x03\\x03\\x00%\\x10\\x00\\x00! \\x8F\\xC3\\xE4Y^w\\xE8t\\xA2\\xE6\\xB2\\xCD\\xB1\\x8F\"..., 16709) = 93\nbrk(va:0x400685000) = va:0x400685000\nbrk(va:0x400684000) = va:0x400684000\ntime(0x0, 0x0, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x4185df680, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40065bfbc, ...) = 0x672a7e27\nwrite(fd:8, \"\\x16\\x03\\x03\\x00\\xBA\\x04\\x00\\x00\\xB6\\x00\\x00\\x01,\\x00\\xB0\\x87W:0\\xF7\\xBF\\x87sL\"..., 242) = 242\nread(fd:8, \u003cout\u003ebuf:0x40065f653, 16709) = Resource temporarily unavailable (-11)\nepoll_wait(0x3, 0x40062d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=10, tv_nsec=228463762}) = OK\nread(fd:8, \u003cout\u003e\"\\x17\\x03\\x03\\x00m\\x15\\xEB\\x05\\xCB\\xBF%og\\xBA\\xC2^R:P\\xC4\\xDA\\x1B\\x1Dr\"..., 16709) = 114\nread(fd:8, \u003cout\u003ebuf:0x40065f653, 16709) = Resource temporarily unavailable (-11)\nopenat(AT_FDCWD, \"/wwwroot/8k.html\", O_RDONLY|O_NONBLOCK) = fd:9\nfstat(fd:9, \u003cout\u003estat:{st_size=8192, st_mode=0100664, ...}) = OK\npread64(fd:9, \u003cout\u003e\"\\xD7\\xE6Ks\\xAA\\xF7\\xF8{\\xC0\\xB3\\xD6\\x0E\\xAE\\x15\\x0C\\xE2\\xDB\\xE4\\x9Bt.\\xC4\\xA0j\"..., 8192, 0) = 8192\nwrite(fd:8, \"\\x17\\x03\\x03!\\x0C\\x19\\xE8E\\xDD\\x02Y\\\\xA2\\x03\\xA0\\xC4\\x12\"\\xD5G\\xB1\\x18'?\"..., 8465) = 8465\nclose(fd:9) = OK\nwrite(fd:8, \"\\x15\\x03\\x03\\x00\\x1A\\x19\\xE8E\\xDD\\x02Y\\\\xA3\\x96\\xE8eV\\xCD\\xFE\\xCFl\\x8D\\xF1~\"..., 31) = 31\nclose(fd:8) = OK\n```\n\n```\nepoll_wait[0xe8]         count: 138      avg_inst_count: 33605767.89130435\nbrk[0xc]         count: 10       avg_inst_count: 43982.9\nwrite[0x1]       count: 427      avg_inst_count: 13077.585480093678\nclose[0x3]       count: 112      avg_inst_count: 12396.61607142857\nopenat[0x101]    count: 1        avg_inst_count: 7740.0\naccept4[0x120]   count: 113      avg_inst_count: 3415.849557522124\nread[0x0]        count: 665      avg_inst_count: 1183.3172932330826\nepoll_ctl[0xe9]  count: 115      avg_inst_count: 1111.6434782608696\npread64[0x11]    count: 100      avg_inst_count: 1076.12\nrecvfrom[0x2d]   count: 113      avg_inst_count: 923.0\nfstat[0x5]       count: 1        avg_inst_count: 482.0\nsetsockopt[0x36]         count: 113      avg_inst_count: 421.0\ngettimeofday[0x60]       count: 139      avg_inst_count: 163.0\nclock_gettime[0xe4]      count: 138      avg_inst_count: 157.0\ntime[0xc9]       count: 801      avg_inst_count: 157.0\ngetpid[0x27]     count: 1150     avg_inst_count: 120.0\ngettid[0xba]     count: 1        avg_inst_count: 117.0\n```","snippets":["#archive"],"rawContent":"# IncognitOS archive\n\n#archive\n\n## 2024-07-25\n\n```bash\nBASELINE\nTEST                : Iterations/sec.  : Old Index   : New Index\n                    :                  : Pentium 90* : AMD K6/233*\n--------------------:------------------:-------------:------------\nNUMERIC SORT        :          2553.5  :      65.49  :      21.51\nSTRING SORT         :          2874.8  :    1284.53  :     198.82\nBITFIELD            :      1.1325e+09  :     194.26  :      40.58\nFP EMULATION        :          1134.5  :     544.39  :     125.62\nFOURIER             :      2.1469e+05  :     244.16  :     137.14\nASSIGNMENT          :          94.417  :     359.27  :      93.19\nIDEA                :           20703  :     316.64  :      94.01\nHUFFMAN             :          8929.9  :     247.63  :      79.07\nNEURAL NET          :\n\nCFR + O3\n\nmode                  = Linux ELF executable\ninput_binary          = ./nbench\noutput_binary         = a.out\nnum_patched           = 793 / 794 (99.87%)\nnum_patched_B2        = 15 / 794 (1.89%)\nnum_patched_T0        = 703 / 794 (88.54%)\nnum_patched_T1        = 14 / 794 (1.76%)\nnum_patched_T2        = 0 / 794 (0.00%)\nnum_patched_T3        = 1 / 794 (0.13%)\nnum_virtual_mappings  = 49\nnum_physical_mappings = 20 (40.82%)\nnum_virtual_bytes     = 200704\nnum_physical_bytes    = 81920 (40.82%)\ninput_file_size       = 73344\noutput_file_size      = 209130 (285.14%)\ntime_elapsed          = 11ms\nmemory_used           = 4812KB\n\nTEST                : Iterations/sec.  : Old Index   : New Index\n                    :                  : Pentium 90* : AMD K6/233*\n--------------------:------------------:-------------:------------\nNUMERIC SORT        :            1329  :      34.08  :      11.19\nSTRING SORT         :          1360.4  :     607.85  :      94.08\nBITFIELD            :      7.1621e+08  :     122.86  :      25.66\nFP EMULATION        :          852.94  :     409.28  :      94.44\nFOURIER             :      1.9182e+05  :     218.15  :     122.53\nASSIGNMENT          :          30.292  :     115.26  :      29.90\nIDEA                :          4766.1  :      72.90  :      21.64\nHUFFMAN             :          2588.7  :      71.79  :      22.92\n\nO3\n\nmode                  = Linux ELF executable\ninput_binary          = ./nbench\noutput_binary         = a.out\nnum_patched           = 793 / 794 (99.87%)\nnum_patched_B2        = 96 / 794 (12.09%)\nnum_patched_T1        = 28 / 794 (3.53%)\nnum_patched_T2        = 1 / 794 (0.13%)\nnum_patched_T3        = 3 / 794 (0.38%)\nnum_virtual_mappings  = 75\nnum_physical_mappings = 22 (29.33%)\nnum_virtual_bytes     = 307200\nnum_physical_bytes    = 90112 (29.33%)\ninput_file_size       = 73344\noutput_file_size      = 217634 (296.73%)\ntime_elapsed          = 11ms\nmemory_used           = 4812KB\n\nTEST                : Iterations/sec.  : Old Index   : New Index\n                    :                  : Pentium 90* : AMD K6/233*\n--------------------:------------------:-------------:------------\nNUMERIC SORT        :          1275.4  :      32.71  :      10.74\nSTRING SORT         :          1139.9  :     509.36  :      78.84\nBITFIELD            :      5.5403e+08  :      95.04  :      19.85\nFP EMULATION        :          840.37  :     403.25  :      93.05\nFOURIER             :      1.8739e+05  :     213.12  :     119.70\nASSIGNMENT          :           25.15  :      95.70  :      24.82\nIDEA                :          4872.7  :      74.53  :      22.13\nHUFFMAN             :            2497  :      69.24  :      22.11\n\n\nO2\n\nmode                  = Linux ELF executable\ninput_binary          = ./nbench\noutput_binary         = a.out\nnum_patched           = 793 / 794 (99.87%)\nnum_patched_B2        = 97 / 794 (12.22%)\nnum_patched_T1        = 27 / 794 (3.40%)\nnum_patched_T2        = 1 / 794 (0.13%)\nnum_patched_T3        = 3 / 794 (0.38%)\nnum_virtual_mappings  = 74\nnum_physical_mappings = 20 (27.03%)\nnum_virtual_bytes     = 303104\nnum_physical_bytes    = 81920 (27.03%)\ninput_file_size       = 73344\noutput_file_size      = 209430 (285.54%)\ntime_elapsed          = 10ms\nmemory_used           = 4428KB\n\n1284\n```\n\n## 2024-07-31\n\n```\nOK\nAT_NOTELF:            0\nAT_UCACHEBSIZE:       0x0\nAT_ICACHEBSIZE:       0x0\nAT_DCACHEBSIZE:       0x0\nAT_EXECFN:            nbench\nAT_SECURE:            0\nAT_EGID:              0\nAT_GID:               0\nAT_EUID:              0\nAT_UID:               0\nAT_ENTRY:             0x100001d8c0\nAT_FLAGS:             0x0\nAT_CLKTCK:            100\nAT_HWCAP:             0\nAT_PAGESZ:            4096\nAT_BASE:              0x1000060000\nAT_RANDOM:            0x11ec0\nAT_PHENT:             56\nAT_PHNUM:             13\nAT_PHDR:              0x100001a040\nAT_PLATFORM:          x86_64\n         2:\n\nFAIL\nAT_NOTELF:            0\nAT_UCACHEBSIZE:       0x0\nAT_ICACHEBSIZE:       0x0\nAT_DCACHEBSIZE:       0x0\nAT_EXECFN:            a.out\nAT_SECURE:            0\nAT_EGID:              0\nAT_GID:               0\nAT_EUID:              0\nAT_UID:               0\nAT_ENTRY:             0x120ea29688\nAT_FLAGS:             0x0\nAT_CLKTCK:            100\nAT_HWCAP:             0\nAT_PAGESZ:            4096\nAT_BASE:              0x1000057000\nAT_RANDOM:            0x11ec0\nAT_PHENT:             56\nAT_PHNUM:             13\nAT_PHDR:              0x1000040040\nAT_PLATFORM:          x86_64\n```\n\n```\n[    0.308951] dbg:  [appelfloader] \u003celf_load.c @  104\u003e a.out: ELF machine type: 62\n[    0.310271] dbg:  [appelfloader] \u003celf_load.c @  120\u003e a.out: ELF OS ABI: 0\n[    0.311515] dbg:  [appelfloader] \u003celf_load.c @  134\u003e a.out: ELF object type: 3\n[    0.312813] dbg:  [appelfloader] \u003celf_load.c @  177\u003e a.out: phdr[2]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 6912 B, memsz 6912 B, align: 4096 B\n[    0.314856] dbg:  [appelfloader] \u003celf_load.c @  188\u003e a.out: \\_ segment at pie + 0x0 (len: 0x1b00) from file @ 0x0 (len: 0x1b00)\n[    0.316631] dbg:  [appelfloader] \u003celf_load.c @  177\u003e a.out: phdr[3]: R-X, offset: 0x2000, vaddr: 0x2000, paddr: 0x2000, filesz: 47269 B, memsz 47269 B, align: 4096 B\n[    0.318792] dbg:  [appelfloader] \u003celf_load.c @  188\u003e a.out: \\_ segment at pie + 0x2000 (len: 0xb8a5) from file @ 0x2000 (len: 0xb8a5)\n[    0.320628] dbg:  [appelfloader] \u003celf_load.c @  177\u003e a.out: phdr[4]: R--, offset: 0xe000, vaddr: 0xe000, paddr: 0xe000, filesz: 9104 B, memsz 9104 B, align: 4096 B\n[    0.322764] dbg:  [appelfloader] \u003celf_load.c @  188\u003e a.out: \\_ segment at pie + 0xe000 (len: 0x2390) from file @ 0xe000 (len: 0x2390)\n[    0.324600] dbg:  [appelfloader] \u003celf_load.c @  177\u003e a.out: phdr[5]: RW-, offset: 0x10c78, vaddr: 0x11c78, paddr: 0x11c78, filesz: 2208 B, memsz 17456 B, align: 4096 B\n[    0.326775] dbg:  [appelfloader] \u003celf_load.c @  188\u003e a.out: \\_ segment at pie + 0x11c78 (len: 0x4430) from file @ 0x10c78 (len: 0x8a0)\n[    0.328620] dbg:  [appelfloader] \u003celf_load.c @  177\u003e a.out: phdr[8]: R-X, offset: 0x38000, vaddr: 0x20e9e9000, paddr: 0, filesz: 5313 B, memsz 5313 B, align: 4096 B\n[    0.330773] dbg:  [appelfloader] \u003celf_load.c @  188\u003e a.out: \\_ segment at pie + 0x0 (len: 0x14c1) from file @ 0x38000 (len: 0x14c1)\n[    0.332588] dbg:  [appelfloader] \u003celf_load.c @  211\u003e a.out: base: pie + 0x0, len: 0x160a8\n[    0.333993] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 98304 fd = 3\n[    0.335448] dbg:  [appelfloader] \u003celf_load.c @  442\u003e a.out: Memory mapped 0x0 - 0x1b00 to 0x1000040000 - 0x1000041b00\n[    0.337141] dbg:  [appelfloader] \u003celf_load.c @  464\u003e a.out: Program/Library memory region: 0x1000040000-0x1000057000\n[    0.338809] dbg:  [appelfloader] \u003celf_load.c @  349\u003e a.out: Zeroing 0x1000041b00 - 0x1000042000\n[    0.340269] dbg:  [appelfloader] \u003celf_load.c @  510\u003e a.out: Memory mapping 0x2000 - 0xd8a5 to 0x1000042000 - 0x100004d8a5\n[    0.341991] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000042000 len = 47269 fd = 3\n[    0.343545] dbg:  [appelfloader] \u003celf_load.c @  349\u003e a.out: Zeroing 0x100004d8a5 - 0x100004e000\n[    0.345010] dbg:  [appelfloader] \u003celf_load.c @  510\u003e a.out: Memory mapping 0xe000 - 0x10390 to 0x100004e000 - 0x1000050390\n[    0.346738] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100004e000 len = 9104 fd = 3\n[    0.348280] dbg:  [appelfloader] \u003celf_load.c @  349\u003e a.out: Zeroing 0x1000050390 - 0x1000051000\n[    0.349752] dbg:  [appelfloader] \u003celf_load.c @  510\u003e a.out: Memory mapping 0x10000 - 0x12190 to 0x1000051000 - 0x1000052518\n[    0.351602] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000051000 len = 5400 fd = 3\n[    0.353151] dbg:  [appelfloader] \u003celf_load.c @  349\u003e a.out: Zeroing 0x1000052518 - 0x1000057000\n[    0.354615] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000053000 len = 16384 fd = -1\n[    0.356184] dbg:  [appelfloader] \u003celf_load.c @  510\u003e a.out: Memory mapping 0x38000 - 0x394c1 to 0x1000040000 - 0x10000414c1\n[    0.357939] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000040000 len = 5313 fd = 3\n[    0.359488] dbg:  [appelfloader] \u003celf_load.c @  349\u003e a.out: Zeroing 0x10000414c1 - 0x1000042000\n[    0.360959] dbg:  [appelfloader] \u003celf_load.c @  781\u003e a.out: Protecting 0x1000040000 - 0x1000042000: R--\n[    0.362506] dbg:  [appelfloader] \u003celf_load.c @  781\u003e a.out: Protecting 0x1000042000 - 0x100004e000: R-X\n[    0.364054] dbg:  [appelfloader] \u003celf_load.c @  781\u003e a.out: Protecting 0x100004e000 - 0x1000051000: R--\n[    0.365613] dbg:  [appelfloader] \u003celf_load.c @  781\u003e a.out: Protecting 0x1000051000 - 0x1000057000: RW-\n[    0.367160] dbg:  [appelfloader] \u003celf_load.c @  781\u003e a.out: Protecting 0x1000040000 - 0x1000042000: R-X\n[    0.368714] dbg:  [appelfloader] \u003celf_load.c @ 1024\u003e a.out: Loading program interpreter /lib64/ld-linux-x86-64.so.2...\n[    0.370417] Info: [libvfscore] \u003csyscalls.c @  124\u003e sys_open: path=/lib64/ld-linux-x86-64.so.2 flags=0 mode=0\n[    0.372060] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 191504 fd = 3\n[    0.373536] dbg:  [appelfloader] \u003celf_load.c @  104\u003e \u003cinterp\u003e: ELF machine type: 62\n[    0.374885] dbg:  [appelfloader] \u003celf_load.c @  120\u003e \u003cinterp\u003e: ELF OS ABI: 0\n[    0.376165] dbg:  [appelfloader] \u003celf_load.c @  134\u003e \u003cinterp\u003e: ELF object type: 3\n[    0.377502] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[0]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 4040 B, memsz 4040 B, align: 4096 B\n[    0.379525] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x0 (len: 0xfc8) from file @ 0x0 (len: 0xfc8)\n[    0.381325] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[1]: R-X, offset: 0x1000, vaddr: 0x1000, paddr: 0x1000, filesz: 140932 B, memsz 140932 B, align: 4096 B\n[    0.383532] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x1000 (len: 0x22684) from file @ 0x1000 (len: 0x22684)\n[    0.385434] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[2]: R--, offset: 0x24000, vaddr: 0x24000, paddr: 0x24000, filesz: 31948 B, memsz 31948 B, align: 4096 B\n[    0.387654] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x24000 (len: 0x7ccc) from file @ 0x24000 (len: 0x7ccc)\n[    0.389549] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[3]: RW-, offset: 0x2c520, vaddr: 0x2d520, paddr: 0x2d520, filesz: 6872 B, memsz 7280 B, align: 4096 B\n[    0.391749] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x2d520 (len: 0x1c70) from file @ 0x2c520 (len: 0x1ad8)\n[    0.393647] dbg:  [appelfloader] \u003celf_load.c @  211\u003e \u003cinterp\u003e: base: pie + 0x0, len: 0x2f190\n[    0.395085] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 200704 fd = 3\n[    0.396568] dbg:  [appelfloader] \u003celf_load.c @  442\u003e \u003cinterp\u003e: Memory mapped 0x0 - 0xfc8 to 0x1000057000 - 0x1000057fc8\n[    0.398294] dbg:  [appelfloader] \u003celf_load.c @  464\u003e \u003cinterp\u003e: Program/Library memory region: 0x1000057000-0x1000087000\n[    0.399999] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x1000057fc8 - 0x1000058000\n[    0.401502] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x1000 - 0x23684 to 0x1000058000 - 0x100007a684\n[    0.403266] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000058000 len = 140932 fd = 3\n[    0.404854] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x100007a684 - 0x100007b000\n[    0.406353] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x24000 - 0x2bccc to 0x100007b000 - 0x1000082ccc\n[    0.408126] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100007b000 len = 31948 fd = 3\n[    0.409691] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x1000082ccc - 0x1000083000\n[    0.411189] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x2c000 - 0x2e518 to 0x1000084000 - 0x1000085ff8\n[    0.412968] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000084000 len = 8184 fd = 3\n[    0.414514] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x1000085ff8 - 0x1000087000\n[    0.416011] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000086000 len = 4096 fd = -1\n[    0.417580] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000057000 - 0x1000058000: R--\n[    0.419157] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000058000 - 0x100007b000: R-X\n[    0.420733] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x100007b000 - 0x1000083000: R--\n[    0.422316] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000084000 - 0x1000087000: RW-\n[    0.423904] Info: [appelfloader] \u003cmain.c @  213\u003e a.out: ELF program loaded to 0x1000040000-0x1000057000 (94208 B), entry at 0x120ea29688\n[    0.425832] dbg:  [appelfloader] \u003cmain.c @  231\u003e a.out: Prepare application thread...\n[    0.427202] dbg:  [appelfloader] \u003celf_ctx.c @  145\u003e a.out: image:          0x1000040000 - 0x1000057000\n[    0.428746] dbg:  [appelfloader] \u003celf_ctx.c @  148\u003e a.out: start:          0x1000040000\n[    0.430150] dbg:  [appelfloader] \u003celf_ctx.c @  150\u003e a.out: entry:          0x120ea29688\n[    0.431542] dbg:  [appelfloader] \u003celf_ctx.c @  152\u003e a.out: phdr.off:       0x40\n[    0.432858] dbg:  [appelfloader] \u003celf_ctx.c @  154\u003e a.out: phdr.num:       13\n[    0.434150] dbg:  [appelfloader] \u003celf_ctx.c @  156\u003e a.out: phdr.entsize:   0x38\n[    0.435466] dbg:  [appelfloader] \u003celf_ctx.c @  159\u003e a.out: interp:         0x1000057000 - 0x1000087000\n[    0.437007] dbg:  [appelfloader] \u003celf_ctx.c @  163\u003e a.out: interp.start:   0x1000057000\n[    0.438396] dbg:  [appelfloader] \u003celf_ctx.c @  165\u003e a.out: interp.entry:   0x1000058100\n[    0.439786] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[4]=\"LD_DEBUG=all\"\n[    0.441045] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[3]=\"LD_BIND_NOW=1\"\n[    0.442304] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[2]=\"LD_SHOW_AUXV=1\"\n[    0.443578] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[1]=\"LD_LIBRARY_PATH=/lib/x86_64-linux-gnu/\"\n[    0.445094] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[0]=\"PATH=/bin\"\n[    0.446314] dbg:  [appelfloader] \u003cmain.c @  240\u003e a.out: Application stack at 0x400380020 - 0x4003a0020, pointer: 0x40039fdd0\n[    0.448075] dbg:  [appelfloader] \u003cmain.c @  246\u003e a.out: Application entrance at 0x2d8230\n\n\n[    0.318200] dbg:  [appelfloader] \u003celf_load.c @  104\u003e nbench: ELF machine type: 62\n[    0.319588] dbg:  [appelfloader] \u003celf_load.c @  120\u003e nbench: ELF OS ABI: 0\n[    0.320904] dbg:  [appelfloader] \u003celf_load.c @  134\u003e nbench: ELF object type: 3\n[    0.322282] dbg:  [appelfloader] \u003celf_load.c @  177\u003e nbench: phdr[2]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 6912 B, memsz 6912 B, align: 4096 B\n[    0.324392] dbg:  [appelfloader] \u003celf_load.c @  188\u003e nbench: \\_ segment at pie + 0x0 (len: 0x1b00) from file @ 0x0 (len: 0x1b00)\n[    0.326247] dbg:  [appelfloader] \u003celf_load.c @  177\u003e nbench: phdr[3]: R-X, offset: 0x2000, vaddr: 0x2000, paddr: 0x2000, filesz: 47269 B, memsz 47269 B, align: 4096 B\n[    0.328490] dbg:  [appelfloader] \u003celf_load.c @  188\u003e nbench: \\_ segment at pie + 0x2000 (len: 0xb8a5) from file @ 0x2000 (len: 0xb8a5)\n[    0.330444] dbg:  [appelfloader] \u003celf_load.c @  177\u003e nbench: phdr[4]: R--, offset: 0xe000, vaddr: 0xe000, paddr: 0xe000, filesz: 9104 B, memsz 9104 B, align: 4096 B\n[    0.332701] dbg:  [appelfloader] \u003celf_load.c @  188\u003e nbench: \\_ segment at pie + 0xe000 (len: 0x2390) from file @ 0xe000 (len: 0x2390)\n[    0.334650] dbg:  [appelfloader] \u003celf_load.c @  177\u003e nbench: phdr[5]: RW-, offset: 0x10c78, vaddr: 0x11c78, paddr: 0x11c78, filesz: 2208 B, memsz 17456 B, align: 4096 B\n[    0.336963] dbg:  [appelfloader] \u003celf_load.c @  188\u003e nbench: \\_ segment at pie + 0x11c78 (len: 0x4430) from file @ 0x10c78 (len: 0x8a0)\n[    0.338911] dbg:  [appelfloader] \u003celf_load.c @  211\u003e nbench: base: pie + 0x0, len: 0x160a8\n[    0.340389] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 98304 fd = 3\n[    0.341924] dbg:  [appelfloader] \u003celf_load.c @  442\u003e nbench: Memory mapped 0x0 - 0x1b00 to 0x100001a000 - 0x100001bb00\n[    0.343708] dbg:  [appelfloader] \u003celf_load.c @  464\u003e nbench: Program/Library memory region: 0x100001a000-0x1000031000\n[    0.345487] dbg:  [appelfloader] \u003celf_load.c @  349\u003e nbench: Zeroing 0x100001bb00 - 0x100001c000\n[    0.347044] dbg:  [appelfloader] \u003celf_load.c @  510\u003e nbench: Memory mapping 0x2000 - 0xd8a5 to 0x100001c000 - 0x10000278a5\n[    0.348874] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100001c000 len = 47269 fd = 3\n[    0.350509] dbg:  [appelfloader] \u003celf_load.c @  349\u003e nbench: Zeroing 0x10000278a5 - 0x1000028000\n[    0.352025] dbg:  [appelfloader] \u003celf_load.c @  510\u003e nbench: Memory mapping 0xe000 - 0x10390 to 0x1000028000 - 0x100002a390\n[    0.353837] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000028000 len = 9104 fd = 3\n[    0.355418] dbg:  [appelfloader] \u003celf_load.c @  349\u003e nbench: Zeroing 0x100002a390 - 0x100002b000\n[    0.356948] dbg:  [appelfloader] \u003celf_load.c @  510\u003e nbench: Memory mapping 0x10000 - 0x12190 to 0x100002b000 - 0x100002c518\n[    0.358776] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100002b000 len = 5400 fd = 3\n[    0.360371] dbg:  [appelfloader] \u003celf_load.c @  349\u003e nbench: Zeroing 0x100002c518 - 0x1000031000\n[    0.361907] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100002d000 len = 16384 fd = -1\n[    0.363510] dbg:  [appelfloader] \u003celf_load.c @  781\u003e nbench: Protecting 0x100001a000 - 0x100001c000: R--\n[    0.365125] dbg:  [appelfloader] \u003celf_load.c @  781\u003e nbench: Protecting 0x100001c000 - 0x1000028000: R-X\n[    0.366722] dbg:  [appelfloader] \u003celf_load.c @  781\u003e nbench: Protecting 0x1000028000 - 0x100002b000: R--\n[    0.368326] dbg:  [appelfloader] \u003celf_load.c @  781\u003e nbench: Protecting 0x100002b000 - 0x1000031000: RW-\n[    0.369945] dbg:  [appelfloader] \u003celf_load.c @ 1024\u003e nbench: Loading program interpreter /lib64/ld-linux-x86-64.so.2...\n[    0.371685] Info: [libvfscore] \u003csyscalls.c @  124\u003e sys_open: path=/lib64/ld-linux-x86-64.so.2 flags=0 mode=0\n[    0.373399] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 191504 fd = 3\n[    0.374940] dbg:  [appelfloader] \u003celf_load.c @  104\u003e \u003cinterp\u003e: ELF machine type: 62\n[    0.376330] dbg:  [appelfloader] \u003celf_load.c @  120\u003e \u003cinterp\u003e: ELF OS ABI: 0\n[    0.377659] dbg:  [appelfloader] \u003celf_load.c @  134\u003e \u003cinterp\u003e: ELF object type: 3\n[    0.379048] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[0]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 4040 B, memsz 4040 B, align: 4096 B\n[    0.381169] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x0 (len: 0xfc8) from file @ 0x0 (len: 0xfc8)\n[    0.383032] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[1]: R-X, offset: 0x1000, vaddr: 0x1000, paddr: 0x1000, filesz: 140932 B, memsz 140932 B, align: 4096 B\n[    0.385336] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x1000 (len: 0x22684) from file @ 0x1000 (len: 0x22684)\n[    0.387270] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[2]: R--, offset: 0x24000, vaddr: 0x24000, paddr: 0x24000, filesz: 31948 B, memsz 31948 B, align: 4096 B\n[    0.389593] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x24000 (len: 0x7ccc) from file @ 0x24000 (len: 0x7ccc)\n[    0.391580] dbg:  [appelfloader] \u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[3]: RW-, offset: 0x2c520, vaddr: 0x2d520, paddr: 0x2d520, filesz: 6872 B, memsz 7280 B, align: 4096 B\n[    0.393870] dbg:  [appelfloader] \u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x2d520 (len: 0x1c70) from file @ 0x2c520 (len: 0x1ad8)\n[    0.395854] dbg:  [appelfloader] \u003celf_load.c @  211\u003e \u003cinterp\u003e: base: pie + 0x0, len: 0x2f190\n[    0.397338] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0 len = 200704 fd = 3\n[    0.398861] dbg:  [appelfloader] \u003celf_load.c @  442\u003e \u003cinterp\u003e: Memory mapped 0x0 - 0xfc8 to 0x1000060000 - 0x1000060fc8\n[    0.400631] dbg:  [appelfloader] \u003celf_load.c @  464\u003e \u003cinterp\u003e: Program/Library memory region: 0x1000060000-0x1000090000\n[    0.402407] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x1000060fc8 - 0x1000061000\n[    0.403934] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x1000 - 0x23684 to 0x1000061000 - 0x1000083684\n[    0.405760] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000061000 len = 140932 fd = 3\n[    0.407375] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x1000083684 - 0x1000084000\n[    0.408929] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x24000 - 0x2bccc to 0x1000084000 - 0x100008bccc\n[    0.410838] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x1000084000 len = 31948 fd = 3\n[    0.412438] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x100008bccc - 0x100008c000\n[    0.413967] dbg:  [appelfloader] \u003celf_load.c @  510\u003e \u003cinterp\u003e: Memory mapping 0x2c000 - 0x2e518 to 0x100008d000 - 0x100008eff8\n[    0.415775] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100008d000 len = 8184 fd = 3\n[    0.417357] dbg:  [appelfloader] \u003celf_load.c @  349\u003e \u003cinterp\u003e: Zeroing 0x100008eff8 - 0x1000090000\n[    0.418882] Info: [libposix_mmap] \u003cmmap.c @   52\u003e mmap called addr = 0x100008f000 len = 4096 fd = -1\n[    0.420482] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000060000 - 0x1000061000: R--\n[    0.422089] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000061000 - 0x1000084000: R-X\n[    0.423699] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x1000084000 - 0x100008c000: R--\n[    0.425313] dbg:  [appelfloader] \u003celf_load.c @  781\u003e \u003cinterp\u003e: Protecting 0x100008d000 - 0x1000090000: RW-\n[    0.426930] Info: [appelfloader] \u003cmain.c @  213\u003e nbench: ELF program loaded to 0x100001a000-0x1000031000 (94208 B), entry at 0x100001d8c0\n[    0.428915] dbg:  [appelfloader] \u003cmain.c @  231\u003e nbench: Prepare application thread...\n[    0.430331] dbg:  [appelfloader] \u003celf_ctx.c @  145\u003e nbench: image:          0x100001a000 - 0x1000031000\n[    0.431942] dbg:  [appelfloader] \u003celf_ctx.c @  148\u003e nbench: start:          0x100001a000\n[    0.433399] dbg:  [appelfloader] \u003celf_ctx.c @  150\u003e nbench: entry:          0x100001d8c0\n[    0.434826] dbg:  [appelfloader] \u003celf_ctx.c @  152\u003e nbench: phdr.off:       0x40\n[    0.436177] dbg:  [appelfloader] \u003celf_ctx.c @  154\u003e nbench: phdr.num:       13\n[    0.437524] dbg:  [appelfloader] \u003celf_ctx.c @  156\u003e nbench: phdr.entsize:   0x38\n[    0.438867] dbg:  [appelfloader] \u003celf_ctx.c @  159\u003e nbench: interp:         0x1000060000 - 0x1000090000\n[    0.440446] dbg:  [appelfloader] \u003celf_ctx.c @  163\u003e nbench: interp.start:   0x1000060000\n[    0.441871] dbg:  [appelfloader] \u003celf_ctx.c @  165\u003e nbench: interp.entry:   0x1000061100\n[    0.443299] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[4]=\"LD_DEBUG=all\"\n[    0.444588] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[3]=\"LD_BIND_NOW=1\"\n[    0.445883] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[2]=\"LD_SHOW_AUXV=1\"\n[    0.447184] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[1]=\"LD_LIBRARY_PATH=/lib/x86_64-linux-gnu/\"\n[    0.448743] dbg:  [appelfloader] \u003celf_ctx.c @  285\u003e env[0]=\"PATH=/bin\"\n[    0.450003] dbg:  [appelfloader] \u003cmain.c @  240\u003e nbench: Application stack at 0x400380020 - 0x4003a0020, pointer: 0x40039fdd0\n[    0.451826] dbg:  [appelfloader] \u003cmain.c @  246\u003e nbench: Application entrance at 0x2d8230\n```\n\n### NOTE:\n\n- loader_base of e9patch is too high which prevent it from being mapped by\n  unikraft -remaining: e9init use /proc/self/map_files for some weird shit. must\n  fix in unikraft\n\n## 2024-08-01\n\n### Writing\n\n- Why adaptive reshuffling\n\n## 2024-08-08\n\n### Measure reliability of vmexit tracking\n\n- After 1s, record the number of exit tracked\n- Send the number to kvm, which it will uses to log an event\n- Use perf to count the mismatch\n\n- Perfect scenario: attacker interrupt after every instruction\n- To reliably detect, one might need twice the sampling rate 0.5 instruction,\n  which is infeasible.\n\n## 2024-08-09\n\nPACMEM\n\n- assume Assmume 8.6 crash behavior\n-\n- Overhead cannot be low\n-\n- should mark what you are talking about in the figure\n\n## 2024-08-17\n\ntest\n\n## 2024-08-19\n\n```\n[    3.820096] Info: [oblivium] \u003cvma_obliv_file.c @  188\u003e Creating new obliv file vma 0x60111000~x60113000\n[    3.822188] Info: [oblivium] \u003csyscall_hooks.c @   99\u003e    VAS layout:\n[    3.823804] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [00] 0x000060000000-0x000060003000 0x000000003000 rw- virtqueue\n[    3.826110] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [01] 0x000060003000-0x000060006000 0x000000003000 rw- virtqueue\n[    3.828419] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [02] 0x000060006000-0x000060007000 0x000000001000 r-- /lib/x86_64-linux-gnu/libdl.so.2\n[    3.831040] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [03] 0x000060007000-0x000060009000 0x000000002000 r-x /lib/x86_64-linux-gnu/libdl.so.2\n[    3.833636] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [04] 0x000060009000-0x00006000a000 0x000000001000 r-- /lib/x86_64-linux-gnu/libdl.so.2\n[    3.836237] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [05] 0x00006000a000-0x00006000c000 0x000000002000 rw- /lib/x86_64-linux-gnu/libdl.so.2\n[    3.838841] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [06] 0x00006000c000-0x00006000e000 0x000000002000 rw- oblivium_data_bss\n[    3.841242] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [07] 0x00006000e000-0x000060014000 0x000000006000 r-- /lib/x86_64-linux-gnu/libpthread.so.0\n[    3.843957] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [08] 0x000060014000-0x000060025000 0x000000011000 r-x /lib/x86_64-linux-gnu/libpthread.so.0\n[    3.846614] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [09] 0x000060025000-0x00006002b000 0x000000006000 r-- /lib/x86_64-linux-gnu/libpthread.so.0\n[    3.849266] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [10] 0x00006002b000-0x00006002d000 0x000000002000 rw- /lib/x86_64-linux-gnu/libpthread.so.0\n[    3.851930] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [11] 0x00006002d000-0x000060031000 0x000000004000 rw- oblivium_data_bss\n[    3.854338] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [12] 0x000060035000-0x000060036000 0x000000001000 r-- /lib64/ld-linux-x86-64.so.2\n[    3.856861] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [13] 0x000060036000-0x000060059000 0x000000023000 r-x /lib64/ld-linux-x86-64.so.2\n[    3.859387] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [14] 0x000060059000-0x000060061000 0x000000008000 r-- /lib64/ld-linux-x86-64.so.2\n[    3.861918] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [15] 0x000060062000-0x000060064000 0x000000002000 rw- /lib64/ld-linux-x86-64.so.2\n[    3.864450] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [16] 0x000060064000-0x000060065000 0x000000001000 rw- oblivium_code\n[    3.866796] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [17] 0x000060065000-0x000060067000 0x000000002000 r-- /lib/x86_64-linux-gnu/libcrypt.so.1\n[    3.869426] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [18] 0x000060067000-0x00006007c000 0x000000015000 r-x /lib/x86_64-linux-gnu/libcrypt.so.1\n[    3.872049] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [19] 0x00006007c000-0x000060096000 0x00000001a000 r-- /lib/x86_64-linux-gnu/libcrypt.so.1\n[    3.874681] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [20] 0x000060096000-0x000060098000 0x000000002000 rw- /lib/x86_64-linux-gnu/libcrypt.so.1\n\n[    3.877306] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [21] 0x000060098000-0x0000600a0000 0x000000008000 rw- oblivium_data_bss\n[    3.879702] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [22] 0x0000600a0000-0x0000600a2000 0x000000002000 r-- /lib/x86_64-linux-gnu/libpcre.so.3\n[    3.882330] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [23] 0x0000600a2000-0x0000600f3000 0x000000051000 r-x /lib/x86_64-linux-gnu/libpcre.so.3\n[    3.884951] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [24] 0x0000600f3000-0x000060111000 0x00000001e000 r-- /lib/x86_64-linux-gnu/libpcre.so.3\n[    3.887567] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [25] 0x000060111000-0x000060113000 0x000000002000 rw- /lib/x86_64-linux-gnu/libpcre.so.3\n[    3.890185] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [26] 0x000060135000-0x000060157000 0x000000022000 r-- /usr/local/nginx/sbin/nginx\n[    3.892709] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [27] 0x000060157000-0x000060213000 0x0000000bc000 r-x /usr/local/nginx/sbin/nginx\n[    3.895241] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [28] 0x000060213000-0x000060247000 0x000000034000 r-- /usr/local/nginx/sbin/nginx\n[    3.897766] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [29] 0x000060247000-0x000060264000 0x00000001d000 rw- /usr/local/nginx/sbin/nginx\n[    3.900287] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [30] 0x000060264000-0x000060284000 0x000000020000 rw- oblivium_code\n[    3.902633] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [31] 0x000400000000-0x000404040000 0x000004040000 rw- heap\n[    3.904861] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [32] 0x000450000000-0x000450080000 0x000000080000 rw- oblivium_internal_heap\n[    3.907328] Info: [oblivium] \u003csyscall_hooks.c @  105\u003e      [33] 0x000480000000-0x000480200000 0x000000200000 rw- oblivium_stack\n```\n\n## 2024-08-25\n\n### Issues:\n\n- ramfs_vnops must use unsafe heap.\n  - Symptom: crash when thying to map new file\n- application stack must use unsafe heap\n\n  - Symptom: page fault when trying to tlbflush\n\n- Eval nginx\n  - Normal 3889.65\n  - Instrumented 3152.73\n  -\n\n### NAE\n\n```\n[    8.289434] Info: [oblivium] \u003coblivium.c @  425\u003e ------------- STATISTICS ------------\n[    8.291480] Info: [oblivium] \u003coblivium.c @  425\u003e oblivium_data_bss:\n[    8.293225] Info: [oblivium] \u003coblivium.c @  370\u003e     fault_handled: 33\n[    8.294815] Info: [oblivium] \u003coblivium.c @  372\u003e     block used: 49\n[    8.296372] Info: [oblivium] \u003coblivium.c @  373\u003e     rw_scratchpad: 44/512\n[    8.298008] Info: [oblivium] \u003coblivium.c @  369\u003e oblivium_rodata:\n[    8.299606] Info: [oblivium] \u003coblivium.c @  370\u003e     fault_handled: 15\n[    8.301239] Info: [oblivium] \u003coblivium.c @  372\u003e     block used: 882\n[    8.302801] Info: [oblivium] \u003coblivium.c @  373\u003e     rw_scratchpad: 44/512\n[    8.304488] Info: [oblivium] \u003coblivium.c @  369\u003e oblivium_pt:\n[    8.306032] Info: [oblivium] \u003coblivium.c @  370\u003e     fault_handled: 0\n[    8.307616] Info: [oblivium] \u003coblivium.c @  372\u003e     block used: 6\n[    8.309151] Info: [oblivium] \u003coblivium.c @  373\u003e     pt_scratchpad: 6/512\n[    8.310775] Info: [oblivium] \u003coblivium.c @  369\u003e oblivium_code:\n[    8.312317] Info: [oblivium] \u003coblivium.c @  370\u003e     fault_handled: 718\n[    8.313909] Info: [oblivium] \u003coblivium.c @  372\u003e     block used: 28298\n[    8.315497] Info: [oblivium] \u003coblivium.c @  373\u003e     code_scratchpad: 188/512\n[    8.317243] Info: [oblivium] \u003coblivium.c @  435\u003e ------------- GLOBAL STATS ------------\n[    8.319260] Info: [oblivium] \u003coblivium.c @  435\u003e     block used: 29235/65532\n[    8.321144] Info: [oblivium] \u003coblivium.c @  454\u003e     fault handled : 30000\n[    8.322773] Info: [oblivium] \u003coblivium.c @  455\u003e     nae_skipped: 0\n[    8.324325] Info: [oblivium] \u003coblivium.c @  456\u003e     exit_tracked: 301\n[    8.325905] Info: [oblivium] \u003coblivium.c @  457\u003e     rerandomization_performed: 3\n[    8.327629] Info: [oblivium] \u003coblivium.c @  459\u003e     block copied: 1283076\n[    8.329282] Info: [oblivium] \u003coblivium.c @  460\u003e     dummy accesses: 342944\n[    8.330925] Info: [oblivium] \u003coblivium.c @  465\u003e     background eviction performed: 10421\n[    8.332757] Info: [oblivium] \u003coblivium.c @  467\u003e     oram_access: 766\n[    8.334323] Info: [oblivium] \u003coblivium.c @  492\u003e     mem_used: 0\n[    8.335832] Info: [oblivium] \u003coblivium.c @  493\u003e validation perfomed: 0\n[    8.337463] Info: [oblivium] \u003coblivium.c @  506\u003e -------------------------------------\nRequests per second:    2193.14 [#/sec] (mean)\n```\n\n## 2024-09-05\n\n```\nset env LD_LIBRARY_PATH ./lib/x86_64-linux-gnu/\n\nrun -p  /home/khadd/projects/oblivium/experiments/nginx-exit-rates/workdir/fs0-app-elfloader-nginx-instrumented  -c /home/khadd/projects/oblivium/experiments/nginx-exit-rates/workdir/fs0-app-elfloader-nginx-instrumented/usr/local/nginx/conf/nginx.conf\n\n\n```\n\n## Today meeting\n\n### Main points\n\n- Optimization is not the main concern atm.\n- ORAM-back Paging: there is no ground-breaking contributions, so it should\n  consists of micro-contributions to look like a well-thought-out design\n- How to show our tick rate consistency: Show average, median, max, min of the\n  ticks.\n\n- N-step vs. Controlled-channel vs. singlestep\n\n  - Even controlled-channel attacks have very high exit rates, allowing us to\n    also detect them.\n\n- Ensuring ticks are executing in the kernel is important\n- Security analysis is important: Must compare safety against existing\n  solutions: obfuscuro and klotski.\n\n### TODO:\n\n- Kernel ticks analysis: Find out the hotspot in the kernel where there are long\n  execution without any ticks. This can be done by profiling the CVM and collect\n  events like syscalls. Based on the results we may manually place ticks into\n  the kernel code.\n- Security analysis: How do we argue for our defense's safety?\n  - 4K vs 2K paging (klotski)\n  - Impact of adaptive defense on fine-grained side-channels\n\n```\n\nsocketpair(0x1, 0x1, ...) = Address family not supported by protocol (-97)\ngettid() = pid:2\nwrite(fd:4, \"2024/11/05 20:20:48 [ale\"..., 100) = 100\nepoll_ctl(0x3, 0x1, ...) = 0x0\nepoll_ctl(0x3, 0x1, ...) = 0x0\ngettimeofday(0x4185df9e0, 0x0, ...) = 0x0\nepoll_wait(0x3, 0x40062d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=10, tv_nsec=113322252}) = OK\naccept4(0x6, 0x4185df850, ...) = 0x8\nepoll_ctl(0x3, 0x1, ...) = 0x0\nepoll_wait(0x3, 0x40062d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=10, tv_nsec=122914748}) = OK\nrecvfrom(0x8, 0x4185df8c0, ...) = 0x1\nsetsockopt(0x8, 0x6, ...) = 0x0\nread(fd:8, \u003cout\u003e\"\\x16\\x03\\x01\\x00\\xB7\\x01\\x00\\x00\\xB3\\x03\\x03(\\x07\\xA1\\xAD\\x94o3\\x8B\\xCB(\\x82\\xEF\\xA5\"..., 16709) = 188\ntime(0x0, 0x0, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40064beb8, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40064a0b0, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x400649bf0, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40065c6b0, ...) = 0x672a7e27\nwrite(fd:8, \"\\x16\\x03\\x03\\x00A\\x02\\x00\\x00=\\x03\\x03\\xA4E\\xBF\\xBA\\xF7\\xDDJ\\x0D,\\xF7\\xC0\u0026\\xD7\"..., 2218) = 2218\nread(fd:8, \u003cout\u003ebuf:0x40065eb43, 16709) = Resource temporarily unavailable (-11)\nepoll_wait(0x3, 0x40062d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=10, tv_nsec=212074748}) = OK\nread(fd:8, \u003cout\u003e\"\\x16\\x03\\x03\\x00%\\x10\\x00\\x00! \\x8F\\xC3\\xE4Y^w\\xE8t\\xA2\\xE6\\xB2\\xCD\\xB1\\x8F\"..., 16709) = 93\nbrk(va:0x400685000) = va:0x400685000\nbrk(va:0x400684000) = va:0x400684000\ntime(0x0, 0x0, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x4185df680, ...) = 0x672a7e27\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40065bfbc, ...) = 0x672a7e27\nwrite(fd:8, \"\\x16\\x03\\x03\\x00\\xBA\\x04\\x00\\x00\\xB6\\x00\\x00\\x01,\\x00\\xB0\\x87W:0\\xF7\\xBF\\x87sL\"..., 242) = 242\nread(fd:8, \u003cout\u003ebuf:0x40065f653, 16709) = Resource temporarily unavailable (-11)\nepoll_wait(0x3, 0x40062d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=10, tv_nsec=228463762}) = OK\nread(fd:8, \u003cout\u003e\"\\x17\\x03\\x03\\x00m\\x15\\xEB\\x05\\xCB\\xBF%og\\xBA\\xC2^R:P\\xC4\\xDA\\x1B\\x1Dr\"..., 16709) = 114\nread(fd:8, \u003cout\u003ebuf:0x40065f653, 16709) = Resource temporarily unavailable (-11)\nopenat(AT_FDCWD, \"/wwwroot/8k.html\", O_RDONLY|O_NONBLOCK) = fd:9\nfstat(fd:9, \u003cout\u003estat:{st_size=8192, st_mode=0100664, ...}) = OK\npread64(fd:9, \u003cout\u003e\"\\xD7\\xE6Ks\\xAA\\xF7\\xF8{\\xC0\\xB3\\xD6\\x0E\\xAE\\x15\\x0C\\xE2\\xDB\\xE4\\x9Bt.\\xC4\\xA0j\"..., 8192, 0) = 8192\nwrite(fd:8, \"\\x17\\x03\\x03!\\x0C\\x19\\xE8E\\xDD\\x02Y\\\\xA2\\x03\\xA0\\xC4\\x12\"\\xD5G\\xB1\\x18'?\"..., 8465) = 8465\nclose(fd:9) = OK\nwrite(fd:8, \"\\x15\\x03\\x03\\x00\\x1A\\x19\\xE8E\\xDD\\x02Y\\\\xA3\\x96\\xE8eV\\xCD\\xFE\\xCFl\\x8D\\xF1~\"..., 31) = 31\nclose(fd:8) = OK\n```\n\n```\nepoll_wait[0xe8]         count: 138      avg_inst_count: 33605767.89130435\nbrk[0xc]         count: 10       avg_inst_count: 43982.9\nwrite[0x1]       count: 427      avg_inst_count: 13077.585480093678\nclose[0x3]       count: 112      avg_inst_count: 12396.61607142857\nopenat[0x101]    count: 1        avg_inst_count: 7740.0\naccept4[0x120]   count: 113      avg_inst_count: 3415.849557522124\nread[0x0]        count: 665      avg_inst_count: 1183.3172932330826\nepoll_ctl[0xe9]  count: 115      avg_inst_count: 1111.6434782608696\npread64[0x11]    count: 100      avg_inst_count: 1076.12\nrecvfrom[0x2d]   count: 113      avg_inst_count: 923.0\nfstat[0x5]       count: 1        avg_inst_count: 482.0\nsetsockopt[0x36]         count: 113      avg_inst_count: 421.0\ngettimeofday[0x60]       count: 139      avg_inst_count: 163.0\nclock_gettime[0xe4]      count: 138      avg_inst_count: 157.0\ntime[0xc9]       count: 801      avg_inst_count: 157.0\ngetpid[0x27]     count: 1150     avg_inst_count: 120.0\ngettid[0xba]     count: 1        avg_inst_count: 117.0\n```\n","wordCount":4599,"tags":["archive"],"metadata":{},"created":"2024-12-09T08:04:24.731748745Z","modified":"2024-12-09T08:04:34.444509675Z","checksum":"99da4106ab84c4ee78adc96327b405ec6d7c1c2c444e41282201d3ed02340d66"},
    {"filename":"dpg049d1.md","filenameStem":"dpg049d1","path":"dpg049d1.md","absPath":"/home/khadd/mynotes/dpg049d1.md","title":"IncognitOS binary-compatible annotations","link":"[[dpg049d1]]","lead":"#archive","body":"#archive\n\n# Goals\n\n- Provide binary compatible annotations of security policies\n- Compatible with existing attacks\n- Provide opt-in protection for applicable functions\n\n# How\n\n- Annotation should be able to specify the following things:\n  - **T1: Context**: A user can decide the context where the protection is\n    enabled\n  - **T2: Protection type**: Among **P1: Paging**, **P2: Cache** and **P3:\n    Ciphertext**\n  - **T3: Semantic of memory**: A user can selectively enable protection based\n    memory semantic (stack, heap, code and data)\n  - **T4: Protection granularity**: The user may decide to trade-off security\n    for performance by coarsening the protection granularity\n\n# Example\n\n## Case study 1: protecting constant-time EdDSA from ciphertext\n\n- The implementation of EdDSA is vulnerable to collision attack.\n- While secret may resides in the heap or global data, the actual target for\n  ciphertext attacks is secret-dependent variables resides on the stack memory.\n\n  - This is true for most of ciphertext-vulnerable implementation\n\n- T1: EdDSA signing function (e.g., libsodium `crypto_sign`)\n- T2: P3\n- T3: Stack memory\n- T4: Scratchpad size\n\n# Page-level\n\n# Fine-grained protection","snippets":["#archive"],"rawContent":"# IncognitOS binary-compatible annotations\n\n#archive\n\n# Goals\n\n- Provide binary compatible annotations of security policies\n- Compatible with existing attacks\n- Provide opt-in protection for applicable functions\n\n# How\n\n- Annotation should be able to specify the following things:\n  - **T1: Context**: A user can decide the context where the protection is\n    enabled\n  - **T2: Protection type**: Among **P1: Paging**, **P2: Cache** and **P3:\n    Ciphertext**\n  - **T3: Semantic of memory**: A user can selectively enable protection based\n    memory semantic (stack, heap, code and data)\n  - **T4: Protection granularity**: The user may decide to trade-off security\n    for performance by coarsening the protection granularity\n\n# Example\n\n## Case study 1: protecting constant-time EdDSA from ciphertext\n\n- The implementation of EdDSA is vulnerable to collision attack.\n- While secret may resides in the heap or global data, the actual target for\n  ciphertext attacks is secret-dependent variables resides on the stack memory.\n\n  - This is true for most of ciphertext-vulnerable implementation\n\n- T1: EdDSA signing function (e.g., libsodium `crypto_sign`)\n- T2: P3\n- T3: Stack memory\n- T4: Scratchpad size\n\n# Page-level\n\n# Fine-grained protection\n","wordCount":181,"tags":["archive"],"metadata":{},"created":"2024-05-23T06:28:57.318638683Z","modified":"2024-11-18T05:54:48.647331774Z","checksum":"971238a7454dbe4d9808f92c7c9e3a7b1a8c21f9c0db5aeda0156e194d6e295f"},
    {"filename":"baoqhski.md","filenameStem":"baoqhski","path":"baoqhski.md","absPath":"/home/khadd/mynotes/baoqhski.md","title":"IncognitOS binary-instrumentation-based scheduling","link":"[[baoqhski]]","lead":"## Motivations","body":"## Motivations\n\nOur binary-instrumentation-based seek to solve two problems. First, it uphold\nthe security invariant of the ORAM-backed paging scheme, that require the timely\nvalidation of huge mappings that may be smashed by the hypervisor. Second, it\nimplements a layer of defense that is adaptive to the costly extraction phase\nattacks. Extraction phase attacks are costly, thus inevitably leave side effects\nsuch as prolonged execution time, or identifiable interceptions. Previous work\ndemonstrated compiler-based detection schemes for SGX that use the compiler to\ninsert checking code at configured interval, e.g., per-basic blocks\n[@chen2017detecting,@oleksenko2018varys], but require application source code.\n\nMore generally, we want to reliably schedule security tasks alongside execution\nof the unikernel application thread.\n\nNow with OS support, this security tasks could be built into the kernel through\nits scheduling. Unfortunately, there are challenges., scheduling is made\nunreliable in CVMs, due to the hardware timer being virtualized. Moreover,\nunikernels use cooperative scheduler that is unsuited for scheduling tasks\nper-interval.\n\n## Idea\n\nOur idea is to leverage binary rewriting to self-insert interception code (i.e.,\nprobes) into the application binary. The interception is then used as scheduling\nticks, which replace the unreliable virtualized interrupts of the kernel.\n\nBy carefully choosing the probe insertion, the OS can now dictate when the\ncontrol flow must be passed back to the scheduler, which solve two problems at\nthe same time: (1) lack of reliable hardware interrupts and (2) unikernel's lack\nof preemptive scheduling.\n\n## Design goals\n\nRequirements:\n\n- R1. For reliability, the scheduling ticks must be performed at least at each\n  basic block. This is to handle loops that may delay the scheduling of security\n  tasks.\n- R2. The intercepted execution must not leak information about the code. Now\n  that the original instruction is replaced with a probe, the execution flow\n  must take a _detour_ to a different location.\n- R3. The location of the probes must be randomized per CVM boots. This is to\n  avoid the attacker bruteforcing to try to infer probe locations.\n- R4. The probes must not incur significant overheads.\n- R5. Should not relies on complex analyses. Analyzing binaries is challenging\n  and error prone.\n\n## Design decisions\n\nTo achieve R1, we must insert probes at every `jmp` instructions.\n\nTo achieve R3, we implement load-time binary rewriting. Our kernel binary\nrewriting facility (based on linux kprobe) randomize location of probes on every\nCVM boots.\n\n## Design space\n\n## Internal\n\n- Kprobe [[1mhpx5ds]] offer similar functionalities.","snippets":["## Motivations"],"rawContent":"# IncognitOS binary-instrumentation-based scheduling\n\n## Motivations\n\nOur binary-instrumentation-based seek to solve two problems. First, it uphold\nthe security invariant of the ORAM-backed paging scheme, that require the timely\nvalidation of huge mappings that may be smashed by the hypervisor. Second, it\nimplements a layer of defense that is adaptive to the costly extraction phase\nattacks. Extraction phase attacks are costly, thus inevitably leave side effects\nsuch as prolonged execution time, or identifiable interceptions. Previous work\ndemonstrated compiler-based detection schemes for SGX that use the compiler to\ninsert checking code at configured interval, e.g., per-basic blocks\n[@chen2017detecting,@oleksenko2018varys], but require application source code.\n\nMore generally, we want to reliably schedule security tasks alongside execution\nof the unikernel application thread.\n\nNow with OS support, this security tasks could be built into the kernel through\nits scheduling. Unfortunately, there are challenges., scheduling is made\nunreliable in CVMs, due to the hardware timer being virtualized. Moreover,\nunikernels use cooperative scheduler that is unsuited for scheduling tasks\nper-interval.\n\n## Idea\n\nOur idea is to leverage binary rewriting to self-insert interception code (i.e.,\nprobes) into the application binary. The interception is then used as scheduling\nticks, which replace the unreliable virtualized interrupts of the kernel.\n\nBy carefully choosing the probe insertion, the OS can now dictate when the\ncontrol flow must be passed back to the scheduler, which solve two problems at\nthe same time: (1) lack of reliable hardware interrupts and (2) unikernel's lack\nof preemptive scheduling.\n\n## Design goals\n\nRequirements:\n\n- R1. For reliability, the scheduling ticks must be performed at least at each\n  basic block. This is to handle loops that may delay the scheduling of security\n  tasks.\n- R2. The intercepted execution must not leak information about the code. Now\n  that the original instruction is replaced with a probe, the execution flow\n  must take a _detour_ to a different location.\n- R3. The location of the probes must be randomized per CVM boots. This is to\n  avoid the attacker bruteforcing to try to infer probe locations.\n- R4. The probes must not incur significant overheads.\n- R5. Should not relies on complex analyses. Analyzing binaries is challenging\n  and error prone.\n\n## Design decisions\n\nTo achieve R1, we must insert probes at every `jmp` instructions.\n\nTo achieve R3, we implement load-time binary rewriting. Our kernel binary\nrewriting facility (based on linux kprobe) randomize location of probes on every\nCVM boots.\n\n## Design space\n\n## Internal\n\n- Kprobe [[1mhpx5ds]] offer similar functionalities.\n","wordCount":407,"tags":[],"metadata":{},"created":"2024-06-19T05:36:03.937708326Z","modified":"2024-12-16T06:41:58.56632898Z","checksum":"832d95304cede4ec2314eebc00a37bd62ee2794d409d983fd2dbb305d0e73a4a"},
    {"filename":"4xsm1oks.md","filenameStem":"4xsm1oks","path":"4xsm1oks.md","absPath":"/home/khadd/mynotes/4xsm1oks.md","title":"IncognitOS binary-instrumentation-based scheduling","link":"[[4xsm1oks]]","lead":"## Motivations","body":"## Motivations\n\nOur binary-instrumentation-based seek to solve two problems. First, it uphold\nthe security invariant of the ORAM-backed paging scheme, which require the\ntimely validation of huge mappings that may be smashed by the hypervisor.\n\nSecond, it implements a layer of defense that is adaptive to the costly\nextraction phase attacks. Extraction phase attacks are costly, thus inevitably\nleave side effects such as prolonged execution time, or identifiable\ninterceptions. Previous work demonstrated compiler-based detection schemes for\nSGX that use the compiler to insert checking code at configured interval, e.g.,\nper-basic blocks, but require application source code.\n\nMore generally, we want to reliably schedule _security threads_ alongside\nexecution of the unikernel application thread.\n\nUnfortunately, there are challenges. Scheduling is made unreliable in CVMs, due\nto the hardware timer being virtualized. Moreover, unikernels uses a cooperative\nscheduler (non-preemptive) that is unsuited for scheduling tasks per-interval.\n\n## Idea\n\nOur idea is to leverage binary rewriting to self-insert interception code (i.e.,\nprobes) into the application binary. The interception is then used as scheduling\nticks, which replace the unreliable virtualized interrupts of the kernel.\n\nBy carefully choosing the probe insertion, the OS can now dictate when the\ncontrol flow must be passed back to the scheduler, which solve two problems at\nthe same time: (1) lack of reliable hardware interrupts and (2) unikernel's lack\nof preemptive scheduling.\n\n## Design goals\n\nRequirements:\n\n- R1. For reliability, the scheduling ticks must be performed at least at each\n  basic block. This is to handle loops that may delay the scheduling of security\n  tasks.\n- R2. The intercepted execution must not leak information about the code. Now\n  that the original instruction is replaced with a probe, the execution flow\n  must take a _detour_ to a different location. Such detour must not leak\n  information through side-channels\n- R3. The location of the probes must be randomized per CVM boots. This is to\n  avoid the attacker bruteforcing to try to infer probe locations.\n- R4. Compatibility. Must not hurt existing unikernel binary compatibility\n\n## Design decisions\n\n### R1 Reliable per-basic-block ticks\n\n- We may intercept every `jmp` instructions.\n\n     - Using this, we may rewrite existing 5-bytes `jmp` instructions with jmp\n       to our detour execution cache as an optimization - In NGINX, about 70% of\n       `jmp` are 5-bytes\n     - More complex 2B `jmp` may be supported through normal `int3` - Concern:\n       Long basic blocks\n\n- [Control transfer instructions](https://pdos.csail.mit.edu/6.828/2018/readings/i386/s03_05.htm)\n\n### R2 Oblivious _detour_ execution\n\n- _Detour execution_ just takes place in the ORAM-backed huge page\n- Self-protection: the timely scheduling of security tasks already prevents\n  using extraction primitives to leak informations\n\n### R3 Randomization\n\n- We implement load-time binary rewriting. Our kernel binary rewriting facility\n  (based on linux kprobe) randomize location of probes on every CVM boots.\n\n### R4 Eagerly loading dependencies\n\n- We include a dynamic loader that eagerly load all binary dependencies. This\n  dynamic loader replaces the ELF's default loader. This reduces the overheads\n  of runtime instrumentation.\n\n## Design\n\n### Workflow\n\n```graphviz\ndigraph {\n    rankdir=LR\n   \tsubgraph cluster_0 {\n    label=\"Input\"\n    elf [label=\"ELF\",shape=square]\n    lib [label=\"*.so\",shape=square]\n    }\n\n\n    subgraph cluster0 {\n    func [label=\"Analyze symbol table\"];\n    load [label=\"Load to memory (mmap)\"];\n    }\n\n    subgraph cluster1 {\n    decode [label=\"Decode functions\"];\n    jmp [label=\"JMP locations\"];\n    }\n\n    subgraph cluster2 {\n    i1[label=\"INT3 replacement\",];\n    i2[label=\"Optimize 5-byte JMPs\"];\n    i3[label=\"Optimize 2-byte JMPs\"];\n    }\n\n    elf-\u003efunc\n    lib-\u003efunc\n\n    elf-\u003eload\n    lib-\u003eload\n\n    func-\u003edecode[label=\"function addresses\"]\n    jmp-\u003ei1\n    load -\u003e decode[]\n    decode -\u003e jmp[constraint=false]\n    i1-\u003ei2[constraint=false]\n    i2-\u003ei3[constraint=false]\n\n}\n```\n\n### Jump optimization\n\n```mermaid\nflowchart LR\nsubgraph t\ndirection TB\nsubgraph a [original exec]\n    org[\"0x1000: jmp RIP+64\"]\n    modified[\"0x1000: jmp 0x2000\"]\n    orig_target[\"0x1040: XXXX\"]\nend\n\nmodified--\u003eA\norg--\u003emodified\nA--\u003eorig_target\n\n\nsubgraph b [trampoline cache]\n    A---B---C---D\n    A[\"0x2000: backup_registers \u003cbr\u003e0x20XX: call security_cb\u003cbr\u003e 0x20XX: restore_registers\u003cbr\u003e0x20XX: jmp RIP-0xFC0// target with modified RIP\"]\n    B[\"0x3000: \"]\nend\nend\nstyle A text-align:left\nstyle B text-align:left\nstyle C text-align:left\nstyle D text-align:left\nstyle org text-align:left\nstyle modified text-align:left\n\n```\n\n## Design Space\n\n- `jmp` probe vs. `int3`\n     - `jmp` is 16x faster per intercept\n\n### How to handle dynamic libraries\n\nDynamic libraries loaded at runtime by the dynamic loader\n(`/lib64/ld-linux-x86-64.so.2`). How do we rewrite dynamic libraries as they are\nloaded?\n\nChallenges: Program loader is also pre-compiled and loaded at runtime\n\n#### Approach 1: Runtime rewriting: hooking dynamic linker\n\nAt runtime, dynamic linker open the shared object files (`libc.so`), maps it\ninto memory, and resolve missing plt calls.\n\nWe need to somehow obtain the load address + which shared library it is (for the\nfunction addresses) when it is after it is loaded into memory\n\nOne way we can do this is by hooking PLT entries.\n\n```\nDisassembly of section .plt:\n\n0000000000001020 \u003c.plt\u003e:\n    1020:       ff 35 9a 2f 00 00       pushq  0x2f9a(%rip)        # 3fc0 \u003c_GLOBAL_OFFSET_TABLE_+0x8\u003e\n    1026:       f2 ff 25 9b 2f 00 00    bnd jmpq *0x2f9b(%rip)        # 3fc8 \u003c_GLOBAL_OFFSET_TABLE_+0x10\u003e\n    102d:       0f 1f 00                nopl   (%rax)\n    1030:       f3 0f 1e fa             endbr64\n    1034:       68 00 00 00 00          pushq  $0x0\n    1039:       f2 e9 e1 ff ff ff       bnd jmpq 1020 \u003c.plt\u003e\n    103f:       90                      nop\n\nDisassembly of section .plt.got:\n\n0000000000001040 \u003c__cxa_finalize@plt\u003e:\n    1040:       f3 0f 1e fa             endbr64\n    1044:       f2 ff 25 ad 2f 00 00    bnd jmpq *0x2fad(%rip)        # 3ff8 \u003c__cxa_finalize@GLIBC_2.2.5\u003e\n    104b:       0f 1f 44 00 00          nopl   0x0(%rax,%rax,1)\n\nDisassembly of section .plt.sec:\n\n0000000000001050 \u003c__printf_chk@plt\u003e:\n    1050:       f3 0f 1e fa             endbr64\n    1054:       f2 ff 25 75 2f 00 00    bnd jmpq *0x2f75(%rip)        # 3fd0 \u003c__printf_chk@GLIBC_2.3.4\u003e\n    105b:       0f 1f 44 00 00          nopl   0x0(%rax,%rax,1)\n\n```\n\n#### Approach 2: Eager libraries loading\n\nOur own elf loader loads the dynamic libraries and prepare plt before execution\nhappen. We can perform binary rewrite at this stage.\n\nChallenges: How to find all required symbols\n\nAdvantages:\n\n- Unikernel don't need to share libraries, so we can do crazy things\n\n#### Approach 3: Rewrite pre-execution\n\nWe rewrite the shared libraries before load time and make the rewritten version\navailable to the loader.\n\n- Challenge: Relocation?\n\n### Instrumentation (LIM)\n\n```asm\n;; Original (2byte jump)\n0x00:\t48 85 c0                test   rax,rax\n0x03:\t75 03                   jne    8\n```\n\n#### Naive Approach(Base Line): Inject Interrupt(`int3`)\n\nWe instruments every jump instructions to ensure that our interrupt handler\nexecuted on every _basic blocks_.\n\n```asm\n;; Phase-1 : Inject Interrupt\n0x00:\t48 85 c0                test   rax,rax\n0x03:\tcc                      int3           ; Interrupt Handler Emulates `jne`\n0x04:\t90                      nop\n```\n\nThe `0x03:int3` transfers the control to our interrupt handler. emulates the\noriginal `jne` instruction\n\n#### Optimization : Jump Instrumentation\n\n```asm\n;; Phase-2 : Jump Optimization\n; Emulates `test`+`jne`\n0x00:\te9 00 00 cc 90          jmp    cc001b \u003cEmulate0x00\u003e\n```\n\n### Optimization Space for jmp\n\n- Reduce registers to backup\n- Reusing trampolines for same jmp opcodes\n- Sampling reduces the cost of too frequent jumps, thanks to branch predictor\n\n```c\nif (jmp_cnt \u003e 1000){\n    do_security_ticks();\n    jmp_cnt = 0;\n}\nelse {\n    jmp_cnt++;\n}\nemulate_jmp();\n```","snippets":["## Motivations"],"rawContent":"# IncognitOS binary-instrumentation-based scheduling\n\n## Motivations\n\nOur binary-instrumentation-based seek to solve two problems. First, it uphold\nthe security invariant of the ORAM-backed paging scheme, which require the\ntimely validation of huge mappings that may be smashed by the hypervisor.\n\nSecond, it implements a layer of defense that is adaptive to the costly\nextraction phase attacks. Extraction phase attacks are costly, thus inevitably\nleave side effects such as prolonged execution time, or identifiable\ninterceptions. Previous work demonstrated compiler-based detection schemes for\nSGX that use the compiler to insert checking code at configured interval, e.g.,\nper-basic blocks, but require application source code.\n\nMore generally, we want to reliably schedule _security threads_ alongside\nexecution of the unikernel application thread.\n\nUnfortunately, there are challenges. Scheduling is made unreliable in CVMs, due\nto the hardware timer being virtualized. Moreover, unikernels uses a cooperative\nscheduler (non-preemptive) that is unsuited for scheduling tasks per-interval.\n\n## Idea\n\nOur idea is to leverage binary rewriting to self-insert interception code (i.e.,\nprobes) into the application binary. The interception is then used as scheduling\nticks, which replace the unreliable virtualized interrupts of the kernel.\n\nBy carefully choosing the probe insertion, the OS can now dictate when the\ncontrol flow must be passed back to the scheduler, which solve two problems at\nthe same time: (1) lack of reliable hardware interrupts and (2) unikernel's lack\nof preemptive scheduling.\n\n## Design goals\n\nRequirements:\n\n- R1. For reliability, the scheduling ticks must be performed at least at each\n  basic block. This is to handle loops that may delay the scheduling of security\n  tasks.\n- R2. The intercepted execution must not leak information about the code. Now\n  that the original instruction is replaced with a probe, the execution flow\n  must take a _detour_ to a different location. Such detour must not leak\n  information through side-channels\n- R3. The location of the probes must be randomized per CVM boots. This is to\n  avoid the attacker bruteforcing to try to infer probe locations.\n- R4. Compatibility. Must not hurt existing unikernel binary compatibility\n\n## Design decisions\n\n### R1 Reliable per-basic-block ticks\n\n- We may intercept every `jmp` instructions.\n\n     - Using this, we may rewrite existing 5-bytes `jmp` instructions with jmp\n       to our detour execution cache as an optimization - In NGINX, about 70% of\n       `jmp` are 5-bytes\n     - More complex 2B `jmp` may be supported through normal `int3` - Concern:\n       Long basic blocks\n\n- [Control transfer instructions](https://pdos.csail.mit.edu/6.828/2018/readings/i386/s03_05.htm)\n\n### R2 Oblivious _detour_ execution\n\n- _Detour execution_ just takes place in the ORAM-backed huge page\n- Self-protection: the timely scheduling of security tasks already prevents\n  using extraction primitives to leak informations\n\n### R3 Randomization\n\n- We implement load-time binary rewriting. Our kernel binary rewriting facility\n  (based on linux kprobe) randomize location of probes on every CVM boots.\n\n### R4 Eagerly loading dependencies\n\n- We include a dynamic loader that eagerly load all binary dependencies. This\n  dynamic loader replaces the ELF's default loader. This reduces the overheads\n  of runtime instrumentation.\n\n## Design\n\n### Workflow\n\n```graphviz\ndigraph {\n    rankdir=LR\n   \tsubgraph cluster_0 {\n    label=\"Input\"\n    elf [label=\"ELF\",shape=square]\n    lib [label=\"*.so\",shape=square]\n    }\n\n\n    subgraph cluster0 {\n    func [label=\"Analyze symbol table\"];\n    load [label=\"Load to memory (mmap)\"];\n    }\n\n    subgraph cluster1 {\n    decode [label=\"Decode functions\"];\n    jmp [label=\"JMP locations\"];\n    }\n\n    subgraph cluster2 {\n    i1[label=\"INT3 replacement\",];\n    i2[label=\"Optimize 5-byte JMPs\"];\n    i3[label=\"Optimize 2-byte JMPs\"];\n    }\n\n    elf-\u003efunc\n    lib-\u003efunc\n\n    elf-\u003eload\n    lib-\u003eload\n\n    func-\u003edecode[label=\"function addresses\"]\n    jmp-\u003ei1\n    load -\u003e decode[]\n    decode -\u003e jmp[constraint=false]\n    i1-\u003ei2[constraint=false]\n    i2-\u003ei3[constraint=false]\n\n}\n```\n\n### Jump optimization\n\n```mermaid\nflowchart LR\nsubgraph t\ndirection TB\nsubgraph a [original exec]\n    org[\"0x1000: jmp RIP+64\"]\n    modified[\"0x1000: jmp 0x2000\"]\n    orig_target[\"0x1040: XXXX\"]\nend\n\nmodified--\u003eA\norg--\u003emodified\nA--\u003eorig_target\n\n\nsubgraph b [trampoline cache]\n    A---B---C---D\n    A[\"0x2000: backup_registers \u003cbr\u003e0x20XX: call security_cb\u003cbr\u003e 0x20XX: restore_registers\u003cbr\u003e0x20XX: jmp RIP-0xFC0// target with modified RIP\"]\n    B[\"0x3000: \"]\nend\nend\nstyle A text-align:left\nstyle B text-align:left\nstyle C text-align:left\nstyle D text-align:left\nstyle org text-align:left\nstyle modified text-align:left\n\n```\n\n## Design Space\n\n- `jmp` probe vs. `int3`\n     - `jmp` is 16x faster per intercept\n\n### How to handle dynamic libraries\n\nDynamic libraries loaded at runtime by the dynamic loader\n(`/lib64/ld-linux-x86-64.so.2`). How do we rewrite dynamic libraries as they are\nloaded?\n\nChallenges: Program loader is also pre-compiled and loaded at runtime\n\n#### Approach 1: Runtime rewriting: hooking dynamic linker\n\nAt runtime, dynamic linker open the shared object files (`libc.so`), maps it\ninto memory, and resolve missing plt calls.\n\nWe need to somehow obtain the load address + which shared library it is (for the\nfunction addresses) when it is after it is loaded into memory\n\nOne way we can do this is by hooking PLT entries.\n\n```\nDisassembly of section .plt:\n\n0000000000001020 \u003c.plt\u003e:\n    1020:       ff 35 9a 2f 00 00       pushq  0x2f9a(%rip)        # 3fc0 \u003c_GLOBAL_OFFSET_TABLE_+0x8\u003e\n    1026:       f2 ff 25 9b 2f 00 00    bnd jmpq *0x2f9b(%rip)        # 3fc8 \u003c_GLOBAL_OFFSET_TABLE_+0x10\u003e\n    102d:       0f 1f 00                nopl   (%rax)\n    1030:       f3 0f 1e fa             endbr64\n    1034:       68 00 00 00 00          pushq  $0x0\n    1039:       f2 e9 e1 ff ff ff       bnd jmpq 1020 \u003c.plt\u003e\n    103f:       90                      nop\n\nDisassembly of section .plt.got:\n\n0000000000001040 \u003c__cxa_finalize@plt\u003e:\n    1040:       f3 0f 1e fa             endbr64\n    1044:       f2 ff 25 ad 2f 00 00    bnd jmpq *0x2fad(%rip)        # 3ff8 \u003c__cxa_finalize@GLIBC_2.2.5\u003e\n    104b:       0f 1f 44 00 00          nopl   0x0(%rax,%rax,1)\n\nDisassembly of section .plt.sec:\n\n0000000000001050 \u003c__printf_chk@plt\u003e:\n    1050:       f3 0f 1e fa             endbr64\n    1054:       f2 ff 25 75 2f 00 00    bnd jmpq *0x2f75(%rip)        # 3fd0 \u003c__printf_chk@GLIBC_2.3.4\u003e\n    105b:       0f 1f 44 00 00          nopl   0x0(%rax,%rax,1)\n\n```\n\n#### Approach 2: Eager libraries loading\n\nOur own elf loader loads the dynamic libraries and prepare plt before execution\nhappen. We can perform binary rewrite at this stage.\n\nChallenges: How to find all required symbols\n\nAdvantages:\n\n- Unikernel don't need to share libraries, so we can do crazy things\n\n#### Approach 3: Rewrite pre-execution\n\nWe rewrite the shared libraries before load time and make the rewritten version\navailable to the loader.\n\n- Challenge: Relocation?\n\n### Instrumentation (LIM)\n\n```asm\n;; Original (2byte jump)\n0x00:\t48 85 c0                test   rax,rax\n0x03:\t75 03                   jne    8\n```\n\n#### Naive Approach(Base Line): Inject Interrupt(`int3`)\n\nWe instruments every jump instructions to ensure that our interrupt handler\nexecuted on every _basic blocks_.\n\n```asm\n;; Phase-1 : Inject Interrupt\n0x00:\t48 85 c0                test   rax,rax\n0x03:\tcc                      int3           ; Interrupt Handler Emulates `jne`\n0x04:\t90                      nop\n```\n\nThe `0x03:int3` transfers the control to our interrupt handler. emulates the\noriginal `jne` instruction\n\n#### Optimization : Jump Instrumentation\n\n```asm\n;; Phase-2 : Jump Optimization\n; Emulates `test`+`jne`\n0x00:\te9 00 00 cc 90          jmp    cc001b \u003cEmulate0x00\u003e\n```\n\n### Optimization Space for jmp\n\n- Reduce registers to backup\n- Reusing trampolines for same jmp opcodes\n- Sampling reduces the cost of too frequent jumps, thanks to branch predictor\n\n```c\nif (jmp_cnt \u003e 1000){\n    do_security_ticks();\n    jmp_cnt = 0;\n}\nelse {\n    jmp_cnt++;\n}\nemulate_jmp();\n```\n","wordCount":1102,"tags":[],"metadata":{},"created":"2024-07-02T05:10:01.882928552Z","modified":"2024-07-02T05:18:19.043525914Z","checksum":"71fabceb092de1af97b497bb33ef4fb50aaef166790fcd70411cfd3817505ee1"},
    {"filename":"8kvntsqe.md","filenameStem":"8kvntsqe","path":"8kvntsqe.md","absPath":"/home/khadd/mynotes/8kvntsqe.md","title":"IncognitOS new paging outline","link":"[[8kvntsqe]]","lead":"- [ ] Shorten 5.1, challenges \u0026 contribution\n- [ ] Follow R1 R2 R3 structure\n- [ ] Use positive terms (no attacker-observable, constrained)\n- [ ] Novelty?","body":"- [ ] Shorten 5.1, challenges \u0026 contribution\n- [ ] Follow R1 R2 R3 structure\n- [ ] Use positive terms (no attacker-observable, constrained)\n- [ ] Novelty?\n\nOverview: here are the rules\n\n- R1\n- R2\n- R3\n\n- Some background on access pattern leakage and implications\n\nChallenges\n\n- We must efficiently protect the page table access due attack vectors above.\n  Particularly, GPT access from from MMU and also the OS must follow R1-3. We\n  make two observations that enable efficientcy:\n\n  - (1) unused space in the PTE may be retrofitted for ORAM metadata and\n  - (2) due to the hierarchy of the page table, the rerandomization and\n    ORAM-access of both GPT and data pages may be incorporated in a single OS\n    page table walking without requiring multiple page faults.\n  - Sec 5.1 describe the paging scheme that also protect page table pages.\n\n- Page eviction is a component swapping page in and out of active regions on R2\n  and also used for rerandomization (R3).\n\n  - Now that page tables are also incorporate in ORAM-accesses and\n    rerandomization, the page eviction scheme must respect paging hierarchy.\n\n- Finally, we must retrofitting existing full system memory to use the proposed\n  paging rules. We analyze how unikernel memory is initialized, and also found\n  some unevitable exceptions that must be made to the rules (5.3).\n\n## Evaluations\n\n\u003c!-- We evaluate the securit of two components, runtime exit rate tracking and --\u003e\n\u003c!-- adaptive rerandomization that is based on the measured exit rate. --\u003e\n\n## Exit rate tracking accuracy\n\n- We repeat the scenarios (S1-3, S5) on the NGINX webserver to see how well the\n  exit rate is tracked.\n- We use our profiling framework to collect ground truth measurements traces\n  along the CVM execution the results and compare against the measured rate\n  (ExitRate).\n\n- Results in Fig5 shows that seen that the tick placement is indeed effective in\n  detecting premonitions of attacks.\n\n  - During normal execution, the groundtruth as well as measured exit is low\n  - As long as an attack begins (annotated in figure), the detected exit rate as\n    well as the rerandomization rate quickly spike up and stay there for the\n    duration of the attack.\n  - While our detected exit rate maxed out at 0.2, this is more than enough to\n    detect the potential of attacks.\n\n- Moreover, while there are overlapping between upper bound of I/O exit rate the\n  lower-bound of attack scenarios, the rate-adaptive approach allows it to\n  response without crashing.\n\n## Effectiveness against real attack\n\n- Goal: Show that our system makes attacks impractical by minimizing attacker's\n  temporal resolution\n\n- Protection against profiling:\n\n  - We repeat the attack methodology from [] that collect a profile of GPA\n    access during an attacker-contrlled event (chosen to be NGINX webserver\n    handling requests).\n    - Profiling require frequent exits, which causes high rerandomization rate.\n  - The results are shown in Figure6. Without adaptive rerandomization, the\n    frequency of page accesses is distictive in the histogram.\n  - On the ohter hand, our adaptive rerandomization flatten out the histogram\n    and make it hard to any useful frequency.\n  - Moreover, we show that adaptive rerandomization scheme allow larger\n    scratchpad sizes while preserving security.\n    - Scratchpad sizes: 512 causes significantly more faults than 1028 due to\n      frequent replacement. However, both shows the same level of security.\n\n- Protection agaisnt Secret extraction:\n\n  - We repeat the image extraction attack, re-implemented to use the NPF\n    controlled channel.\n  - We assume ideal attacker: start and end of the sensitive section is known to\n    attacker since constant rerandomization makes profiling difficult.\n  - The results shows that our adaptive eviction scheme adds significant noises\n    to the extracted image compared to the unprotected execution.\n  - Random vs full eviction:\n    - Compared to full eviction, random-eviction introduce more noises to the\n      extracted image.\n\n## Microbenchmark\n\n- nbench also used in other works and is representative of general workloads\n- We study the three aspect that contribute to the overheads: instrumentation,\n  page swapping from limited scratchpad sizes and adaptive rerandomization.\n\n- Configurations: different configurations to\n\n  - Sched: Only instrumentation\n  - Paging: Only enable paging (no rerandomization) to study isolated\n    performance of paging subsystem\n  - NonAdaptive vs. Adaptive: Shows the effectiveness in supressing runtime\n    overheads.\n\n- Instrumentation causes majority of overehads ( 4x)\n\n  - This is worst-case since nbench has tight loops. Will be better in\n    real-world applications with I/O ()\n  - We also instrument all program libraries and elf for most security.\n  - This overhead may be improved through optimizations, and non-sensitive\n    libraries skipping\n\n- Paging: We stresstest performance of paging under limited scratchpad size\n\n  - Larger scratchpad compared to previous work to facilitate whole-system pages\n  - Even with high amount of PF, it shows low relatively low overheads, thanks\n    to efficient paging (compared to klotski)\n  - Also, it achieve scratchpad contains whole working set, overheads is minimum\n    due to lack of software MMU instrumentation\n\n- NonAdaptive vs. Adaptive\n  - We test non-adaptive using static rerandomization rates.\n    - Low static rate causes high overheads, while high static rate leads to\n      extended attack window.\n  - On the other hand, \\thename's adaptiveness enable minimized static rate\n    during normal execution, leading to small amount of PF. This leads to only\n    small increase in overheadsheads compared to just instrumentation overheads.\n\n### Real-world applications\n\n- Shows our practicality through large application evaluations\n- ...\n-\n\n\n# subsec: IncognitOS Page tables \n## Unique feature 1: integrates ORAM page pool as its backend (i.e., replacing disk)\n- **ORAM page pool for securing paging-in** Any page-in process is subject to ORAM shuffling of page pool \n   - **Security Objective**: hypervisor does not learn which page has been brought in.\n   \n- **Modified soft MMU walk** We extend the traditional page-in process also perfrom ORAM-backed paging for table pages recursively.\n  - Security Objective: \n  \t- Same as above\n  \t- Support the page table rerandomization scheme\n  - Efficiency: \n  \t- A single page fault fetches the GPT and data page similar to a recursive ORAM\n  \t- Additional metadata maintenance is avoided.\n\n## Unique feature 2: Pages that map page tables (PG_{pgt}) themselves are subject to rerandomization\n- **Motivation**: Hypervisor can single out NPF-on-PGTs to group memory accesses into distinct 2MB regions (while exact address is unknown without knowing PTE content)\n   - **Leak through NPF-on-PGTs** can happen in two cases\n        - Soft walk during OS page management code (e.g., page fault handler) walking the PGTs\n        - MMU's hardware walk\n      \n\n- **Remaining challenge**:  Normal page to PGT page dependency\n  - **dependency-aware eviction scheme**\n\t- Explanation on security of this scheme?\n\n# Subsec: Rerandomization\n- Rerandomization happens through random eviction \n  - Upon demand from scheduler, We randomly choose N pages, where N is a random number between 0.5 * 512 (Num. 4K pages in 2MB active region) and 1.0 *512),\n      -  Evicted pages naturally go through the shuffling of ORAM page pool explained above \n       - Security Objective: hypervisor does not know which pages had been evicted\n          - Brings complete change in access trace: in both total counts, and order of accesses\n          - **Conclusion**: Eviction and ORAM-backed paging-in naturally creates a seemingly random access pattern","snippets":["- [ ] Shorten 5.1, challenges \u0026 contribution\n- [ ] Follow R1 R2 R3 structure\n- [ ] Use positive terms (no attacker-observable, constrained)\n- [ ] Novelty?"],"rawContent":"# IncognitOS new paging outline\n\n- [ ] Shorten 5.1, challenges \u0026 contribution\n- [ ] Follow R1 R2 R3 structure\n- [ ] Use positive terms (no attacker-observable, constrained)\n- [ ] Novelty?\n\nOverview: here are the rules\n\n- R1\n- R2\n- R3\n\n- Some background on access pattern leakage and implications\n\nChallenges\n\n- We must efficiently protect the page table access due attack vectors above.\n  Particularly, GPT access from from MMU and also the OS must follow R1-3. We\n  make two observations that enable efficientcy:\n\n  - (1) unused space in the PTE may be retrofitted for ORAM metadata and\n  - (2) due to the hierarchy of the page table, the rerandomization and\n    ORAM-access of both GPT and data pages may be incorporated in a single OS\n    page table walking without requiring multiple page faults.\n  - Sec 5.1 describe the paging scheme that also protect page table pages.\n\n- Page eviction is a component swapping page in and out of active regions on R2\n  and also used for rerandomization (R3).\n\n  - Now that page tables are also incorporate in ORAM-accesses and\n    rerandomization, the page eviction scheme must respect paging hierarchy.\n\n- Finally, we must retrofitting existing full system memory to use the proposed\n  paging rules. We analyze how unikernel memory is initialized, and also found\n  some unevitable exceptions that must be made to the rules (5.3).\n\n## Evaluations\n\n\u003c!-- We evaluate the securit of two components, runtime exit rate tracking and --\u003e\n\u003c!-- adaptive rerandomization that is based on the measured exit rate. --\u003e\n\n## Exit rate tracking accuracy\n\n- We repeat the scenarios (S1-3, S5) on the NGINX webserver to see how well the\n  exit rate is tracked.\n- We use our profiling framework to collect ground truth measurements traces\n  along the CVM execution the results and compare against the measured rate\n  (ExitRate).\n\n- Results in Fig5 shows that seen that the tick placement is indeed effective in\n  detecting premonitions of attacks.\n\n  - During normal execution, the groundtruth as well as measured exit is low\n  - As long as an attack begins (annotated in figure), the detected exit rate as\n    well as the rerandomization rate quickly spike up and stay there for the\n    duration of the attack.\n  - While our detected exit rate maxed out at 0.2, this is more than enough to\n    detect the potential of attacks.\n\n- Moreover, while there are overlapping between upper bound of I/O exit rate the\n  lower-bound of attack scenarios, the rate-adaptive approach allows it to\n  response without crashing.\n\n## Effectiveness against real attack\n\n- Goal: Show that our system makes attacks impractical by minimizing attacker's\n  temporal resolution\n\n- Protection against profiling:\n\n  - We repeat the attack methodology from [] that collect a profile of GPA\n    access during an attacker-contrlled event (chosen to be NGINX webserver\n    handling requests).\n    - Profiling require frequent exits, which causes high rerandomization rate.\n  - The results are shown in Figure6. Without adaptive rerandomization, the\n    frequency of page accesses is distictive in the histogram.\n  - On the ohter hand, our adaptive rerandomization flatten out the histogram\n    and make it hard to any useful frequency.\n  - Moreover, we show that adaptive rerandomization scheme allow larger\n    scratchpad sizes while preserving security.\n    - Scratchpad sizes: 512 causes significantly more faults than 1028 due to\n      frequent replacement. However, both shows the same level of security.\n\n- Protection agaisnt Secret extraction:\n\n  - We repeat the image extraction attack, re-implemented to use the NPF\n    controlled channel.\n  - We assume ideal attacker: start and end of the sensitive section is known to\n    attacker since constant rerandomization makes profiling difficult.\n  - The results shows that our adaptive eviction scheme adds significant noises\n    to the extracted image compared to the unprotected execution.\n  - Random vs full eviction:\n    - Compared to full eviction, random-eviction introduce more noises to the\n      extracted image.\n\n## Microbenchmark\n\n- nbench also used in other works and is representative of general workloads\n- We study the three aspect that contribute to the overheads: instrumentation,\n  page swapping from limited scratchpad sizes and adaptive rerandomization.\n\n- Configurations: different configurations to\n\n  - Sched: Only instrumentation\n  - Paging: Only enable paging (no rerandomization) to study isolated\n    performance of paging subsystem\n  - NonAdaptive vs. Adaptive: Shows the effectiveness in supressing runtime\n    overheads.\n\n- Instrumentation causes majority of overehads ( 4x)\n\n  - This is worst-case since nbench has tight loops. Will be better in\n    real-world applications with I/O ()\n  - We also instrument all program libraries and elf for most security.\n  - This overhead may be improved through optimizations, and non-sensitive\n    libraries skipping\n\n- Paging: We stresstest performance of paging under limited scratchpad size\n\n  - Larger scratchpad compared to previous work to facilitate whole-system pages\n  - Even with high amount of PF, it shows low relatively low overheads, thanks\n    to efficient paging (compared to klotski)\n  - Also, it achieve scratchpad contains whole working set, overheads is minimum\n    due to lack of software MMU instrumentation\n\n- NonAdaptive vs. Adaptive\n  - We test non-adaptive using static rerandomization rates.\n    - Low static rate causes high overheads, while high static rate leads to\n      extended attack window.\n  - On the other hand, \\thename's adaptiveness enable minimized static rate\n    during normal execution, leading to small amount of PF. This leads to only\n    small increase in overheadsheads compared to just instrumentation overheads.\n\n### Real-world applications\n\n- Shows our practicality through large application evaluations\n- ...\n-\n\n\n# subsec: IncognitOS Page tables \n## Unique feature 1: integrates ORAM page pool as its backend (i.e., replacing disk)\n- **ORAM page pool for securing paging-in** Any page-in process is subject to ORAM shuffling of page pool \n   - **Security Objective**: hypervisor does not learn which page has been brought in.\n   \n- **Modified soft MMU walk** We extend the traditional page-in process also perfrom ORAM-backed paging for table pages recursively.\n  - Security Objective: \n  \t- Same as above\n  \t- Support the page table rerandomization scheme\n  - Efficiency: \n  \t- A single page fault fetches the GPT and data page similar to a recursive ORAM\n  \t- Additional metadata maintenance is avoided.\n\n## Unique feature 2: Pages that map page tables (PG_{pgt}) themselves are subject to rerandomization\n- **Motivation**: Hypervisor can single out NPF-on-PGTs to group memory accesses into distinct 2MB regions (while exact address is unknown without knowing PTE content)\n   - **Leak through NPF-on-PGTs** can happen in two cases\n        - Soft walk during OS page management code (e.g., page fault handler) walking the PGTs\n        - MMU's hardware walk\n      \n\n- **Remaining challenge**:  Normal page to PGT page dependency\n  - **dependency-aware eviction scheme**\n\t- Explanation on security of this scheme?\n\n# Subsec: Rerandomization\n- Rerandomization happens through random eviction \n  - Upon demand from scheduler, We randomly choose N pages, where N is a random number between 0.5 * 512 (Num. 4K pages in 2MB active region) and 1.0 *512),\n      -  Evicted pages naturally go through the shuffling of ORAM page pool explained above \n       - Security Objective: hypervisor does not know which pages had been evicted\n          - Brings complete change in access trace: in both total counts, and order of accesses\n          - **Conclusion**: Eviction and ORAM-backed paging-in naturally creates a seemingly random access pattern\n","wordCount":1177,"tags":[],"metadata":{},"created":"2024-10-15T03:24:54.128874238Z","modified":"2024-10-16T06:00:42.103853952Z","checksum":"ae947926e6b97943c9effed863e1b2d53dc53fd87c371146c0e35fe2dce04095"},
    {"filename":"index.md","filenameStem":"index","path":"index.md","absPath":"/home/khadd/mynotes/index.md","title":"Index","link":"[[index]]","lead":"## Hashtags","body":"## Hashtags\n\nPARA hashtags ([[iwu6p0mt]]).\n\n- #resource: Not my own, just dumping it here for references. Personally find\n  this not very useful.\n- #project: Currently working on project\n- #archive: Notes not useful at the moment.\n- There is no #area tag, because are notes should be mantained continuously\n\nOther hashtags: arbitrary hashtag topic, e.g., #os.\n\n## Meta files\n\n### Configurations\n\nLanguage servers:\n\n- `zk/config.toml`: Configuration for zk\n- `.bibli.toml`: Bibliographies\n- `.markdownlint.jsonc`: Silent some annoying markdown lint\n- `.marksman.toml`: Marksman, used for some useful LSP features.\n\nFormatting:\n\n- `.editorconfig`: Formatting config for embedded languages like C.\n- `.prettierrc`: Formatting config for Markdown.\n\nSpell checking:\n\n- `.vale.ini`: Advanced prose checker (not used atm)\n\n### Spell checks\n\nLtex dictionaries \u0026 files.\n\n- `ltex.dictionary.en-US.txt`\n- `ltex.disabledRules.en-US.txt`\n- `ltex.hiddenFalsePositives.en-US.txt`\n\n### Bibliographies\n\n- ~`references.bib`~\n- Got rid manual bibfile in favor of automatic online library [bibli-ls]()","snippets":["## Hashtags"],"rawContent":"# Index\n\n## Hashtags\n\nPARA hashtags ([[iwu6p0mt]]).\n\n- #resource: Not my own, just dumping it here for references. Personally find\n  this not very useful.\n- #project: Currently working on project\n- #archive: Notes not useful at the moment.\n- There is no #area tag, because are notes should be mantained continuously\n\nOther hashtags: arbitrary hashtag topic, e.g., #os.\n\n## Meta files\n\n### Configurations\n\nLanguage servers:\n\n- `zk/config.toml`: Configuration for zk\n- `.bibli.toml`: Bibliographies\n- `.markdownlint.jsonc`: Silent some annoying markdown lint\n- `.marksman.toml`: Marksman, used for some useful LSP features.\n\nFormatting:\n\n- `.editorconfig`: Formatting config for embedded languages like C.\n- `.prettierrc`: Formatting config for Markdown.\n\nSpell checking:\n\n- `.vale.ini`: Advanced prose checker (not used atm)\n\n### Spell checks\n\nLtex dictionaries \u0026 files.\n\n- `ltex.dictionary.en-US.txt`\n- `ltex.disabledRules.en-US.txt`\n- `ltex.hiddenFalsePositives.en-US.txt`\n\n### Bibliographies\n\n- ~`references.bib`~\n- Got rid manual bibfile in favor of automatic online library [bibli-ls]()\n","wordCount":144,"tags":["os","area","resource:","project:","archive:"],"metadata":{},"created":"2023-05-09T04:12:51.850644773Z","modified":"2024-12-12T08:08:04.191741952Z","checksum":"8d30c5e082fcb23f98022920010f8f5c7a3b77c4b43ddb02e391d83927294819"},
    {"filename":"u55zie42.md","filenameStem":"u55zie42","path":"u55zie42.md","absPath":"/home/khadd/mynotes/u55zie42.md","title":"InkTag: Secure Applications on an Untrusted Operating System","link":"[[u55zie42]]","lead":"#literature #hypervisor","body":"#literature #hypervisor\n\n# Background\n\nAt the time of this paper, SGX that have the same functionality but without\nhypervisor have yet to exist.\n\nPrevious system on protection against untrusted OS, OverShadow\n[@chen2008overshadow] only focus on isolation of memory (code and data) from the\nOS. This papers provides methods for verifying OS behaviors, allowing the\nprotected program to use OS services securely.\n\n# Main arguments\n\n## Verifying OS behaviors with the hypervisors is more simple than reimplementing OS services inside the hypervisor\n\n- OS services often have simple specifications.\n- Only implementing verification in the kernel reduces the TCB of hypervisor.\n- The introduced technique called _paraverification_ to verify the unstrusted\n  OS. Essentially, the OS is changed to cooperate with the hypervisor for\n  verifiable OS services (e.g., page management).\n\n## Untrusted OS verification leads to security\n\n- This directly address the Iago Attack [[ns7lcn8t]] where the untrusted OS\n  feeds incorrect values to trusted application.\n- InkTag enable crash consistency\n- InkTag is able to secure files with defined access control policies.\n\n# Control flow\n\nThe High assurance programs (HAPs) and the operating system interacts through a\n_untrusted trampoline_. The application first invoke the hypervisor to request\nsystem call. The hypervisor switch the control to an untrusted trampoline that\nactually invoke the system call.\n\nThis allows the untrusted OS to schedule among the untrusted trampolines and\nother contexts.\n\nNOTE: Not quite understand.\n\n# Memory isolation\n\nInkTag provides two layers of memory isolation: kernel to High assurance\nprograms (HAPs), and between the HAPs. Memory isolation are provided by EPT\nvirtualization plus paraverfication. This isolation is maintained from the file\nsystem up to the memory pages.\n\nThe _object_ abstraction represents files. Each object is given a unique ID\n(_OID_). An objects consists of _secure pages (S-pages)_ that contains metadata\nabout the owner object and the offset within the object (_\u003cOID, offset\u003e_), and\nalso the _hash_ of the data (for verification).\n\n## Two EPTs\n\nTwo EPTs are used for trusted context (HAPs) and untrusted context (kernel /\nnormal apps). The trusted EPT maps the plaintext S-page physical frames. The\nuntrusted EPT maps the other frames.\n\n- When OS / untrusted applications access a mapped S-pages in trusted EPT (not\n  mapped in untrusted), the hypervisor unmap it in trusted EPT, take the hash,\n  encrypt the page, then map it to untrusted EPT.\n- When HAP access the frame, hypervisor decrypt the page, verify the hash, map\n  it to trusted EPT, unmap it from untrusted EPT.\n\n## Isolation between HAPs\n\nThe hypervisor manage page table updates for HAPs, to enforce access control\npolicies of objects. For normal pages, the OS can map without intervention.","snippets":["#literature #hypervisor"],"rawContent":"# InkTag: Secure Applications on an Untrusted Operating System\n\n#literature #hypervisor\n\n# Background\n\nAt the time of this paper, SGX that have the same functionality but without\nhypervisor have yet to exist.\n\nPrevious system on protection against untrusted OS, OverShadow\n[@chen2008overshadow] only focus on isolation of memory (code and data) from the\nOS. This papers provides methods for verifying OS behaviors, allowing the\nprotected program to use OS services securely.\n\n# Main arguments\n\n## Verifying OS behaviors with the hypervisors is more simple than reimplementing OS services inside the hypervisor\n\n- OS services often have simple specifications.\n- Only implementing verification in the kernel reduces the TCB of hypervisor.\n- The introduced technique called _paraverification_ to verify the unstrusted\n  OS. Essentially, the OS is changed to cooperate with the hypervisor for\n  verifiable OS services (e.g., page management).\n\n## Untrusted OS verification leads to security\n\n- This directly address the Iago Attack [[ns7lcn8t]] where the untrusted OS\n  feeds incorrect values to trusted application.\n- InkTag enable crash consistency\n- InkTag is able to secure files with defined access control policies.\n\n# Control flow\n\nThe High assurance programs (HAPs) and the operating system interacts through a\n_untrusted trampoline_. The application first invoke the hypervisor to request\nsystem call. The hypervisor switch the control to an untrusted trampoline that\nactually invoke the system call.\n\nThis allows the untrusted OS to schedule among the untrusted trampolines and\nother contexts.\n\nNOTE: Not quite understand.\n\n# Memory isolation\n\nInkTag provides two layers of memory isolation: kernel to High assurance\nprograms (HAPs), and between the HAPs. Memory isolation are provided by EPT\nvirtualization plus paraverfication. This isolation is maintained from the file\nsystem up to the memory pages.\n\nThe _object_ abstraction represents files. Each object is given a unique ID\n(_OID_). An objects consists of _secure pages (S-pages)_ that contains metadata\nabout the owner object and the offset within the object (_\u003cOID, offset\u003e_), and\nalso the _hash_ of the data (for verification).\n\n## Two EPTs\n\nTwo EPTs are used for trusted context (HAPs) and untrusted context (kernel /\nnormal apps). The trusted EPT maps the plaintext S-page physical frames. The\nuntrusted EPT maps the other frames.\n\n- When OS / untrusted applications access a mapped S-pages in trusted EPT (not\n  mapped in untrusted), the hypervisor unmap it in trusted EPT, take the hash,\n  encrypt the page, then map it to untrusted EPT.\n- When HAP access the frame, hypervisor decrypt the page, verify the hash, map\n  it to trusted EPT, unmap it from untrusted EPT.\n\n## Isolation between HAPs\n\nThe hypervisor manage page table updates for HAPs, to enforce access control\npolicies of objects. For normal pages, the OS can map without intervention.\n","wordCount":446,"tags":["literature","hypervisor"],"metadata":{},"created":"2024-05-22T08:24:03.300694153Z","modified":"2024-10-23T07:38:19.22105693Z","checksum":"695725c0d79926e3c0db14c146ab40947c0564af9ccdbbe3dff028bca640796b"},
    {"filename":"llhmwuim.md","filenameStem":"llhmwuim","path":"llhmwuim.md","absPath":"/home/khadd/mynotes/llhmwuim.md","title":"Inside of Linux support for AMD SEV","link":"[[llhmwuim]]","lead":"#sev #virtualization #os #linux","body":"#sev #virtualization #os #linux\n\nConfiguration for SEV starts at, where kernel initialization starts. This is\ncalled after the kernel have been decompressed and loaded into memory\n(`kernel/arch/x86/boot/compressed/head_64.S`).\n\n## Configuration\n\n`CONFIG_AMD_MEM_ENCRYPT`\n\n## Booting\n\n### Protected mode\n\n### Long mode\n\nIn `startup_64`, `kernel/arch/x86/boot/compressed/head_64.S`, which is the\nbooting code in 64-bit long mode that performs kernel decompression, there is\nthis code;\n\n```c\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\t/*\n\t * Now that the stage1 interrupt handlers are set up, #VC exceptions from\n\t * CPUID instructions can be properly handled for SEV-ES guests.\n\t *\n\t * For SEV-SNP, the CPUID table also needs to be set up in advance of any\n\t * CPUID instructions being issued, so go ahead and do that now via\n\t * sev_enable(), which will also handle the rest of the SEV-related\n\t * detection/setup to ensure that has been done in advance of any dependent\n\t * code.\n\t */\n\tpushq\t%rsi\n\tmovq\t%rsi, %rdi\t\t/* real mode address */\n\tcall\tsev_enable\n\tpopq\t%rsi\n#endif\n```\n\n`sev_enable` first checks whether SEV is supported using `native_cpuid`, which\ncalls `cpuid` instruction. Then, it call `snp_init`. The function looks for the\nstruct `cc_blob_sev_info` defined as follows:\n\n```c\n/*\n * AMD SEV Confidential computing blob structure. The structure is\n * defined in OVMF UEFI firmware header:\n * https://github.com/tianocore/edk2/blob/master/OvmfPkg/Include/Guid/ConfidentialComputingSevSnpBlob.h\n */\n#define CC_BLOB_SEV_HDR_MAGIC\t0x45444d41\nstruct cc_blob_sev_info {\n\tu32 magic;\n\tu16 version;\n\tu16 reserved;\n\tu64 secrets_phys;\n\tu32 secrets_len;\n\tu32 rsvd1;\n\tu64 cpuid_phys;\n\tu32 cpuid_len;\n\tu32 rsvd2;\n} __packed;\n\n```\n\nIn this struct's definition, you can notice `secrets_phys` and `cpuid_phys`\nfields, which correspond to the physical address of the _special pages_ inserted\ninto the guest memory\n([AMD manual](https://www.amd.com/system/files/TechDocs/56860.pdf), 4.5). The\ncommand `SNP_LAUNCH_UPDATE` is used by the hypervisor to insert a _secrets_ page\nand a _CPUID_ page. The secrets page contains encryption keys that the guest can\nuse to interact with the firmware. The CPUID page contains the\nhypervisor-provided CPUID information, which the guest can request the firmware\nto validate.\n\nThe blob for this struct is contained in the vendor in the EFI configuration\ntable\n[uefi-spec](https://uefi.org/specs/UEFI/2.10/04_EFI_System_Table.html#efi-configuration-table).\nThe table is set up by AMD UEFI-compatible firmware (I think?). The table is\nindexed using GUID\n([check](https://github.com/tianocore/edk2/blob/master/OvmfPkg/Include/Guid/ConfidentialComputingSevSnpBlob.h)).\nIf a lookup using the GUID for this specific structure (`EFI_CC_BLOB_GUID`)\nsucceed, then it indicates that SNP feature is enabled. Note that the _physical_\naddress of the blob is returned. Here is the implementation of `snp_init`\n\n```c\n/*\n * Indicate SNP based on presence of SNP-specific CC blob. Subsequent checks\n * will verify the SNP CPUID/MSR bits.\n */\nbool snp_init(struct boot_params *bp)\n{\n\tstruct cc_blob_sev_info *cc_info;\n\n\tif (!bp)\n\t\treturn false;\n\n\tcc_info = find_cc_blob(bp);\n\tif (!cc_info)\n\t\treturn false;\n\n\t/*\n\t * If a SNP-specific Confidential Computing blob is present, then\n\t * firmware/bootloader have indicated SNP support. Verifying this\n\t * involves CPUID checks which will be more reliable if the SNP\n\t * CPUID table is used. See comments over snp_setup_cpuid_table() for\n\t * more details.\n\t */\n\tsetup_cpuid_table(cc_info);\n\n\t/*\n\t * Pass run-time kernel a pointer to CC info via boot_params so EFI\n\t * config table doesn't need to be searched again during early startup\n\t * phase.\n\t */\n\tbp-\u003ecc_blob_address = (u32)(unsigned long)cc_info;\n\n\treturn true;\n}\n```\n\nAfter, `snp_init` set `cc_blob_address` in `boot_params` to the address of the\n`cc_blob_sev_info` struct. This address is used later to initialize the\nSEV-related parts of the kernel.\n\nAfter, booting occurs as normal, and the control flow eventually reaches the\n`startup_64`` function (`arch/x86/kernel/head_64.S`) for kernel initialization.\n\n## Kernel initialization\n\nIn `startup_64` (`arch/x86/kernel/head64.S`), you will see the following code,\n\n```c\nSYM_CODE_START_NOALIGN(startup_64)\n  // ...\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\t/*\n\t * Activate SEV/SME memory encryption if supported/enabled. This needs to\n\t * be done now, since this also includes setup of the SEV-SNP CPUID table,\n\t * which needs to be done before any CPUID instructions are executed in\n\t * subsequent code.\n\t */\n\tmovq\t%rsi, %rdi\n\tpushq\t%rsi\n\tcall\tsme_enable\n\tpopq\t%rsi\n#endif\n\t/* Sanitize CPU configuration */\n\tcall verify_cpu\n\n\t/*\n\t * Perform pagetable fixups. Additionally, if SME is active, encrypt\n\t * the kernel and retrieve the modifier (SME encryption mask if SME\n\t * is active) to be added to the initial pgdir entry that will be\n\t * programmed into CR3.\n\t */\n\tleaq\t_text(%rip), %rdi\n\tpushq\t%rsi\n\tcall\t__startup_64\n\tpopq\t%rsi\n\n\t/* Form the CR3 value being sure to include the CR3 modifier */\n\taddq\t$(early_top_pgt - __START_KERNEL_map), %rax\n\tjmp 1f\nSYM_CODE_END(startup_64)\n```\n\nIf the config `CONFIG_AMD_MEM_ENCRYPT` is enabled, it calls `sme_enable`\n(`mem_encrypt_idendity.c`) to enable the Secure memory encryption (SME) feature.\n\nThe function calls `snp_init` (`x86/kernel/sev.c`). Note that this function is\nfor the _kernel initialization_ of SEV, which is different from _boot time\ninitialization_ in `boot/compressed/sev.c`. It uses `find_cc_blob` check for the\nvalue of `bp-\u003ecc_blob_address` initialized previously by the boot time\n`snp_init`. If not found, it checks for setup_data defined by Linux boot\nprotocol.\n\n```c\nvoid __init sme_enable(struct boot_params *bp)\n{\n  //...\n\t/* Check the SEV MSR whether SEV or SME is enabled */\n\tsev_status   = __rdmsr(MSR_AMD64_SEV);\n\tfeature_mask = (sev_status \u0026 MSR_AMD64_SEV_ENABLED) ? AMD_SEV_BIT : AMD_SME_BIT;\n\n\t/* The SEV-SNP CC blob should never be present unless SEV-SNP is enabled. */\n\tif (snp \u0026\u0026 !(sev_status \u0026 MSR_AMD64_SEV_SNP_ENABLED))\n\t\tsnp_abort();\n\n\t/* Check if memory encryption is enabled */\n\tif (feature_mask == AMD_SME_BIT) {\n    //...\n\t} else {\n\t\t/* SEV state cannot be controlled by a command line option */\n\t\tsme_me_mask = me_mask;\n\t\tgoto out;\n\t}\n  //...\n\nout:\n\tif (sme_me_mask) {\n\t\tphysical_mask \u0026= ~sme_me_mask;\n\t\tcc_vendor = CC_VENDOR_AMD;\n\t\tcc_set_mask(sme_me_mask);\n\t}\n}\n\n```\n\nLinux provides an abstraction abstract of the capabilities of confidential\ncomputing platforms, under namespace `x86/coco/core.c`. The interface defines\nthe `cc_attr`` enum that represents confidential computing features. The current\nlist of features are:\n\n```c\nenum cc_attr {\n\t/**\n\t * @CC_ATTR_MEM_ENCRYPT: Memory encryption is active\n\t *\n\t * The platform/OS is running with active memory encryption. This\n\t * includes running either as a bare-metal system or a hypervisor\n\t * and actively using memory encryption or as a guest/virtual machine\n\t * and actively using memory encryption.\n\t *\n\t * Examples include SME, SEV and SEV-ES.\n\t */\n\tCC_ATTR_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_HOST_MEM_ENCRYPT: Host memory encryption is active\n\t *\n\t * The platform/OS is running as a bare-metal system or a hypervisor\n\t * and actively using memory encryption.\n\t *\n\t * Examples include SME.\n\t */\n\tCC_ATTR_HOST_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_MEM_ENCRYPT: Guest memory encryption is active\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using memory encryption.\n\t *\n\t * Examples include SEV and SEV-ES.\n\t */\n\tCC_ATTR_GUEST_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_STATE_ENCRYPT: Guest state encryption is active\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using memory encryption and register state encryption.\n\t *\n\t * Examples include SEV-ES.\n\t */\n\tCC_ATTR_GUEST_STATE_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_UNROLL_STRING_IO: String I/O is implemented with\n\t *                                  IN/OUT instructions\n\t *\n\t * The platform/OS is running as a guest/virtual machine and uses\n\t * IN/OUT instructions in place of string I/O.\n\t *\n\t * Examples include TDX guest \u0026 SEV.\n\t */\n\tCC_ATTR_GUEST_UNROLL_STRING_IO,\n\n\t/**\n\t * @CC_ATTR_SEV_SNP: Guest SNP is active.\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using AMD SEV-SNP features.\n\t */\n\tCC_ATTR_GUEST_SEV_SNP,\n\n\t/**\n\t * @CC_ATTR_HOTPLUG_DISABLED: Hotplug is not supported or disabled.\n\t *\n\t * The platform/OS is running as a guest/virtual machine does not\n\t * support CPU hotplug feature.\n\t *\n\t * Examples include TDX Guest.\n\t */\n\tCC_ATTR_HOTPLUG_DISABLED,\n};\n\n\n```\n\nThe `cc_set_mask` set the global `cc_mask` variable. The `cc_mask` variable is\ndefined in `x86/coco/core.c`, which provides an architectural-independent\ninterface to control memory encryption in different architecture. `cc_mask`\nholds the mask for the bit in the page table entry that indicates memory\nencryption should be performed.\n\n```c\n\n// arch/x86/include/asm/pgtable.h\n#define pgprot_encrypted(prot)\t__pgprot(cc_mkenc(pgprot_val(prot)))\n#define pgprot_decrypted(prot)\t__pgprot(cc_mkdec(pgprot_val(prot)))\n\n// arch/x86/coco/core.c\nu64 cc_mkenc(u64 val)\n{\n\t/*\n\t * Both AMD and Intel use a bit in the page table to indicate\n\t * encryption status of the page.\n\t *\n\t * - for AMD, bit *set* means the page is encrypted\n\t * - for AMD with vTOM and for Intel, *clear* means encrypted\n\t */\n\tswitch (cc_vendor) {\n\tcase CC_VENDOR_AMD:\n\t\tif (sev_status \u0026 MSR_AMD64_SNP_VTOM)\n\t\t\treturn val \u0026 ~cc_mask;\n\t\telse\n\t\t\treturn val | cc_mask;\n\tcase CC_VENDOR_INTEL:\n\t\treturn val \u0026 ~cc_mask;\n\tdefault:\n\t\treturn val;\n\t}\n}\n```\n\nTo enable SME, the mask has to be set according to the bit position in the page\ntable entry, returned by CPUID. In `sme_enable`, line 528, you can see\n\n```c /*\n\t/*\n\t * Check for the SME/SEV feature:\n\t *   CPUID Fn8000_001F[EAX]\n\t *   - Bit 0 - Secure Memory Encryption support\n\t *   - Bit 1 - Secure Encrypted Virtualization support\n\t *   CPUID Fn8000_001F[EBX]\n\t *   - Bits 5:0 - Pagetable bit position used to indicate encryption\n\t */\n\teax = 0x8000001f;\n\tecx = 0;\n\tnative_cpuid(\u0026eax, \u0026ebx, \u0026ecx, \u0026edx);\n\t/* Check whether SEV or SME is supported */\n\tif (!(eax \u0026 (AMD_SEV_BIT | AMD_SME_BIT)))\n\t\treturn;\n\n\tme_mask = 1UL \u003c\u003c (ebx \u0026 0x3f);\n```\n\nThe bit operation clears the other bits in ebx (`ebx \u0026 0b11111`), then shift the\nbit right according to the value in bits 5:0. For example, if bits 5:0 in ebx is\n0b000011, it means the encryption bit (c-bit) is bit 3 of the page table entry,\nand the mask should be 0b0...01000.","snippets":["#sev #virtualization #os #linux"],"rawContent":"# Inside of Linux support for AMD SEV\n\n#sev #virtualization #os #linux\n\nConfiguration for SEV starts at, where kernel initialization starts. This is\ncalled after the kernel have been decompressed and loaded into memory\n(`kernel/arch/x86/boot/compressed/head_64.S`).\n\n## Configuration\n\n`CONFIG_AMD_MEM_ENCRYPT`\n\n## Booting\n\n### Protected mode\n\n### Long mode\n\nIn `startup_64`, `kernel/arch/x86/boot/compressed/head_64.S`, which is the\nbooting code in 64-bit long mode that performs kernel decompression, there is\nthis code;\n\n```c\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\t/*\n\t * Now that the stage1 interrupt handlers are set up, #VC exceptions from\n\t * CPUID instructions can be properly handled for SEV-ES guests.\n\t *\n\t * For SEV-SNP, the CPUID table also needs to be set up in advance of any\n\t * CPUID instructions being issued, so go ahead and do that now via\n\t * sev_enable(), which will also handle the rest of the SEV-related\n\t * detection/setup to ensure that has been done in advance of any dependent\n\t * code.\n\t */\n\tpushq\t%rsi\n\tmovq\t%rsi, %rdi\t\t/* real mode address */\n\tcall\tsev_enable\n\tpopq\t%rsi\n#endif\n```\n\n`sev_enable` first checks whether SEV is supported using `native_cpuid`, which\ncalls `cpuid` instruction. Then, it call `snp_init`. The function looks for the\nstruct `cc_blob_sev_info` defined as follows:\n\n```c\n/*\n * AMD SEV Confidential computing blob structure. The structure is\n * defined in OVMF UEFI firmware header:\n * https://github.com/tianocore/edk2/blob/master/OvmfPkg/Include/Guid/ConfidentialComputingSevSnpBlob.h\n */\n#define CC_BLOB_SEV_HDR_MAGIC\t0x45444d41\nstruct cc_blob_sev_info {\n\tu32 magic;\n\tu16 version;\n\tu16 reserved;\n\tu64 secrets_phys;\n\tu32 secrets_len;\n\tu32 rsvd1;\n\tu64 cpuid_phys;\n\tu32 cpuid_len;\n\tu32 rsvd2;\n} __packed;\n\n```\n\nIn this struct's definition, you can notice `secrets_phys` and `cpuid_phys`\nfields, which correspond to the physical address of the _special pages_ inserted\ninto the guest memory\n([AMD manual](https://www.amd.com/system/files/TechDocs/56860.pdf), 4.5). The\ncommand `SNP_LAUNCH_UPDATE` is used by the hypervisor to insert a _secrets_ page\nand a _CPUID_ page. The secrets page contains encryption keys that the guest can\nuse to interact with the firmware. The CPUID page contains the\nhypervisor-provided CPUID information, which the guest can request the firmware\nto validate.\n\nThe blob for this struct is contained in the vendor in the EFI configuration\ntable\n[uefi-spec](https://uefi.org/specs/UEFI/2.10/04_EFI_System_Table.html#efi-configuration-table).\nThe table is set up by AMD UEFI-compatible firmware (I think?). The table is\nindexed using GUID\n([check](https://github.com/tianocore/edk2/blob/master/OvmfPkg/Include/Guid/ConfidentialComputingSevSnpBlob.h)).\nIf a lookup using the GUID for this specific structure (`EFI_CC_BLOB_GUID`)\nsucceed, then it indicates that SNP feature is enabled. Note that the _physical_\naddress of the blob is returned. Here is the implementation of `snp_init`\n\n```c\n/*\n * Indicate SNP based on presence of SNP-specific CC blob. Subsequent checks\n * will verify the SNP CPUID/MSR bits.\n */\nbool snp_init(struct boot_params *bp)\n{\n\tstruct cc_blob_sev_info *cc_info;\n\n\tif (!bp)\n\t\treturn false;\n\n\tcc_info = find_cc_blob(bp);\n\tif (!cc_info)\n\t\treturn false;\n\n\t/*\n\t * If a SNP-specific Confidential Computing blob is present, then\n\t * firmware/bootloader have indicated SNP support. Verifying this\n\t * involves CPUID checks which will be more reliable if the SNP\n\t * CPUID table is used. See comments over snp_setup_cpuid_table() for\n\t * more details.\n\t */\n\tsetup_cpuid_table(cc_info);\n\n\t/*\n\t * Pass run-time kernel a pointer to CC info via boot_params so EFI\n\t * config table doesn't need to be searched again during early startup\n\t * phase.\n\t */\n\tbp-\u003ecc_blob_address = (u32)(unsigned long)cc_info;\n\n\treturn true;\n}\n```\n\nAfter, `snp_init` set `cc_blob_address` in `boot_params` to the address of the\n`cc_blob_sev_info` struct. This address is used later to initialize the\nSEV-related parts of the kernel.\n\nAfter, booting occurs as normal, and the control flow eventually reaches the\n`startup_64`` function (`arch/x86/kernel/head_64.S`) for kernel initialization.\n\n## Kernel initialization\n\nIn `startup_64` (`arch/x86/kernel/head64.S`), you will see the following code,\n\n```c\nSYM_CODE_START_NOALIGN(startup_64)\n  // ...\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\t/*\n\t * Activate SEV/SME memory encryption if supported/enabled. This needs to\n\t * be done now, since this also includes setup of the SEV-SNP CPUID table,\n\t * which needs to be done before any CPUID instructions are executed in\n\t * subsequent code.\n\t */\n\tmovq\t%rsi, %rdi\n\tpushq\t%rsi\n\tcall\tsme_enable\n\tpopq\t%rsi\n#endif\n\t/* Sanitize CPU configuration */\n\tcall verify_cpu\n\n\t/*\n\t * Perform pagetable fixups. Additionally, if SME is active, encrypt\n\t * the kernel and retrieve the modifier (SME encryption mask if SME\n\t * is active) to be added to the initial pgdir entry that will be\n\t * programmed into CR3.\n\t */\n\tleaq\t_text(%rip), %rdi\n\tpushq\t%rsi\n\tcall\t__startup_64\n\tpopq\t%rsi\n\n\t/* Form the CR3 value being sure to include the CR3 modifier */\n\taddq\t$(early_top_pgt - __START_KERNEL_map), %rax\n\tjmp 1f\nSYM_CODE_END(startup_64)\n```\n\nIf the config `CONFIG_AMD_MEM_ENCRYPT` is enabled, it calls `sme_enable`\n(`mem_encrypt_idendity.c`) to enable the Secure memory encryption (SME) feature.\n\nThe function calls `snp_init` (`x86/kernel/sev.c`). Note that this function is\nfor the _kernel initialization_ of SEV, which is different from _boot time\ninitialization_ in `boot/compressed/sev.c`. It uses `find_cc_blob` check for the\nvalue of `bp-\u003ecc_blob_address` initialized previously by the boot time\n`snp_init`. If not found, it checks for setup_data defined by Linux boot\nprotocol.\n\n```c\nvoid __init sme_enable(struct boot_params *bp)\n{\n  //...\n\t/* Check the SEV MSR whether SEV or SME is enabled */\n\tsev_status   = __rdmsr(MSR_AMD64_SEV);\n\tfeature_mask = (sev_status \u0026 MSR_AMD64_SEV_ENABLED) ? AMD_SEV_BIT : AMD_SME_BIT;\n\n\t/* The SEV-SNP CC blob should never be present unless SEV-SNP is enabled. */\n\tif (snp \u0026\u0026 !(sev_status \u0026 MSR_AMD64_SEV_SNP_ENABLED))\n\t\tsnp_abort();\n\n\t/* Check if memory encryption is enabled */\n\tif (feature_mask == AMD_SME_BIT) {\n    //...\n\t} else {\n\t\t/* SEV state cannot be controlled by a command line option */\n\t\tsme_me_mask = me_mask;\n\t\tgoto out;\n\t}\n  //...\n\nout:\n\tif (sme_me_mask) {\n\t\tphysical_mask \u0026= ~sme_me_mask;\n\t\tcc_vendor = CC_VENDOR_AMD;\n\t\tcc_set_mask(sme_me_mask);\n\t}\n}\n\n```\n\nLinux provides an abstraction abstract of the capabilities of confidential\ncomputing platforms, under namespace `x86/coco/core.c`. The interface defines\nthe `cc_attr`` enum that represents confidential computing features. The current\nlist of features are:\n\n```c\nenum cc_attr {\n\t/**\n\t * @CC_ATTR_MEM_ENCRYPT: Memory encryption is active\n\t *\n\t * The platform/OS is running with active memory encryption. This\n\t * includes running either as a bare-metal system or a hypervisor\n\t * and actively using memory encryption or as a guest/virtual machine\n\t * and actively using memory encryption.\n\t *\n\t * Examples include SME, SEV and SEV-ES.\n\t */\n\tCC_ATTR_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_HOST_MEM_ENCRYPT: Host memory encryption is active\n\t *\n\t * The platform/OS is running as a bare-metal system or a hypervisor\n\t * and actively using memory encryption.\n\t *\n\t * Examples include SME.\n\t */\n\tCC_ATTR_HOST_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_MEM_ENCRYPT: Guest memory encryption is active\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using memory encryption.\n\t *\n\t * Examples include SEV and SEV-ES.\n\t */\n\tCC_ATTR_GUEST_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_STATE_ENCRYPT: Guest state encryption is active\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using memory encryption and register state encryption.\n\t *\n\t * Examples include SEV-ES.\n\t */\n\tCC_ATTR_GUEST_STATE_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_UNROLL_STRING_IO: String I/O is implemented with\n\t *                                  IN/OUT instructions\n\t *\n\t * The platform/OS is running as a guest/virtual machine and uses\n\t * IN/OUT instructions in place of string I/O.\n\t *\n\t * Examples include TDX guest \u0026 SEV.\n\t */\n\tCC_ATTR_GUEST_UNROLL_STRING_IO,\n\n\t/**\n\t * @CC_ATTR_SEV_SNP: Guest SNP is active.\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using AMD SEV-SNP features.\n\t */\n\tCC_ATTR_GUEST_SEV_SNP,\n\n\t/**\n\t * @CC_ATTR_HOTPLUG_DISABLED: Hotplug is not supported or disabled.\n\t *\n\t * The platform/OS is running as a guest/virtual machine does not\n\t * support CPU hotplug feature.\n\t *\n\t * Examples include TDX Guest.\n\t */\n\tCC_ATTR_HOTPLUG_DISABLED,\n};\n\n\n```\n\nThe `cc_set_mask` set the global `cc_mask` variable. The `cc_mask` variable is\ndefined in `x86/coco/core.c`, which provides an architectural-independent\ninterface to control memory encryption in different architecture. `cc_mask`\nholds the mask for the bit in the page table entry that indicates memory\nencryption should be performed.\n\n```c\n\n// arch/x86/include/asm/pgtable.h\n#define pgprot_encrypted(prot)\t__pgprot(cc_mkenc(pgprot_val(prot)))\n#define pgprot_decrypted(prot)\t__pgprot(cc_mkdec(pgprot_val(prot)))\n\n// arch/x86/coco/core.c\nu64 cc_mkenc(u64 val)\n{\n\t/*\n\t * Both AMD and Intel use a bit in the page table to indicate\n\t * encryption status of the page.\n\t *\n\t * - for AMD, bit *set* means the page is encrypted\n\t * - for AMD with vTOM and for Intel, *clear* means encrypted\n\t */\n\tswitch (cc_vendor) {\n\tcase CC_VENDOR_AMD:\n\t\tif (sev_status \u0026 MSR_AMD64_SNP_VTOM)\n\t\t\treturn val \u0026 ~cc_mask;\n\t\telse\n\t\t\treturn val | cc_mask;\n\tcase CC_VENDOR_INTEL:\n\t\treturn val \u0026 ~cc_mask;\n\tdefault:\n\t\treturn val;\n\t}\n}\n```\n\nTo enable SME, the mask has to be set according to the bit position in the page\ntable entry, returned by CPUID. In `sme_enable`, line 528, you can see\n\n```c /*\n\t/*\n\t * Check for the SME/SEV feature:\n\t *   CPUID Fn8000_001F[EAX]\n\t *   - Bit 0 - Secure Memory Encryption support\n\t *   - Bit 1 - Secure Encrypted Virtualization support\n\t *   CPUID Fn8000_001F[EBX]\n\t *   - Bits 5:0 - Pagetable bit position used to indicate encryption\n\t */\n\teax = 0x8000001f;\n\tecx = 0;\n\tnative_cpuid(\u0026eax, \u0026ebx, \u0026ecx, \u0026edx);\n\t/* Check whether SEV or SME is supported */\n\tif (!(eax \u0026 (AMD_SEV_BIT | AMD_SME_BIT)))\n\t\treturn;\n\n\tme_mask = 1UL \u003c\u003c (ebx \u0026 0x3f);\n```\n\nThe bit operation clears the other bits in ebx (`ebx \u0026 0b11111`), then shift the\nbit right according to the value in bits 5:0. For example, if bits 5:0 in ebx is\n0b000011, it means the encryption bit (c-bit) is bit 3 of the page table entry,\nand the mask should be 0b0...01000.\n","wordCount":1478,"tags":["os","linux","sev","virtualization"],"metadata":{},"created":"2023-08-21T08:35:46.084633189Z","modified":"2024-07-28T07:41:51.196606077Z","checksum":"a2aac6038319174665aa9a51a7ffa72ed68774dc45c8e036f26784a5c3b08bbf"},
    {"filename":"6ulf2s6p.md","filenameStem":"6ulf2s6p","path":"6ulf2s6p.md","absPath":"/home/khadd/mynotes/6ulf2s6p.md","title":"Installing custom lspconfig server","link":"[[6ulf2s6p]]","lead":"#nvim #lsp","body":"#nvim #lsp\n\n```lua\nlocal lspconfig = require(\"lspconfig\")\nlocal configs = require(\"lspconfig.configs\")\n\nif not configs.bibli_ls then\n  configs.bibli_ls = {\n    default_config = {\n      cmd = { \"bibli_ls\" },\n      filetypes = { \"markdown\" },\n      root_dir = lspconfig.util.root_pattern(\".git\"),\n    },\n  }\nend\nlspconfig.bibli_ls.setup({})\n```","snippets":["#nvim #lsp"],"rawContent":"# Installing custom lspconfig server\n\n#nvim #lsp\n\n```lua\nlocal lspconfig = require(\"lspconfig\")\nlocal configs = require(\"lspconfig.configs\")\n\nif not configs.bibli_ls then\n  configs.bibli_ls = {\n    default_config = {\n      cmd = { \"bibli_ls\" },\n      filetypes = { \"markdown\" },\n      root_dir = lspconfig.util.root_pattern(\".git\"),\n    },\n  }\nend\nlspconfig.bibli_ls.setup({})\n```\n","wordCount":44,"tags":["nvim","lsp"],"metadata":{},"created":"2024-06-21T10:53:18.296545942Z","modified":"2024-07-12T10:36:21.603785964Z","checksum":"fe6a07f5d33646aec500672197c7a413ef3cd264f4f75a3128e1c7b45b93f4f8"},
    {"filename":"jejw1spb.md","filenameStem":"jejw1spb","path":"jejw1spb.md","absPath":"/home/khadd/mynotes/jejw1spb.md","title":"Instruction punning","link":"[[jejw1spb]]","lead":"#binary-analysis","body":"#binary-analysis\n\nInstruction punning is used in binary rewrite\n[@duck2020binary,@chamith2017instruction] extends the support for `jmp`-based\nprobes to instruction smaller than 5 bytes. The problem is that any bytes next\nto the target rewrite may be a valid jump target.\n\n```asm\n   jmp probe (5B)\ne9 xx xx xx xx xx                Target probe (only 3B)\n                                          │\n48 89 03 \tmov %rax (%rbx) ◄─────────┘\n48 83 c0 20\tadd $32 %rax  ◄───────────  Some instructions may jump here\n\n```\n\nPunning reuse the bytes of the following instructions as the offset.\n\n```asm\n\n[48 89 03]  [48 83 c0 20]\n            ┌──────────────── Still valid if some instructions jump here.\n            ▼\n[e9 XX XX  [48 83]]c0 20]\n              │\n              └───► 2 bytes are \"punned\"\n```\n\nNow, this requires that the jump target to falls in the range of (little endian)\nthe punned byte `83 48 XX XX`\n\n## Adding flexibility with trapping\n\nAnother strategy is to additionally insert trapping opcode (`int3` and illegal\ninstructions) to flexibly changes the target for `jmp` target\n[@chamith2017instruction].\n\n```asm\n            ┌────────────── int3 trap if some instruction jump here so its fine\n            │  ┌─────────── Now we can repurpose this byte for extra flexiblity\n            ▼  ▼\n[e9 XX XX  [cc XX]]c0 20]\n              │\n              └───► 2 bytes are \"punned\"\n\n```\n\nNow, if the replaced instruction happens to be frequent target of control flow,\nthe amount of traps will destroy any performance gain from punning, so this\napproach need some kind of control flow recovery [@duck2020binary] that has its\nown limitations [[4yeegysq]]\n\n## Playing with instruction encodings\n\nInstead of relying on traps which might create overheads, e9patch\n[@duck2020binary] uses several strategies, including:\n\n### Padding\n\nPad the `jmp` instruction with dummy bytes to change the relative offset\nencoding.\n\n```\nNow the encoded offset is c8 83 48 XX  (from 83 48 XX XX)\n         │\n         ▼\n[48 [e9 XX ]  [48 83 c8]]\n```\n\n### Evicting instructions\n\nThis technique rewrite neighboring instructions so that the byte encoding\nchanges, leading to more potential jump targets.\n\n```\n    ┌─────────── Now encoded address is XX e9 XX XX\n    │         ┌─────── Rewritten (evicted) with a trampoline\n    ▼         ▼\n[e9 XX XX ]  [e9 XX] XX]]\n```\n\nThe rewriter can insert short jump to another location, so that it can evict an\ninstruction at another address. This technique, though incur more performance,\nleads to reliability because most of the time there is a good evicting target\nwithin the range of the short jump\n\n```asm\n\n            Rewritten to a short jump\n    ┌──────────────────────────────┐┌─────────► Jump to the actual trampoline\n    │                              ▼│\n[eb 07 03]   .........     [e9 YY [e9] 83 7b]\n                            ▲\n                            └───────────── Evicted\n```","snippets":["#binary-analysis"],"rawContent":"# Instruction punning\n\n#binary-analysis\n\nInstruction punning is used in binary rewrite\n[@duck2020binary,@chamith2017instruction] extends the support for `jmp`-based\nprobes to instruction smaller than 5 bytes. The problem is that any bytes next\nto the target rewrite may be a valid jump target.\n\n```asm\n   jmp probe (5B)\ne9 xx xx xx xx xx                Target probe (only 3B)\n                                          │\n48 89 03 \tmov %rax (%rbx) ◄─────────┘\n48 83 c0 20\tadd $32 %rax  ◄───────────  Some instructions may jump here\n\n```\n\nPunning reuse the bytes of the following instructions as the offset.\n\n```asm\n\n[48 89 03]  [48 83 c0 20]\n            ┌──────────────── Still valid if some instructions jump here.\n            ▼\n[e9 XX XX  [48 83]]c0 20]\n              │\n              └───► 2 bytes are \"punned\"\n```\n\nNow, this requires that the jump target to falls in the range of (little endian)\nthe punned byte `83 48 XX XX`\n\n## Adding flexibility with trapping\n\nAnother strategy is to additionally insert trapping opcode (`int3` and illegal\ninstructions) to flexibly changes the target for `jmp` target\n[@chamith2017instruction].\n\n```asm\n            ┌────────────── int3 trap if some instruction jump here so its fine\n            │  ┌─────────── Now we can repurpose this byte for extra flexiblity\n            ▼  ▼\n[e9 XX XX  [cc XX]]c0 20]\n              │\n              └───► 2 bytes are \"punned\"\n\n```\n\nNow, if the replaced instruction happens to be frequent target of control flow,\nthe amount of traps will destroy any performance gain from punning, so this\napproach need some kind of control flow recovery [@duck2020binary] that has its\nown limitations [[4yeegysq]]\n\n## Playing with instruction encodings\n\nInstead of relying on traps which might create overheads, e9patch\n[@duck2020binary] uses several strategies, including:\n\n### Padding\n\nPad the `jmp` instruction with dummy bytes to change the relative offset\nencoding.\n\n```\nNow the encoded offset is c8 83 48 XX  (from 83 48 XX XX)\n         │\n         ▼\n[48 [e9 XX ]  [48 83 c8]]\n```\n\n### Evicting instructions\n\nThis technique rewrite neighboring instructions so that the byte encoding\nchanges, leading to more potential jump targets.\n\n```\n    ┌─────────── Now encoded address is XX e9 XX XX\n    │         ┌─────── Rewritten (evicted) with a trampoline\n    ▼         ▼\n[e9 XX XX ]  [e9 XX] XX]]\n```\n\nThe rewriter can insert short jump to another location, so that it can evict an\ninstruction at another address. This technique, though incur more performance,\nleads to reliability because most of the time there is a good evicting target\nwithin the range of the short jump\n\n```asm\n\n            Rewritten to a short jump\n    ┌──────────────────────────────┐┌─────────► Jump to the actual trampoline\n    │                              ▼│\n[eb 07 03]   .........     [e9 YY [e9] 83 7b]\n                            ▲\n                            └───────────── Evicted\n```\n","wordCount":425,"tags":["binary-analysis"],"metadata":{},"created":"2024-07-12T05:41:30.497331672Z","modified":"2024-07-22T02:00:09.490851067Z","checksum":"7698ca604e00ab87f5013cdb73787a381e25270caf7e97521a2836bd68da57c5"},
    {"filename":"nxznwhum.md","filenameStem":"nxznwhum","path":"nxznwhum.md","absPath":"/home/khadd/mynotes/nxznwhum.md","title":"Instrumenting function prologue and epilogue with LLVM","link":"[[nxznwhum]]","lead":"#compiler #llvm #ir","body":"#compiler #llvm #ir\n\nInstrumenting functions' prologue and epilogue is not as straight forward as it\nseem.\n\nTo instrument every function's prologue:\n\n```cpp\n  auto FirstI = \u0026*F.getEntryBlock().begin();\n  IRBuilder\u003c\u003e ProIRB(FirstI);\n  CallInst *Prologue = ProIRB.CreateCall(CapacPrologue);\n\n  DILocation *Loc =\n      DILocation::get(F.getParent()-\u003egetContext(), 0, 0, F.getSubprogram());\n  Prologue-\u003esetDebugLoc(Loc);\n```\n\nNote that The debug location is needed because of this error:\n\n\u003e inlinable function call in a function with debug info must have a !dbg\n\u003e location\n\nThe epilogue must cover all exit points of the function. This can be done by\nscanning for return instructions in the basic blocks.\n\n```cpp\n\n   // Collect possible exit points\n   std::vector\u003cBasicBlock *\u003e ReturningBlocks;\n   for (BasicBlock \u0026I : F)\n     if (isa\u003cReturnInst\u003e(I.getTerminator()))\n       ReturningBlocks.push_back(\u0026I);\n\n   // Insert epilogue to all blocks\n   if (ReturningBlocks.size() != 0) {\n     for (BasicBlock *BB : ReturningBlocks) {\n       IRBuilder\u003c\u003e EpiIRB(BB-\u003egetTerminator());\n       CallInst *Epi = EpiIRB.CreateCall(CapacEpilogue);\n       Epi-\u003esetDebugLoc(EpiIRB.getCurrentDebugLocation());\n     }\n   }\n```","snippets":["#compiler #llvm #ir"],"rawContent":"# Instrumenting function prologue and epilogue with LLVM\n\n#compiler #llvm #ir\n\nInstrumenting functions' prologue and epilogue is not as straight forward as it\nseem.\n\nTo instrument every function's prologue:\n\n```cpp\n  auto FirstI = \u0026*F.getEntryBlock().begin();\n  IRBuilder\u003c\u003e ProIRB(FirstI);\n  CallInst *Prologue = ProIRB.CreateCall(CapacPrologue);\n\n  DILocation *Loc =\n      DILocation::get(F.getParent()-\u003egetContext(), 0, 0, F.getSubprogram());\n  Prologue-\u003esetDebugLoc(Loc);\n```\n\nNote that The debug location is needed because of this error:\n\n\u003e inlinable function call in a function with debug info must have a !dbg\n\u003e location\n\nThe epilogue must cover all exit points of the function. This can be done by\nscanning for return instructions in the basic blocks.\n\n```cpp\n\n   // Collect possible exit points\n   std::vector\u003cBasicBlock *\u003e ReturningBlocks;\n   for (BasicBlock \u0026I : F)\n     if (isa\u003cReturnInst\u003e(I.getTerminator()))\n       ReturningBlocks.push_back(\u0026I);\n\n   // Insert epilogue to all blocks\n   if (ReturningBlocks.size() != 0) {\n     for (BasicBlock *BB : ReturningBlocks) {\n       IRBuilder\u003c\u003e EpiIRB(BB-\u003egetTerminator());\n       CallInst *Epi = EpiIRB.CreateCall(CapacEpilogue);\n       Epi-\u003esetDebugLoc(EpiIRB.getCurrentDebugLocation());\n     }\n   }\n```\n","wordCount":143,"tags":["llvm","ir","compiler"],"metadata":{},"created":"2023-05-23T08:56:35.452616966Z","modified":"2024-06-20T07:34:28.441076726Z","checksum":"f085c8aa04315a57559f6c0c4c9eadaaeea667379127adcf80a0a44d86046aff"},
    {"filename":"ya2sfv7q.md","filenameStem":"ya2sfv7q","path":"ya2sfv7q.md","absPath":"/home/khadd/mynotes/ya2sfv7q.md","title":"Integrity Attacks on SEV","link":"[[ya2sfv7q]]","lead":"Previous versions of AMD SEV lacks integrity protection for both (1) memory\nencryption and (2) nested table mappings, which leads to several integrity\nattacks.","body":"Previous versions of AMD SEV lacks integrity protection for both (1) memory\nencryption and (2) nested table mappings, which leads to several integrity\nattacks.\n\n- No integrity protection for memory allow the Hypervisor to inject arbitrary\n  encrypted payload and rely on an decryption oracle (a gadget that copy memory\n  from private to shared) to decrypt memory [@wilke2020sevurity]. SEV-SNP\n  disallow the hypervisor write access to private memory pages with RMP checks.\n- Non page table mapping enables the attacker to change the page table mapping\n  to point to an injected code page [@morbitzer2021severity]. SEV-SNP verify the\n  integrity of page table mappings.","snippets":["Previous versions of AMD SEV lacks integrity protection for both (1) memory\nencryption and (2) nested table mappings, which leads to several integrity\nattacks."],"rawContent":"# Integrity Attacks on SEV\n\nPrevious versions of AMD SEV lacks integrity protection for both (1) memory\nencryption and (2) nested table mappings, which leads to several integrity\nattacks.\n\n- No integrity protection for memory allow the Hypervisor to inject arbitrary\n  encrypted payload and rely on an decryption oracle (a gadget that copy memory\n  from private to shared) to decrypt memory [@wilke2020sevurity]. SEV-SNP\n  disallow the hypervisor write access to private memory pages with RMP checks.\n- Non page table mapping enables the attacker to change the page table mapping\n  to point to an injected code page [@morbitzer2021severity]. SEV-SNP verify the\n  integrity of page table mappings.\n","wordCount":105,"tags":[],"metadata":{},"created":"2024-12-09T09:19:40.891226448Z","modified":"2024-12-09T09:27:28.670341467Z","checksum":"21b646f009e82c7ad93cd0606f55e7af699df85109f0e77d6962e843e72e1d3c"},
    {"filename":"taztx2mo.md","filenameStem":"taztx2mo","path":"taztx2mo.md","absPath":"/home/khadd/mynotes/taztx2mo.md","title":"Intel SGX","link":"[[taztx2mo]]","lead":"#sgx","body":"#sgx\n\n# Execution flow\n\nAn enclave is entered with the instruction `EENTER`\n(\u003chttps://www.felixcloutier.com/x86/eenter\u003e), which launches the enclave at a\npredefined and attested entry point. CENTER is invoked with `ENCLU`, with the\nindex for it contained in the eax register (i.e., `ENCLU[EENTER]`).\n\n## `EENTER`\n\n`EENTER` takes RBX and RCX as an argument. RBX contains the memory region for\nthe thread control block (TCS) of the enclave to be executed. RCX contains the\naddress of the Asynchronous exit pointer (AEP), which is a handler that will be\nexecuted when the host serves faults from the enclave through asynchronous\nenclave exit. `EENTER` flushes the TLB, then put the processor into the enclave\nmode. Note that more checks are also performed, such as disabling Precise Event\nBased Sampling\n([SGX Internals](https://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html)).\n\n## EAX \u0026 `ERESUME`\n\nOn a fault, an Asynchronous enclave exit (AEX) happens, which (1) saves the\ncurrent context into a region called the state save area (SSA), pointed to by\nthe OS, fill the context (register content) with dummy ones, and invoke the OS\nexception handler.\n\n`ERESUME` restores the context saved by AEX and resumes the enclave's execution.\nAEX and `ERESUME` mechanisms are transparent to the enclave\n\nThe SSA is managed as a stack: the TCS contains the counter for the current SSA,\nand the counter is increased for each AEX. The size of an SSA is in the\n`SSAFRAMESIZE` inside the enclave's SECS. `ERESUME` decreases the counter to pop\nthe stack of SSAs. The SSA stack allows for the reentering (`EENTER`) of the\nenclave during an AEX while preserving the SSA for the previous AEX. For\ninstance, calling `EENTER` to query an enclave's information used to serve AEX?\n\n# Memory management\n\n## EPCM\n\nThe processor uses an Enclave page cache (EPC) map (EPCM) to kep track of the\nstatus of EPC pages. The EPCM contains an entry for each EPC page to keep track\nof the owner enclave and the allocation status:\n\n| field       | bit | description                 |\n| ----------- | --- | --------------------------- |\n| VALID       | 1   | 0 for unallocated EPC pages |\n| PT          | 8   | Page type                   |\n| ENCLAVESECS |     | identify the owner enclave  |\n\nWhen the processor is in enclave mode, after the PTE is fetched and PTE\npermissions are checked, the MMU is modified to look up the EPCM. Hence, the\nenclave is protected from the OS mapping pages incorrectly: mapping another\nenclave's page, or mapping two pages to the same virtual address.\n\n## Demand paging\n\nSGX has two isntructions to support demand-paging:\n\n- `EWB` evicts a page from the EPC memory and stores it in normal memory. This\n  encrypts the page and also integrity-protect it. It takes `PAGEINFO` in RBX,\n  EPC page address in `RCX` and the VA of normal memory in `RDX`.\n- `ELDU` restores the encrypted page into EPC memory.\n\n## SGXv1\n\nIn SGXv1, the EPCM is updated by SGX instructions `EADD`, which adds a page to\nan enclave's initial memory. This allocation is static and can be attested. It\nonly works if the VALID bit is not set.\n\n`EADD` takes a `PAGEINFO` structure as the parameter, which contains\n\n1. The virtual address\n2. The source non-EPC page\n3. The virtual address of the SECS of the enclave\n4. The virtual address of the Security information (SECINFO) of the page\n\n### SGXv2 extensions\n\nSGXv2 included instructions to dynamically allocate/deallocate EPC pages at\nruntime. The OS uses the following instructions to manage EPC pages.\n\n- `EAUG` add a page. It takes `SECINFO` and the virtual address of the EPC page\n  as the argument.\n- `EMODT` deallocate a page\n- `EMODPR` changes the permissions\n\nThe enclave can then use additional instructions to confirm the allocation\nrequests by the OS: `EACCEPT` and `EACCEPTCOPY`.\n\n- `EACCEPT` [felixcloutier](https://www.felixcloutier.com/x86/eaccept) takes the\n  same arguments as `EAUG`.\n\n# Related\n\n- [[fvom56lw]]\n- [[1yhmh234]]\n\n# References\n\n- [Quarks lab SGX Internals](https://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html)\n- [SGX 101](https://sgx101.gitbook.io/sgx101/)","snippets":["#sgx"],"rawContent":"# Intel SGX\n\n#sgx\n\n# Execution flow\n\nAn enclave is entered with the instruction `EENTER`\n(\u003chttps://www.felixcloutier.com/x86/eenter\u003e), which launches the enclave at a\npredefined and attested entry point. CENTER is invoked with `ENCLU`, with the\nindex for it contained in the eax register (i.e., `ENCLU[EENTER]`).\n\n## `EENTER`\n\n`EENTER` takes RBX and RCX as an argument. RBX contains the memory region for\nthe thread control block (TCS) of the enclave to be executed. RCX contains the\naddress of the Asynchronous exit pointer (AEP), which is a handler that will be\nexecuted when the host serves faults from the enclave through asynchronous\nenclave exit. `EENTER` flushes the TLB, then put the processor into the enclave\nmode. Note that more checks are also performed, such as disabling Precise Event\nBased Sampling\n([SGX Internals](https://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html)).\n\n## EAX \u0026 `ERESUME`\n\nOn a fault, an Asynchronous enclave exit (AEX) happens, which (1) saves the\ncurrent context into a region called the state save area (SSA), pointed to by\nthe OS, fill the context (register content) with dummy ones, and invoke the OS\nexception handler.\n\n`ERESUME` restores the context saved by AEX and resumes the enclave's execution.\nAEX and `ERESUME` mechanisms are transparent to the enclave\n\nThe SSA is managed as a stack: the TCS contains the counter for the current SSA,\nand the counter is increased for each AEX. The size of an SSA is in the\n`SSAFRAMESIZE` inside the enclave's SECS. `ERESUME` decreases the counter to pop\nthe stack of SSAs. The SSA stack allows for the reentering (`EENTER`) of the\nenclave during an AEX while preserving the SSA for the previous AEX. For\ninstance, calling `EENTER` to query an enclave's information used to serve AEX?\n\n# Memory management\n\n## EPCM\n\nThe processor uses an Enclave page cache (EPC) map (EPCM) to kep track of the\nstatus of EPC pages. The EPCM contains an entry for each EPC page to keep track\nof the owner enclave and the allocation status:\n\n| field       | bit | description                 |\n| ----------- | --- | --------------------------- |\n| VALID       | 1   | 0 for unallocated EPC pages |\n| PT          | 8   | Page type                   |\n| ENCLAVESECS |     | identify the owner enclave  |\n\nWhen the processor is in enclave mode, after the PTE is fetched and PTE\npermissions are checked, the MMU is modified to look up the EPCM. Hence, the\nenclave is protected from the OS mapping pages incorrectly: mapping another\nenclave's page, or mapping two pages to the same virtual address.\n\n## Demand paging\n\nSGX has two isntructions to support demand-paging:\n\n- `EWB` evicts a page from the EPC memory and stores it in normal memory. This\n  encrypts the page and also integrity-protect it. It takes `PAGEINFO` in RBX,\n  EPC page address in `RCX` and the VA of normal memory in `RDX`.\n- `ELDU` restores the encrypted page into EPC memory.\n\n## SGXv1\n\nIn SGXv1, the EPCM is updated by SGX instructions `EADD`, which adds a page to\nan enclave's initial memory. This allocation is static and can be attested. It\nonly works if the VALID bit is not set.\n\n`EADD` takes a `PAGEINFO` structure as the parameter, which contains\n\n1. The virtual address\n2. The source non-EPC page\n3. The virtual address of the SECS of the enclave\n4. The virtual address of the Security information (SECINFO) of the page\n\n### SGXv2 extensions\n\nSGXv2 included instructions to dynamically allocate/deallocate EPC pages at\nruntime. The OS uses the following instructions to manage EPC pages.\n\n- `EAUG` add a page. It takes `SECINFO` and the virtual address of the EPC page\n  as the argument.\n- `EMODT` deallocate a page\n- `EMODPR` changes the permissions\n\nThe enclave can then use additional instructions to confirm the allocation\nrequests by the OS: `EACCEPT` and `EACCEPTCOPY`.\n\n- `EACCEPT` [felixcloutier](https://www.felixcloutier.com/x86/eaccept) takes the\n  same arguments as `EAUG`.\n\n# Related\n\n- [[fvom56lw]]\n- [[1yhmh234]]\n\n# References\n\n- [Quarks lab SGX Internals](https://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html)\n- [SGX 101](https://sgx101.gitbook.io/sgx101/)\n","wordCount":650,"tags":["sgx"],"metadata":{},"created":"2023-08-30T07:26:51.72985824Z","modified":"2024-06-22T14:36:52.630928495Z","checksum":"57b45af8a1b988b93d6c3e68ff9bce5cb1bca0da2c7985aef5a57ea2b789b676"},
    {"filename":"dx7vz8d5.md","filenameStem":"dx7vz8d5","path":"dx7vz8d5.md","absPath":"/home/khadd/mynotes/dx7vz8d5.md","title":"Intel Transactional Synchronization Extensions (TSX)","link":"[[dx7vz8d5]]","lead":"#intel #tsx","body":"#intel #tsx\n\nTSX simplifies concurrent programming with ISA support for transactional memory\n([[cosmdjej]]). It introduce two modes of execution, hardware lock elision\n(HLE), which\n\n## Restricted Transactional Memory (RTM)\n\nRTM adds 4 instructions: `XBEGIN`, `XEND`, `XABORT` and `XTEST` A thread can\ninitiate transaction with the `XBEGIN` instruction, and terminate the\ntransaction with `XEND`.\n\n```c\nif ((status = _xbegin()) == XBEGIN_STARTED)\n  // Perform transaction\n  // ...\n  // commit to memory\n  _xend();\nelse {\n  // handle transaction error\n}\n```\n\nIn the above example, a transaction begin by calling `_xbegin()`. If it can\nhappen, the code inside the `if` block is executed. During the execution, if\nconflicts or exceptions occur, the transaction is rolled back to `_xbegin()`,\nand the program execute the `else` block, which handle the error.\n\nTSX uses the L1 cache as the intermediate buffer for transaction. Hence, the\nexisting cache coherence protocols can be used to detect conflicts (e.g., memory\nis modified by two transactions) without introducing new hardware logics.\n\n### Faults during transactions\n\nA transaction is also aborted when an interrupt occurs. For synchronous\nexceptions (e.g., page faults), TSX _suppress_ the transaction and does not\ndeliver it to the OS. For asynchronous exceptions (e.g., timer/IO interrupts),\nthe exception is delivered to the OS _after_ the transaction is rolled back and\naborted, since blocking it would interfere with OS scheduling.\n\nHowever, TSX does not allows the program know which type of exception happened.\nHence, page fault, divided-by-zero, conflicts, ..., are treated equally.\n\n## Use for security\n\nSince page faults are suppressed by TSX, the OS cannot know whether page faults\noccurs or not. This property has been used by defenses against control-channel\nattacks that use the page table on SGX [@shih2017tsgx]. The enclave can stop\nexecution, when ever it encounters a page fault. See [[fvom56lw]].","snippets":["#intel #tsx"],"rawContent":"# Intel Transactional Synchronization Extensions (TSX)\n\n#intel #tsx\n\nTSX simplifies concurrent programming with ISA support for transactional memory\n([[cosmdjej]]). It introduce two modes of execution, hardware lock elision\n(HLE), which\n\n## Restricted Transactional Memory (RTM)\n\nRTM adds 4 instructions: `XBEGIN`, `XEND`, `XABORT` and `XTEST` A thread can\ninitiate transaction with the `XBEGIN` instruction, and terminate the\ntransaction with `XEND`.\n\n```c\nif ((status = _xbegin()) == XBEGIN_STARTED)\n  // Perform transaction\n  // ...\n  // commit to memory\n  _xend();\nelse {\n  // handle transaction error\n}\n```\n\nIn the above example, a transaction begin by calling `_xbegin()`. If it can\nhappen, the code inside the `if` block is executed. During the execution, if\nconflicts or exceptions occur, the transaction is rolled back to `_xbegin()`,\nand the program execute the `else` block, which handle the error.\n\nTSX uses the L1 cache as the intermediate buffer for transaction. Hence, the\nexisting cache coherence protocols can be used to detect conflicts (e.g., memory\nis modified by two transactions) without introducing new hardware logics.\n\n### Faults during transactions\n\nA transaction is also aborted when an interrupt occurs. For synchronous\nexceptions (e.g., page faults), TSX _suppress_ the transaction and does not\ndeliver it to the OS. For asynchronous exceptions (e.g., timer/IO interrupts),\nthe exception is delivered to the OS _after_ the transaction is rolled back and\naborted, since blocking it would interfere with OS scheduling.\n\nHowever, TSX does not allows the program know which type of exception happened.\nHence, page fault, divided-by-zero, conflicts, ..., are treated equally.\n\n## Use for security\n\nSince page faults are suppressed by TSX, the OS cannot know whether page faults\noccurs or not. This property has been used by defenses against control-channel\nattacks that use the page table on SGX [@shih2017tsgx]. The enclave can stop\nexecution, when ever it encounters a page fault. See [[fvom56lw]].\n","wordCount":302,"tags":["intel","tsx"],"metadata":{},"created":"2023-06-19T03:04:24.8909816Z","modified":"2024-07-01T03:53:43.88769954Z","checksum":"f1559e9b1022e9b6aff99a60c1104644a85d56d2786fe6139f43f200dfa93a34"},
    {"filename":"rternftl.md","filenameStem":"rternftl","path":"rternftl.md","absPath":"/home/khadd/mynotes/rternftl.md","title":"Interface classification and partitioning","link":"[[rternftl]]","lead":"#security #interface","body":"#security #interface\n\nWhen trying to harden an interface that were not built with security in mind,\nwhile not wanting to limit the set of features, a useful course of action is to\nclassify the interface with security label, and enforce further policies based\non these labels.\n\nOne guideline is to determine (1) the type of resources that an API access, and\n(2) the subject that may be allowed access this resource. Confidential threat\nmodels introduce complexity to this process. The host is in charge of resource\nmanagement but cannot access the resource. The protected application owner is\nallowed to access the resource, but cannot be given too much access for resource\nmanagement.\n\n## Example: Splitting interfaces for configurable trust\n\nProxOS [@ta-min2006splitting] split the application-OS interfaces into trusted\nand untrusted system calls. Trusted system calls are routed to a trusted OS in\nthe private VM, while untrusted OS system calls are routed to the untrusted OS.\n\nThis allows for \"configurable trust\" in the app-OS interface\n[@ta-min2006splitting]. Useful in cases where the trusted app must communicate\nwith the other apps through shared OS facilities (socket, pipes). This shared OS\nis subjected to attacks from the untrusted application, while the trusted OS is\nsafely isolated.\n\n## Example: Confidential containers\n\nConfidential container technologies is not built with confidential computing\nsecurity model in mind, but trying to reuse the existing deployment model,\nleading to a mismatch in threat model [@valdez2024crossing].\n\n[@valdez2024crossing] apply the labels `Host-Exclusive`, `Owner-Exclusive`,\n`Shared`, `Sanitized`, `Switch`, `Not Supported` to the API endpoints of in-CVM\nkata container management (kata-agent). The purpose is to cleanly separate the\nresponsibilities between the Host system (resource allocation and management)\nand owner (container management) and avoid common attack vectors such as\ninformation leakage.\n\nThe `Sanitized`, `Switch`, `Not Supported` labels makes the partitioning process\nexpressive.\n\n- `Sanitized` marks that the API input/output must be _sanitized_.\n- `Switch` makes the API _state-aware_: for certain period it is accessible by\n  the Host\n- For certain cases where the security model cannot be applied, `Not Support` is\n  reasonable.","snippets":["#security #interface"],"rawContent":"# Interface classification and partitioning\n\n#security #interface\n\nWhen trying to harden an interface that were not built with security in mind,\nwhile not wanting to limit the set of features, a useful course of action is to\nclassify the interface with security label, and enforce further policies based\non these labels.\n\nOne guideline is to determine (1) the type of resources that an API access, and\n(2) the subject that may be allowed access this resource. Confidential threat\nmodels introduce complexity to this process. The host is in charge of resource\nmanagement but cannot access the resource. The protected application owner is\nallowed to access the resource, but cannot be given too much access for resource\nmanagement.\n\n## Example: Splitting interfaces for configurable trust\n\nProxOS [@ta-min2006splitting] split the application-OS interfaces into trusted\nand untrusted system calls. Trusted system calls are routed to a trusted OS in\nthe private VM, while untrusted OS system calls are routed to the untrusted OS.\n\nThis allows for \"configurable trust\" in the app-OS interface\n[@ta-min2006splitting]. Useful in cases where the trusted app must communicate\nwith the other apps through shared OS facilities (socket, pipes). This shared OS\nis subjected to attacks from the untrusted application, while the trusted OS is\nsafely isolated.\n\n## Example: Confidential containers\n\nConfidential container technologies is not built with confidential computing\nsecurity model in mind, but trying to reuse the existing deployment model,\nleading to a mismatch in threat model [@valdez2024crossing].\n\n[@valdez2024crossing] apply the labels `Host-Exclusive`, `Owner-Exclusive`,\n`Shared`, `Sanitized`, `Switch`, `Not Supported` to the API endpoints of in-CVM\nkata container management (kata-agent). The purpose is to cleanly separate the\nresponsibilities between the Host system (resource allocation and management)\nand owner (container management) and avoid common attack vectors such as\ninformation leakage.\n\nThe `Sanitized`, `Switch`, `Not Supported` labels makes the partitioning process\nexpressive.\n\n- `Sanitized` marks that the API input/output must be _sanitized_.\n- `Switch` makes the API _state-aware_: for certain period it is accessible by\n  the Host\n- For certain cases where the security model cannot be applied, `Not Support` is\n  reasonable.\n","wordCount":341,"tags":["security","interface"],"metadata":{},"created":"2024-12-12T04:32:26.428218951Z","modified":"2024-12-17T05:20:12.597021975Z","checksum":"8ac64b848a28a0d388ed2f8eb56ff97991a237f91e4d417f97c1cede99e2b903"},
    {"filename":"qti6u06p.md","filenameStem":"qti6u06p","path":"qti6u06p.md","absPath":"/home/khadd/mynotes/qti6u06p.md","title":"Interface design for distrust","link":"[[qti6u06p]]","lead":"#compartmentalization","body":"#compartmentalization\n\n[@lefeuvre2022assessing] proposed 8 guidelines for designing safe interface that\nhelps reduce the interface vulnerabilities.\n\n## 1. Clearly segregate resources\n\nThis means that each component must be responsible for allocating and freeing\ntheir own resources. In other words, they should _not_ expose a malloc-like\ninterface to other compartments. Doing so, attackers from a compartment can\nexploit the allocator (e.g., heap feng shui), or trigger arbitrary\nuse-after-free (if the allocated data is used at both side).\n\n## 2. Always copy cross boundary objects\n\nIn other words, never let two compartments concurrently modify data. Doing so\nleads to TOCTOU issues, and the need of cross-compartment synchronization.\n\n## 3. Simplifying API-crossing objects\n\nAPIs should not contains private states of the compartment, since they can\neasily corrupted.\n\nMoreover, private states are very hard to check for correctness, especially\npointer data.\n\nMaintaining immutability of those state is also a hard problem.\n\n## 4. Trusted-components allocates\n\nThe trusted component must allocates memory.\n\nThis guideline is to avoid validating may-corrupted data from other components.\nEspecially, for strings, since the trusted component allocate, it knows the size\nof the buffer, so checking NULL-termination is not needed.\n\nIt is not sure if it is applicable to other data except from String. A more\ngeneralized version is that the trusted component must allocate memory where the\nsize is unknown.\n\n## 5. Trusted interface functions must be thread-safe\n\nThis is to avoid temporal attacks.\n\n## 6. Ordering requirements\n\nInterface must enforce ordering requirements if possible.\n\n## 7. No sharing of unintialized data\n\nThis is to avoid leaking of private data in uninitalized memory.\n\n## 8. Check for CIV ASAP\n\nSafety checks should be performed as soon as the untrusted data is received.\nThis is because it is very hard to ensure the safety once the data is propagated\nthroughout the program, which leads to duplicated checks.\n\nMoreover, it prevent untrusted data from flowing to other compartments.","snippets":["#compartmentalization"],"rawContent":"# Interface design for distrust\n\n#compartmentalization\n\n[@lefeuvre2022assessing] proposed 8 guidelines for designing safe interface that\nhelps reduce the interface vulnerabilities.\n\n## 1. Clearly segregate resources\n\nThis means that each component must be responsible for allocating and freeing\ntheir own resources. In other words, they should _not_ expose a malloc-like\ninterface to other compartments. Doing so, attackers from a compartment can\nexploit the allocator (e.g., heap feng shui), or trigger arbitrary\nuse-after-free (if the allocated data is used at both side).\n\n## 2. Always copy cross boundary objects\n\nIn other words, never let two compartments concurrently modify data. Doing so\nleads to TOCTOU issues, and the need of cross-compartment synchronization.\n\n## 3. Simplifying API-crossing objects\n\nAPIs should not contains private states of the compartment, since they can\neasily corrupted.\n\nMoreover, private states are very hard to check for correctness, especially\npointer data.\n\nMaintaining immutability of those state is also a hard problem.\n\n## 4. Trusted-components allocates\n\nThe trusted component must allocates memory.\n\nThis guideline is to avoid validating may-corrupted data from other components.\nEspecially, for strings, since the trusted component allocate, it knows the size\nof the buffer, so checking NULL-termination is not needed.\n\nIt is not sure if it is applicable to other data except from String. A more\ngeneralized version is that the trusted component must allocate memory where the\nsize is unknown.\n\n## 5. Trusted interface functions must be thread-safe\n\nThis is to avoid temporal attacks.\n\n## 6. Ordering requirements\n\nInterface must enforce ordering requirements if possible.\n\n## 7. No sharing of unintialized data\n\nThis is to avoid leaking of private data in uninitalized memory.\n\n## 8. Check for CIV ASAP\n\nSafety checks should be performed as soon as the untrusted data is received.\nThis is because it is very hard to ensure the safety once the data is propagated\nthroughout the program, which leads to duplicated checks.\n\nMoreover, it prevent untrusted data from flowing to other compartments.\n","wordCount":320,"tags":["compartmentalization"],"metadata":{},"created":"2023-05-24T04:12:18.744165461Z","modified":"2024-12-12T06:15:32.599582295Z","checksum":"159061b4a53f053f03fc5da389143bbf69fd8e11c8d582ee5addd52085a83ccc"},
    {"filename":"yef2w9yc.md","filenameStem":"yef2w9yc","path":"yef2w9yc.md","absPath":"/home/khadd/mynotes/yef2w9yc.md","title":"Interface security","link":"[[yef2w9yc]]","lead":"Thanks to abstractions, software components exposes _interfaces_ (APIs,\nnotifications, RPCs, queues) to each other to hide the underlying\nimplementations. Each software components are also encouraged to be\nisolated/compartmentalized from each other according to the principle of least\nprivilege.","body":"Thanks to abstractions, software components exposes _interfaces_ (APIs,\nnotifications, RPCs, queues) to each other to hide the underlying\nimplementations. Each software components are also encouraged to be\nisolated/compartmentalized from each other according to the principle of least\nprivilege.\n\nCommunications between isolated components leads to the problem of _interface\nsecurity_, where the interface between the components should not compromise the\nenforced isolation between them. Interface vulnerabilities is a manifestation of\nthe confused deputy problem [@lefeuvre2023assessing] [[y9wu5ut7]].\n\nThus, considerations must be made in designing interfaces for security\n[[qti6u06p]].\n\n## Across the stacks\n\nThe interface problem exists in multiple layers of software where there exist\nisolation boundaries. Here are some examples:\n\n1. The two-way boundaries between (confidential) virtual machines and host\n   [@hetzelt2021analyzing,@li2019exploiting].\n2. Syscall: A malicious process can exploit the system call interface to\n   tricking the kernel into corrupting itself. The kernel can feed data through\n   syscall responses to a protected application (Iago attack\n   [@checkoway2013iago]). Subprocess components can use the syscall to attack\n   each other [@yang2024endokernel,@connor2020pku] other.\n3. Libraries APIs, in-process compartments, whose are not originally designed\n   for compartmentalization [@lefeuvre2023assessing].","snippets":["Thanks to abstractions, software components exposes _interfaces_ (APIs,\nnotifications, RPCs, queues) to each other to hide the underlying\nimplementations. Each software components are also encouraged to be\nisolated/compartmentalized from each other according to the principle of least\nprivilege."],"rawContent":"# Interface security\n\nThanks to abstractions, software components exposes _interfaces_ (APIs,\nnotifications, RPCs, queues) to each other to hide the underlying\nimplementations. Each software components are also encouraged to be\nisolated/compartmentalized from each other according to the principle of least\nprivilege.\n\nCommunications between isolated components leads to the problem of _interface\nsecurity_, where the interface between the components should not compromise the\nenforced isolation between them. Interface vulnerabilities is a manifestation of\nthe confused deputy problem [@lefeuvre2023assessing] [[y9wu5ut7]].\n\nThus, considerations must be made in designing interfaces for security\n[[qti6u06p]].\n\n## Across the stacks\n\nThe interface problem exists in multiple layers of software where there exist\nisolation boundaries. Here are some examples:\n\n1. The two-way boundaries between (confidential) virtual machines and host\n   [@hetzelt2021analyzing,@li2019exploiting].\n2. Syscall: A malicious process can exploit the system call interface to\n   tricking the kernel into corrupting itself. The kernel can feed data through\n   syscall responses to a protected application (Iago attack\n   [@checkoway2013iago]). Subprocess components can use the syscall to attack\n   each other [@yang2024endokernel,@connor2020pku] other.\n3. Libraries APIs, in-process compartments, whose are not originally designed\n   for compartmentalization [@lefeuvre2023assessing].\n","wordCount":180,"tags":[],"metadata":{},"created":"2024-12-03T06:04:01.274307385Z","modified":"2024-12-23T04:42:41.327055126Z","checksum":"ea72397b00774cbb047e95da04fb03ff61860a4106940f8dd0e65c0a9e882749"},
    {"filename":"1k9i1cr3.md","filenameStem":"1k9i1cr3","path":"1k9i1cr3.md","absPath":"/home/khadd/mynotes/1k9i1cr3.md","title":"Interrupt handling in Unikraft (x86)","link":"[[1k9i1cr3]]","lead":"#unikraft","body":"#unikraft\n\nOn x86, `lidt %0` loads the IDT address into IDT register ([osdev]).\n\nIn Unikraft, `traps_table_init` initialize the traps vector table, a.k.a the IDT\n([osdev]). It writes into the `cpu_idt` table, with the corresponding trap\nindex.\n\nThe function pointer to the handler in IDT is set to a stub, named\n`asm_trap_{trapname}` (defined by the macro `ASM_TRAP_SYM`). E.g.,\n`asm_trap_page_fault`.\n\nThe stubs are defined in `cpu_vectors_x86_64.S`. Its implementation stores the\nregister states into `struct __reg` and calls the function with the name\n`do_{trapname}`. Declarations of these `do_*` functions can be found in\n`plat/x86/traps.c`.\n\nThe following macro create implementations for the trap that actually call a\n`_raise_event_{event}` function.\n\n```c\n#define DECLARE_TRAP(name, str, event)                                         \\\n  void do_##name(struct __regs *regs) {                                        \\\n    int rc;                                                                    \\\n    rc = _raise_event_##event(TRAP_##name, regs, 0);                           \\\n    if (unlikely(rc \u003c 0))                                                      \\\n      uk_pr_crit(\"trap handler returned error: %d\\n\", rc);                     \\\n                                                                               \\\n    if (!rc)                                                                   \\\n      do_unhandled_trap(TRAP_##name, str, regs, 0);                            \\\n  }\n```\n\n```c\nDECLARE_TRAP(debug, \"debug\", UKARCH_TRAP_DEBUG)\nDECLARE_TRAP_EC(int3, \"int3\", UKARCH_TRAP_DEBUG)\n```\n\nWhen raise_event is called, it invokes the list of handlers registered for the\nevent. For example, `do_page_fault` invoke the registered handler for\n`UKARCH_TRAP_PAGE_FAULT`. The handler is registered in\n`ukvmem/arch/x86_64/pagefault.c` with `UK_EVENT_HANDLER_PRIO`.\n\nThis design enables an architectural event to be handled in many stages.\n\n## References\n\n- [osdev]: [url](https://wiki.osdev.org/Interrupt_Descriptor_Table)","snippets":["#unikraft"],"rawContent":"# Interrupt handling in Unikraft (x86)\n\n#unikraft\n\nOn x86, `lidt %0` loads the IDT address into IDT register ([osdev]).\n\nIn Unikraft, `traps_table_init` initialize the traps vector table, a.k.a the IDT\n([osdev]). It writes into the `cpu_idt` table, with the corresponding trap\nindex.\n\nThe function pointer to the handler in IDT is set to a stub, named\n`asm_trap_{trapname}` (defined by the macro `ASM_TRAP_SYM`). E.g.,\n`asm_trap_page_fault`.\n\nThe stubs are defined in `cpu_vectors_x86_64.S`. Its implementation stores the\nregister states into `struct __reg` and calls the function with the name\n`do_{trapname}`. Declarations of these `do_*` functions can be found in\n`plat/x86/traps.c`.\n\nThe following macro create implementations for the trap that actually call a\n`_raise_event_{event}` function.\n\n```c\n#define DECLARE_TRAP(name, str, event)                                         \\\n  void do_##name(struct __regs *regs) {                                        \\\n    int rc;                                                                    \\\n    rc = _raise_event_##event(TRAP_##name, regs, 0);                           \\\n    if (unlikely(rc \u003c 0))                                                      \\\n      uk_pr_crit(\"trap handler returned error: %d\\n\", rc);                     \\\n                                                                               \\\n    if (!rc)                                                                   \\\n      do_unhandled_trap(TRAP_##name, str, regs, 0);                            \\\n  }\n```\n\n```c\nDECLARE_TRAP(debug, \"debug\", UKARCH_TRAP_DEBUG)\nDECLARE_TRAP_EC(int3, \"int3\", UKARCH_TRAP_DEBUG)\n```\n\nWhen raise_event is called, it invokes the list of handlers registered for the\nevent. For example, `do_page_fault` invoke the registered handler for\n`UKARCH_TRAP_PAGE_FAULT`. The handler is registered in\n`ukvmem/arch/x86_64/pagefault.c` with `UK_EVENT_HANDLER_PRIO`.\n\nThis design enables an architectural event to be handled in many stages.\n\n## References\n\n- [osdev]: [url](https://wiki.osdev.org/Interrupt_Descriptor_Table)\n","wordCount":211,"tags":["unikraft"],"metadata":{},"created":"2023-07-03T02:43:48.497989255Z","modified":"2024-07-01T03:39:27.727573916Z","checksum":"55227655b5eb3c4cbc720d02e2659505f41fb7a745660a10338b4db4a74c4092"},
    {"filename":"2hnk4l00.md","filenameStem":"2hnk4l00","path":"2hnk4l00.md","absPath":"/home/khadd/mynotes/2hnk4l00.md","title":"Invariants in Rust","link":"[[2hnk4l00]]","lead":"#rust","body":"#rust\n\nRalf Jung described two types of *invariants* in Rust in [this post](https://www.ralfj.de/blog/2018/08/22/two-kinds-of-invariants.html), *safety* and *validity*.\n\n# Safety invariant\nEssentially, *safety invariants* are the invariants of a particualr types, that must be upholded, such that that *no matter what safe code does, it must not cause undefine behaviors*.\n\nOne example of this for any primitive type `T`, the invariant is that the object having the type must be initialized (accesing unintialized data is an undefined behavior). Another example is that reference types must be aligned, non-null, and points to an allocated memory that have no other pointer accesses.\n\n\n## Custom/higher-order safety invariants\nThere can also be *custom* safety invariants -- *higher-order* invariants that are not maintained by the compiler, but must be maintained by the unsafe code @bae2021rudra. For example, *Vec*, defined as \n```rust\npub struct Vec\u003cT\u003e {\n    ptr: Unique\u003cT\u003e, // pointing to the heap-allocated backing store holding all the data\n    cap: usize, // number of elements that fit the backing store\n    len: usize, // number of elements that are actually initialized in the backing store\n}\n```\n, must uphold that `ptr` must points to valid memory size of `cap*sizeof(T)`, . The difference between invariants of Vec and other primitive types is that it is defined by the owner, and that the implementer of the type and the unsafe users must uphold them.\n\nMore specifically, for those types, the Rust compiler only guarantee the corectnesses of the signature. Some higher-order invariants can related to (see @bae2021rudra): \n1. Logical consistency (e.g., respecting total ordering)\n2. Purity (e.g., always returns same value for the same input, have no side effect) (possibly related to [[013pr50f]])\n3. Semantic restrictions (e.g., only write to the arguments because it may contains unintialized memory)\nNOTE: It seems that the first and second types of higher-order invariants cannot trigger undefined behaviors by themself. It is not sure we should consider them safety invariants, even. [There has been discussion among Rust community about this](https://users.rust-lang.org/t/should-i-use-unsafe-merely-to-encourage-users-to-maintain-invariants/27856/4). The conclusion was that they should *not* be unsafe invariants.\n\n### Invariant boundaries of unsafe\nThe unsafe code writter to make sure that they are correct *only at the boundaries* with safe code.\nThis boundary highly depends on the unsafe user. Generally, if an *unsafe* block is well-contained, the safety invariants should be upholded *at the end* of the unsafe scope.\nOn the other hand, for some libraries that use unsafe, but provide safe wrapper for safe code to use, the safety\n\n---\n\n# Validity invariants\nThe other type of invariant is the validity invariant. Validity invariants are the invariants that must be maintained between Rust and the compiler, so that the optimization can be performed safely. For instance, `Option\u003cbool\u003e` can be stored in 1 byte of memory, because it can only have three possible values (`true`, `false` and `None`).\n\n\nDifferent from safety invariant that the unsafe code must uphold only at the boundaries with safe code, validity invariants are the invariants unsafe must *always* uphold.\n\n\n# Related notes\n[[zzq5zy5v]]","snippets":["#rust"],"rawContent":"# Invariants in Rust\n#rust\n\nRalf Jung described two types of *invariants* in Rust in [this post](https://www.ralfj.de/blog/2018/08/22/two-kinds-of-invariants.html), *safety* and *validity*.\n\n# Safety invariant\nEssentially, *safety invariants* are the invariants of a particualr types, that must be upholded, such that that *no matter what safe code does, it must not cause undefine behaviors*.\n\nOne example of this for any primitive type `T`, the invariant is that the object having the type must be initialized (accesing unintialized data is an undefined behavior). Another example is that reference types must be aligned, non-null, and points to an allocated memory that have no other pointer accesses.\n\n\n## Custom/higher-order safety invariants\nThere can also be *custom* safety invariants -- *higher-order* invariants that are not maintained by the compiler, but must be maintained by the unsafe code @bae2021rudra. For example, *Vec*, defined as \n```rust\npub struct Vec\u003cT\u003e {\n    ptr: Unique\u003cT\u003e, // pointing to the heap-allocated backing store holding all the data\n    cap: usize, // number of elements that fit the backing store\n    len: usize, // number of elements that are actually initialized in the backing store\n}\n```\n, must uphold that `ptr` must points to valid memory size of `cap*sizeof(T)`, . The difference between invariants of Vec and other primitive types is that it is defined by the owner, and that the implementer of the type and the unsafe users must uphold them.\n\nMore specifically, for those types, the Rust compiler only guarantee the corectnesses of the signature. Some higher-order invariants can related to (see @bae2021rudra): \n1. Logical consistency (e.g., respecting total ordering)\n2. Purity (e.g., always returns same value for the same input, have no side effect) (possibly related to [[013pr50f]])\n3. Semantic restrictions (e.g., only write to the arguments because it may contains unintialized memory)\nNOTE: It seems that the first and second types of higher-order invariants cannot trigger undefined behaviors by themself. It is not sure we should consider them safety invariants, even. [There has been discussion among Rust community about this](https://users.rust-lang.org/t/should-i-use-unsafe-merely-to-encourage-users-to-maintain-invariants/27856/4). The conclusion was that they should *not* be unsafe invariants.\n\n### Invariant boundaries of unsafe\nThe unsafe code writter to make sure that they are correct *only at the boundaries* with safe code.\nThis boundary highly depends on the unsafe user. Generally, if an *unsafe* block is well-contained, the safety invariants should be upholded *at the end* of the unsafe scope.\nOn the other hand, for some libraries that use unsafe, but provide safe wrapper for safe code to use, the safety\n\n---\n\n# Validity invariants\nThe other type of invariant is the validity invariant. Validity invariants are the invariants that must be maintained between Rust and the compiler, so that the optimization can be performed safely. For instance, `Option\u003cbool\u003e` can be stored in 1 byte of memory, because it can only have three possible values (`true`, `false` and `None`).\n\n\nDifferent from safety invariant that the unsafe code must uphold only at the boundaries with safe code, validity invariants are the invariants unsafe must *always* uphold.\n\n\n# Related notes\n[[zzq5zy5v]]\n","wordCount":500,"tags":["rust"],"metadata":{},"created":"2023-06-14T07:36:42.073457893Z","modified":"2023-06-15T08:33:27.124694469Z","checksum":"1468dd3e35c1a379f0ed798005a56db9710f6f4909d272d1c34e3ce2731f8114"},
    {"filename":"w0weqamx.md","filenameStem":"w0weqamx","path":"w0weqamx.md","absPath":"/home/khadd/mynotes/w0weqamx.md","title":"InvisiPage: Oblivious Demand Paging for Secure Enclaves","link":"[[w0weqamx]]","lead":"#literature [@aga2019invisipage]","body":"#literature [@aga2019invisipage]\n\n## Summary\n\nTwo-page tables are assumed: one to map EPC pages, and the other to map normal\npages. The EPC page table is safely stored within the EPC, and only the enclave\ncan maintain it. Moreover, page faults are handled by the in-enclave page fault\nhandler, so that the faulting address is not learned by the OS. Based on this,\nInvisiPage then supports the oblivious _demand paging_ for the EPC pages. It\nsupports the spilling of EPC pages into non-EPC memory and uses ORAM to decide\nwhich pages to spill.\n\n## Oblivious page management\n\nThe goal is to allow the OS to control how many pages that are allocated to an\nenclave, but not which virtual address that are mapped.\n\nFirst, it maintains two page tables, one to map the EPC pages, the other is for\nnormal use. This approach already exists in [@costan2016sanctum]. However, the\nnew thing is that it allows the OS to swap EPC pages into non-EPC memory\nobliviously.\n\nTo do this, the enclave and the OS have to collaborate for memory management.\n\n## Collaborative memory management\n\n### Spilling EPC page to non-EPC\n\nThe OS provides interface to spill a list of provided virtual addresses to\nnon-EPC memory (`opam_access(o-vpn[])`)\n\nThe ORAM tree is maintained by the OS in a separate tree data structure. This\ntree is indexed by the oblivious page number (`o-vpn`), which is essentially the\nblock ID in the ORAM tree.\n\nOn receiving the `opam_access()` request, the OS has to keep the requested pages\n_memory-resident_. The enclave runtime then spills/fetches the EPC pages\naccording to the ORAM algorithm.\n\nOn a spill, data from EPC pages are copied into non-EPC pages. For fetches, data\nfrom non-EPC pages are copied into EPC pages. For this step, there is one\noptimization introduced: only one page is copied from thea non-EPC into EPC\nmemory. The rest of the non-EPC pages are reshuffled within the non-EPC memory.\nTo the OS, it only seems like a path is accessed. It cannot tell which page is\nactually copied into the EPC.\n\nThe page table is retrofitted to store position map information.\n\n### Freeing an EPC page\n\nTo free a EPC page, the OS request a free request to the enclave, but the actual\npage that get freed is schosen by the enclave.","snippets":["#literature [@aga2019invisipage]"],"rawContent":"# InvisiPage: Oblivious Demand Paging for Secure Enclaves\n\n#literature [@aga2019invisipage]\n\n## Summary\n\nTwo-page tables are assumed: one to map EPC pages, and the other to map normal\npages. The EPC page table is safely stored within the EPC, and only the enclave\ncan maintain it. Moreover, page faults are handled by the in-enclave page fault\nhandler, so that the faulting address is not learned by the OS. Based on this,\nInvisiPage then supports the oblivious _demand paging_ for the EPC pages. It\nsupports the spilling of EPC pages into non-EPC memory and uses ORAM to decide\nwhich pages to spill.\n\n## Oblivious page management\n\nThe goal is to allow the OS to control how many pages that are allocated to an\nenclave, but not which virtual address that are mapped.\n\nFirst, it maintains two page tables, one to map the EPC pages, the other is for\nnormal use. This approach already exists in [@costan2016sanctum]. However, the\nnew thing is that it allows the OS to swap EPC pages into non-EPC memory\nobliviously.\n\nTo do this, the enclave and the OS have to collaborate for memory management.\n\n## Collaborative memory management\n\n### Spilling EPC page to non-EPC\n\nThe OS provides interface to spill a list of provided virtual addresses to\nnon-EPC memory (`opam_access(o-vpn[])`)\n\nThe ORAM tree is maintained by the OS in a separate tree data structure. This\ntree is indexed by the oblivious page number (`o-vpn`), which is essentially the\nblock ID in the ORAM tree.\n\nOn receiving the `opam_access()` request, the OS has to keep the requested pages\n_memory-resident_. The enclave runtime then spills/fetches the EPC pages\naccording to the ORAM algorithm.\n\nOn a spill, data from EPC pages are copied into non-EPC pages. For fetches, data\nfrom non-EPC pages are copied into EPC pages. For this step, there is one\noptimization introduced: only one page is copied from thea non-EPC into EPC\nmemory. The rest of the non-EPC pages are reshuffled within the non-EPC memory.\nTo the OS, it only seems like a path is accessed. It cannot tell which page is\nactually copied into the EPC.\n\nThe page table is retrofitted to store position map information.\n\n### Freeing an EPC page\n\nTo free a EPC page, the OS request a free request to the enclave, but the actual\npage that get freed is schosen by the enclave.\n","wordCount":390,"tags":["literature"],"metadata":{},"created":"2024-05-22T08:24:03.305984292Z","modified":"2024-06-24T14:00:10.051609927Z","checksum":"172ecbf7eae15fba40aa581ad958d82704e3cf1de95769df2a69d5c79737726e"},
    {"filename":"qctx04tc.md","filenameStem":"qctx04tc","path":"qctx04tc.md","absPath":"/home/khadd/mynotes/qctx04tc.md","title":"Kernel Bypass / Direct I/O / DPDK","link":"[[qctx04tc]]","lead":"#io #os","body":"#io #os\n\nKernel bypass maps the IO memory for hardware devices (PCIe, NIC) directly to\ninto userspace memory, allowing applications to build their I/O processing\nentirely outside of the kernel, avoiding expensive syscalls. DPDK is the main\nuser of the approach by Intel.\n\n## Performance\n\nDPDK achives 4.5x performance gain against traditional Linux stack ([src]).\nHowever, many of the performance gain is from the decisions made by DPDK, which\nmay also be applied to Linux. When the Linux is fully optimzied, DPDK is only\nabout 50% faster ([src])\n\n- [src]: https://talawah.io/blog/linux-kernel-vs-dpdk-http-performance-showdown/\n\n## Safety issues\n\nDPDK requires that the application be the sole user of the device. While runing\nDPDK in a virtualized environment is possible ot multiplex hardware, it defeat\nthe purpose of the technique the first place (while it can be used to boost\nvirtualized I/O performance [@li2024bridge] similarly to non-virtualized).\n\nSingle Root I/O Virtualization (SR-IOV) is an extension to the PCIe inteface to\nallows a single physical device to be safely **partitioned** between VMs at the\nhardware level. Several work introduces OS abstractions to take advantage of\nthis for safe [@peter2014arrakis]. Hardware support leads to near-native\nvirtualized I/O performances using DPDK, but require dedicated hardware support\nand reduce the host OS flexibility [@hedayati2019hodor].\n\n### Isolation\n\n[@hedayati2019hodor] suggests fault-isolating the DPDK stack via fast in-process\nisolation (PKU,VMFUNC) with a protected library abstraction. Library OSes\n[@belay2014ix,@peter2014arrakis] are also proposed to provide VM-level isolation\nto direct-IO stacks.","snippets":["#io #os"],"rawContent":"# Kernel Bypass / Direct I/O / DPDK\n\n#io #os\n\nKernel bypass maps the IO memory for hardware devices (PCIe, NIC) directly to\ninto userspace memory, allowing applications to build their I/O processing\nentirely outside of the kernel, avoiding expensive syscalls. DPDK is the main\nuser of the approach by Intel.\n\n## Performance\n\nDPDK achives 4.5x performance gain against traditional Linux stack ([src]).\nHowever, many of the performance gain is from the decisions made by DPDK, which\nmay also be applied to Linux. When the Linux is fully optimzied, DPDK is only\nabout 50% faster ([src])\n\n- [src]: https://talawah.io/blog/linux-kernel-vs-dpdk-http-performance-showdown/\n\n## Safety issues\n\nDPDK requires that the application be the sole user of the device. While runing\nDPDK in a virtualized environment is possible ot multiplex hardware, it defeat\nthe purpose of the technique the first place (while it can be used to boost\nvirtualized I/O performance [@li2024bridge] similarly to non-virtualized).\n\nSingle Root I/O Virtualization (SR-IOV) is an extension to the PCIe inteface to\nallows a single physical device to be safely **partitioned** between VMs at the\nhardware level. Several work introduces OS abstractions to take advantage of\nthis for safe [@peter2014arrakis]. Hardware support leads to near-native\nvirtualized I/O performances using DPDK, but require dedicated hardware support\nand reduce the host OS flexibility [@hedayati2019hodor].\n\n### Isolation\n\n[@hedayati2019hodor] suggests fault-isolating the DPDK stack via fast in-process\nisolation (PKU,VMFUNC) with a protected library abstraction. Library OSes\n[@belay2014ix,@peter2014arrakis] are also proposed to provide VM-level isolation\nto direct-IO stacks.\n","wordCount":244,"tags":["os","io"],"metadata":{},"created":"2024-12-03T07:03:10.967895613Z","modified":"2024-12-16T03:56:38.548890167Z","checksum":"12d37fb395f52222def282c64e0429166dfb88a81b9933b277b71b5c82789116"},
    {"filename":"z8aj9hk9.md","filenameStem":"z8aj9hk9","path":"z8aj9hk9.md","absPath":"/home/khadd/mynotes/z8aj9hk9.md","title":"Kernel long development cycles","link":"[[z8aj9hk9]]","lead":"#os","body":"#os\n\nDeveloping things at the kernel level takes a lot of time. Take networking for\nexample. To reload a driver, one would need to close all the active networking\napplications, or more reboot the entire system. It takes up to 1-2 months do\ndeploy a change to the networking stack [@marty2019snap].\n\nFor this reason, an option for fast development cycles is to bring things to the\nuserspace. This is especially important for applications that intimately\ninteract with hardware and are performance sensitive like networking.","snippets":["#os"],"rawContent":"# Kernel long development cycles\n\n#os\n\nDeveloping things at the kernel level takes a lot of time. Take networking for\nexample. To reload a driver, one would need to close all the active networking\napplications, or more reboot the entire system. It takes up to 1-2 months do\ndeploy a change to the networking stack [@marty2019snap].\n\nFor this reason, an option for fast development cycles is to bring things to the\nuserspace. This is especially important for applications that intimately\ninteract with hardware and are performance sensitive like networking.\n","wordCount":89,"tags":["os"],"metadata":{},"created":"2024-12-16T03:56:49.167902856Z","modified":"2024-12-16T03:56:38.552223511Z","checksum":"0e41272c21295aed1ab5fb177538ba7e4dd6cd755c8e2f9dc3fcfeff0e9a92ac"},
    {"filename":"jb9ebbaw.md","filenameStem":"jb9ebbaw","path":"jb9ebbaw.md","absPath":"/home/khadd/mynotes/jb9ebbaw.md","title":"Kernel/User Semantic Gaps","link":"[[jb9ebbaw]]","lead":"Semantic gaps are commonly discussed in the context of virtualizations between\nVMs and hypervisor. However, it is also the bottleneck in many userspace\nmechanisms. Here are two:","body":"Semantic gaps are commonly discussed in the context of virtualizations between\nVMs and hypervisor. However, it is also the bottleneck in many userspace\nmechanisms. Here are two:\n\n- **In-process resources isolation**. When userspace security domains are\n  created, the system call interface inerently interface vulnerabilities\n  [@lefeuvre2024sok] enabling the bypassing of userspace memory isolation\n  mechanisms. This is inerently due to the kernel not being aware of userspace\n  security domains, and enforce a different security policy for process-wide\n  system resources. Many userspace comparmentalization work are made to be aware\n  of this gap. Still, it's complicated to make safe with signal deliveries and\n  threading [@yang2024endokernel].\n- **Memory mapping management**. Leveraging the mostly unused address space to\n  implement one-time-allocation is a common technique to prevent use-after-free.\n  However, this approach results in huge memory consumptions, so a common\n  technique is to create \"alias\" mappings. Creating these mappings require\n  syscalls incur a lot of overheads [@ahn2024budalloc].\n\n## Overcoming the gap\n\nA way to overcome this semantic gap is to (1) make the kernelspace aware of\nuserspace mechanisms, or (2) the other way around.\n\nFor (1), this comes as the cost of introducing complexities to kernel\nimplementation, and also leads to safety issues.\n\n- Many work propose \"minimal\" modifications to the kernel to achieve their goal\n  [@peng2023mswitch].\n- eBPF is a safe interface that enable extensibility [@ahn2024budalloc], but\n  also have costs in expressiveness.\n- Single address-space libOSes and unikernels\n  [@belay2012dune,@gorter2022dangzero] allows userspace mechansims to directly\n  access the underlying hardware. However, they loose the rich abstrations\n  provided by Linux kernel, and also lead to reduced compatibility.\n- This approach reuses existing kernel abstrations, better for maintainability.\n  It may lack expressiveness, due to having to constrain to existing APIs and\n  interfaces (e.g., eBPF). Otherwise, significant changes to the kernel is\n\nThe other case (2) introduce significant complexities to the userspace.\n\n- [@schrammel2022jenny] uses the Syscall User Dispatch SUD to forward the system\n  call decisions to userspace.\n- [@yang2024endokernel] basically virtualizes all kernel abstrations (syscall,\n  signals, file system, memory mappings, threads).\n- This approach may be better for more expressiveness in defining userspace\n  policies.\n- This create new complexities that is challenging to ensure security.\n\n## Synchronization\n\nWhen bridging the semantic gap, a kind of \"synchronization\" of states is\nrequired. This synchronization must cross the user-kernel worlds, e.g., through\nsyscalls, which is expensive. A common technique is to only perform this\nsynchronization whenever required.\n\n- $\\mu$switch switches [@peng2023mswitch] the memory view in the userspace, and\n  only synchronize the kernel state on system calls (e.g., implicit context\n  switch).\n- Budalloc [@ahn2024budalloc] install custom eBPF handler that automatically\n  manage VA-to-PA mappings based on user-defined memory mappings policies.","snippets":["Semantic gaps are commonly discussed in the context of virtualizations between\nVMs and hypervisor. However, it is also the bottleneck in many userspace\nmechanisms. Here are two:"],"rawContent":"# Kernel/User Semantic Gaps\n\nSemantic gaps are commonly discussed in the context of virtualizations between\nVMs and hypervisor. However, it is also the bottleneck in many userspace\nmechanisms. Here are two:\n\n- **In-process resources isolation**. When userspace security domains are\n  created, the system call interface inerently interface vulnerabilities\n  [@lefeuvre2024sok] enabling the bypassing of userspace memory isolation\n  mechanisms. This is inerently due to the kernel not being aware of userspace\n  security domains, and enforce a different security policy for process-wide\n  system resources. Many userspace comparmentalization work are made to be aware\n  of this gap. Still, it's complicated to make safe with signal deliveries and\n  threading [@yang2024endokernel].\n- **Memory mapping management**. Leveraging the mostly unused address space to\n  implement one-time-allocation is a common technique to prevent use-after-free.\n  However, this approach results in huge memory consumptions, so a common\n  technique is to create \"alias\" mappings. Creating these mappings require\n  syscalls incur a lot of overheads [@ahn2024budalloc].\n\n## Overcoming the gap\n\nA way to overcome this semantic gap is to (1) make the kernelspace aware of\nuserspace mechanisms, or (2) the other way around.\n\nFor (1), this comes as the cost of introducing complexities to kernel\nimplementation, and also leads to safety issues.\n\n- Many work propose \"minimal\" modifications to the kernel to achieve their goal\n  [@peng2023mswitch].\n- eBPF is a safe interface that enable extensibility [@ahn2024budalloc], but\n  also have costs in expressiveness.\n- Single address-space libOSes and unikernels\n  [@belay2012dune,@gorter2022dangzero] allows userspace mechansims to directly\n  access the underlying hardware. However, they loose the rich abstrations\n  provided by Linux kernel, and also lead to reduced compatibility.\n- This approach reuses existing kernel abstrations, better for maintainability.\n  It may lack expressiveness, due to having to constrain to existing APIs and\n  interfaces (e.g., eBPF). Otherwise, significant changes to the kernel is\n\nThe other case (2) introduce significant complexities to the userspace.\n\n- [@schrammel2022jenny] uses the Syscall User Dispatch SUD to forward the system\n  call decisions to userspace.\n- [@yang2024endokernel] basically virtualizes all kernel abstrations (syscall,\n  signals, file system, memory mappings, threads).\n- This approach may be better for more expressiveness in defining userspace\n  policies.\n- This create new complexities that is challenging to ensure security.\n\n## Synchronization\n\nWhen bridging the semantic gap, a kind of \"synchronization\" of states is\nrequired. This synchronization must cross the user-kernel worlds, e.g., through\nsyscalls, which is expensive. A common technique is to only perform this\nsynchronization whenever required.\n\n- $\\mu$switch switches [@peng2023mswitch] the memory view in the userspace, and\n  only synchronize the kernel state on system calls (e.g., implicit context\n  switch).\n- Budalloc [@ahn2024budalloc] install custom eBPF handler that automatically\n  manage VA-to-PA mappings based on user-defined memory mappings policies.\n","wordCount":438,"tags":[],"metadata":{},"created":"2024-11-26T13:32:37.427773988Z","modified":"2024-11-29T10:15:35.667074419Z","checksum":"e10d71c99cc282a465dcd2fd762aab5aaa503242c6f63ba9586dd2f098d0a7c0"},
    {"filename":"d8hi0u6t.md","filenameStem":"d8hi0u6t","path":"d8hi0u6t.md","absPath":"/home/khadd/mynotes/d8hi0u6t.md","title":"Klotski: Efficient Obfuscated Execution against Controlled-Channel Attacks","link":"[[d8hi0u6t]]","lead":"#literature #controlled-channel #oblivious #sgx @zhang2020klotski","body":"#literature #controlled-channel #oblivious #sgx @zhang2020klotski\n\n## Noteworthy Arguments\n\n### Positioning\n\n- Previous solutions for controlled-channel protection are either (0) incomplete\n  against attacks, (2) have incomplete protection for code and data, and (3) has\n  high overheads.\n- Incompleteness against attack:\n\n  - TSX-based solutions [@shih2017tsgx] , that tries to detect interrupts of\n    enclaves, but there has been attacks that can trigger without enclave exit.\n\n- Incomplete protection for code and data\n\n  - Some only protect data accesses @sasy2018zerotrace @drsgx\n  - Other only protect code access @zizagger, and can be defeated fine-grained\n    attack\n\n- High overheads\n  - @shinde2016preventing places sensitive code and data inside one page, but\n    has high overheads (4000x)\n  - Obfuscuro @ahmad2019obfuscuro only supports small code and data size (8KB).\n\n## Oblivious memory subsystem scheme\n\n### Memory subsystem\n\nKlotski's memory subsystem consists of three levels (akin to the actual memory\nsubsystem). The first is the code and data caches, that has reconfigurable\nsizes, called the _vCache_. The second level is the ORAM _stashes_ for code and\ndata. The final layer is the _ORAM tree_.\n\nThe stash and the tree are parts of an ORAM scheme.\n\nMemory from the higher level is evicted into the lower level, with some\npolicies.\n\nThe main reason for _vCache_ is to trade-off security for some performance. This\nis the main difference with Obfuscuro @ahmad2019obfuscuro vCache can be\nconfigure to be larger than the page size.\n\n- ❓Why do you need three levels, why not just configure the stash size then?\n  - ORAM algorithms requires the stash to be certain sizes, or else it will not\n    work (e.g., the path does not fit into the stash).\n  - The stash in untrusted memory, an can span several pages.\n  - Similar to [@ahmad2019obfuscuro]: just storing pages in the stash would leak\n    lotta info since stash size is large.\n\nIs there a scheme for storing data into untrusted storage, like in\n@sasy2018zerotrace?\n\n- This paper assume all memory is within the enclave, and there is no spilling\n  into untrusted storage.\n\n## Memory access hierarchy\n\n### Logical addresses\n\nLogical addresses are the address that the instructions use (i.e., virtual\naddresses).\n\nKlotski use 32-bit addresses in their implementation, maybe to limit the number\nof entries in the software PT?\n\n### Logical address translation\n\nThe program is instrumented to _translate_ the logical address on every\noperations into _real address_, which is an address inside the execution cache.\n\nLogical addresses are translated using a software page table using same method\nas real page table. The following function translates logical address into page\ntable index:\n\n```cpp\nsize_t getRealAddress(size_t logicAddr){\n    size_t index = logicAddr\u003e\u003eSHADOWPAGEWIDE;\n    //if the page does not exist in cache,swap the page in\n    if(!pagetable[index]){\n        struct OramPool * oramPool;\n        size_t blockIndex;\n        if(isBigObject(index)){\n            LOGIC_INDEX_TO_BLOCK_INDEX_FOR_BIG(index,blockIndex)\n            oramPool = \u0026DataPool_bigData;\n        }else{\n            LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)\n            oramPool = \u0026DataPool_smallData;\n        }\n        handleObliviousPageExchangeData(index,blockIndex,oramPool);\n    }\n    return pagetable[index]+logicAddr;\n}\n```\n\nThe address itself also seems to contain the block ID.\n`LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)` gets the correct block ID from\nthe position map index.\n\nIn this translation function, if page is not in the page table, then it is not\nin the cache, so address translation happen. This is not what is described in\nthe paper: a PTE also contains the path ID. Maybe this function is only used for\nstatic data...\n\nThe real translation function seems to be `dereference_data()`.\n\n### ORAM access\n\nOn a page miss, ORAM access is triggered to fetch block into the vCache. First,\nthe ORAM block (2KB _minipage_) is fetched in to the _stash_, and the position\nmap is updated. The block is then moved to the vCache, and a block inside vCache\nis swapped out.\n\n#### Stash\u003c-\u003eORAM\n\nRing ORAM evict the blocks after $k$ accesses. On eviction, blocks inside the\nstash is flushed into the ORAM tree.\n\n#### vCache\u003c-\u003eStash\n\nThe minipage is then swapped into the vCache, where a block is _randomly_\nevicted from the vCache to make space.\n\nThe paper argue that _LRU_ cache eviction may leak information.\n\nThere is also a reconfigurable re-randomization of the vCache: the user can\nconfigure such that the vCache is flushed after $n$ accesses.\n\n## Address translation\n\nKlotski uses a scheme to _translate_ logical address to the actual address\ninside vCache, in the same way a MMU translate physical to virtual address.\n\n```c\n// virtual addr use in Klotski-instrumented program\nloadImm R1, logicalAddr\ncall vPTE_lookup(R1)\n// use pointer\nload R2, R1\n...\n\nv_addr vPTE_lookup(v_addr logicalAddr){\n    vPTE_t vPTE = position_map_scan(logicalAddr);\n    if (vPTE.cached)\n        return vPTE.addr;\n    else\n        // slow path\n       if (vPTE.in_stash)\n           vPTE = stash_fetch(vPTE.oramIndex);\n       else\n           vPTE = oram_read(vPTE.oramIndex);\n       return vPTE.addr;\n}\n```\n\n### Operations\n\n#### vCache and Stash\n\n- `LoadCache` reads the target minipage\n\n## Compiler \u0026 runtime\n\nCompiler changes all memory instructions, call, return, into calls into the\nruntime functions. Implementation:\n[Here](https://github.com/nczhang88pan/KlotskiSGX/tree/master/klotski/llvmProgram/llvm/lib/Transforms/Instrumentation/Klotski)\nMaybe the compiler transformation would looks like this:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n---\n%1 = call mmu_load(%arg1)\n%2 = add %1, 100\ncall mmu_call(\u0026foo)\ncall mmu_store(%2, %1)\n```\n\nThe compiler also split code and data into blocks of 2KB, which is also the ORAM\nblock size. The code is compiled as relocatable code, so that it can be\nrelocated to any virtual addresses.\n\n- ❓ Why do you need relocatable code here?\n- ❓ What is effiective virtual address, why does it change at runtime?\n\nThe runtime functions acts as a memory subsystem: given a virtual address, it\nlook up\n\n## ORAM Accesses\n\nThe paper uses Ring ORAM for its ORAM algorithm. However, there are several\nnoteworthy extensions. Because the memory used for posmap (virtual page table)\nand stash is in untrusted memory, attackers can find out which stash slot and\nposmap entry is accessed.\n\n### ORead\n\nAn `ORead` operation is introduced to lineary scan over all data that must be\ntouched to remain oblivious, similar to a `cmov`. The data is stored into a\n256-bit ymm registers. 1 register is reserved for reading unused data, and the\nremainings is used to store the required data.\n\nNOTE: it is not exactly similar to `CMOV`, you only need to actually touch the\ndata in `ORead`, but not write it back.\n\n---\n\nThe `ReadPath` operation that read from ORAM path into stash uses this to bring\ndata into the stash without revealing the actual bucket/block that is accessed.\n\nFor example, consider fetching of a path in traditional Ring ORAM. On each\nbucket along the path, a block is fetched, but discarded. On the block that\ncontain non-dummy data, it is actually read into the stash. With visibility over\nstash and tree, the attacker can see that there is a read from the tree,\nfollowing by a write into the stash. This means that the block that is just read\ncontains the requested data.\n\nBy fetching all data into YMM registers, and delay the write back to the stash\nto the last moment, this can be hidden.\n\n---\n\n`LoadCache` that load an entry from stash into cache also needs this (for same\nreason above). It must scan over all stash entries, and only copy the one needed\ninto the vCache.\n\n## WriteStash\n\nThe WriteStash operation, that write into the stash, is also made oblivious.\nThere are two potential leakage, when the attacker learns about the stash\naccess:\n\n1. If data is written into a slot, it means that the slot is empty, so it must\n   have been evicted recently.\n2. If data is written into a stash slot twice (without being read), it can be\n   infered that the slot contained dummy blocks. ❓ Is there actually dummy\n   blocks in the stash?\n\nTo solve this, every (1) block must only be written once (before being\nreshuffled), and (2) a write to a slot must not reveal the last block being\nevicted Klotski solve this by keeping a pointer to slot that is last written,\nand increment the pointer to the next slot at every write. When the pointer move\nto the last empty blocks, the stash is reshuffled.\n\n```\n      Spare stash ptr\n            |\n            v\n| 2 | 5 | 3 | \u003cempty\u003e | 4 | \u003cempty\u003e |\n```\n\nAfter write:\n\n```\n                      v\n| 2 | 5 | 3 | *6* | 4 | \u003c empty \u003e |\n```\n\nPointer moved to the last empty block, so reshuffle:\n\n```\n                           v\n| 2 | \u003cevited\u003e | \u003cevicted\u003e | 6 | 4 | *1* |\n```\n\nReshuffling moves actual blocks to the begining and update the spare stash ptr.\n\n```\n                v\n| 6 | 1 | 4 | 2 | \u003cempty\u003e | \u003cempty\u003e |\n```","snippets":["#literature #controlled-channel #oblivious #sgx @zhang2020klotski"],"rawContent":"# Klotski: Efficient Obfuscated Execution against Controlled-Channel Attacks\n\n#literature #controlled-channel #oblivious #sgx @zhang2020klotski\n\n## Noteworthy Arguments\n\n### Positioning\n\n- Previous solutions for controlled-channel protection are either (0) incomplete\n  against attacks, (2) have incomplete protection for code and data, and (3) has\n  high overheads.\n- Incompleteness against attack:\n\n  - TSX-based solutions [@shih2017tsgx] , that tries to detect interrupts of\n    enclaves, but there has been attacks that can trigger without enclave exit.\n\n- Incomplete protection for code and data\n\n  - Some only protect data accesses @sasy2018zerotrace @drsgx\n  - Other only protect code access @zizagger, and can be defeated fine-grained\n    attack\n\n- High overheads\n  - @shinde2016preventing places sensitive code and data inside one page, but\n    has high overheads (4000x)\n  - Obfuscuro @ahmad2019obfuscuro only supports small code and data size (8KB).\n\n## Oblivious memory subsystem scheme\n\n### Memory subsystem\n\nKlotski's memory subsystem consists of three levels (akin to the actual memory\nsubsystem). The first is the code and data caches, that has reconfigurable\nsizes, called the _vCache_. The second level is the ORAM _stashes_ for code and\ndata. The final layer is the _ORAM tree_.\n\nThe stash and the tree are parts of an ORAM scheme.\n\nMemory from the higher level is evicted into the lower level, with some\npolicies.\n\nThe main reason for _vCache_ is to trade-off security for some performance. This\nis the main difference with Obfuscuro @ahmad2019obfuscuro vCache can be\nconfigure to be larger than the page size.\n\n- ❓Why do you need three levels, why not just configure the stash size then?\n  - ORAM algorithms requires the stash to be certain sizes, or else it will not\n    work (e.g., the path does not fit into the stash).\n  - The stash in untrusted memory, an can span several pages.\n  - Similar to [@ahmad2019obfuscuro]: just storing pages in the stash would leak\n    lotta info since stash size is large.\n\nIs there a scheme for storing data into untrusted storage, like in\n@sasy2018zerotrace?\n\n- This paper assume all memory is within the enclave, and there is no spilling\n  into untrusted storage.\n\n## Memory access hierarchy\n\n### Logical addresses\n\nLogical addresses are the address that the instructions use (i.e., virtual\naddresses).\n\nKlotski use 32-bit addresses in their implementation, maybe to limit the number\nof entries in the software PT?\n\n### Logical address translation\n\nThe program is instrumented to _translate_ the logical address on every\noperations into _real address_, which is an address inside the execution cache.\n\nLogical addresses are translated using a software page table using same method\nas real page table. The following function translates logical address into page\ntable index:\n\n```cpp\nsize_t getRealAddress(size_t logicAddr){\n    size_t index = logicAddr\u003e\u003eSHADOWPAGEWIDE;\n    //if the page does not exist in cache,swap the page in\n    if(!pagetable[index]){\n        struct OramPool * oramPool;\n        size_t blockIndex;\n        if(isBigObject(index)){\n            LOGIC_INDEX_TO_BLOCK_INDEX_FOR_BIG(index,blockIndex)\n            oramPool = \u0026DataPool_bigData;\n        }else{\n            LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)\n            oramPool = \u0026DataPool_smallData;\n        }\n        handleObliviousPageExchangeData(index,blockIndex,oramPool);\n    }\n    return pagetable[index]+logicAddr;\n}\n```\n\nThe address itself also seems to contain the block ID.\n`LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)` gets the correct block ID from\nthe position map index.\n\nIn this translation function, if page is not in the page table, then it is not\nin the cache, so address translation happen. This is not what is described in\nthe paper: a PTE also contains the path ID. Maybe this function is only used for\nstatic data...\n\nThe real translation function seems to be `dereference_data()`.\n\n### ORAM access\n\nOn a page miss, ORAM access is triggered to fetch block into the vCache. First,\nthe ORAM block (2KB _minipage_) is fetched in to the _stash_, and the position\nmap is updated. The block is then moved to the vCache, and a block inside vCache\nis swapped out.\n\n#### Stash\u003c-\u003eORAM\n\nRing ORAM evict the blocks after $k$ accesses. On eviction, blocks inside the\nstash is flushed into the ORAM tree.\n\n#### vCache\u003c-\u003eStash\n\nThe minipage is then swapped into the vCache, where a block is _randomly_\nevicted from the vCache to make space.\n\nThe paper argue that _LRU_ cache eviction may leak information.\n\nThere is also a reconfigurable re-randomization of the vCache: the user can\nconfigure such that the vCache is flushed after $n$ accesses.\n\n## Address translation\n\nKlotski uses a scheme to _translate_ logical address to the actual address\ninside vCache, in the same way a MMU translate physical to virtual address.\n\n```c\n// virtual addr use in Klotski-instrumented program\nloadImm R1, logicalAddr\ncall vPTE_lookup(R1)\n// use pointer\nload R2, R1\n...\n\nv_addr vPTE_lookup(v_addr logicalAddr){\n    vPTE_t vPTE = position_map_scan(logicalAddr);\n    if (vPTE.cached)\n        return vPTE.addr;\n    else\n        // slow path\n       if (vPTE.in_stash)\n           vPTE = stash_fetch(vPTE.oramIndex);\n       else\n           vPTE = oram_read(vPTE.oramIndex);\n       return vPTE.addr;\n}\n```\n\n### Operations\n\n#### vCache and Stash\n\n- `LoadCache` reads the target minipage\n\n## Compiler \u0026 runtime\n\nCompiler changes all memory instructions, call, return, into calls into the\nruntime functions. Implementation:\n[Here](https://github.com/nczhang88pan/KlotskiSGX/tree/master/klotski/llvmProgram/llvm/lib/Transforms/Instrumentation/Klotski)\nMaybe the compiler transformation would looks like this:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n---\n%1 = call mmu_load(%arg1)\n%2 = add %1, 100\ncall mmu_call(\u0026foo)\ncall mmu_store(%2, %1)\n```\n\nThe compiler also split code and data into blocks of 2KB, which is also the ORAM\nblock size. The code is compiled as relocatable code, so that it can be\nrelocated to any virtual addresses.\n\n- ❓ Why do you need relocatable code here?\n- ❓ What is effiective virtual address, why does it change at runtime?\n\nThe runtime functions acts as a memory subsystem: given a virtual address, it\nlook up\n\n## ORAM Accesses\n\nThe paper uses Ring ORAM for its ORAM algorithm. However, there are several\nnoteworthy extensions. Because the memory used for posmap (virtual page table)\nand stash is in untrusted memory, attackers can find out which stash slot and\nposmap entry is accessed.\n\n### ORead\n\nAn `ORead` operation is introduced to lineary scan over all data that must be\ntouched to remain oblivious, similar to a `cmov`. The data is stored into a\n256-bit ymm registers. 1 register is reserved for reading unused data, and the\nremainings is used to store the required data.\n\nNOTE: it is not exactly similar to `CMOV`, you only need to actually touch the\ndata in `ORead`, but not write it back.\n\n---\n\nThe `ReadPath` operation that read from ORAM path into stash uses this to bring\ndata into the stash without revealing the actual bucket/block that is accessed.\n\nFor example, consider fetching of a path in traditional Ring ORAM. On each\nbucket along the path, a block is fetched, but discarded. On the block that\ncontain non-dummy data, it is actually read into the stash. With visibility over\nstash and tree, the attacker can see that there is a read from the tree,\nfollowing by a write into the stash. This means that the block that is just read\ncontains the requested data.\n\nBy fetching all data into YMM registers, and delay the write back to the stash\nto the last moment, this can be hidden.\n\n---\n\n`LoadCache` that load an entry from stash into cache also needs this (for same\nreason above). It must scan over all stash entries, and only copy the one needed\ninto the vCache.\n\n## WriteStash\n\nThe WriteStash operation, that write into the stash, is also made oblivious.\nThere are two potential leakage, when the attacker learns about the stash\naccess:\n\n1. If data is written into a slot, it means that the slot is empty, so it must\n   have been evicted recently.\n2. If data is written into a stash slot twice (without being read), it can be\n   infered that the slot contained dummy blocks. ❓ Is there actually dummy\n   blocks in the stash?\n\nTo solve this, every (1) block must only be written once (before being\nreshuffled), and (2) a write to a slot must not reveal the last block being\nevicted Klotski solve this by keeping a pointer to slot that is last written,\nand increment the pointer to the next slot at every write. When the pointer move\nto the last empty blocks, the stash is reshuffled.\n\n```\n      Spare stash ptr\n            |\n            v\n| 2 | 5 | 3 | \u003cempty\u003e | 4 | \u003cempty\u003e |\n```\n\nAfter write:\n\n```\n                      v\n| 2 | 5 | 3 | *6* | 4 | \u003c empty \u003e |\n```\n\nPointer moved to the last empty block, so reshuffle:\n\n```\n                           v\n| 2 | \u003cevited\u003e | \u003cevicted\u003e | 6 | 4 | *1* |\n```\n\nReshuffling moves actual blocks to the begining and update the spare stash ptr.\n\n```\n                v\n| 6 | 1 | 4 | 2 | \u003cempty\u003e | \u003cempty\u003e |\n```\n","wordCount":1417,"tags":["literature","sgx","controlled-channel","oblivious"],"metadata":{},"created":"2024-05-22T08:24:03.242090358Z","modified":"2024-10-24T03:47:21.816802953Z","checksum":"f3c07eae44bf4a1e868555e49cc768942b313cb9ac7a8ee20ef7708c7b8c678d"},
    {"filename":"dyx2t4oz.md","filenameStem":"dyx2t4oz","path":"dyx2t4oz.md","absPath":"/home/khadd/mynotes/dyx2t4oz.md","title":"Knowledge flower","link":"[[dyx2t4oz]]","lead":"#zettelkasten #note-taking","body":"#zettelkasten #note-taking\n\n[This blog post](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/)\nproposes a framework to think about zettelkasten notes.\n\n1. Choose an idea and place it in the center.\n2. Think of each leaf as an aspect of the thought that is needed to fully\n   develop it. The thought blossoms like a flower.\n\n- _Truth_: Are there arguments for its truth? Is there empirical evidence for\n  its truth? Is it free of self-contradiction?\n- _Relevance_: To whom is the thought important? To whom is it not?\n- _Usefulness_: What problem can be solved by the thought? Can it become a tool?\n- _Beauty_: How does the thought promote harmony and elegance?\n- _Simplicity_: How can you make the thought simpler and easier to understand?\n  Can the thought be used to simplify something else?","snippets":["#zettelkasten #note-taking"],"rawContent":"# Knowledge flower\n\n#zettelkasten #note-taking\n\n[This blog post](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/)\nproposes a framework to think about zettelkasten notes.\n\n1. Choose an idea and place it in the center.\n2. Think of each leaf as an aspect of the thought that is needed to fully\n   develop it. The thought blossoms like a flower.\n\n- _Truth_: Are there arguments for its truth? Is there empirical evidence for\n  its truth? Is it free of self-contradiction?\n- _Relevance_: To whom is the thought important? To whom is it not?\n- _Usefulness_: What problem can be solved by the thought? Can it become a tool?\n- _Beauty_: How does the thought promote harmony and elegance?\n- _Simplicity_: How can you make the thought simpler and easier to understand?\n  Can the thought be used to simplify something else?\n","wordCount":130,"tags":["zettelkasten","note-taking"],"metadata":{},"created":"2023-05-03T03:47:47.579037486Z","modified":"2024-06-20T07:52:35.090413564Z","checksum":"5eea877f84c2828062e8d7a9d196058818637b1949cabd76ee143cacc85e8566"},
    {"filename":"vne1zoi3.md","filenameStem":"vne1zoi3","path":"vne1zoi3.md","absPath":"/home/khadd/mynotes/vne1zoi3.md","title":"LLVM register data flow graph","link":"[[vne1zoi3]]","lead":"#area #llvm #analysis #backend","body":"#area #llvm #analysis #backend\n\nLLVM provides a Register Data Flow Graph that contains the flow of registers\nbetween instructions. Probably useful for some backend analysis.\n\n- [LLVM: include/llvm/CodeGen/RDFGraph.h Source File](https://llvm.org/doxygen/RDFGraph_8h_source.html).\n\nThe graph is a collection of **Nodes**, where each node can be either a **code\nnode** or a **reference node**.\n\n- A **code node** is a collection of other nodes. E.g., A **basic block** code\n  node contains **instruction** code nodes, and instruction code node contains\n  **Reference nodes**\n- **Reference node** describe the register reference. It can either be a\n  **DefNode** or a **UseNode**\n  - DefNode defines the register\n  - UseNode uses the register\n\nDefNode contains:\n\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node\n- First reached use: the first node that use this definition.\n  - To traverse other register uses, we can use the slibing of the UseNode\n- First reached definition: First node after this that redefine the register\n  UseNode contains :\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node","snippets":["#area #llvm #analysis #backend"],"rawContent":"# LLVM register data flow graph\n\n#area #llvm #analysis #backend\n\nLLVM provides a Register Data Flow Graph that contains the flow of registers\nbetween instructions. Probably useful for some backend analysis.\n\n- [LLVM: include/llvm/CodeGen/RDFGraph.h Source File](https://llvm.org/doxygen/RDFGraph_8h_source.html).\n\nThe graph is a collection of **Nodes**, where each node can be either a **code\nnode** or a **reference node**.\n\n- A **code node** is a collection of other nodes. E.g., A **basic block** code\n  node contains **instruction** code nodes, and instruction code node contains\n  **Reference nodes**\n- **Reference node** describe the register reference. It can either be a\n  **DefNode** or a **UseNode**\n  - DefNode defines the register\n  - UseNode uses the register\n\nDefNode contains:\n\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node\n- First reached use: the first node that use this definition.\n  - To traverse other register uses, we can use the slibing of the UseNode\n- First reached definition: First node after this that redefine the register\n  UseNode contains :\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node\n","wordCount":189,"tags":["analysis","llvm","backend","area"],"metadata":{},"created":"2023-05-23T08:54:41.12084436Z","modified":"2024-12-05T04:28:50.000345946Z","checksum":"a278b9e0eff11cc7f93d0526b464bcd5473aefcf1db4e1e3114e32f3ec956f74"},
    {"filename":"3ciove99.md","filenameStem":"3ciove99","path":"3ciove99.md","absPath":"/home/khadd/mynotes/3ciove99.md","title":"Link-time Optimization in LLVM","link":"[[3ciove99]]","lead":"#lto #llvm","body":"#lto #llvm\n\nTo enable LTO:\n\n1. Register the pass so that it happen during LTO\n   (`EP_FullLinkTimeOptimizaitonLast` or `Early`).\n2. Enable `-flto` flag at compile-time, load the pass in Clang, change linker to\n   lld (not sure about gold linker). e.g.,\n   `clang -flto -fuse-ld=lld -Wl,-mllvm=-load=pass.so`\n\n## Note\n\n- Tested on LLVM 15\n- `-flegacy-pass-manager` must be passed when the pass is registered with legacy\n  APIs","snippets":["#lto #llvm"],"rawContent":"# Link-time Optimization in LLVM\n\n#lto #llvm\n\nTo enable LTO:\n\n1. Register the pass so that it happen during LTO\n   (`EP_FullLinkTimeOptimizaitonLast` or `Early`).\n2. Enable `-flto` flag at compile-time, load the pass in Clang, change linker to\n   lld (not sure about gold linker). e.g.,\n   `clang -flto -fuse-ld=lld -Wl,-mllvm=-load=pass.so`\n\n## Note\n\n- Tested on LLVM 15\n- `-flegacy-pass-manager` must be passed when the pass is registered with legacy\n  APIs\n","wordCount":68,"tags":["llvm","lto"],"metadata":{},"created":"2023-05-23T08:52:32.389751217Z","modified":"2024-06-28T08:36:15.706924122Z","checksum":"6b021afb6f055b63126962a24f45821f31c33c5d1a88a268f226c4aa9d720460"},
    {"filename":"se0pwev9.md","filenameStem":"se0pwev9","path":"se0pwev9.md","absPath":"/home/khadd/mynotes/se0pwev9.md","title":"Linux APIC timer virtualization","link":"[[se0pwev9]]","lead":"#linux #kernel #virtualization","body":"#linux #kernel #virtualization\n\n## Initialization\n\nThe interrupt controller structure (`kvm_lapic`) is created along with the\nvirtual cpu in `kvm_arch_vcpu_create`.\n\nInternally, Linux uses the `hrtimer` (High resolution timer) abstraction to\nmanage virtualized interrupt.\n\n```C\nhrtimer_init(\u0026apic-\u003elapic_timer.timer, CLOCK_MONOTONIC,\n       HRTIMER_MODE_ABS_HARD);\napic-\u003elapic_timer.timer.function = apic_timer_fn;\nif (timer_advance_ns == -1) {\n  apic-\u003elapic_timer.timer_advance_ns = LAPIC_TIMER_ADVANCE_NS_INIT;\n  lapic_timer_advance_dynamic = true;\n} else {\n  apic-\u003elapic_timer.timer_advance_ns = timer_advance_ns;\n  lapic_timer_advance_dynamic = false;\n}\n```\n\nMaybe tiemr advance\n\n## Runtime\n\nAt the end of `svm_vcpu_run`, there is the call that handle frequent exits.\n\n```c\n return svm_exit_handlers_fastpath(vcpu);\n```\n\n## APIC device\n\n`apic_mmio_write`-\u003e`kvm_lapic_reg_write`-\u003e`apic_update_lvtt`\n\n## Note\n\n### Limiting interrupt frequency\n\nTimer frequency is limited if it is periodic.\n\n```c\nstatic void apic_update_lvtt(struct kvm_lapic *apic)\n{\n u32 timer_mode = kvm_lapic_get_reg(apic, APIC_LVTT) \u0026\n   apic-\u003elapic_timer.timer_mode_mask;\n\n if (apic-\u003elapic_timer.timer_mode != timer_mode) {\n  if (apic_lvtt_tscdeadline(apic) != (timer_mode ==\n    APIC_LVT_TIMER_TSCDEADLINE)) {\n   cancel_apic_timer(apic);\n   kvm_lapic_set_reg(apic, APIC_TMICT, 0);\n   apic-\u003elapic_timer.period = 0;\n   apic-\u003elapic_timer.tscdeadline = 0;\n  }\n  apic-\u003elapic_timer.timer_mode = timer_mode;\n  limit_periodic_timer_frequency(apic);\n }\n}\n```","snippets":["#linux #kernel #virtualization"],"rawContent":"# Linux APIC timer virtualization\n\n#linux #kernel #virtualization\n\n## Initialization\n\nThe interrupt controller structure (`kvm_lapic`) is created along with the\nvirtual cpu in `kvm_arch_vcpu_create`.\n\nInternally, Linux uses the `hrtimer` (High resolution timer) abstraction to\nmanage virtualized interrupt.\n\n```C\nhrtimer_init(\u0026apic-\u003elapic_timer.timer, CLOCK_MONOTONIC,\n       HRTIMER_MODE_ABS_HARD);\napic-\u003elapic_timer.timer.function = apic_timer_fn;\nif (timer_advance_ns == -1) {\n  apic-\u003elapic_timer.timer_advance_ns = LAPIC_TIMER_ADVANCE_NS_INIT;\n  lapic_timer_advance_dynamic = true;\n} else {\n  apic-\u003elapic_timer.timer_advance_ns = timer_advance_ns;\n  lapic_timer_advance_dynamic = false;\n}\n```\n\nMaybe tiemr advance\n\n## Runtime\n\nAt the end of `svm_vcpu_run`, there is the call that handle frequent exits.\n\n```c\n return svm_exit_handlers_fastpath(vcpu);\n```\n\n## APIC device\n\n`apic_mmio_write`-\u003e`kvm_lapic_reg_write`-\u003e`apic_update_lvtt`\n\n## Note\n\n### Limiting interrupt frequency\n\nTimer frequency is limited if it is periodic.\n\n```c\nstatic void apic_update_lvtt(struct kvm_lapic *apic)\n{\n u32 timer_mode = kvm_lapic_get_reg(apic, APIC_LVTT) \u0026\n   apic-\u003elapic_timer.timer_mode_mask;\n\n if (apic-\u003elapic_timer.timer_mode != timer_mode) {\n  if (apic_lvtt_tscdeadline(apic) != (timer_mode ==\n    APIC_LVT_TIMER_TSCDEADLINE)) {\n   cancel_apic_timer(apic);\n   kvm_lapic_set_reg(apic, APIC_TMICT, 0);\n   apic-\u003elapic_timer.period = 0;\n   apic-\u003elapic_timer.tscdeadline = 0;\n  }\n  apic-\u003elapic_timer.timer_mode = timer_mode;\n  limit_periodic_timer_frequency(apic);\n }\n}\n```\n","wordCount":150,"tags":["linux","virtualization","kernel"],"metadata":{},"created":"2024-06-13T08:02:32.705297778Z","modified":"2024-06-28T08:05:16.492154408Z","checksum":"f1115741a4bd3dc0184ecdb718027e941306febaaf74d5e76c65a5e90615295f"},
    {"filename":"asuoudgb.md","filenameStem":"asuoudgb","path":"asuoudgb.md","absPath":"/home/khadd/mynotes/asuoudgb.md","title":"Linux DMA APIs","link":"[[asuoudgb]]","lead":"There are two types of DMA mappings, streaming and consistent. Streaming are\nmapped for one DMA transfer, then unmapped right after. This mean only one party\ncan access the DMA memory at a time. Consistent/coherent remains mapped\nthroughout execution, allowing both side access.","body":"There are two types of DMA mappings, streaming and consistent. Streaming are\nmapped for one DMA transfer, then unmapped right after. This mean only one party\ncan access the DMA memory at a time. Consistent/coherent remains mapped\nthroughout execution, allowing both side access.\n\nAPI interaction with IOMMU [[hxm4jt6e]]:\n\n- `dma_map` Initialize the transaction. It takes a buffer address, size and\n  access rights, allocate an IOVA from the device address space, then create a\n  mapping in the device's IOMMU page table. An IOVA address is returned to the\n  caller. The control of the buffer is now belong to the device.\n- `dma_unmap` Ends the transaction. It takes IOVA address, unmap the buffer\n  inside IOMMU page table, returns the address range IOVA space. Now the device\n  is not able to access the buffer, and the driver can read data from it.\n- `dma_alloc_coherent`/ `dma_free_coherent` allocate/free memory accessible by\n  both device and OS (remained mapped in IOMMU). Useful in implementing\n  descriptor rings, mailboxes.\n\n- [linux-dma]: https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt","snippets":["There are two types of DMA mappings, streaming and consistent. Streaming are\nmapped for one DMA transfer, then unmapped right after. This mean only one party\ncan access the DMA memory at a time. Consistent/coherent remains mapped\nthroughout execution, allowing both side access."],"rawContent":"# Linux DMA APIs\n\nThere are two types of DMA mappings, streaming and consistent. Streaming are\nmapped for one DMA transfer, then unmapped right after. This mean only one party\ncan access the DMA memory at a time. Consistent/coherent remains mapped\nthroughout execution, allowing both side access.\n\nAPI interaction with IOMMU [[hxm4jt6e]]:\n\n- `dma_map` Initialize the transaction. It takes a buffer address, size and\n  access rights, allocate an IOVA from the device address space, then create a\n  mapping in the device's IOMMU page table. An IOVA address is returned to the\n  caller. The control of the buffer is now belong to the device.\n- `dma_unmap` Ends the transaction. It takes IOVA address, unmap the buffer\n  inside IOMMU page table, returns the address range IOVA space. Now the device\n  is not able to access the buffer, and the driver can read data from it.\n- `dma_alloc_coherent`/ `dma_free_coherent` allocate/free memory accessible by\n  both device and OS (remained mapped in IOMMU). Useful in implementing\n  descriptor rings, mailboxes.\n\n- [linux-dma]: https://www.kernel.org/doc/Documentation/DMA-API-HOWTO.txt\n","wordCount":167,"tags":[],"metadata":{},"created":"2024-12-10T05:04:13.352555991Z","modified":"2024-12-10T05:40:15.35951549Z","checksum":"33dc1b532f50d1050cb0e9dc84f97f8ec55855948fb9599e4149d88a287ad904"},
    {"filename":"y1vxikqo.md","filenameStem":"y1vxikqo","path":"y1vxikqo.md","absPath":"/home/khadd/mynotes/y1vxikqo.md","title":"Linux File System","link":"[[y1vxikqo]]","lead":"#linux #os #file-system","body":"#linux #os #file-system\n\n## Metadata\n\n- `superblock` define metadata about file system\n- `inode` represents metadata about files.\n- `dentry` link between file path and `inodes`\n\n## Data\n\n- `file` is a block of bytes on the disk.","snippets":["#linux #os #file-system"],"rawContent":"# Linux File System\n\n#linux #os #file-system\n\n## Metadata\n\n- `superblock` define metadata about file system\n- `inode` represents metadata about files.\n- `dentry` link between file path and `inodes`\n\n## Data\n\n- `file` is a block of bytes on the disk.\n","wordCount":42,"tags":["os","linux","file-system"],"metadata":{},"created":"2024-07-03T06:37:54.633419841Z","modified":"2024-07-03T06:40:02.061585555Z","checksum":"83fab9ebe44d1a2b401ce782f30d1c2c9753d1e666db636d8ed0635b32d70812"},
    {"filename":"q3de57f9.md","filenameStem":"q3de57f9","path":"q3de57f9.md","absPath":"/home/khadd/mynotes/q3de57f9.md","title":"Linux Networking Stack","link":"[[q3de57f9]]","lead":"#os #io","body":"#os #io\n\n- More about the networking stack\n  https://wiki.linuxfoundation.org/networking/start\n\n![network stack](https://upload.wikimedia.org/wikipedia/commons/3/37/Netfilter-packet-flow.svg)","snippets":["#os #io"],"rawContent":"# Linux Networking Stack\n\n#os #io\n\n- More about the networking stack\n  https://wiki.linuxfoundation.org/networking/start\n\n![network stack](https://upload.wikimedia.org/wikipedia/commons/3/37/Netfilter-packet-flow.svg)\n","wordCount":15,"tags":["os","io"],"metadata":{},"created":"2024-12-03T08:57:00.067167477Z","modified":"2024-12-18T10:10:17.357981597Z","checksum":"0a20c0faa809a26a42c6221f19100506b24d05be8c9d47dc923b3732dc4bb1c2"},
    {"filename":"nobagcn6.md","filenameStem":"nobagcn6","path":"nobagcn6.md","absPath":"/home/khadd/mynotes/nobagcn6.md","title":"Linux Support for SEV-SNP","link":"[[nobagcn6]]","lead":"#linux #sev","body":"#linux #sev\n\n\n# Guest\n\n# Kernel\n- [amd-memory-encryption](https://www.kernel.org/doc/Documentation/virt/kvm/amd-memory-encryption.rst)\n- The patch for hypervisor support is found [here](https://lwn.net/Articles/923844/)","snippets":["#linux #sev"],"rawContent":"# Linux Support for SEV-SNP\n#linux #sev\n\n\n# Guest\n\n# Kernel\n- [amd-memory-encryption](https://www.kernel.org/doc/Documentation/virt/kvm/amd-memory-encryption.rst)\n- The patch for hypervisor support is found [here](https://lwn.net/Articles/923844/) \n\n\n","wordCount":22,"tags":["linux","sev"],"metadata":{},"created":"2023-06-19T05:34:27.373501309Z","modified":"2024-05-20T08:53:45.510671971Z","checksum":"342edfdfc5064fcd68afdbbe075df26045a416d46a590dbdbe19153e70bbed4f"},
    {"filename":"w4gmjm7a.md","filenameStem":"w4gmjm7a","path":"w4gmjm7a.md","absPath":"/home/khadd/mynotes/w4gmjm7a.md","title":"Linux exception table","link":"[[w4gmjm7a]]","lead":"#linux","body":"#linux\n\nThe exception table is used in Linux to handle faults in userspace access (e.g.,\nthrough `get_user`). The point is to delay the checking of safe user access\nuntil a page fault.\n\nOn a user access, one of 4 scenarios may occur:\n\n1. Accessible, nothing is wrong\n2. Inaccessible, but the address is in the user process's VMA\n3. Inaccessible, and the address is NOT in user process's VMA, and\n      1. The faulting instruction is in the exception table\n      2. The faulting instruction is NOT in the exception table\n\nIn cases 2 and 3, the page fault handler is invoked due to permission\nerrors/unmapped pages. Case 2 is treated as normal user space page fault, so the\npage fault handler maps the address.\n\nFor case 3, the kernel now must determine if the inaccessible instruction is\nrecoverable. If exception happens from userspace memory access, kernel should be\nable to recover from it. Exception table allows the kernel to register custom\nexection handler for these user access sites to handle case 3.1.\n\nFor case 3.2, the user access is done at an unknown site.\n\n`do_user_addr_fault`\n\n```c\n /*\n  * Kernel-mode access to the user address space should only occur\n  * on well-defined single instructions listed in the exception\n  * tables.  But, an erroneous kernel fault occurring outside one of\n  * those areas which also holds mmap_lock might deadlock attempting\n  * to validate the fault against the address space.\n  *\n  * Only do the expensive exception table search when we might be at\n  * risk of a deadlock.  This happens if we\n  * 1. Failed to acquire mmap_lock, and\n  * 2. The access did not originate in userspace.\n  */\n if (unlikely(!mmap_read_trylock(mm))) {\n   if (!user_mode(regs) \u0026\u0026 !search_exception_tables(regs-\u003eip)) {\n     /*\n      * Fault from code in kernel from\n      * which we do not expect faults.\n      */\n     bad_area_nosemaphore(regs, error_code, address);\n     return;\n   }\n   /* ... */\n }\n```\n\n## Exception table\n\nIn Linux's source code:\n\n```c\n/*\n * The exception table consists of two addresses relative to the\n * exception table entry itself and a type selector field.\n *\n * The first address is of an instruction that is allowed to fault, the\n * second is the target at which the program should continue.\n *\n * The type entry is used by fixup_exception() to select the handler to\n * deal with the fault caused by the instruction in the first field.\n *\n * All the routines below use bits of fixup code that are out of line\n * with the main instruction path.  This means when everything is well,\n * we don't even have to jump over them.  Further, they do not intrude\n * on our cache or tlb entries.\n */\n\nstruct exception_table_entry {\n  int insn, fixup, data;\n};\n```\n\nAt every user access site, an entry to the exception table is registered. e.g..\n\n```c\n#define __get_user_asm(x, addr, itype, ltype, label)                           \\\n  asm_volatile_goto(\"\\n\"                                                       \\\n                    \"1: mov\" itype                                             \\\n                    \" %[umem],%[output]\\n\" _ASM_EXTABLE_UA(1b, % l2)           \\\n                    : [output] ltype(x)                                        \\\n                    : [umem] \"m\"(__m(addr))                                    \\\n                    :                                                          \\\n                    : label)\n```\n\nThe kernel linker script `vmlinux.lds.h` collects these entries into the\n`__ex_table` symbol:\n\n```c\n*Exception table * /\n#define EXCEPTION_TABLE(align)                                                 \\\n  .= ALIGN(align);                                                             \\\n  __ex_table:                                                                  \\\n  AT(ADDR(__ex_table) - LOAD_OFFSET) {                                         \\\n    __start___ex_table =.;                                                     \\\n    KEEP(*(__ex_table))                                                        \\\n    __stop___ex_table =.;                                                      \\\n  }\n```\n\n## Reference\n\n- \u003chttps://www.kernel.org/doc/Documentation/x86/exception-tables.txt\u003e","snippets":["#linux"],"rawContent":"# Linux exception table\n\n#linux\n\nThe exception table is used in Linux to handle faults in userspace access (e.g.,\nthrough `get_user`). The point is to delay the checking of safe user access\nuntil a page fault.\n\nOn a user access, one of 4 scenarios may occur:\n\n1. Accessible, nothing is wrong\n2. Inaccessible, but the address is in the user process's VMA\n3. Inaccessible, and the address is NOT in user process's VMA, and\n      1. The faulting instruction is in the exception table\n      2. The faulting instruction is NOT in the exception table\n\nIn cases 2 and 3, the page fault handler is invoked due to permission\nerrors/unmapped pages. Case 2 is treated as normal user space page fault, so the\npage fault handler maps the address.\n\nFor case 3, the kernel now must determine if the inaccessible instruction is\nrecoverable. If exception happens from userspace memory access, kernel should be\nable to recover from it. Exception table allows the kernel to register custom\nexection handler for these user access sites to handle case 3.1.\n\nFor case 3.2, the user access is done at an unknown site.\n\n`do_user_addr_fault`\n\n```c\n /*\n  * Kernel-mode access to the user address space should only occur\n  * on well-defined single instructions listed in the exception\n  * tables.  But, an erroneous kernel fault occurring outside one of\n  * those areas which also holds mmap_lock might deadlock attempting\n  * to validate the fault against the address space.\n  *\n  * Only do the expensive exception table search when we might be at\n  * risk of a deadlock.  This happens if we\n  * 1. Failed to acquire mmap_lock, and\n  * 2. The access did not originate in userspace.\n  */\n if (unlikely(!mmap_read_trylock(mm))) {\n   if (!user_mode(regs) \u0026\u0026 !search_exception_tables(regs-\u003eip)) {\n     /*\n      * Fault from code in kernel from\n      * which we do not expect faults.\n      */\n     bad_area_nosemaphore(regs, error_code, address);\n     return;\n   }\n   /* ... */\n }\n```\n\n## Exception table\n\nIn Linux's source code:\n\n```c\n/*\n * The exception table consists of two addresses relative to the\n * exception table entry itself and a type selector field.\n *\n * The first address is of an instruction that is allowed to fault, the\n * second is the target at which the program should continue.\n *\n * The type entry is used by fixup_exception() to select the handler to\n * deal with the fault caused by the instruction in the first field.\n *\n * All the routines below use bits of fixup code that are out of line\n * with the main instruction path.  This means when everything is well,\n * we don't even have to jump over them.  Further, they do not intrude\n * on our cache or tlb entries.\n */\n\nstruct exception_table_entry {\n  int insn, fixup, data;\n};\n```\n\nAt every user access site, an entry to the exception table is registered. e.g..\n\n```c\n#define __get_user_asm(x, addr, itype, ltype, label)                           \\\n  asm_volatile_goto(\"\\n\"                                                       \\\n                    \"1: mov\" itype                                             \\\n                    \" %[umem],%[output]\\n\" _ASM_EXTABLE_UA(1b, % l2)           \\\n                    : [output] ltype(x)                                        \\\n                    : [umem] \"m\"(__m(addr))                                    \\\n                    :                                                          \\\n                    : label)\n```\n\nThe kernel linker script `vmlinux.lds.h` collects these entries into the\n`__ex_table` symbol:\n\n```c\n*Exception table * /\n#define EXCEPTION_TABLE(align)                                                 \\\n  .= ALIGN(align);                                                             \\\n  __ex_table:                                                                  \\\n  AT(ADDR(__ex_table) - LOAD_OFFSET) {                                         \\\n    __start___ex_table =.;                                                     \\\n    KEEP(*(__ex_table))                                                        \\\n    __stop___ex_table =.;                                                      \\\n  }\n```\n\n## Reference\n\n- \u003chttps://www.kernel.org/doc/Documentation/x86/exception-tables.txt\u003e\n","wordCount":547,"tags":["linux"],"metadata":{},"created":"2024-06-26T09:44:04.95657898Z","modified":"2024-06-26T10:16:18.385284858Z","checksum":"574050fdfd135023d6bd9730f7dc5ffab790e167b100099452ddae033bb39cbc"},
    {"filename":"0igotm4i.md","filenameStem":"0igotm4i","path":"0igotm4i.md","absPath":"/home/khadd/mynotes/0igotm4i.md","title":"Linux poweruser","link":"[[0igotm4i]]","lead":"#area #index-area","body":"#area #index-area\n\n- [[k57qb7oh]]","snippets":["#area #index-area"],"rawContent":"# Linux poweruser\n\n#area #index-area\n\n- [[k57qb7oh]]\n","wordCount":7,"tags":["area","index-area"],"metadata":{},"created":"2024-05-22T08:24:03.202374142Z","modified":"2024-07-05T06:55:51.909435405Z","checksum":"29001f34cc941345a9e3a4a8227a528d70fb9d2c3c77a808beaf0d18cec39e60"},
    {"filename":"gk3t1doe.md","filenameStem":"gk3t1doe","path":"gk3t1doe.md","absPath":"/home/khadd/mynotes/gk3t1doe.md","title":"Linux thrashing on OOM","link":"[[gk3t1doe]]","lead":"#linux-user #distro #arch","body":"#linux-user #distro #arch\n\nOn linux, when swap is enabled, sometimes the system becomes unresponsive when\nthe memory use is high. This is because of continuous swapping of memory that\nlocks the system.\n\n## EarlyOOM\n\nEarlyOOM utility kills the process before the system goes into thrashing.\n\n- \u003chttps://fedoraproject.org/wiki/Changes/EnableEarlyoom\u003e\n- \u003chttps://github.com/rfjakob/earlyoom\u003e\n\nIn arch it can be enabled through package earlyoom\n\n```bash\nsudo pacman -S earlyoom\nsystemctl enable earlyoom\nsystemctl start earlyoom\n```","snippets":["#linux-user #distro #arch"],"rawContent":"# Linux thrashing on OOM\n\n#linux-user #distro #arch\n\nOn linux, when swap is enabled, sometimes the system becomes unresponsive when\nthe memory use is high. This is because of continuous swapping of memory that\nlocks the system.\n\n## EarlyOOM\n\nEarlyOOM utility kills the process before the system goes into thrashing.\n\n- \u003chttps://fedoraproject.org/wiki/Changes/EnableEarlyoom\u003e\n- \u003chttps://github.com/rfjakob/earlyoom\u003e\n\nIn arch it can be enabled through package earlyoom\n\n```bash\nsudo pacman -S earlyoom\nsystemctl enable earlyoom\nsystemctl start earlyoom\n```\n","wordCount":75,"tags":["distro","arch","linux-user"],"metadata":{},"created":"2024-06-20T05:23:21.358586874Z","modified":"2024-06-20T05:28:33.485451476Z","checksum":"010bb437323f31488bace36c50b7ba4b6fc086e2b1ac12de59b9e82b2ddbd673"},
    {"filename":"cn9u3d79.md","filenameStem":"cn9u3d79","path":"cn9u3d79.md","absPath":"/home/khadd/mynotes/cn9u3d79.md","title":"Linux's kernel page table","link":"[[cn9u3d79]]","lead":"#linux #os","body":"#linux #os\n\nLinux's kernel image is direct-mapped to the virtual address space. Physical addresses within the kernel can be translated into virtual addresses by simply adding a `PAGE_OFFSET`\n\n```c\n// in asm/page.h\n#define __va(x)\t\t\t((void *)((unsigned long)(x)+PAGE_OFFSET))\n\n// in asm/io.h\nstatic inline void *phys_to_virt(phys_addr_t address)\n{\n\treturn __va(address);\n}\n```\n\n# References\n- [understand006](https://www.kernel.org/doc/gorman/html/understand/understand006.html)","snippets":["#linux #os"],"rawContent":"# Linux's kernel page table\n#linux #os\n\nLinux's kernel image is direct-mapped to the virtual address space. Physical addresses within the kernel can be translated into virtual addresses by simply adding a `PAGE_OFFSET`\n\n```c\n// in asm/page.h\n#define __va(x)\t\t\t((void *)((unsigned long)(x)+PAGE_OFFSET))\n\n// in asm/io.h\nstatic inline void *phys_to_virt(phys_addr_t address)\n{\n\treturn __va(address);\n}\n```\n\n# References\n- [understand006](https://www.kernel.org/doc/gorman/html/understand/understand006.html)\n","wordCount":59,"tags":["os","linux"],"metadata":{},"created":"2023-07-06T02:37:17.661608506Z","modified":"2023-07-20T08:50:35.155839415Z","checksum":"47a43d9394e581d4309cd4d9537a7aa55b14180cf54fc5e2474d81e5dd85afd6"},
    {"filename":"l80vag29.md","filenameStem":"l80vag29","path":"l80vag29.md","absPath":"/home/khadd/mynotes/l80vag29.md","title":"Low-Fat Pointers: Compact Encoding and Efficient Gate-Level Implementation of Fat Pointers for Spatial Safety and Capability-based Security","link":"[[l80vag29]]","lead":"#literature #capabilities [@kwon2013lowfat]","body":"#literature #capabilities [@kwon2013lowfat]\n\nURL: \u003chttps://dl.acm.org/doi/pdf/10.1145/2508859.2516713\u003e\n\n## Context\n\nThis work introduces a new bound encoding scheme that encodes object-bound\ninformation into 64-bit pointers, and 46-bit address space. The claim is that it\nintroduces zero runtime overheads since the check is performed in parallel with\nthe access.\n\n### Background \u0026 related work\n\n- [@wulf1974hydra] HYDRA system and C.mmp processor combine pointers and access\n  right\n- [guarded pointers]:","snippets":["#literature #capabilities [@kwon2013lowfat]"],"rawContent":"# Low-Fat Pointers: Compact Encoding and Efficient Gate-Level Implementation of Fat Pointers for Spatial Safety and Capability-based Security\n\n#literature #capabilities [@kwon2013lowfat]\n\nURL: \u003chttps://dl.acm.org/doi/pdf/10.1145/2508859.2516713\u003e\n\n## Context\n\nThis work introduces a new bound encoding scheme that encodes object-bound\ninformation into 64-bit pointers, and 46-bit address space. The claim is that it\nintroduces zero runtime overheads since the check is performed in parallel with\nthe access.\n\n### Background \u0026 related work\n\n- [@wulf1974hydra] HYDRA system and C.mmp processor combine pointers and access\n  right\n- [guarded pointers]:\n","wordCount":83,"tags":["literature","capabilities"],"metadata":{},"created":"2024-05-22T08:24:03.276365674Z","modified":"2024-06-22T14:37:58.411176807Z","checksum":"4a64a19a36cb8a6b3d6c43bcd52895a610c756236caa3bf4fd390f0ad3223ad7"},
    {"filename":"8qvweuj8.md","filenameStem":"8qvweuj8","path":"8qvweuj8.md","absPath":"/home/khadd/mynotes/8qvweuj8.md","title":"Memory Encryption vs. Access Control","link":"[[8qvweuj8]]","lead":"TEEs often uses a combination of access control and automatic memory encryption\nto achieve confidentiality and integrity. For software attacks, access control\nis sufficient.","body":"TEEs often uses a combination of access control and automatic memory encryption\nto achieve confidentiality and integrity. For software attacks, access control\nis sufficient.\n\nAccess control prevent subjects that use the shared CPU to access shared memory.\nHardware DMA accesses also have a kind of access control through the IOMMU\n[[hxm4jt6e]] [@feng2024siopmp] [@sang2024portal].\n\nMemory encryption is useful against attackers with very high capabilities that\nbypass the CPU (e.g., hardware attacks on DRAM or bus snooping\n[@lee2020offchip]).\n\nHowever, doing _both_ at the same time may be redundant if the assumption of\nhardware attack is not practical. For example, on mobile SoC, every component is\nbaked into the chip and there also some kind of hardware tamper detection, so\ninserting probe into the SoC is very unlikely [@sang2024portal].\n\nEspecially, _memory encryption is not free_, as it needs (1) CPU acceleration\nfor encryption and (2) the device to also support decryption for I/O case. In\nthese scenarios, getting rid of memory encryption and adding more comprehensive\naccess control is a more practical choice [@sang2024portal].","snippets":["TEEs often uses a combination of access control and automatic memory encryption\nto achieve confidentiality and integrity. For software attacks, access control\nis sufficient."],"rawContent":"# Memory Encryption vs. Access Control\n\nTEEs often uses a combination of access control and automatic memory encryption\nto achieve confidentiality and integrity. For software attacks, access control\nis sufficient.\n\nAccess control prevent subjects that use the shared CPU to access shared memory.\nHardware DMA accesses also have a kind of access control through the IOMMU\n[[hxm4jt6e]] [@feng2024siopmp] [@sang2024portal].\n\nMemory encryption is useful against attackers with very high capabilities that\nbypass the CPU (e.g., hardware attacks on DRAM or bus snooping\n[@lee2020offchip]).\n\nHowever, doing _both_ at the same time may be redundant if the assumption of\nhardware attack is not practical. For example, on mobile SoC, every component is\nbaked into the chip and there also some kind of hardware tamper detection, so\ninserting probe into the SoC is very unlikely [@sang2024portal].\n\nEspecially, _memory encryption is not free_, as it needs (1) CPU acceleration\nfor encryption and (2) the device to also support decryption for I/O case. In\nthese scenarios, getting rid of memory encryption and adding more comprehensive\naccess control is a more practical choice [@sang2024portal].\n","wordCount":177,"tags":[],"metadata":{},"created":"2024-12-02T08:43:57.567086387Z","modified":"2024-12-10T05:00:43.773607024Z","checksum":"e07da081d2ba13b2fc54761facf48b2d890f9fb576771ee7830dc020e03bcc39"},
    {"filename":"ouv5s2fi.md","filenameStem":"ouv5s2fi","path":"ouv5s2fi.md","absPath":"/home/khadd/mynotes/ouv5s2fi.md","title":"Memory errors in Rust","link":"[[ouv5s2fi]]","lead":"#memory-safety #rust","body":"#memory-safety #rust\n\nRust seems like a memory-safe language, but due to the prevalent use of unsafe,\nmemory corruption is quite common. In fact, except from compiler-introduced\nbugs, _all_ of memory errors in Rust are triggered by unsafe (insight 4,\n[@astrauskas2020how], [@xu2021memorysafety]).\n\nUnsafe Rust can trigger both spatial and temporal memory safety violation.\n\nMany of the bugs do not contain memory error, but only introduce unsoundness\nthat violate Rust's memory safety @xu2021memorysafety.\n\n## Spatial safety\n\n### Integer overflow\n\nA lot of bugs are triggered by integer overflow, where the calculation for\nbuffer size may overflow, leads to allocating a smaller buffer than expected.\n\nSince all dynamic array accesses in _safe_ Rust are bound-checked, such bug can\nonly trigger for in cases where the array is used later in unsafe code\n[@hua2021rupair]. More specifically, only the pattern unsafe-\u003eunsafe and\nsafe-\u003eunsafe (LHS: cause, RHS: effect) can trigger memory safety error with this\nbug.\n\nIn debug mode, integer overflow is checked at both compile-time (e.g.,\n`u8 = 255 + 1` is not possile) and runtime. However, there is no runtime check\nin release mode.\n\nHere is an example for unsafe-\u003esafe case:\n\n```rust\nfn foo(int i, int j){\n  // may have integer overflow\n  let buf = Vec::with_capacity(i + j);\n  unsafe {\n    // May be out-of-bound access\n    let p = buf2.as_ptr();\n    *(p + i + 100) = 20;\n  }\n}\n```\n\n#### CVE-2017-1000430 : integer overflow to heap-based buffer overflow in encode_config_buf\n\n```rust\n// Many possible integer overflow here\nfn encoded_size(bytes_len: usize, config: Config) -\u003e usize {\n  let rem = bytes_len % 3;\n\n  let complete_input_chunks = bytes_len / 3;\n  let complete_output_chars = complete_input_chunks * 4;\n  let printing_output_chars = if rem == 0 {\n    complete_output_chars\n  } else {\n    complete_output_chars + 4\n  };\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e 0,\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e printing_output_chars / n * 2,\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e printing_output_chars / n,\n  };\n  return printing_output_chars + line_ending_output_chars;\n}\npub fn encode_config\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config) -\u003e String {\n  // Integer overflow\n  let mut buf = String::with_capacity(encoded_size(input.as_ref().len(), config));\n  encode_config_buf(input, config, \u0026mut buf);\n  buf\n}\n\npub fn encode_config_buf\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config, buf: \u0026mut String) {\n  //...\n  // Another possible integer overflow\n  buf.reserve(encoded_size(input_bytes.len(), config));\n  // ...\n  let mut raw = unsafe { buf.as_mut_vec() };\n\n  // ...\n  // May access out-of-bound here due to unsafe !?!?!?!??!?!?!?!\n  let mut output_ptr = unsafe { raw.as_mut_ptr().offset(orig_buf_len as isize) };\n  let mut input_index: usize = 0;\n  if input_bytes.len() \u003e= 8 {\n    while input_index \u003c= last_fast_index {\n      let input_chunk = BigEndian::read_u64(\u0026input_bytes[input_index..(input_index + 8)]);\n      // strip off 6 bits at a time for the first 6 bytes\n      unsafe {\n        std::ptr::write(output_ptr, charset[((input_chunk \u003e\u003e 58) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(1), charset[((input_chunk \u003e\u003e 52) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(2), charset[((input_chunk \u003e\u003e 46) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(3), charset[((input_chunk \u003e\u003e 40) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(4), charset[((input_chunk \u003e\u003e 34) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(5), charset[((input_chunk \u003e\u003e 28) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(6), charset[((input_chunk \u003e\u003e 22) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(7), charset[((input_chunk \u003e\u003e 16) \u0026 0x3F) as usize]);\n        output_ptr = output_ptr.offset(8);\n      }\n      input_index += input_chunk_len;\n      fast_loop_output_buf_len += 8;\n    }\n  }\n  unsafe {\n    // expand len to include the bytes we just wrote\n    raw.set_len(fast_loop_output_buf_len);\n  }\n}\n```\n\nThe function `encoded_size` is used to calculate size for allocation. However,\nit could silently have integer overflow. In `encode_config` a buffer is\nallocated using the calculated size.\n\nThe fix for this is to use overflow-checked arithmetics. The patch for this\nchanges the function to return `None` if overflow is detected:\n\n```rust\nfn encoded_size(bytes_len: usize, config: Config) -\u003e Option\u003cusize\u003e {\n  let printing_output_chars = bytes_len\n    .checked_add(2)\n    .map(|x| x / 3)\n    .and_then(|x| x.checked_mul(4));\n\n  //TODO this is subtly wrong but in a not dangerous way\n  //pushing patch with identical to previous behavior, then fixing\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e Some(0),\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e\n      printing_output_chars.map(|y| y / n).and_then(|y| y.checked_mul(2)),\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e\n      printing_output_chars.map(|y| y / n),\n  };\n\n  printing_output_chars.and_then(|x|\n    line_ending_output_chars.and_then(|y| x.checked_add(y))\n  )\n}\n```\n\n### Wrong usage of unsafe API\n\n#### CVE-2018-21000: Vec-to-vec transmutations could lead to heap overflow/corruption\n\n```rust\n// Error\nVec::from_raw_parts(ptr as *mut T, capacity, len)\n// Fixed\nVec::from_raw_parts(ptr as *mut T, len, capacity)\n```\n\nThe above CVE swap the capacity and len arguments, which could lead to buffer\noverflow.\n\n## Temporal safety\n\n### Lifetime corruption\n\nUnsafe Rust can corrupt the ownership system by making invalid pointers or\nmutable aliases. Such pointers may propagate to the safe world, and is\nautomatically freed by the ownership system, causing double-free or\nuse-after-free.\n\n#### CVE-2019-16140: dangling pointer created by unsafe\n\n```rust\nfn from(buffer: Buffer) -\u003e Vec\u003cu8\u003e {\n  let mut slice = Buffer::allocate(buffer.len);\n  let len = buffer.copy_to(\u0026mut slice);\n  unsafe {\n    Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len())\n  }\n}\n```\n\nThe above example from CVE-2019-16140 shows an example of lifetime corruption.\nIn the example, `Vec::from_raw_parts` on line 5 obtain the ownership of `slice`\nallocated at line 2, and return the created `Vec`. This violate Rust ownership;\nline 5 and line 2 now share ownership to the underlying slice. When the function\nreturns, `slice` at line 2 is automatically dropped. Any access to the returned\nvalue of `from` will now become use-after-free.\n\nThe fix to this is simple, `mem::forget` must be added to forget the previous\nslice (so that it will not be dropped after), before its ownership is being\ntaken by constructing a new Vec.\n\n```rust\nunsafe {\n  let vec = Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len());\n  mem::forget(slice);\n  vec\n}\n```\n\nIn all, the cause of this bug is the use of raw pointer that bypass Rust\nownership protection.\n\n#### More\n\nMore examples are CVE-2019-15552 and CVE-2019-15553.\n\n## Panic/unwind safety\n\nAnother common memory issue is the unwinding code triggering unsound behaviors.","snippets":["#memory-safety #rust"],"rawContent":"# Memory errors in Rust\n\n#memory-safety #rust\n\nRust seems like a memory-safe language, but due to the prevalent use of unsafe,\nmemory corruption is quite common. In fact, except from compiler-introduced\nbugs, _all_ of memory errors in Rust are triggered by unsafe (insight 4,\n[@astrauskas2020how], [@xu2021memorysafety]).\n\nUnsafe Rust can trigger both spatial and temporal memory safety violation.\n\nMany of the bugs do not contain memory error, but only introduce unsoundness\nthat violate Rust's memory safety @xu2021memorysafety.\n\n## Spatial safety\n\n### Integer overflow\n\nA lot of bugs are triggered by integer overflow, where the calculation for\nbuffer size may overflow, leads to allocating a smaller buffer than expected.\n\nSince all dynamic array accesses in _safe_ Rust are bound-checked, such bug can\nonly trigger for in cases where the array is used later in unsafe code\n[@hua2021rupair]. More specifically, only the pattern unsafe-\u003eunsafe and\nsafe-\u003eunsafe (LHS: cause, RHS: effect) can trigger memory safety error with this\nbug.\n\nIn debug mode, integer overflow is checked at both compile-time (e.g.,\n`u8 = 255 + 1` is not possile) and runtime. However, there is no runtime check\nin release mode.\n\nHere is an example for unsafe-\u003esafe case:\n\n```rust\nfn foo(int i, int j){\n  // may have integer overflow\n  let buf = Vec::with_capacity(i + j);\n  unsafe {\n    // May be out-of-bound access\n    let p = buf2.as_ptr();\n    *(p + i + 100) = 20;\n  }\n}\n```\n\n#### CVE-2017-1000430 : integer overflow to heap-based buffer overflow in encode_config_buf\n\n```rust\n// Many possible integer overflow here\nfn encoded_size(bytes_len: usize, config: Config) -\u003e usize {\n  let rem = bytes_len % 3;\n\n  let complete_input_chunks = bytes_len / 3;\n  let complete_output_chars = complete_input_chunks * 4;\n  let printing_output_chars = if rem == 0 {\n    complete_output_chars\n  } else {\n    complete_output_chars + 4\n  };\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e 0,\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e printing_output_chars / n * 2,\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e printing_output_chars / n,\n  };\n  return printing_output_chars + line_ending_output_chars;\n}\npub fn encode_config\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config) -\u003e String {\n  // Integer overflow\n  let mut buf = String::with_capacity(encoded_size(input.as_ref().len(), config));\n  encode_config_buf(input, config, \u0026mut buf);\n  buf\n}\n\npub fn encode_config_buf\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config, buf: \u0026mut String) {\n  //...\n  // Another possible integer overflow\n  buf.reserve(encoded_size(input_bytes.len(), config));\n  // ...\n  let mut raw = unsafe { buf.as_mut_vec() };\n\n  // ...\n  // May access out-of-bound here due to unsafe !?!?!?!??!?!?!?!\n  let mut output_ptr = unsafe { raw.as_mut_ptr().offset(orig_buf_len as isize) };\n  let mut input_index: usize = 0;\n  if input_bytes.len() \u003e= 8 {\n    while input_index \u003c= last_fast_index {\n      let input_chunk = BigEndian::read_u64(\u0026input_bytes[input_index..(input_index + 8)]);\n      // strip off 6 bits at a time for the first 6 bytes\n      unsafe {\n        std::ptr::write(output_ptr, charset[((input_chunk \u003e\u003e 58) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(1), charset[((input_chunk \u003e\u003e 52) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(2), charset[((input_chunk \u003e\u003e 46) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(3), charset[((input_chunk \u003e\u003e 40) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(4), charset[((input_chunk \u003e\u003e 34) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(5), charset[((input_chunk \u003e\u003e 28) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(6), charset[((input_chunk \u003e\u003e 22) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(7), charset[((input_chunk \u003e\u003e 16) \u0026 0x3F) as usize]);\n        output_ptr = output_ptr.offset(8);\n      }\n      input_index += input_chunk_len;\n      fast_loop_output_buf_len += 8;\n    }\n  }\n  unsafe {\n    // expand len to include the bytes we just wrote\n    raw.set_len(fast_loop_output_buf_len);\n  }\n}\n```\n\nThe function `encoded_size` is used to calculate size for allocation. However,\nit could silently have integer overflow. In `encode_config` a buffer is\nallocated using the calculated size.\n\nThe fix for this is to use overflow-checked arithmetics. The patch for this\nchanges the function to return `None` if overflow is detected:\n\n```rust\nfn encoded_size(bytes_len: usize, config: Config) -\u003e Option\u003cusize\u003e {\n  let printing_output_chars = bytes_len\n    .checked_add(2)\n    .map(|x| x / 3)\n    .and_then(|x| x.checked_mul(4));\n\n  //TODO this is subtly wrong but in a not dangerous way\n  //pushing patch with identical to previous behavior, then fixing\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e Some(0),\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e\n      printing_output_chars.map(|y| y / n).and_then(|y| y.checked_mul(2)),\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e\n      printing_output_chars.map(|y| y / n),\n  };\n\n  printing_output_chars.and_then(|x|\n    line_ending_output_chars.and_then(|y| x.checked_add(y))\n  )\n}\n```\n\n### Wrong usage of unsafe API\n\n#### CVE-2018-21000: Vec-to-vec transmutations could lead to heap overflow/corruption\n\n```rust\n// Error\nVec::from_raw_parts(ptr as *mut T, capacity, len)\n// Fixed\nVec::from_raw_parts(ptr as *mut T, len, capacity)\n```\n\nThe above CVE swap the capacity and len arguments, which could lead to buffer\noverflow.\n\n## Temporal safety\n\n### Lifetime corruption\n\nUnsafe Rust can corrupt the ownership system by making invalid pointers or\nmutable aliases. Such pointers may propagate to the safe world, and is\nautomatically freed by the ownership system, causing double-free or\nuse-after-free.\n\n#### CVE-2019-16140: dangling pointer created by unsafe\n\n```rust\nfn from(buffer: Buffer) -\u003e Vec\u003cu8\u003e {\n  let mut slice = Buffer::allocate(buffer.len);\n  let len = buffer.copy_to(\u0026mut slice);\n  unsafe {\n    Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len())\n  }\n}\n```\n\nThe above example from CVE-2019-16140 shows an example of lifetime corruption.\nIn the example, `Vec::from_raw_parts` on line 5 obtain the ownership of `slice`\nallocated at line 2, and return the created `Vec`. This violate Rust ownership;\nline 5 and line 2 now share ownership to the underlying slice. When the function\nreturns, `slice` at line 2 is automatically dropped. Any access to the returned\nvalue of `from` will now become use-after-free.\n\nThe fix to this is simple, `mem::forget` must be added to forget the previous\nslice (so that it will not be dropped after), before its ownership is being\ntaken by constructing a new Vec.\n\n```rust\nunsafe {\n  let vec = Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len());\n  mem::forget(slice);\n  vec\n}\n```\n\nIn all, the cause of this bug is the use of raw pointer that bypass Rust\nownership protection.\n\n#### More\n\nMore examples are CVE-2019-15552 and CVE-2019-15553.\n\n## Panic/unwind safety\n\nAnother common memory issue is the unwinding code triggering unsound behaviors.\n","wordCount":926,"tags":["rust","memory-safety"],"metadata":{},"created":"2023-06-14T03:24:35.052210621Z","modified":"2024-06-20T08:59:29.416060705Z","checksum":"cc134413916ba9c4d074119a5d891ce6226025b020cb5e0fead3e63a9e830de7"},
    {"filename":"sn99wrm0.md","filenameStem":"sn99wrm0","path":"sn99wrm0.md","absPath":"/home/khadd/mynotes/sn99wrm0.md","title":"Microkernels","link":"[[sn99wrm0]]","lead":"#os","body":"#os\n\nThe microkernel is a minimized OS layer that only implement the minimal\n_mechanisms_ [[8113ygxd]] for safe multiplexing and interactions, while letting\nthe _policies_ being implemented in the userspace.\n\nThe three fundamental pieces of a microkernel are **address spaces** (memory\nmanagement), **scheduling** (time-share management), **inter-process**\ncommunication (IPC) (first conceptualized in [@liedtke1995microkernel]). Looking\nback at the goals of operating systems [[7t4jlnaq]], these are the minimum\nabstraction to achieve them.\n\n- **Scheduling**: Kernel only implement context switching mechanisms and\n  interruption. Scheduling decisions is implemented in userspace.\n- **Memory management**: Memory allocation policies, e.g., malloc, free are\n  implemented in userspace.\n- **IPC**: Message routing and services are implemented in userspace. The kernel\n  does not try to interpret the message content.\n\nMicrokernel offloads most the remaining functionality, e.g., device drivers,\nfile system, into the userspace. This contributes to the minimal kernel control\nplane, making formal verification feasible [@klein2009sel4].","snippets":["#os"],"rawContent":"# Microkernels\n\n#os\n\nThe microkernel is a minimized OS layer that only implement the minimal\n_mechanisms_ [[8113ygxd]] for safe multiplexing and interactions, while letting\nthe _policies_ being implemented in the userspace.\n\nThe three fundamental pieces of a microkernel are **address spaces** (memory\nmanagement), **scheduling** (time-share management), **inter-process**\ncommunication (IPC) (first conceptualized in [@liedtke1995microkernel]). Looking\nback at the goals of operating systems [[7t4jlnaq]], these are the minimum\nabstraction to achieve them.\n\n- **Scheduling**: Kernel only implement context switching mechanisms and\n  interruption. Scheduling decisions is implemented in userspace.\n- **Memory management**: Memory allocation policies, e.g., malloc, free are\n  implemented in userspace.\n- **IPC**: Message routing and services are implemented in userspace. The kernel\n  does not try to interpret the message content.\n\nMicrokernel offloads most the remaining functionality, e.g., device drivers,\nfile system, into the userspace. This contributes to the minimal kernel control\nplane, making formal verification feasible [@klein2009sel4].\n","wordCount":146,"tags":["os"],"metadata":{},"created":"2024-12-17T04:36:03.410761777Z","modified":"2024-12-23T05:53:09.633628907Z","checksum":"5b48f03057a2520280e11cf9518d3bccbb6585e92b129fb617c14a1201197410"},
    {"filename":"h6c34egw.md","filenameStem":"h6c34egw","path":"h6c34egw.md","absPath":"/home/khadd/mynotes/h6c34egw.md","title":"My nvim note taking workflow","link":"[[h6c34egw]]","lead":"#neovim #zettelkasten #note-taking","body":"#neovim #zettelkasten #note-taking\n\n[Zk](https://github.com/mickael-menu/zk) is a nice command-line application that\nhas minimalistic features to take zettelkasten-style [[ae6fatms]] notes. What I\nlike about Zk:\n\n- its seamless integration with neovim\n- plaintext storage with markdown\n\nIt is used in combination with\n[marksman LSP](https://github.com/artempyanykh/marksman) that provides a nice\nmarkdown editing experience.\n\n## Alternative\n\n- I tried the Obsidian app but found its UI distracting.\n\n## Missing features\n\n- Some reference and citation is needed\n- I tried vim-pandoc but haven't found success.","snippets":["#neovim #zettelkasten #note-taking"],"rawContent":"# My nvim note taking workflow\n\n#neovim #zettelkasten #note-taking\n\n[Zk](https://github.com/mickael-menu/zk) is a nice command-line application that\nhas minimalistic features to take zettelkasten-style [[ae6fatms]] notes. What I\nlike about Zk:\n\n- its seamless integration with neovim\n- plaintext storage with markdown\n\nIt is used in combination with\n[marksman LSP](https://github.com/artempyanykh/marksman) that provides a nice\nmarkdown editing experience.\n\n## Alternative\n\n- I tried the Obsidian app but found its UI distracting.\n\n## Missing features\n\n- Some reference and citation is needed\n- I tried vim-pandoc but haven't found success.\n","wordCount":86,"tags":["zettelkasten","neovim","note-taking"],"metadata":{},"created":"2023-05-05T05:46:12.290506095Z","modified":"2024-06-21T09:12:16.046180402Z","checksum":"15b9f328c0a09b1b12f08e0607f4126e6d5fc91f409b8d968b9cd509b17d529a"},
    {"filename":"s5ss13en.md","filenameStem":"s5ss13en","path":"s5ss13en.md","absPath":"/home/khadd/mynotes/s5ss13en.md","title":"Neccessary OS support for SEV","link":"[[s5ss13en]]","lead":"#sev","body":"#sev\n\n\n# Boot time\n\n# Related\n- [[llhmwuim]]\n- [[nobagcn6]]","snippets":["#sev"],"rawContent":"# Neccessary OS support for SEV\n#sev\n\n\n# Boot time\n\n# Related\n- [[llhmwuim]]\n- [[nobagcn6]]\n","wordCount":16,"tags":["sev"],"metadata":{},"created":"2023-08-24T05:20:05.062443572Z","modified":"2024-05-22T08:23:40.666608407Z","checksum":"9f284f47c8d2b308f3a8d54d0fee5b271ea15818c140670a990fa50b85e99647"},
    {"filename":"00nywxqx.md","filenameStem":"00nywxqx","path":"00nywxqx.md","absPath":"/home/khadd/mynotes/00nywxqx.md","title":"Neorg","link":"[[00nywxqx]]","lead":"Neorg seems like a nice format that solve same of markdown's downfalls:","body":"Neorg seems like a nice format that solve same of markdown's downfalls:\n\n- Does not use indent for list, instead the number of `-` correspond to the list\n  level\n\nDoes not support linking yet.","snippets":["Neorg seems like a nice format that solve same of markdown's downfalls:"],"rawContent":"# Neorg\n\nNeorg seems like a nice format that solve same of markdown's downfalls:\n\n- Does not use indent for list, instead the number of `-` correspond to the list\n  level\n\nDoes not support linking yet.\n","wordCount":36,"tags":[],"metadata":{},"created":"2024-11-08T08:09:58.96624369Z","modified":"2024-11-08T08:31:46.11570273Z","checksum":"011231508011e0c912c9295ce8235927479627ede4e5317ae757bb6b2fa05399"},
    {"filename":"98062o5k.md","filenameStem":"98062o5k","path":"98062o5k.md","absPath":"/home/khadd/mynotes/98062o5k.md","title":"Neovim plugin ideas","link":"[[98062o5k]]","lead":"# Margin notes","body":"# Margin notes\n\n- Tools such as zk reuse nvim diagnostics to display inline informations.\n- This is not ideal for note writing:\n  - Multiple annotations may be overlapped\n  - Distrations from the actual writing","snippets":["# Margin notes"],"rawContent":"# Neovim plugin ideas\n\n# Margin notes\n\n- Tools such as zk reuse nvim diagnostics to display inline informations.\n- This is not ideal for note writing:\n  - Multiple annotations may be overlapped\n  - Distrations from the actual writing\n","wordCount":39,"tags":[],"metadata":{},"created":"2024-10-24T03:51:41.403137913Z","modified":"2024-10-24T03:55:41.142320823Z","checksum":"234eae5e17492a1f8f023d0ef22e61326ee8b21c1cc5db331c28e379bce549c6"},
    {"filename":"szlwwqsj.md","filenameStem":"szlwwqsj","path":"szlwwqsj.md","absPath":"/home/khadd/mynotes/szlwwqsj.md","title":"Network Functions Virtualization (NFV) and Middleboxes","link":"[[szlwwqsj]]","lead":"#networking","body":"#networking\n\nNetwork function virtualization virtualize a class of networking functions\n(commonly provided by hardware devices) and implement them in software that run\non COTS processors. This is the results of efforts done by large carriers\nsomewhere in 2012 [@panda2016netbricks]. A virtual network function is also\ncalled a _software middlebox_.\n\nThis approach provides several advantages to traditional devices:\n\n- **Flexible network architecture implementations** (e.g., firewall, load\n  balancers, WAN [[q4cvky96]], ... ). This allows faster development and also\n  deployment.\n- **Simplified management.** NFV are usually deployed in virtual\n  machines/containers, so there management is the same as VM management.\n  - Multiple NF can be served in a single machine leading to better resource\n    utilization.\n  - This also provide fine-grained resource accounting for implementing\n    pay-as-you-go models.\n\nThis naturally leads to a service model where third party services provide\nnetworking functionalities like firewall, load balancer, VPN, to enterprises as\ncloud services [[ijh22i54]].\n\nTraditionally network functions are running in VMs, which comes at a high costs\nfor isolation, which leads to exploration for more lightweight isolation models,\ne.g., using language runtime [@panda2016netbricks].","snippets":["#networking"],"rawContent":"# Network Functions Virtualization (NFV) and Middleboxes\n\n#networking\n\nNetwork function virtualization virtualize a class of networking functions\n(commonly provided by hardware devices) and implement them in software that run\non COTS processors. This is the results of efforts done by large carriers\nsomewhere in 2012 [@panda2016netbricks]. A virtual network function is also\ncalled a _software middlebox_.\n\nThis approach provides several advantages to traditional devices:\n\n- **Flexible network architecture implementations** (e.g., firewall, load\n  balancers, WAN [[q4cvky96]], ... ). This allows faster development and also\n  deployment.\n- **Simplified management.** NFV are usually deployed in virtual\n  machines/containers, so there management is the same as VM management.\n  - Multiple NF can be served in a single machine leading to better resource\n    utilization.\n  - This also provide fine-grained resource accounting for implementing\n    pay-as-you-go models.\n\nThis naturally leads to a service model where third party services provide\nnetworking functionalities like firewall, load balancer, VPN, to enterprises as\ncloud services [[ijh22i54]].\n\nTraditionally network functions are running in VMs, which comes at a high costs\nfor isolation, which leads to exploration for more lightweight isolation models,\ne.g., using language runtime [@panda2016netbricks].\n","wordCount":183,"tags":["networking"],"metadata":{},"created":"2024-12-18T03:03:08.162930917Z","modified":"2024-12-23T04:27:56.223873048Z","checksum":"edc5fe2032b39641793cf4b454f26f990b563ff6b1f7fa0ef04635083f33cc83"},
    {"filename":"vbeb82fs.md","filenameStem":"vbeb82fs","path":"vbeb82fs.md","absPath":"/home/khadd/mynotes/vbeb82fs.md","title":"Network flow","link":"[[vbeb82fs]]","lead":"#networking","body":"#networking\n\nA flow in networking is a set of identifying information that helps identifying\npackets belonging to a particular trafic. This is important in ensuring scalable\nnetwork processing.\n\nA _flow identifier_ identify packet belong to a certain flow. This is useful in\nautomating networking tasks like forwarding packets of some flow to some ports.\n\n```\nin_port(1), eth(src=e0:91:f5:21:d0:b2, dst=00:02:e3:0f:80:a4),\neth_type(0x0800), ipv4(src=172.16.0.20, dst=172.18.0.52, proto=17, tos=0,\nfrag=no), tcp(src=49163, dst=80)\n```\n\nIdentifying flows useful in scaling network processing. For example, hardware\nNICs provides multiple Tx, Rx rings, and enforces each rings to contain packets\nof certain flow [@turtles] [[2i45v7qf]]. Some NICs determine the rings is based\non the hashing of certain fields packet headers (also called Recieved Side\nScalling (RSS)).","snippets":["#networking"],"rawContent":"# Network flow\n\n#networking\n\nA flow in networking is a set of identifying information that helps identifying\npackets belonging to a particular trafic. This is important in ensuring scalable\nnetwork processing.\n\nA _flow identifier_ identify packet belong to a certain flow. This is useful in\nautomating networking tasks like forwarding packets of some flow to some ports.\n\n```\nin_port(1), eth(src=e0:91:f5:21:d0:b2, dst=00:02:e3:0f:80:a4),\neth_type(0x0800), ipv4(src=172.16.0.20, dst=172.18.0.52, proto=17, tos=0,\nfrag=no), tcp(src=49163, dst=80)\n```\n\nIdentifying flows useful in scaling network processing. For example, hardware\nNICs provides multiple Tx, Rx rings, and enforces each rings to contain packets\nof certain flow [@turtles] [[2i45v7qf]]. Some NICs determine the rings is based\non the hashing of certain fields packet headers (also called Recieved Side\nScalling (RSS)).\n","wordCount":119,"tags":["networking"],"metadata":{},"created":"2024-12-16T03:56:49.127977544Z","modified":"2024-12-16T03:56:38.548890167Z","checksum":"75a44bb2a3cb8ac78a247be2cacae6e6f9d8a9bb576e625dadfad2c433500b32"},
    {"filename":"ijh22i54.md","filenameStem":"ijh22i54","path":"ijh22i54.md","absPath":"/home/khadd/mynotes/ijh22i54.md","title":"Network-as-a-Service (NaaS)","link":"[[ijh22i54]]","lead":"#networking #service-model","body":"#networking #service-model\n\nNetwork-as-a-Service (NaaS) is a cloud service model where network services are\nprovided to customers that replace traditional networking devices. These\nservices are usually implemented with NFV [[szlwwqsj]].\n\nThis service model leads to a conflict of security interests between the parties\n[[oktf2gql]], which motived development of TEE-protected NF services\n[@poddar2018safebricks,@duan2019lightbox].","snippets":["#networking #service-model"],"rawContent":"# Network-as-a-Service (NaaS)\n\n#networking #service-model\n\nNetwork-as-a-Service (NaaS) is a cloud service model where network services are\nprovided to customers that replace traditional networking devices. These\nservices are usually implemented with NFV [[szlwwqsj]].\n\nThis service model leads to a conflict of security interests between the parties\n[[oktf2gql]], which motived development of TEE-protected NF services\n[@poddar2018safebricks,@duan2019lightbox].\n","wordCount":54,"tags":["networking","service-model"],"metadata":{},"created":"2024-12-18T03:23:01.946699559Z","modified":"2024-12-18T04:33:13.894881905Z","checksum":"577ea9b0a0fb9d4f548135cb1054d86fca21cc75f3b54ca9f9d70bfddeb2cc1b"},
    {"filename":"471vf8vr.md","filenameStem":"471vf8vr","path":"471vf8vr.md","absPath":"/home/khadd/mynotes/471vf8vr.md","title":"Networking Stack Overheads and Optimizations","link":"[[471vf8vr]]","lead":"#io #networking","body":"#io #networking\n\n## Cost study\n\n[@peter2014arrakis] profiled the cost of networking in a Linux process and\ncategorized the costs into 4 categories:\n\n- Network stack costs: Time for packet processing packet headers.\n- Scheduler overheads: Time to wake up a process, select it to run, and context\n  switching.\n- Kernel crossings: The time to switch between kernel/user\n- Copying of packet data: Packets are copied between users and kernel on sendmsg\n  and recvmsg system calls.\n\n|                 |         | Percentage (%) |\n| --------------- | ------- | -------------- |\n| Network stack   | in      | 37.6           |\n|                 | out     | 31.3           |\n| Scheduler       |         | 5              |\n| Copy            | in      | 7.1            |\n|                 | out     | 13.2           |\n| Kernel Crossing | syscall | 2.9            |\n|                 | return  | 2.9            |\n\n## Optimizations\n\nCertain costs might be eliminated completely if the stack is to be refactored.\n\n- Direct I/O ([[qctx04tc]]) and unikernels remove kernel crossing costs.\n- Scheduling costs is removed with a run-to-completion model [[llh2ly47]], where\n  a thread perform all packet processing steps until it completes\n  [@belay2014ix].\n- Removing copying at the syscall boundary (zero-copy) removes the cost of\n  copying [@peter2014arrakis].","snippets":["#io #networking"],"rawContent":"# Networking Stack Overheads and Optimizations\n\n#io #networking\n\n## Cost study\n\n[@peter2014arrakis] profiled the cost of networking in a Linux process and\ncategorized the costs into 4 categories:\n\n- Network stack costs: Time for packet processing packet headers.\n- Scheduler overheads: Time to wake up a process, select it to run, and context\n  switching.\n- Kernel crossings: The time to switch between kernel/user\n- Copying of packet data: Packets are copied between users and kernel on sendmsg\n  and recvmsg system calls.\n\n|                 |         | Percentage (%) |\n| --------------- | ------- | -------------- |\n| Network stack   | in      | 37.6           |\n|                 | out     | 31.3           |\n| Scheduler       |         | 5              |\n| Copy            | in      | 7.1            |\n|                 | out     | 13.2           |\n| Kernel Crossing | syscall | 2.9            |\n|                 | return  | 2.9            |\n\n## Optimizations\n\nCertain costs might be eliminated completely if the stack is to be refactored.\n\n- Direct I/O ([[qctx04tc]]) and unikernels remove kernel crossing costs.\n- Scheduling costs is removed with a run-to-completion model [[llh2ly47]], where\n  a thread perform all packet processing steps until it completes\n  [@belay2014ix].\n- Removing copying at the syscall boundary (zero-copy) removes the cost of\n  copying [@peter2014arrakis].\n","wordCount":202,"tags":["io","networking"],"metadata":{},"created":"2024-12-04T07:03:18.923157839Z","modified":"2024-12-04T07:24:03.733364143Z","checksum":"01f55968f41067572d3eeaab280d77ce3c83e3f503d59a13aae8a4dde67215b3"},
    {"filename":"gl6uzrqm.md","filenameStem":"gl6uzrqm","path":"gl6uzrqm.md","absPath":"/home/khadd/mynotes/gl6uzrqm.md","title":"No Security without Integrity","link":"[[gl6uzrqm]]","lead":"#security","body":"#security\n\nTraditionally, the (Confidentiality Integrity Availability) CIA triad represents\nthree main principles of information security.\n\nHowever, when applied to securing software, _integrity_ is the most important,\nand is the prerequisite for the other two properties. That is, if the attacker\ncan hijack the program execution (i.e., violating execution integrity):\n\n- Avaiability is sure to suffer, if the attacker executes his own code instead\n  of the intended one.\n- Confidentiality also compromised: The attack may now modify program execution\n  to leak its own secret data.\n\nThe manifestation of this imbalance is the integrity attacks on SEV [[ya2sfv7q]]\nthat can compromise confidentiality.\n\nAnother manifestation can be found in SFI techniques, where the \"fault\nisolation\" aspect is emphasized to maximize availability. Thus, confidentiality\nis sometime skipped as an optimization [@nativeclient], e.g., only memory writes\nare instrumented, instead of read.\n\nIn memory safety, Control Flow _Integrity_ is the most adapted, since it has the\nhighest impact from the attacker's perspective. Confidentiality is sometimes\ndiscussed [@scott2017datashield, @dynpte], but not as much.","snippets":["#security"],"rawContent":"# No Security without Integrity\n\n#security\n\nTraditionally, the (Confidentiality Integrity Availability) CIA triad represents\nthree main principles of information security.\n\nHowever, when applied to securing software, _integrity_ is the most important,\nand is the prerequisite for the other two properties. That is, if the attacker\ncan hijack the program execution (i.e., violating execution integrity):\n\n- Avaiability is sure to suffer, if the attacker executes his own code instead\n  of the intended one.\n- Confidentiality also compromised: The attack may now modify program execution\n  to leak its own secret data.\n\nThe manifestation of this imbalance is the integrity attacks on SEV [[ya2sfv7q]]\nthat can compromise confidentiality.\n\nAnother manifestation can be found in SFI techniques, where the \"fault\nisolation\" aspect is emphasized to maximize availability. Thus, confidentiality\nis sometime skipped as an optimization [@nativeclient], e.g., only memory writes\nare instrumented, instead of read.\n\nIn memory safety, Control Flow _Integrity_ is the most adapted, since it has the\nhighest impact from the attacker's perspective. Confidentiality is sometimes\ndiscussed [@scott2017datashield, @dynpte], but not as much.\n","wordCount":171,"tags":["security"],"metadata":{},"created":"2024-11-22T05:20:06.153651138Z","modified":"2024-12-09T09:24:52.172866994Z","checksum":"f1daf155d85d4cd69e0f82167c27613d1b98f7fdf534ded80d8856c61de765f1"},
    {"filename":"gbkc1fhy.md","filenameStem":"gbkc1fhy","path":"gbkc1fhy.md","absPath":"/home/khadd/mynotes/gbkc1fhy.md","title":"Non-control Data Attacks","link":"[[gbkc1fhy]]","lead":"#data-only-attack #attack #memory-safety","body":"#data-only-attack #attack #memory-safety\n\n# Expressiveness\n\nIt is shown that data-only attack can achieve turing-complete execution under a\ncertain condition [@hu2016dataoriented]. More specifically, there must be loop\nthat is vulnerable to buffer overflow, that contain a corruptible switch\ncondition. The original refer to this type of loop as a _gadget dispatcher_.\nThis is an example:\n\n```c\nwhile (...){\n  overflow(); // buffer overflow\n  if (*type == NONE) break;\n  if (*type == STREAM)\n    *size = *(srv-\u003ecur_max); // dereference\n  else {\n    srv-\u003etyp = *type;    // assignment\n    srv-\u003etotal += *size; // addition\n  }\n  ///...\n}\n```\n\nWhen the attacker can infinitely control the loop, he is able to set up the\noperands and run different instructions in a turing-complete manner.","snippets":["#data-only-attack #attack #memory-safety"],"rawContent":"# Non-control Data Attacks\n\n#data-only-attack #attack #memory-safety\n\n# Expressiveness\n\nIt is shown that data-only attack can achieve turing-complete execution under a\ncertain condition [@hu2016dataoriented]. More specifically, there must be loop\nthat is vulnerable to buffer overflow, that contain a corruptible switch\ncondition. The original refer to this type of loop as a _gadget dispatcher_.\nThis is an example:\n\n```c\nwhile (...){\n  overflow(); // buffer overflow\n  if (*type == NONE) break;\n  if (*type == STREAM)\n    *size = *(srv-\u003ecur_max); // dereference\n  else {\n    srv-\u003etyp = *type;    // assignment\n    srv-\u003etotal += *size; // addition\n  }\n  ///...\n}\n```\n\nWhen the attacker can infinitely control the loop, he is able to set up the\noperands and run different instructions in a turing-complete manner.\n","wordCount":119,"tags":["data-only-attack","attack","memory-safety"],"metadata":{},"created":"2023-05-25T08:42:24.056505066Z","modified":"2024-06-20T08:47:01.499451675Z","checksum":"5c3008c3e4e03987f36b393451fdf67c6f8bf8d8b5da66e562085d176c600814"},
    {"filename":"j19hdkto.md","filenameStem":"j19hdkto","path":"j19hdkto.md","absPath":"/home/khadd/mynotes/j19hdkto.md","title":"Norman Hardy","link":"[[j19hdkto]]","lead":"#capabilities #os","body":"#capabilities #os\n\nThe inventor of KeykOS, which laid foundation for many following microkernels\nsuch as EROS, sel4. He is also one of the grandfather of Capabilities.\n\nMaybe the first one to coin the term confused deputy [[y9wu5ut7]] in his paper\n[@hardy1988confused].\n\nIt is interesting that there exists no Wiki article for him.\n\nHis personal website, \u003chttp://www.cap-lore.com/\u003e, contains pieces of notes on\nhis ideas, is written in zettelkasten-like style. Ideas are separated into\nseparated notes and linked together.","snippets":["#capabilities #os"],"rawContent":"# Norman Hardy\n\n#capabilities #os\n\nThe inventor of KeykOS, which laid foundation for many following microkernels\nsuch as EROS, sel4. He is also one of the grandfather of Capabilities.\n\nMaybe the first one to coin the term confused deputy [[y9wu5ut7]] in his paper\n[@hardy1988confused].\n\nIt is interesting that there exists no Wiki article for him.\n\nHis personal website, \u003chttp://www.cap-lore.com/\u003e, contains pieces of notes on\nhis ideas, is written in zettelkasten-like style. Ideas are separated into\nseparated notes and linked together.\n","wordCount":80,"tags":["capabilities","os"],"metadata":{},"created":"2023-05-22T02:06:14.457930559Z","modified":"2024-07-05T05:29:36.890611657Z","checksum":"6cda306c80c2bf4faa7293a42a2643869371100258086017102236d3aac7a30d"},
    {"filename":"itd1o3ic.md","filenameStem":"itd1o3ic","path":"itd1o3ic.md","absPath":"/home/khadd/mynotes/itd1o3ic.md","title":"Novelty is Subjective","link":"[[itd1o3ic]]","lead":"#research","body":"#research\n\nNovelty in research usually refer to an idea, or product of research being\nnew/original. Usually, it add a new perspective, or contribute to existing\nknowledge to the study of the field.\n\nNovelty is subjective.\n\nFirst, your idea (in the form of a research paper) is in the end judged by a\ngroup of people (reviewers) that have their own believes and bias. A reviewer\nwith fewer experiences in the field might consider many ideas novel. On the\nother hand, an experienced reviewer with deep knowledge might notice that a\nsimilar idea has been discussed before.\n\nSecond, it probably follows some principles/patterns that has been applied\nbefore [[kfs6h55d]].\n\nThird, not only the originality is considered, the potential _impact_ of the\nidea is often the more important factor. Potential impact is a highly subjective\nthing, which is again judged by the biased reviewers.","snippets":["#research"],"rawContent":"# Novelty is Subjective\n\n#research\n\nNovelty in research usually refer to an idea, or product of research being\nnew/original. Usually, it add a new perspective, or contribute to existing\nknowledge to the study of the field.\n\nNovelty is subjective.\n\nFirst, your idea (in the form of a research paper) is in the end judged by a\ngroup of people (reviewers) that have their own believes and bias. A reviewer\nwith fewer experiences in the field might consider many ideas novel. On the\nother hand, an experienced reviewer with deep knowledge might notice that a\nsimilar idea has been discussed before.\n\nSecond, it probably follows some principles/patterns that has been applied\nbefore [[kfs6h55d]].\n\nThird, not only the originality is considered, the potential _impact_ of the\nidea is often the more important factor. Potential impact is a highly subjective\nthing, which is again judged by the biased reviewers.\n","wordCount":146,"tags":["research"],"metadata":{},"created":"2024-07-05T05:03:52.240166049Z","modified":"2024-07-05T05:29:27.827237826Z","checksum":"d519daa4750c06a153321ebaff93706017bdf930482497849c19625bf95a06d5"},
    {"filename":"m7plvtcv.md","filenameStem":"m7plvtcv","path":"m7plvtcv.md","absPath":"/home/khadd/mynotes/m7plvtcv.md","title":"ORAM Algorithmic Optimizations","link":"[[m7plvtcv]]","lead":"#oram #oblivious","body":"#oram #oblivious\n\n## Superblock\nIn ORAM, because accesses are always shuffled, the locality is terrible, because individual block's position is shuffled at every access.\n\nSuperblock optimization (@ren2013design) ensures that a group of blocks are always in the stash together. This group of blocks is called the *superblock*. Accessing a block in a superblock would brings all block into the stash, which improve the locality. Note that the number of blocks in a superblock can be smaller than the height of the tree. \n\nAt initialization time, blocks on the superblock $S$ are placed on the same leaf. Whenever a block from the superblock is requested, the entire path is brought into the stash, so the blocks in $S$ is inside the stash. Like normal Path ORAM, the leaf index of the requested block in the position map is updated. This requested block is like a leader, which all blocks in the same superblock follow. Potition of blocks in the superblock are also updated to the leader block's path. Hence, when they are evicted, they would be evicted on the same leaf. \n\n### Security\n@ren2013design (3.2.2) argues that this does not affect the security of ORAM. On each access, superblocks are mapped to a random leaf. Same as normal path ORAM, the observer can only see randomized path accesses, regardless of the superblock. \n\n### Why posmap update for blocks other than the requested block is fine in this case?\nThis is fine fine because the superblock can be seen as a single block in the ORAM access.\n\nIn a more generalized scenario, when updating the position for blocks inside the stash, the new position should be random, or *independent* of the block content/access pattern (not sure if this is correct).","snippets":["#oram #oblivious"],"rawContent":"# ORAM Algorithmic Optimizations\n#oram #oblivious\n\n## Superblock\nIn ORAM, because accesses are always shuffled, the locality is terrible, because individual block's position is shuffled at every access.\n\nSuperblock optimization (@ren2013design) ensures that a group of blocks are always in the stash together. This group of blocks is called the *superblock*. Accessing a block in a superblock would brings all block into the stash, which improve the locality. Note that the number of blocks in a superblock can be smaller than the height of the tree. \n\nAt initialization time, blocks on the superblock $S$ are placed on the same leaf. Whenever a block from the superblock is requested, the entire path is brought into the stash, so the blocks in $S$ is inside the stash. Like normal Path ORAM, the leaf index of the requested block in the position map is updated. This requested block is like a leader, which all blocks in the same superblock follow. Potition of blocks in the superblock are also updated to the leader block's path. Hence, when they are evicted, they would be evicted on the same leaf. \n\n### Security\n@ren2013design (3.2.2) argues that this does not affect the security of ORAM. On each access, superblocks are mapped to a random leaf. Same as normal path ORAM, the observer can only see randomized path accesses, regardless of the superblock. \n\n### Why posmap update for blocks other than the requested block is fine in this case?\nThis is fine fine because the superblock can be seen as a single block in the ORAM access.\n\nIn a more generalized scenario, when updating the position for blocks inside the stash, the new position should be random, or *independent* of the block content/access pattern (not sure if this is correct).\n","wordCount":292,"tags":["oblivious","oram"],"metadata":{},"created":"2023-07-22T12:44:47.615861403Z","modified":"2023-07-23T15:11:40.424034242Z","checksum":"953e101067c5d4e0de6315c7c91e33075e9c2d5ff5cbb38277966faa7ca61130"},
    {"filename":"8wy8yndx.md","filenameStem":"8wy8yndx","path":"8wy8yndx.md","absPath":"/home/khadd/mynotes/8wy8yndx.md","title":"ORAM Stash and Cache","link":"[[8wy8yndx]]","lead":"#oram","body":"#oram\n\nIn traditional ORAM algorithms, data is loaded into the stash and then used\nin-placed.\n\nHowever, when ORAM is retrofitted for obfuscated execution (e.g., SGX), there is\nno secure client storage for stash. Commonly a scratchpad region is added\n[@zhang2020klotski,@ahmad2019obfuscuro] as a cache for ORAM.\n\nThis design can also be seen in secure processor [@fletcher2015freecursive]\ndesigns. While the stash is in secure storage, the cache is needed because there\nis no locality within the stash at all, as blocks are agressively flushed each\nround.","snippets":["#oram"],"rawContent":"# ORAM Stash and Cache\n\n#oram\n\nIn traditional ORAM algorithms, data is loaded into the stash and then used\nin-placed.\n\nHowever, when ORAM is retrofitted for obfuscated execution (e.g., SGX), there is\nno secure client storage for stash. Commonly a scratchpad region is added\n[@zhang2020klotski,@ahmad2019obfuscuro] as a cache for ORAM.\n\nThis design can also be seen in secure processor [@fletcher2015freecursive]\ndesigns. While the stash is in secure storage, the cache is needed because there\nis no locality within the stash at all, as blocks are agressively flushed each\nround.\n","wordCount":89,"tags":["oram"],"metadata":{},"created":"2024-10-24T03:48:32.752384172Z","modified":"2024-12-12T05:44:23.785834273Z","checksum":"1e810700d72bc1d0de87019829dbf45140611e835a5cd568725d98f385ed3aea"},
    {"filename":"a0g41kid.md","filenameStem":"a0g41kid","path":"a0g41kid.md","absPath":"/home/khadd/mynotes/a0g41kid.md","title":"OS Processes","link":"[[a0g41kid]]","lead":"#kernel #os #linux","body":"#kernel #os #linux\n\nIn the most simple term, a process is a running program (that have been loaded\nfrom the disk into memory and launched by the OS). A running process is defined\nby its states, which includes its memory, its registers contents, and opening\nfiles (FDs).\n\nThe OS stores a process's state is stored in the process control block (PCB)\n(`task_struct` in linux). For instance, in xv6, the PCB contains:\n\n```c\n// Per-process state\nstruct proc {\n  uint sz;                     // Size of process memory (bytes)\n  pde_t* pgdir;                // Page table\n  char *kstack;                // Bottom of kernel stack for this process\n  enum procstate state;        // Process state\n  volatile int pid;            // Process ID\n  struct proc *parent;         // Parent process\n  struct trapframe *tf;        // Trap frame for current syscall\n  struct context *context;     // swtch() here to run process\n  void *chan;                  // If non-zero, sleeping on chan\n  int killed;                  // If non-zero, have been killed\n  struct file *ofile[NOFILE];  // Open files\n  struct inode *cwd;           // Current directory\n  struct shared *shared;       // Shared memory record (0 -\u003e none)\n  char name[16];               // Process name (debugging)\n};\n```\n\nThe list of all process is stored by the OS in a _process list_ data structure.\n\n## APIs\n\nProcesses are created through process system call APIs. There are API for:\n\n### Creation\n\n- `fork()` creates a new process identical to the current one. It copies the\n  address space, file descriptors and other info to a new process. Since copying\n  the entire address space is costly, Copy-on-write is used in modern systems to\n  reduce the costs. Fork is rather obsoleted in modern systems .\n- `exec()` spawn a new process with a given executable/forked process.\n\n### Destroy\n\n- A process is controlled through _signals_. The `kill()` syscall send signals\n  to a process (e.g., `SIGINT`) to control it.\n\n### Wait\n\n- The `wait()` system call wait for a spawned process to finish.","snippets":["#kernel #os #linux"],"rawContent":"# OS Processes\n\n#kernel #os #linux\n\nIn the most simple term, a process is a running program (that have been loaded\nfrom the disk into memory and launched by the OS). A running process is defined\nby its states, which includes its memory, its registers contents, and opening\nfiles (FDs).\n\nThe OS stores a process's state is stored in the process control block (PCB)\n(`task_struct` in linux). For instance, in xv6, the PCB contains:\n\n```c\n// Per-process state\nstruct proc {\n  uint sz;                     // Size of process memory (bytes)\n  pde_t* pgdir;                // Page table\n  char *kstack;                // Bottom of kernel stack for this process\n  enum procstate state;        // Process state\n  volatile int pid;            // Process ID\n  struct proc *parent;         // Parent process\n  struct trapframe *tf;        // Trap frame for current syscall\n  struct context *context;     // swtch() here to run process\n  void *chan;                  // If non-zero, sleeping on chan\n  int killed;                  // If non-zero, have been killed\n  struct file *ofile[NOFILE];  // Open files\n  struct inode *cwd;           // Current directory\n  struct shared *shared;       // Shared memory record (0 -\u003e none)\n  char name[16];               // Process name (debugging)\n};\n```\n\nThe list of all process is stored by the OS in a _process list_ data structure.\n\n## APIs\n\nProcesses are created through process system call APIs. There are API for:\n\n### Creation\n\n- `fork()` creates a new process identical to the current one. It copies the\n  address space, file descriptors and other info to a new process. Since copying\n  the entire address space is costly, Copy-on-write is used in modern systems to\n  reduce the costs. Fork is rather obsoleted in modern systems .\n- `exec()` spawn a new process with a given executable/forked process.\n\n### Destroy\n\n- A process is controlled through _signals_. The `kill()` syscall send signals\n  to a process (e.g., `SIGINT`) to control it.\n\n### Wait\n\n- The `wait()` system call wait for a spawned process to finish.\n","wordCount":316,"tags":["os","linux","kernel"],"metadata":{},"created":"2023-05-26T07:17:27.665890979Z","modified":"2024-12-17T08:42:47.196958372Z","checksum":"92686810617863c999e7facfb793f03be4382849498aa95b00b38340f7fc0f87"},
    {"filename":"tjftw12c.md","filenameStem":"tjftw12c","path":"tjftw12c.md","absPath":"/home/khadd/mynotes/tjftw12c.md","title":"OVMF Whitepaper","link":"[[tjftw12c]]","lead":"#uefi #resource","body":"#uefi #resource\n\nI'm making a copy here since this is entirely in text format.\n\n---\n\nOpen Virtual Machine Firmware (OVMF) Status Report July 2014 (with updates in\nAugust 2014 - January 2015)\n\nAuthor: Laszlo Ersek \u003clersek@redhat.com\u003e Copyright (C) 2014-2015, Red Hat, Inc.\nCC BY-SA 4.0 \u003chttp://creativecommons.org/licenses/by-sa/4.0/\u003e\n\n## Abstract\n\nThe Unified Extensible Firmware Interface (UEFI) is a specification that defines\na software interface between an operating system and platform firmware. UEFI is\ndesigned to replace the Basic Input/Output System (BIOS) firmware interface.\n\nHardware platform vendors have been increasingly adopting the UEFI Specification\nto govern their boot firmware developments. OVMF (Open Virtual Machine\nFirmware), a sub-project of Intel's EFI Development Kit II (edk2), enables UEFI\nsupport for Ia32 and X64 Virtual Machines.\n\nThis paper reports on the status of the OVMF project, treats features and\nlimitations, gives end-user hints, and examines some areas in-depth.\n\nKeywords: ACPI, boot options, CSM, edk2, firmware, flash, fw_cfg, KVM, memory\nmap, non-volatile variables, OVMF, PCD, QEMU, reset vector, S3, Secure Boot,\nSmbios, SMM, TianoCore, UEFI, VBE shim, Virtio\n\n## Table of Contents\n\n- Motivation\n- Scope\n- Example qemu invocation\n- Installation of OVMF guests with virt-manager and virt-install\n- Supported guest operating systems\n- Compatibility Support Module (CSM)\n- Phases of the boot process\n- Project structure\n- Platform Configuration Database (PCD)\n- Firmware image structure\n- S3 (suspend to RAM and resume)\n- A comprehensive memory map of OVMF\n- Known Secure Boot limitations\n- Variable store and LockBox in SMRAM\n- Select features\n  - X64-specific reset vector for OVMF\n  - Client library for QEMU's firmware configuration interface\n  - Guest ACPI tables\n  - Guest SMBIOS tables\n  - Platform-specific boot policy\n  - Virtio drivers\n  - Platform Driver\n  - Video driver\n- Afterword\n\n## Motivation\n\nOVMF extends the usual benefits of virtualization to UEFI. Reasons to use OVMF\ninclude:\n\n- Legacy-free guests. A UEFI-based environment eliminates dependencies on legacy\n  address spaces and devices. This is especially beneficial when used with\n  physically assigned devices where the legacy operating mode is troublesome to\n  support, ex. assigned graphics cards operating in legacy-free, non-VGA mode in\n  the guest.\n\n- Future proof guests. The x86 market is steadily moving towards a legacy-free\n  platform and guest operating systems may eventually require a UEFI\n  environment. OVMF provides that next generation firmware support for such\n  applications.\n\n- GUID partition tables (GPTs). MBR partition tables represent partition offsets\n  and sizes with 32-bit integers, in units of 512 byte sectors. This limits the\n  addressable portion of the disk to 2 TB. GPT represents logical block\n  addresses with 64 bits.\n\n- Liberating boot loader binaries from residing in contested and poorly defined\n  space between the partition table and the partitions.\n\n- Support for booting off disks (eg. pass-through physical SCSI devices) with a\n  4kB physical and logical sector size, i.e. which don't have 512-byte block\n  emulation.\n\n- Development and testing of Secure Boot-related features in guest operating\n  systems. Although OVMF's Secure Boot implementation is currently not secure\n  against malicious UEFI drivers, UEFI applications, and guest kernels, trusted\n  guest code that only uses standard UEFI interfaces will find a valid Secure\n  Boot environment under OVMF, with working key enrollment and signature\n  validation. This enables development and testing of portable, Secure\n  Boot-related guest code.\n\n- Presence of non-volatile UEFI variables. This furthers development and testing\n  of OS installers, UEFI boot loaders, and unique, dependent guest OS features.\n  For example, an efivars-backed pstore (persistent storage) file system works\n  under Linux.\n\n- Altogether, a near production-level UEFI environment for virtual machines when\n  Secure Boot is not required.\n\n## Scope\n\nUEFI and especially Secure Boot have been topics fraught with controversy and\npolitical activism. This paper sidesteps these aspects and strives to focus on\nuse cases, hands-on information for end users, and technical details.\n\nUnless stated otherwise, the expression \"X supports Y\" means \"X is technically\ncompatible with interfaces provided or required by Y\". It does not imply support\nas an activity performed by natural persons or companies.\n\nWe discuss the status of OVMF at a state no earlier than edk2 SVN\nrevision 16158. The paper concentrates on upstream projects and communities, but\noccasionally it pans out about OVMF as it is planned to be shipped (as Technical\nPreview) in Red Hat Enterprise Linux 7.1. Such digressions are marked with the\n[RHEL] margin notation.\n\nAlthough other VMMs and accelerators are known to support (or plan to support)\nOVMF to various degrees -- for example, VirtualBox, Xen, BHyVe --, we'll\nemphasize OVMF on qemu/KVM, because QEMU and KVM have always been Red Hat's\nfocus wrt. OVMF.\n\nThe recommended upstream QEMU version is 2.1+. The recommended host Linux kernel\n(KVM) version is 3.10+. The recommended QEMU machine type is \"qemu-system-x86_64\n-M pc-i440fx-2.1\" or later.\n\nThe term \"TianoCore\" is used interchangeably with \"edk2\" in this paper.\n\n## Example qemu invocation\n\nThe following commands give a quick foretaste of installing a UEFI operating\nsystem on OVMF, relying only on upstream edk2 and qemu.\n\n- Clone and build OVMF:\n\n  git clone https://github.com/tianocore/edk2.git cd edk2 nice OvmfPkg/build.sh\n  -a X64 -n $(getconf \\_NPROCESSORS_ONLN)\n\n  (Note that this ad-hoc build will not include the Secure Boot feature.)\n\n- The build output file, \"OVMF.fd\", includes not only the executable firmware\n  code, but the non-volatile variable store as well. For this reason, make a\n  VM-specific copy of the build output (the variable store should be private to\n  the virtual machine):\n\n  cp Build/OvmfX64/DEBUG_GCC4?/FV/OVMF.fd fedora.flash\n\n  (The variable store and the firmware executable are also available in the\n  build output as separate files: \"OVMF_VARS.fd\" and \"OVMF_CODE.fd\". This\n  enables central management and updates of the firmware executable, while each\n  virtual machine can retain its own variable store.)\n\n- Download a Fedora LiveCD:\n\n  wget\n  https://dl.fedoraproject.org/pub/fedora/linux/releases/20/Live/x86_64/Fedora-Live-Xfce-x86_64-20-1.iso\n\n- Create a virtual disk (qcow2 format, 20 GB in size):\n\n  qemu-img create -f qcow2 fedora.img 20G\n\n- Create the following qemu wrapper script under the name \"fedora.sh\":\n\n  # Basic virtual machine properties: a recent i440fx machine type, KVM\n\n  # acceleration, 2048 MB RAM, two VCPUs.\n\n  OPTS=\"-M pc-i440fx-2.1 -enable-kvm -m 2048 -smp 2\"\n\n  # The OVMF binary, including the non-volatile variable store, appears as a\n\n  # \"normal\" qemu drive on the host side, and it is exposed to the guest as a\n\n  # persistent flash device.\n\n  OPTS=\"$OPTS -drive if=pflash,format=raw,file=fedora.flash\"\n\n  # The hard disk is exposed to the guest as a virtio-block device. OVMF has a\n\n  # driver stack that supports such a disk. We specify this disk as first boot\n\n  # option. OVMF recognizes the boot order specification.\n\n  OPTS=\"$OPTS -drive id=disk0,if=none,format=qcow2,file=fedora.img\"\n  OPTS=\"$OPTS\n  -device virtio-blk-pci,drive=disk0,bootindex=0\"\n\n  # The Fedora installer disk appears as an IDE CD-ROM in the guest. This is\n\n  # the 2nd boot option.\n\n  OPTS=\"$OPTS -drive id=cd0,if=none,format=raw,readonly\"\n  OPTS=\"$OPTS,file=Fedora-Live-Xfce-x86_64-20-1.iso\"\n  OPTS=\"$OPTS -device ide-cd,bus=ide.1,drive=cd0,bootindex=1\"\n\n  # The following setting enables S3 (suspend to RAM). OVMF supports S3\n\n  # suspend/resume.\n\n  OPTS=\"$OPTS -global PIIX4_PM.disable_s3=0\"\n\n  # OVMF emits a number of info / debug messages to the QEMU debug console, at\n\n  # ioport 0x402. We configure qemu so that the debug console is indeed\n\n  # available at that ioport. We redirect the host side of the debug console to\n\n  # a file.\n\n  OPTS=\"$OPTS -global isa-debugcon.iobase=0x402 -debugcon file:fedora.ovmf.log\"\n\n  # QEMU accepts various commands and queries from the user on the monitor\n\n  # interface. Connect the monitor with the qemu process's standard input and\n\n  # output.\n\n  OPTS=\"$OPTS -monitor stdio\"\n\n  # A USB tablet device in the guest allows for accurate pointer tracking\n\n  # between the host and the guest.\n\n  OPTS=\"$OPTS -device piix3-usb-uhci -device usb-tablet\"\n\n  # Provide the guest with a virtual network card (virtio-net).\n\n  #\n\n  # Normally, qemu provides the guest with a UEFI-conformant network driver\n\n  # from the iPXE project, in the form of a PCI expansion ROM. For this test,\n\n  # we disable the expansion ROM and allow OVMF's built-in virtio-net driver to\n\n  # take effect.\n\n  #\n\n  # On the host side, we use the SLIRP (\"user\") network backend, which has\n\n  # relatively low performance, but it doesn't require extra privileges from\n\n  # the user executing qemu.\n\n  OPTS=\"$OPTS -netdev id=net0,type=user\"\n  OPTS=\"$OPTS -device\n  virtio-net-pci,netdev=net0,romfile=\"\n\n  # A Spice QXL GPU is recommended as the primary VGA-compatible display\n\n  # device. It is a full-featured virtual video card, with great operating\n\n  # system driver support. OVMF supports it too.\n\n  OPTS=\"$OPTS -device qxl-vga\"\n\n  qemu-system-x86_64 $OPTS\n\n- Start the Fedora guest:\n\n  sh fedora.sh\n\n- The above command can be used for both installation and later boots of the\n  Fedora guest.\n\n- In order to verify basic OVMF network connectivity:\n\n  - Assuming that the non-privileged user running qemu belongs to group G (where\n    G is a numeric identifier), ensure as root on the host that the group range\n    in file \"/proc/sys/net/ipv4/ping_group_range\" includes G.\n\n  - As the non-privileged user, boot the guest as usual.\n\n  - On the TianoCore splash screen, press ESC.\n\n  - Navigate to Boot Manager | EFI Internal Shell\n\n  - In the UEFI Shell, issue the following commands:\n\n    ifconfig -s eth0 dhcp ping A.B.C.D\n\n    where A.B.C.D is a public IPv4 address in dotted decimal notation that your\n    host can reach.\n\n  - Type \"quit\" at the (qemu) monitor prompt.\n\n## Installation of OVMF guests with virt-manager and virt-install\n\n(1) Assuming OVMF has been installed on the host with the following files: -\n/usr/share/OVMF/OVMF_CODE.fd - /usr/share/OVMF/OVMF_VARS.fd\n\n    locate the \"nvram\" stanza in \"/etc/libvirt/qemu.conf\", and edit it as\n    follows:\n\n    nvram = [ \"/usr/share/OVMF/OVMF_CODE.fd:/usr/share/OVMF/OVMF_VARS.fd\" ]\n\n(2) Restart libvirtd with your Linux distribution's service management tool; for\nexample,\n\n    systemctl restart libvirtd\n\n(3) In virt-manager, proceed with the guest installation as usual: - select File\n| New Virtual Machine, - advance to Step 5 of 5, - in Step 5, check \"Customize\nconfiguration before install\", - click Finish; - in the customization dialog,\nselect Overview | Firmware, and choose UEFI, - click Apply and Begin\nInstallation.\n\n(4) With virt-install:\n\n    LDR=\"loader=/usr/share/OVMF/OVMF_CODE.fd,loader_ro=yes,loader_type=pflash\"\n    virt-install \\\n      --name fedora20 \\\n      --memory 2048 \\\n      --vcpus 2 \\\n      --os-variant fedora20 \\\n      --boot hd,cdrom,$LDR \\\n      --disk size=20 \\\n      --disk path=Fedora-Live-Xfce-x86_64-20-1.iso,device=cdrom,bus=scsi\n\n(5) A popular, distribution-independent, bleeding-edge OVMF package is available\nunder \u003chttps://www.kraxel.org/repos/\u003e, courtesy of Gerd Hoffmann.\n\n    The \"edk2.git-ovmf-x64\" package provides the following files, among others:\n    - /usr/share/edk2.git/ovmf-x64/OVMF_CODE-pure-efi.fd\n    - /usr/share/edk2.git/ovmf-x64/OVMF_VARS-pure-efi.fd\n\n    When using this package, adapt steps (1) and (4) accordingly.\n\n(6) Additionally, the \"edk2.git-ovmf-x64\" package seeks to simplify the\nenablement of Secure Boot in a virtual machine (strictly for development and\ntesting purposes).\n\n    - Boot the virtual machine off the CD-ROM image called\n      \"/usr/share/edk2.git/ovmf-x64/UefiShell.iso\"; before or after installing\n      the main guest operating system.\n\n    - When the UEFI shell appears, issue the following commands:\n\n      EnrollDefaultKeys.efi\n      reset -s\n\n    - The EnrollDefaultKeys.efi utility enrolls the following keys:\n\n      - A static example X.509 certificate (CN=TestCommonName) as Platform Key\n        and first Key Exchange Key.\n\n        The private key matching this certificate has been destroyed (but you\n        shouldn't trust this statement).\n\n      - \"Microsoft Corporation KEK CA 2011\" as second Key Exchange Key\n        (SHA1: 31:59:0b:fd:89:c9:d7:4e:d0:87:df:ac:66:33:4b:39:31:25:4b:30).\n\n      - \"Microsoft Windows Production PCA 2011\" as first DB entry\n        (SHA1: 58:0a:6f:4c:c4:e4:b6:69:b9:eb:dc:1b:2b:3e:08:7b:80:d0:67:8d).\n\n      - \"Microsoft Corporation UEFI CA 2011\" as second DB entry\n        (SHA1: 46:de:f6:3b:5c:e6:1c:f8:ba:0d:e2:e6:63:9c:10:19:d0:ed:14:f3).\n\n      These keys suffice to boot released versions of popular Linux\n      distributions (through the shim.efi utility), and Windows 8 and Windows\n      Server 2012 R2, in Secure Boot mode.\n\n## Supported guest operating systems\n\nUpstream OVMF does not favor some guest operating systems over others for\npolitical or ideological reasons. However, some operating systems are harder to\nobtain and/or technically more difficult to support. The general expectation is\nthat recent UEFI OSes should just work. Please consult the \"OvmfPkg/README\"\nfile.\n\nThe following guest OSes were tested with OVMF:\n\n- Red Hat Enterprise Linux 6\n- Red Hat Enterprise Linux 7\n- Fedora 18\n- Fedora 19\n- Fedora 20\n- Windows Server 2008 R2 SP1\n- Windows Server 2012\n- Windows 8\n\nNotes about Windows Server 2008 R2 (paraphrasing the \"OvmfPkg/README\" file):\n\n- QEMU should be started with one of the \"-device qxl-vga\" and \"-device VGA\"\n  options.\n\n- Only one video mode, 1024x768x32, is supported at OS runtime.\n\n  Please refer to the section about QemuVideoDxe (OVMF's built-in video driver)\n  for more details on this limitation.\n\n- The qxl-vga video card is recommended (\"-device qxl-vga\"). After booting the\n  installed guest OS, select the video card in Device Manager, and upgrade the\n  video driver to the QXL XDDM one.\n\n  The QXL XDDM driver can be downloaded from\n  \u003chttp://www.spice-space.org/download.html\u003e, under Guest | Windows binaries.\n\n  This driver enables additional graphics resolutions at OS runtime, and\n  provides S3 (suspend/resume) capability.\n\nNotes about Windows Server 2012 and Windows 8:\n\n- QEMU should be started with the \"-device qxl-vga,revision=4\" option (or a\n  later revision, if available).\n\n- The guest OS's builtin video driver inherits the video mode / frame buffer\n  from OVMF. There's no way to change the resolution at OS runtime.\n\n  For this reason, a platform driver has been developed for OVMF, which allows\n  users to change the preferred video mode in the firmware. Please refer to the\n  section about PlatformDxe for details.\n\n- It is recommended to upgrade the guest OS's video driver to the QXL WDDM one,\n  via Device Manager.\n\n  Binaries for the QXL WDDM driver can be found at\n  \u003chttp://people.redhat.com/~vrozenfe/qxlwddm\u003e (pick a version greater than or\n  equal to 0.6), while the source code resides at\n  \u003chttps://github.com/vrozenfe/qxl-dod\u003e.\n\n  This driver enables additional graphics resolutions at OS runtime, and\n  provides S3 (suspend/resume) capability.\n\n## Compatibility Support Module (CSM)\n\nCollaboration between SeaBIOS and OVMF developers has enabled SeaBIOS to be\nbuilt as a Compatibility Support Module, and OVMF to embed and use it.\n\nBenefits of a SeaBIOS CSM include:\n\n- The ability to boot legacy (non-UEFI) operating systems, such as legacy Linux\n  systems, Windows 7, OpenBSD 5.2, FreeBSD 8/9, NetBSD, DragonflyBSD, Solaris\n  10/11.\n\n- Legacy (non-UEFI-compliant) PCI expansion ROMs, such as a VGA BIOS, mapped by\n  QEMU in emulated devices' ROM BARs, are loaded and executed by OVMF.\n\n  For example, this grants the Windows Server 2008 R2 SP1 guest's native, legacy\n  video driver access to all modes of all QEMU video cards.\n\nBuilding the CSM target of the SeaBIOS source tree is out of scope for this\nreport. Additionally, upstream OVMF does not enable the CSM by default.\n\nInterested users and developers should look for OVMF's \"-D CSM_ENABLE\"\nbuild-time option, and check out the \u003chttps://www.kraxel.org/repos/\u003e continuous\nintegration repository, which provides CSM-enabled OVMF builds.\n\n[RHEL] The \"OVMF_CODE.fd\" firmware image made available on the Red Hat\nEnterprise Linux 7.1 host does not include a Compatibility Support Module, for\nthe following reasons:\n\n       - Virtual machines running officially supported, legacy guest operating\n         systems should just use the standalone SeaBIOS firmware. Firmware\n         selection is flexible in virtualization, see eg. \"Installation of OVMF\n         guests with virt-manager and virt-install\" above.\n\n       - The 16-bit thunking interface between OVMF and SeaBIOS is very complex\n         and presents a large debugging and support burden, based on past\n         experience.\n\n       - Secure Boot is incompatible with CSM.\n\n       - Inter-project dependencies should be minimized whenever possible.\n\n       - Using the default QXL video card, the Windows 2008 R2 SP1 guest can be\n         installed with its built-in, legacy video driver. Said driver will\n         select the only available video mode, 1024x768x32. After installation,\n         the video driver can be upgraded to the full-featured QXL XDDM driver.\n\n## Phases of the boot process\n\nThe PI and UEFI specifications, and Intel's UEFI and EDK II Learning and\nDevelopment materials provide ample information on PI and UEFI concepts. The\nfollowing is an absolutely minimal, rough glossary that is included only to help\nreaders new to PI and UEFI understand references in later, OVMF-specific\nsections. We defer heavily to the official specifications and the training\nmaterials, and frequently quote them below.\n\nA central concept to mention early is the GUID -- globally unique identifier. A\nGUID is a 128-bit number, written as XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX, where\neach X stands for a hexadecimal nibble. GUIDs are used to name everything in PI\nand in UEFI. Programmers introduce new GUIDs with the \"uuidgen\" utility, and\nstandards bodies standardize well-known services by positing their GUIDs.\n\nThe boot process is roughly divided in the following phases:\n\n- Reset vector code.\n\n- SEC: Security phase. This phase is the root of firmware integrity.\n\n- PEI: Pre-EFI Initialization. This phase performs \"minimal processor, chipset\n  and platform configuration for the purpose of discovering memory\". Modules in\n  PEI collectively save their findings about the platform in a list of HOBs\n  (hand-off blocks).\n\n  When developing PEI code, the Platform Initialization (PI) specification\n  should be consulted.\n\n- DXE: Driver eXecution Environment, pronounced as \"Dixie\". This \"is the phase\n  where the bulk of the booting occurs: devices are enumerated and initialized,\n  UEFI services are supported, and protocols and drivers are implemented. Also,\n  the tables that create the UEFI interface are produced\".\n\n  On the PEI/DXE boundary, the HOBs produced by PEI are consumed. For example,\n  this is how the memory space map is configured initially.\n\n- BDS: Boot Device Selection. It is \"responsible for determining how and where\n  you want to boot the operating system\".\n\n  When developing DXE and BDS code, it is mainly the UEFI specification that\n  should be consulted. When speaking about DXE, BDS is frequently considered to\n  be a part of it.\n\nThe following concepts are tied to specific boot process phases:\n\n- PEIM: a PEI Module (pronounced \"PIM\"). A binary module running in the PEI\n  phase, consuming some PPIs and producing other PPIs, and producing HOBs.\n\n- PPI: PEIM-to-PEIM interface. A structure of function pointers and related data\n  members that establishes a PEI service, or an instance of a PEI service. PPIs\n  are identified by GUID.\n\n  An example is EFI_PEI_S3_RESUME2_PPI (6D582DBC-DB85-4514-8FCC-5ADF6227B147).\n\n- DXE driver: a binary module running in the DXE and BDS phases, consuming some\n  protocols and producing other protocols.\n\n- Protocol: A structure of function pointers and related data members that\n  establishes a DXE service, or an instance of a DXE service. Protocols are\n  identified by GUID.\n\n  An example is EFI_BLOCK_IO_PROTOCOL (964E5B21-6459-11D2-8E39-00A0C969723B).\n\n- Architectural protocols: a set of standard protocols that are foundational to\n  the working of a UEFI system. Each architectural protocol has at most one\n  instance. Architectural protocols are implemented by a subset of DXE drivers.\n  DXE drivers explicitly list the set of protocols (including architectural\n  protocols) that they need to work. UEFI drivers can only be loaded once all\n  architectural protocols have become available during the DXE phase.\n\n  An example is EFI_VARIABLE_WRITE_ARCH_PROTOCOL\n  (6441F818-6362-4E44-B570-7DBA31DD2453).\n\n## Project structure\n\nThe term \"OVMF\" usually denotes the project (community and development effort)\nthat provide and maintain the subject matter UEFI firmware for virtual machines.\nHowever the term is also frequently applied to the firmware binary proper that a\nvirtual machine executes.\n\nOVMF emerges as a compilation of several modules from the edk2 source\nrepository. \"edk2\" stands for EFI Development Kit II; it is a \"modern,\nfeature-rich, cross-platform firmware development environment for the UEFI and\nPI specifications\".\n\nThe composition of OVMF is dictated by the following build control files:\n\nOvmfPkg/OvmfPkgIa32.dsc OvmfPkg/OvmfPkgIa32.fdf\n\nOvmfPkg/OvmfPkgIa32X64.dsc OvmfPkg/OvmfPkgIa32X64.fdf\n\nOvmfPkg/OvmfPkgX64.dsc OvmfPkg/OvmfPkgX64.fdf\n\nThe format of these files is described in the edk2 DSC and FDF specifications.\nRoughly, the DSC file determines:\n\n- library instance resolutions for library class requirements presented by the\n  modules to be compiled,\n- the set of modules to compile.\n\nThe FDF file roughly determines:\n\n- what binary modules (compilation output files, precompiled binaries, graphics\n  image files, verbatim binary sections) to include in the firmware image,\n- how to lay out the firmware image.\n\nThe Ia32 flavor of these files builds a firmware where both PEI and DXE phases\nare 32-bit. The Ia32X64 flavor builds a firmware where the PEI phase consists of\n32-bit modules, and the DXE phase is 64-bit. The X64 flavor builds a purely\n64-bit firmware.\n\nThe word size of the DXE phase must match the word size of the runtime OS -- a\n32-bit DXE can't cooperate with a 64-bit OS, and a 64-bit DXE can't work a\n32-bit OS.\n\nOVMF pulls together modules from across the edk2 tree. For example:\n\n- common drivers and libraries that are platform independent are usually located\n  under MdeModulePkg and MdePkg,\n\n- common but hardware-specific drivers and libraries that match QEMU's\n  pc-i440fx-\\* machine type are pulled in from IntelFrameworkModulePkg,\n  PcAtChipsetPkg and UefiCpuPkg,\n\n- the platform independent UEFI Shell is built from ShellPkg,\n\n- OvmfPkg includes drivers and libraries that are useful for virtual machines\n  and may or may not be specific to QEMU's pc-i440fx-\\* machine type.\n\n## Platform Configuration Database (PCD)\n\nLike the \"Phases of the boot process\" section, this one introduces a concept in\nvery raw form. We defer to the PCD related edk2 specifications, and we won't\ndiscuss implementation details here. Our purpose is only to offer the reader a\nusable (albeit possibly inaccurate) definition, so that we can refer to PCDs\nlater on.\n\nColloquially, when we say \"PCD\", we actually mean \"PCD entry\"; that is, an entry\nstored in the Platform Configuration Database.\n\nThe Platform Configuration Database is\n\n- a firmware-wide\n- name-value store\n- of scalars and buffers\n- where each entry may be\n  - build-time constant, or\n  - run-time dynamic, or\n  - theoretically, a middle option: patchable in the firmware file itself, using\n    a dedicated tool. (OVMF does not utilize externally patchable entries.)\n\nA PCD entry is declared in the DEC file of the edk2 top-level Package directory\nwhose modules (drivers and libraries) are the primary consumers of the PCD\nentry. (See for example OvmfPkg/OvmfPkg.dec). Basically, a PCD in a DEC file\nexposes a simple customization point.\n\nInterest in a PCD entry is communicated to the build system by naming the PCD\nentry in the INF file of the interested module (application, driver or library).\nThe module may read and -- dependent on the PCD entry's category -- write the\nPCD entry.\n\nLet's investigate the characteristics of the Database and the PCD entries.\n\n- Firmware-wide: technically, all modules may access all entries they are\n  interested in, assuming they advertise their interest in their INF files. With\n  careful design, PCDs enable inter-driver propagation of (simple) system\n  configuration. PCDs are available in both PEI and DXE.\n\n  (UEFI drivers meant to be portable (ie. from third party vendors) are not\n  supposed to use PCDs, since PCDs qualify internal to the specific edk2\n  firmware in question.)\n\n- Name-value store of scalars and buffers: each PCD has a symbolic name, and a\n  fixed scalar type (UINT16, UINT32 etc), or VOID\\* for buffers. Each PCD entry\n  belongs to a namespace, where a namespace is (obviously) a GUID, defined in\n  the DEC file.\n\n- A DEC file can permit several categories for a PCD:\n  - build-time constant (\"FixedAtBuild\"),\n  - patchable in the firmware image (\"PatchableInModule\", unused in OVMF),\n  - runtime modifiable (\"Dynamic\").\n\nThe platform description file (DSC) of a top-level Package directory may choose\nthe exact category for a given PCD entry that its modules wish to use, and\nassign a default (or constant) initial value to it.\n\nIn addition, the edk2 build system too can initialize PCD entries to values that\nit calculates while laying out the flash device image. Such PCD assignments are\ndescribed in the FDF control file.\n\n## Firmware image structure\n\n(We assume the common X64 choice for both PEI and DXE, and the default DEBUG\nbuild target.)\n\nThe OvmfPkg/OvmfPkgX64.fdf file defines the following layout for the flash\ndevice image \"OVMF.fd\":\n\nDescription Compression type Size\n\n---\n\nNon-volatile data storage open-coded binary data 128 KB Variable store 56 KB\nEvent log 4 KB Working block 4 KB Spare area 64 KB\n\nFVMAIN_COMPACT uncompressed 1712 KB FV Firmware File System file LZMA compressed\nPEIFV uncompressed 896 KB individual PEI modules uncompressed DXEFV uncompressed\n8192 KB individual DXE modules uncompressed\n\nSECFV uncompressed 208 KB SEC driver reset vector code\n\nThe top-level image consists of three regions (three firmware volumes):\n\n- non-volatile data store (128 KB),\n- main firmware volume (FVMAIN_COMPACT, 1712 KB),\n- firmware volume containing the reset vector code and the SEC phase code (208\n  KB).\n\nIn total, the OVMF.fd file has size 128 KB + 1712 KB + 208 KB == 2 MB.\n\n(1) The firmware volume with non-volatile data store (128 KB) has the following\ninternal structure, in blocks of 4 KB:\n\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+  L: event log\n       LIVE | varstore                  |L|W|  W: working block\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      SPARE |                               |\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n    The first half of this firmware volume is \"live\", while the second half is\n    \"spare\". The spare half is important when the variable driver reclaims\n    unused storage and reorganizes the variable store.\n\n    The live half dedicates 14 blocks (56 KB) to the variable store itself. On\n    top of those, one block is set aside for an event log, and one block is\n    used as the working block of the fault tolerant write protocol. Fault\n    tolerant writes are used to recover from an occasional (virtual) power loss\n    during variable updates.\n\n    The blocks in this firmware volume are accessed, in stacking order from\n    least abstract to most abstract, by:\n\n    - EFI_FIRMWARE_VOLUME_BLOCK_PROTOCOL (provided by\n      OvmfPkg/QemuFlashFvbServicesRuntimeDxe),\n\n    - EFI_FAULT_TOLERANT_WRITE_PROTOCOL (provided by\n      MdeModulePkg/Universal/FaultTolerantWriteDxe),\n\n    - architectural protocols instrumental to the runtime UEFI variable\n      services:\n      - EFI_VARIABLE_ARCH_PROTOCOL,\n      - EFI_VARIABLE_WRITE_ARCH_PROTOCOL.\n\n      In a non-secure boot build, the DXE driver providing these architectural\n      protocols is MdeModulePkg/Universal/Variable/RuntimeDxe. In a secure boot\n      build, where authenticated variables are available, the DXE driver\n      offering these protocols is SecurityPkg/VariableAuthenticated/RuntimeDxe.\n\n(2) The main firmware volume (FVMAIN_COMPACT, 1712 KB) embeds further firmware\nvolumes. The outermost layer is a Firmware File System (FFS), carrying a single\nfile. This file holds an LZMA-compressed section, which embeds two firmware\nvolumes: PEIFV (896 KB) with PEIMs, and DXEFV (8192 KB) with DXE and UEFI\ndrivers.\n\n    This scheme enables us to build 896 KB worth of PEI drivers and 8192 KB\n    worth of DXE and UEFI drivers, compress them all with LZMA in one go, and\n    store the compressed result in 1712 KB, saving room in the flash device.\n\n(3) The SECFV firmware volume (208 KB) is not compressed. It carries the \"volume\ntop file\" with the reset vector code, to end at 4 GB in guest-physical address\nspace, and the SEC phase driver (OvmfPkg/Sec).\n\n    The last 16 bytes of the volume top file (mapped directly under 4 GB)\n    contain a NOP slide and a jump instruction. This is where QEMU starts\n    executing the firmware, at address 0xFFFF_FFF0. The reset vector and the\n    SEC driver run from flash directly.\n\n    The SEC driver locates FVMAIN_COMPACT in the flash, and decompresses the\n    main firmware image to RAM. The rest of OVMF (PEI, DXE, BDS phases) run\n    from RAM.\n\nAs already mentioned, the OVMF.fd file is mapped by qemu's\n\"hw/block/pflash_cfi01.c\" device just under 4 GB in guest-physical address\nspace, according to the command line option\n\n-drive if=pflash,format=raw,file=fedora.flash\n\n(refer to the Example qemu invocation). This is a \"ROMD device\", which can\nswitch out of \"ROMD mode\" and back into it.\n\nNamely, in the default ROMD mode, the guest-physical address range backed by the\nflash device reads and executes as ROM (it does not trap from KVM to QEMU). The\nfirst write access in this mode traps to QEMU, and flips the device out of ROMD\nmode.\n\nIn non-ROMD mode, the flash chip is programmed by storing CFI (Common Flash\nInterface) command values at the flash-covered addresses; both reads and writes\ntrap to QEMU, and the flash contents are modified and synchronized to the\nhost-side file. A special CFI command flips the flash device back to ROMD mode.\n\nQemu implements the above based on the KVM_CAP_READONLY_MEM / KVM_MEM_READONLY\nKVM features, and OVMF puts it to use in its EFI_FIRMWARE_VOLUME_BLOCK_PROTOCOL\nimplementation, under \"OvmfPkg/QemuFlashFvbServicesRuntimeDxe\".\n\nIMPORTANT: Never pass OVMF.fd to qemu with the -bios option. That option maps\nthe firmware image as ROM into the guest's address space, and forces OVMF to\nemulate non-volatile variables with a fallback driver that is bound to have\ninsufficient and confusing semantics.\n\nThe 128 KB firmware volume with the variable store, discussed under (1), is also\nbuilt as a separate host-side file, named \"OVMF_VARS.fd\". The \"rest\" is built\ninto a third file, \"OVMF_CODE.fd\", which is only 1920 KB in size. The variable\nstore is mapped into its usual location, at 4 GB - 2 MB = 0xFFE0_0000, through\nthe following qemu options:\n\n-drive if=pflash,format=raw,readonly,file=OVMF_CODE.fd \\\n -drive if=pflash,format=raw,file=fedora.varstore.fd\n\nThis way qemu configures two flash chips consecutively, with start addresses\ngrowing downwards, which is transparent to OVMF.\n\n[RHEL] Red Hat Enterprise Linux 7.1 ships a Secure Boot-enabled, X64, DEBUG\nfirmware only. Furthermore, only the split files (\"OVMF_VARS.fd\" and\n\"OVMF_CODE.fd\") are available.\n\n## S3 (suspend to RAM and resume)\n\nAs noted in Example qemu invocation, the\n\n-global PIIX4_PM.disable_s3=0\n\ncommand line option tells qemu and OVMF if the user would like to enable S3\nsupport. (This is corresponds to the /domain/pm/suspend-to-mem/@enabled libvirt\ndomain XML attribute.)\n\nImplementing / orchestrating S3 was a considerable community effort in OVMF. A\ndetailed description exceeds the scope of this report; we only make a few\nstatements.\n\n(1) S3-related PPIs and protocols are well documented in the PI specification.\n\n(2) Edk2 contains most modules that are needed to implement S3 on a given\nplatform. One abstraction that is central to the porting / extending of the\nS3-related modules to a new platform is the LockBox library interface, which a\nspecific platform can fill in by implementing its own LockBox library instance.\n\n    The LockBox library provides a privileged name-value store (to be addressed\n    by GUIDs). The privilege separation stretches between the firmware and the\n    operating system. That is, the S3-related machinery of the firmware saves\n    some items in the LockBox securely, under well-known GUIDs, before booting\n    the operating system. During resume (which is a form of warm reset), the\n    firmware is activated again, and retrieves items from the LockBox. Before\n    jumping to the OS's resume vector, the LockBox is secured again.\n\n    We'll return to this later when we separately discuss SMRAM and SMM.\n\n(3) During resume, the DXE and later phases are never reached; only the reset\nvector, and the SEC and PEI phases of the firmware run. The platform is supposed\nto detect a resume in progress during PEI, and to store that fact in the\nBootMode field of the Phase Handoff Information Table (PHIT) HOB. OVMF keys this\noff the CMOS, see OvmfPkg/PlatformPei.\n\n    At the end of PEI, the DXE IPL PEIM (Initial Program Load PEI Module, see\n    MdeModulePkg/Core/DxeIplPeim) examines the Boot Mode, and if it says \"S3\n    resume in progress\", then the IPL branches to the PEIM that exports\n    EFI_PEI_S3_RESUME2_PPI (provided by UefiCpuPkg/Universal/Acpi/S3Resume2Pei)\n    rather than loading the DXE core.\n\n    S3Resume2Pei executes the technical steps of the resumption, relying on the\n    contents of the LockBox.\n\n(4) During first boot (or after a normal platform reset), when DXE does run,\nhardware drivers in the DXE phase are encouraged to \"stash\" their hardware\nconfiguration steps (eg. accesses to PCI config space, I/O ports, memory mapped\naddresses, and so on) in a centrally maintained, so called \"S3 boot script\".\nHardware accesses are represented with opcodes of a special binary script\nlanguage.\n\n    This boot script is to be replayed during resume, by S3Resume2Pei. The\n    general goal is to bring back hardware devices -- which have been powered\n    off during suspend -- to their original after-first-boot state, and in\n    particular, to do so quickly.\n\n    At the moment, OVMF saves only one opcode in the S3 resume boot script: an\n    INFORMATION opcode, with contents 0xDEADBEEF (in network byte order). The\n    consensus between Linux developers seems to be that boot firmware is only\n    responsible for restoring basic chipset state, which OVMF does during PEI\n    anyway, independently of S3 vs. normal reset. (One example is the power\n    management registers of the i440fx chipset.) Device and peripheral state is\n    the responsibility of the runtime operating system.\n\n    Although an experimental OVMF S3 boot script was at one point captured for\n    the virtual Cirrus VGA card, such a boot script cannot follow eg. video\n    mode changes effected by the OS. Hence the operating system can never avoid\n    restoring device state, and most Linux display drivers (eg. stdvga, QXL)\n    already cover S3 resume fully.\n\n    The XDDM and WDDM driver models used under Windows OSes seem to recognize\n    this notion of runtime OS responsibility as well. (See the list of OSes\n    supported by OVMF in a separate section.)\n\n(5) The S3 suspend/resume data flow in OVMF is included here tersely, for\ninterested developers.\n\n    (a) BdsLibBootViaBootOption()\n          EFI_ACPI_S3_SAVE_PROTOCOL [AcpiS3SaveDxe]\n          - saves ACPI S3 Context to LockBox  ---------------------+\n            (including FACS address -- FACS ACPI table             |\n            contains OS waking vector)                             |\n                                                                   |\n          - prepares boot script:                                  |\n            EFI_S3_SAVE_STATE_PROTOCOL.Write() [S3SaveStateDxe]    |\n              S3BootScriptLib [PiDxeS3BootScriptLib]               |\n              - opcodes \u0026 arguments are saved in NVS.  --+         |\n                                                         |         |\n          - issues a notification by installing          |         |\n            EFI_DXE_SMM_READY_TO_LOCK_PROTOCOL           |         |\n                                                         |         |\n    (b) EFI_S3_SAVE_STATE_PROTOCOL [S3SaveStateDxe]      |         |\n          S3BootScriptLib [PiDxeS3BootScriptLib]         |         |\n          - closes script with special opcode  \u003c---------+         |\n          - script is available in non-volatile memory             |\n            via PcdS3BootScriptTablePrivateDataPtr  --+            |\n                                                      |            |\n        BootScriptExecutorDxe                         |            |\n          S3BootScriptLib [PiDxeS3BootScriptLib]      |            |\n          - Knows about boot script location by  \u003c----+            |\n            synchronizing with the other library                   |\n            instance via                                           |\n            PcdS3BootScriptTablePrivateDataPtr.                    |\n          - Copies relocated image of itself to                    |\n            reserved memory. --------------------------------+     |\n          - Saved image contains pointer to boot script.  ---|--+  |\n                                                             |  |  |\n    Runtime:                                                 |  |  |\n                                                             |  |  |\n    (c) OS is booted, writes OS waking vector to FACS,       |  |  |\n        suspends machine                                     |  |  |\n                                                             |  |  |\n    S3 Resume (PEI):                                         |  |  |\n                                                             |  |  |\n    (d) PlatformPei sets S3 Boot Mode based on CMOS          |  |  |\n                                                             |  |  |\n    (e) DXE core is skipped and EFI_PEI_S3_RESUME2 is        |  |  |\n        called as last step of PEI                           |  |  |\n                                                             |  |  |\n    (f) S3Resume2Pei retrieves from LockBox:                 |  |  |\n        - ACPI S3 Context (path to FACS)  \u003c------------------|--|--+\n                                          |                  |  |\n                                          +------------------|--|--+\n        - Boot Script Executor Image  \u003c----------------------+  |  |\n                                                                |  |\n    (g) BootScriptExecutorDxe                                   |  |\n          S3BootScriptLib [PiDxeS3BootScriptLib]                |  |\n          - executes boot script  \u003c-----------------------------+  |\n                                                                   |\n    (h) OS waking vector available from ACPI S3 Context / FACS  \u003c--+\n        is called\n\n## A comprehensive memory map of OVMF\n\nThe following section gives a detailed analysis of memory ranges below 4 GB that\nOVMF statically uses.\n\nIn the rightmost column, the PCD entry is identified by which the source refers\nto the address or size in question.\n\nThe flash-covered range has been discussed previously in \"Firmware image\nstructure\", therefore we include it only for completeness. Due to the fact that\nthis range is always backed by a memory mapped device (and never RAM), it is\nunaffected by S3 (suspend to RAM and resume).\n\n+--------------------------+ 4194304 KB | | | SECFV | size: 208 KB | |\n+--------------------------+ 4194096 KB | | | FVMAIN_COMPACT | size: 1712 KB | |\n+--------------------------+ 4192384 KB | | | variable store | size: 64 KB\nPcdFlashNvStorageFtwSpareSize | spare area | | | +--------------------------+\n4192320 KB PcdOvmfFlashNvStorageFtwSpareBase | | | FTW working block | size: 4\nKB PcdFlashNvStorageFtwWorkingSize | | +--------------------------+ 4192316 KB\nPcdOvmfFlashNvStorageFtwWorkingBase | | | Event log of | size: 4 KB\nPcdOvmfFlashNvStorageEventLogSize | non-volatile storage | | |\n+--------------------------+ 4192312 KB PcdOvmfFlashNvStorageEventLogBase | | |\nvariable store | size: 56 KB PcdFlashNvStorageVariableSize | |\n+--------------------------+ 4192256 KB PcdOvmfFlashNvStorageVariableBase\n\nThe flash-mapped image of OVMF.fd covers the entire structure above (2048 KB).\n\nWhen using the split files, the address 4192384 KB\n(PcdOvmfFlashNvStorageFtwSpareBase + PcdFlashNvStorageFtwSpareSize) is the\nboundary between the mapped images of OVMF_VARS.fd (56 KB + 4 KB + 4 KB + 64 KB\n= 128 KB) and OVMF_CODE.fd (1712 KB + 208 KB = 1920 KB).\n\nWith regard to RAM that is statically used by OVMF, S3 (suspend to RAM and\nresume) complicates matters. Many ranges have been introduced only to support\nS3, hence for all ranges below, the following questions will be audited:\n\n(a) when and how a given range is initialized after first boot of the VM, (b)\nhow it is protected from memory allocations during DXE, (c) how it is protected\nfrom the OS, (d) how it is accessed on the S3 resume path, (e) how it is\naccessed on the warm reset path.\n\nImportantly, the term \"protected\" is meant as protection against inadvertent\nreallocations and overwrites by co-operating DXE and OS modules. It does not\nimply security against malicious code.\n\n+--------------------------+ 17408 KB | | |DXEFV from FVMAIN_COMPACT | size:\n8192 KB PcdOvmfDxeMemFvSize | decompressed firmware | | volume with DXE modules\n| | | +--------------------------+ 9216 KB PcdOvmfDxeMemFvBase | | |PEIFV from\nFVMAIN_COMPACT | size: 896 KB PcdOvmfPeiMemFvSize | decompressed firmware | |\nvolume with PEI modules | | | +--------------------------+ 8320 KB\nPcdOvmfPeiMemFvBase | | | permanent PEI memory for | size: 32 KB\nPcdS3AcpiReservedMemorySize | the S3 resume path | | |\n+--------------------------+ 8288 KB PcdS3AcpiReservedMemoryBase | | | temporary\nSEC/PEI heap | size: 32 KB PcdOvmfSecPeiTempRamSize | and stack | | |\n+--------------------------+ 8256 KB PcdOvmfSecPeiTempRamBase | | | unused |\nsize: 32 KB | | +--------------------------+ 8224 KB | | | SEC's table of |\nsize: 4 KB PcdGuidedExtractHandlerTableSize | GUIDed section handlers | | |\n+--------------------------+ 8220 KB PcdGuidedExtractHandlerTableAddress | | |\nLockBox storage | size: 4 KB PcdOvmfLockBoxStorageSize | |\n+--------------------------+ 8216 KB PcdOvmfLockBoxStorageBase | | | early page\ntables on X64 | size: 24 KB PcdOvmfSecPageTablesSize | |\n+--------------------------+ 8192 KB PcdOvmfSecPageTablesBase\n\n(1) Early page tables on X64:\n\n(a) when and how it is initialized after first boot of the VM\n\n    The range is filled in during the SEC phase\n    [OvmfPkg/ResetVector/Ia32/PageTables64.asm]. The CR3 register is verified\n    against the base address in SecCoreStartupWithStack()\n    [OvmfPkg/Sec/SecMain.c].\n\n(b) how it is protected from memory allocations during DXE\n\n    If S3 was enabled on the QEMU command line (see \"-global\n    PIIX4_PM.disable_s3=0\" earlier), then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] protects the range with an AcpiNVS memory\n    allocation HOB, in PEI.\n\n    If S3 was disabled, then this range is not protected. DXE's own page tables\n    are first built while still in PEI (see HandOffToDxeCore()\n    [MdeModulePkg/Core/DxeIplPeim/X64/DxeLoadFunc.c]). Those tables are located\n    in permanent PEI memory. After CR3 is switched over to them (which occurs\n    before jumping to the DXE core entry point), we don't have to preserve the\n    initial tables.\n\n(c) how it is protected from the OS\n\n    If S3 is enabled, then (1b) reserves it from the OS too.\n\n    If S3 is disabled, then the range needs no protection.\n\n(d) how it is accessed on the S3 resume path\n\n    It is rewritten same as in (1a), which is fine because (1c) reserved it.\n\n(e) how it is accessed on the warm reset path\n\n    It is rewritten same as in (1a).\n\n(2) LockBox storage:\n\n(a) when and how it is initialized after first boot of the VM\n\n    InitializeRamRegions() [OvmfPkg/PlatformPei/MemDetect.c] zeroes out the\n    area during PEI. This is correct but not strictly necessary, since on first\n    boot the area is zero-filled anyway.\n\n    The LockBox signature of the area is filled in by the PEI module or DXE\n    driver that has been linked against OVMF's LockBoxLib and is run first. The\n    signature is written in LockBoxLibInitialize()\n    [OvmfPkg/Library/LockBoxLib/LockBoxLib.c].\n\n    Any module calling SaveLockBox() [OvmfPkg/Library/LockBoxLib/LockBoxLib.c]\n    will co-populate this area.\n\n(b) how it is protected from memory allocations during DXE\n\n    If S3 is enabled, then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] protects the range as AcpiNVS.\n\n    Otherwise, the range is covered with a BootServicesData memory allocation\n    HOB.\n\n(c) how it is protected from the OS\n\n    If S3 is enabled, then (2b) protects it sufficiently.\n\n    Otherwise the range requires no runtime protection, and the\n    BootServicesData allocation type from (2b) ensures that the range will be\n    released to the OS.\n\n(d) how it is accessed on the S3 resume path\n\n    The S3 Resume PEIM restores data from the LockBox, which has been correctly\n    protected in (2c).\n\n(e) how it is accessed on the warm reset path\n\n    InitializeRamRegions() [OvmfPkg/PlatformPei/MemDetect.c] zeroes out the\n    range during PEI, effectively emptying the LockBox. Modules will\n    re-populate the LockBox as described in (2a).\n\n(3) SEC's table of GUIDed section handlers\n\n(a) when and how it is initialized after first boot of the VM\n\n    The following two library instances are linked into SecMain:\n    - IntelFrameworkModulePkg/Library/LzmaCustomDecompressLib,\n    - MdePkg/Library/BaseExtractGuidedSectionLib.\n\n    The first library registers its LZMA decompressor plugin (which is a called\n    a \"section handler\") by calling the second library:\n\n    LzmaDecompressLibConstructor() [GuidedSectionExtraction.c]\n      ExtractGuidedSectionRegisterHandlers() [BaseExtractGuidedSectionLib.c]\n\n    The second library maintains its table of registered \"section handlers\", to\n    be indexed by GUID, in this fixed memory area, independently of S3\n    enablement.\n\n    (The decompression of FVMAIN_COMPACT's FFS file section that contains the\n    PEIFV and DXEFV firmware volumes occurs with the LZMA decompressor\n    registered above. See (6) and (7) below.)\n\n(b) how it is protected from memory allocations during DXE\n\n    There is no need to protect this area from DXE: because nothing else in\n    OVMF links against BaseExtractGuidedSectionLib, the area loses its\n    significance as soon as OVMF progresses from SEC to PEI, therefore DXE is\n    allowed to overwrite the region.\n\n(c) how it is protected from the OS\n\n    When S3 is enabled, we cover the range with an AcpiNVS memory allocation\n    HOB in InitializeRamRegions().\n\n    When S3 is disabled, the range is not protected.\n\n(d) how it is accessed on the S3 resume path\n\n    The table of registered section handlers is again managed by\n    BaseExtractGuidedSectionLib linked into SecMain exclusively. Section\n    handler registrations update the table in-place (based on GUID matches).\n\n(e) how it is accessed on the warm reset path\n\n    If S3 is enabled, then the OS won't damage the table (due to (3c)), thus\n    see (3d).\n\n    If S3 is disabled, then the OS has most probably overwritten the range with\n    its own data, hence (3a) -- complete reinitialization -- will come into\n    effect, based on the table signature check in BaseExtractGuidedSectionLib.\n\n(4) temporary SEC/PEI heap and stack\n\n(a) when and how it is initialized after first boot of the VM\n\n    The range is configured in [OvmfPkg/Sec/X64/SecEntry.S] and\n    SecCoreStartupWithStack() [OvmfPkg/Sec/SecMain.c]. The stack half is read \u0026\n    written by the CPU transparently. The heap half is used for memory\n    allocations during PEI.\n\n    Data is migrated out (to permanent PEI stack \u0026 memory) in (or soon after)\n    PublishPeiMemory() [OvmfPkg/PlatformPei/MemDetect.c].\n\n(b) how it is protected from memory allocations during DXE\n\n    It is not necessary to protect this range during DXE because its use ends\n    still in PEI.\n\n(c) how it is protected from the OS\n\n    If S3 is enabled, then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] reserves it as AcpiNVS.\n\n    If S3 is disabled, then the range doesn't require protection.\n\n(d) how it is accessed on the S3 resume path\n\n    Same as in (4a), except the target area of the migration triggered by\n    PublishPeiMemory() [OvmfPkg/PlatformPei/MemDetect.c] is different -- see\n    (5).\n\n(e) how it is accessed on the warm reset path\n\n    Same as in (4a). The stack and heap halves both may contain garbage, but it\n    doesn't matter.\n\n(5) permanent PEI memory for the S3 resume path\n\n(a) when and how it is initialized after first boot of the VM\n\n    No particular initialization or use.\n\n(b) how it is protected from memory allocations during DXE\n\n    We don't need to protect this area during DXE.\n\n(c) how it is protected from the OS\n\n    When S3 is enabled, InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] makes sure the OS stays away by covering\n    the range with an AcpiNVS memory allocation HOB.\n\n    When S3 is disabled, the range needs no protection.\n\n(d) how it is accessed on the S3 resume path\n\n    PublishPeiMemory() installs the range as permanent RAM for PEI. The range\n    will serve as stack and will satisfy allocation requests during the rest of\n    PEI. OS data won't overlap due to (5c).\n\n(e) how it is accessed on the warm reset path\n\n    Same as (5a).\n\n(6) PEIFV -- decompressed firmware volume with PEI modules\n\n(a) when and how it is initialized after first boot of the VM\n\n    DecompressMemFvs() [OvmfPkg/Sec/SecMain.c] populates the area, by\n    decompressing the flash-mapped FVMAIN_COMPACT volume's contents. (Refer to\n    \"Firmware image structure\".)\n\n(b) how it is protected from memory allocations during DXE\n\n    When S3 is disabled, PeiFvInitialization() [OvmfPkg/PlatformPei/Fv.c]\n    covers the range with a BootServicesData memory allocation HOB.\n\n    When S3 is enabled, the same is coverage is ensured, just with the stronger\n    AcpiNVS memory allocation type.\n\n(c) how it is protected from the OS\n\n    When S3 is disabled, it is not necessary to keep the range from the OS.\n\n    Otherwise the AcpiNVS type allocation from (6b) provides coverage.\n\n(d) how it is accessed on the S3 resume path\n\n    Rather than decompressing it again from FVMAIN_COMPACT, GetS3ResumePeiFv()\n    [OvmfPkg/Sec/SecMain.c] reuses the protected area for parsing / execution\n    from (6c).\n\n(e) how it is accessed on the warm reset path\n\n    Same as (6a).\n\n(7) DXEFV -- decompressed firmware volume with DXE modules\n\n(a) when and how it is initialized after first boot of the VM\n\n    Same as (6a).\n\n(b) how it is protected from memory allocations during DXE\n\n    PeiFvInitialization() [OvmfPkg/PlatformPei/Fv.c] covers the range with a\n    BootServicesData memory allocation HOB.\n\n(c) how it is protected from the OS\n\n    The OS is allowed to release and reuse this range.\n\n(d) how it is accessed on the S3 resume path\n\n    It's not; DXE never runs during S3 resume.\n\n(e) how it is accessed on the warm reset path\n\n    Same as in (7a).\n\n## Known Secure Boot limitations\n\nUnder \"Motivation\" we've mentioned that OVMF's Secure Boot implementation is not\nsuitable for production use yet -- it's only good for development and testing of\nstandards-conformant, non-malicious guest code (UEFI and operating system\nalike).\n\nNow that we've examined the persistent flash device, the workings of S3, and the\nmemory map, we can discuss two currently known shortcomings of OVMF's Secure\nBoot that in fact make it insecure. (Clearly problems other than these two might\nexist; the set of issues considered here is not meant to be exhaustive.)\n\nOne trait of Secure Boot is tamper-evidence. Secure Boot may not prevent\nmalicious modification of software components (for example, operating system\ndrivers), but by being the root of integrity on a platform, it can catch (or\nindirectly contribute to catching) unauthorized changes, by way of signature and\ncertificate checks at the earliest phases of boot.\n\nIf an attacker can tamper with key material stored in authenticated and/or\nboot-time only persistent variables (for example, PK, KEK, db, dbt, dbx), then\nthe intended security of this scheme is compromised. The UEFI 2.4A specification\nsays\n\n- in section 28.3.4:\n\n  Platform Keys:\n\n  The public key must be stored in non-volatile storage which is tamper and\n  delete resistant.\n\n  Key Exchange Keys:\n\n  The public key must be stored in non-volatile storage which is tamper\n  resistant.\n\n- in section 28.6.1:\n\n  The signature database variables db, dbt, and dbx must be stored in\n  tamper-resistant non-volatile storage.\n\n(1) The combination of QEMU, KVM, and OVMF does not provide this kind of\nresistance. The variable store in the emulated flash chip is directly accessible\nto, and reprogrammable by, UEFI drivers, applications, and operating systems.\n\n(2) Under \"S3 (suspend to RAM and resume)\" we pointed out that the LockBox\nstorage must be similarly secure and tamper-resistant.\n\n    On the S3 resume path, the PEIM providing EFI_PEI_S3_RESUME2_PPI\n    (UefiCpuPkg/Universal/Acpi/S3Resume2Pei) restores and interprets data from\n    the LockBox that has been saved there during boot. This PEIM, being part of\n    the firmware, has full access to the platform. If an operating system can\n    tamper with the contents of the LockBox, then at the next resume the\n    platform's integrity might be subverted.\n\n    OVMF stores the LockBox in normal guest RAM (refer to the memory map\n    section above). Operating systems and third party UEFI drivers and UEFI\n    applications that respect the UEFI memory map will not inadvertently\n    overwrite the LockBox storage, but there's nothing to prevent eg. a\n    malicious kernel from modifying the LockBox.\n\nOne means to address these issues is SMM and SMRAM (System Management Mode and\nSystem Management RAM).\n\nDuring boot and resume, the firmware can enter and leave SMM and access SMRAM.\nBefore the DXE phase is left, and control is transferred to the BDS phase (when\nthird party UEFI drivers and applications can be loaded, and an operating system\ncan be loaded), SMRAM is locked in hardware, and subsequent modules cannot\naccess it directly. (See EFI_DXE_SMM_READY_TO_LOCK_PROTOCOL.)\n\nOnce SMRAM has been locked, UEFI drivers and the operating system can enter SMM\nby raising a System Management Interrupt (SMI), at which point trusted code\n(part of the platform firmware) takes control. SMRAM is also unlocked by\nplatform reset, at which point the boot firmware takes control again.\n\n## Variable store and LockBox in SMRAM\n\nEdk2 provides almost all components to implement the variable store and the\nLockBox in SMRAM. In this section we summarize ideas for utilizing those\nfacilities.\n\nThe SMRAM and SMM infrastructure in edk2 is built up as follows:\n\n(1) The platform hardware provides SMM / SMI / SMRAM.\n\n    Qemu/KVM doesn't support these features currently and should implement them\n    in the longer term.\n\n(2) The platform vendor (in this case, OVMF developers) implement device drivers\nfor the platform's System Management Mode:\n\n    - EFI_SMM_CONTROL2_PROTOCOL: for raising a synchronous (and/or) periodic\n      SMI(s); that is, for entering SMM.\n\n    - EFI_SMM_ACCESS2_PROTOCOL: for describing and accessing SMRAM.\n\n    These protocols are documented in the PI Specification, Volume 4.\n\n(3) The platform DSC file is to include the following platform-independent\nmodules:\n\n    - MdeModulePkg/Core/PiSmmCore/PiSmmIpl.inf: SMM Initial Program Load\n    - MdeModulePkg/Core/PiSmmCore/PiSmmCore.inf: SMM Core\n\n(4) At this point, modules of type DXE_SMM_DRIVER can be loaded.\n\n    Such drivers are privileged. They run in SMM, have access to SMRAM, and are\n    separated and switched from other drivers through SMIs. Secure\n    communication between unprivileged (non-SMM) and privileged (SMM) drivers\n    happens through EFI_SMM_COMMUNICATION_PROTOCOL (implemented by the SMM\n    Core, see (3)).\n\n    DXE_SMM_DRIVER modules must sanitize their input (coming from unprivileged\n    drivers) carefully.\n\n(5) The authenticated runtime variable services driver (for Secure Boot builds)\nis located under \"SecurityPkg/VariableAuthenticated/RuntimeDxe\". OVMF currently\nbuilds the driver (a DXE_RUNTIME_DRIVER module) with the\n\"VariableRuntimeDxe.inf\" control file (refer to \"OvmfPkg/OvmfPkgX64.dsc\"), which\ndoes not use SMM.\n\n    The directory includes two more INF files:\n\n    - VariableSmm.inf -- module type: DXE_SMM_DRIVER. A privileged driver that\n      runs in SMM and has access to SMRAM.\n\n    - VariableSmmRuntimeDxe.inf -- module type: DXE_RUNTIME_DRIVER. A\n      non-privileged driver that implements the variable runtime services\n      (replacing the current \"VariableRuntimeDxe.inf\" file) by communicating\n      with the above privileged SMM half via EFI_SMM_COMMUNICATION_PROTOCOL.\n\n(6) An SMRAM-based LockBox implementation needs to be discussed in two parts,\nbecause the LockBox is accessed in both PEI and DXE.\n\n    (a) During DXE, drivers save data in the LockBox. A save operation is\n        layered as follows:\n\n        - The unprivileged driver wishing to store data in the LockBox links\n          against the \"MdeModulePkg/Library/SmmLockBoxLib/SmmLockBoxDxeLib.inf\"\n          library instance.\n\n          The library allows the unprivileged driver to format requests for the\n          privileged SMM LockBox driver (see below), and to parse responses.\n\n        - The privileged SMM LockBox driver is built from\n          \"MdeModulePkg/Universal/LockBox/SmmLockBox/SmmLockBox.inf\". This\n          driver has module type DXE_SMM_DRIVER and can access SMRAM.\n\n          The driver delegates command parsing and response formatting to\n          \"MdeModulePkg/Library/SmmLockBoxLib/SmmLockBoxSmmLib.inf\".\n\n        - The above two halves (unprivileged and privileged) mirror what we've\n          seen in case of the variable service drivers, under (5).\n\n    (b) In PEI, the S3 Resume PEIM (UefiCpuPkg/Universal/Acpi/S3Resume2Pei)\n        retrieves data from the LockBox.\n\n        Presumably, S3Resume2Pei should be considered an \"unprivileged PEIM\",\n        and the SMRAM access should be layered as seen in DXE. Unfortunately,\n        edk2 does not implement all of the layers in PEI -- the code either\n        doesn't exist, or it is not open source:\n\nrole | DXE: protocol/module | PEI: PPI/module\n-------------+--------------------------------+------------------------------\nunprivileged | any | S3Resume2Pei.inf driver | |\n-------------+--------------------------------+------------------------------\ncommand | LIBRARY_CLASS = LockBoxLib | LIBRARY_CLASS = LockBoxLib formatting | |\nand response | SmmLockBoxDxeLib.inf | SmmLockBoxPeiLib.inf parsing | |\n-------------+--------------------------------+------------------------------\nprivilege | EFI_SMM_COMMUNICATION_PROTOCOL | EFI_PEI_SMM_COMMUNICATION_PPI\nseparation | | | PiSmmCore.inf | missing!\n-------------+--------------------------------+------------------------------\nplatform SMM | EFI_SMM_CONTROL2_PROTOCOL | PEI_SMM_CONTROL_PPI and SMRAM |\nEFI_SMM_ACCESS2_PROTOCOL | PEI_SMM_ACCESS_PPI access | | | to be done in OVMF |\nto be done in OVMF\n-------------+--------------------------------+------------------------------\ncommand | LIBRARY_CLASS = LockBoxLib | LIBRARY_CLASS = LockBoxLib parsing and |\n| response | SmmLockBoxSmmLib.inf | missing! formatting | |\n-------------+--------------------------------+------------------------------\nprivileged | SmmLockBox.inf | missing! LockBox | | driver | |\n\n        Alternatively, in the future OVMF might be able to provide a LockBoxLib\n        instance (an SmmLockBoxPeiLib substitute) for S3Resume2Pei that\n        accesses SMRAM directly, eliminating the need for deeper layers in the\n        stack (that is, EFI_PEI_SMM_COMMUNICATION_PPI and deeper).\n\n        In fact, a \"thin\" EFI_PEI_SMM_COMMUNICATION_PPI implementation whose\n        sole Communicate() member invariably returns EFI_NOT_STARTED would\n        cause the current SmmLockBoxPeiLib library instance to directly perform\n        full-depth SMRAM access and LockBox search, obviating the \"missing\"\n        cells. (With reference to A Tour Beyond BIOS: Implementing S3 Resume\n        with EDK2, by Jiewen Yao and Vincent Zimmer, October 2014.)\n\n## Select features\n\nIn this section we'll browse the top-level \"OvmfPkg\" package directory, and\ndiscuss the more interesting drivers and libraries that have not been mentioned\nthus far.\n\nX64-specific reset vector for OVMF ..................................\n\nThe \"OvmfPkg/ResetVector\" directory customizes the reset vector (found in\n\"UefiCpuPkg/ResetVector/Vtf0\") for \"OvmfPkgX64.fdf\", that is, when the SEC/PEI\nphases run in 64-bit (ie. long) mode.\n\nThe reset vector's control flow looks roughly like:\n\nresetVector [Ia16/ResetVectorVtf0.asm] EarlyBspInitReal16 [Ia16/Init16.asm]\nMain16 [Main.asm] EarlyInit16 [Ia16/Init16.asm]\n\n    ; Transition the processor from\n    ; 16-bit real mode to 32-bit flat mode\n    TransitionFromReal16To32BitFlat         [Ia16/Real16ToFlat32.asm]\n\n    ; Search for the\n    ; Boot Firmware Volume (BFV)\n    Flat32SearchForBfvBase                  [Ia32/SearchForBfvBase.asm]\n\n    ; Search for the SEC entry point\n    Flat32SearchForSecEntryPoint            [Ia32/SearchForSecEntry.asm]\n\n    %ifdef ARCH_IA32\n      ; Jump to the 32-bit SEC entry point\n    %else\n      ; Transition the processor\n      ; from 32-bit flat mode\n      ; to 64-bit flat mode\n      Transition32FlatTo64Flat              [Ia32/Flat32ToFlat64.asm]\n\n        SetCr3ForPageTables64               [Ia32/PageTables64.asm]\n          ; set CR3 to page tables\n          ; built into the ROM image\n\n        ; enable PAE\n        ; set LME\n        ; enable paging\n\n      ; Jump to the 64-bit SEC entry point\n    %endif\n\nOn physical platforms, the initial page tables referenced by\nSetCr3ForPageTables64 are built statically into the flash device image, and are\npresent in ROM at runtime. This is fine on physical platforms because the\npre-built page table entries have the Accessed and Dirty bits set from the\nstart.\n\nAccordingly, for OVMF running in long mode on qemu/KVM, the initial page tables\nwere mapped as a KVM_MEM_READONLY slot, as part of QEMU's pflash device (refer\nto \"Firmware image structure\" above).\n\nIn spite of the Accessed and Dirty bits being pre-set in the read-only, in-flash\nPTEs, in a virtual machine attempts are made to update said PTE bits,\ndifferently from physical hardware. The component attempting to update the\nread-only PTEs can be one of the following:\n\n- The processor itself, if it supports nested paging, and the user enables that\n  processor feature,\n\n- KVM code implementing shadow paging, otherwise.\n\nThe first case presents no user-visible symptoms, but the second case (KVM,\nshadow paging) used to cause a triple fault, prior to Linux commit ba6a354\n(\"KVM: mmu: allow page tables to be in read-only slots\").\n\nFor compatibility with earlier KVM versions, the OvmfPkg/ResetVector directory\nadapts the generic reset vector code as follows:\n\n      Transition32FlatTo64Flat         [UefiCpuPkg/.../Ia32/Flat32ToFlat64.asm]\n\n        SetCr3ForPageTables64       [OvmfPkg/ResetVector/Ia32/PageTables64.asm]\n\n          ; dynamically build the initial page tables in RAM, at address\n          ; PcdOvmfSecPageTablesBase (refer to the memory map above),\n          ; identity-mapping the first 4 GB of address space\n\n          ; set CR3 to PcdOvmfSecPageTablesBase\n\n        ; enable PAE\n        ; set LME\n        ; enable paging\n\nThis way the PTEs that earlier KVM versions try to update (during shadow paging)\nare located in a read-write memory slot, and the write attempts succeed.\n\nClient library for QEMU's firmware configuration interface\n..........................................................\n\nQEMU provides a write-only, 16-bit wide control port, and a read-write, 8-bit\nwide data port for exchanging configuration elements with the firmware.\n\nThe firmware writes a selector (a key) to the control port (0x510), and then\nreads the corresponding configuration data (produced by QEMU) from the data port\n(0x511).\n\nIf the selected entry is writable, the firmware may overwrite it. If QEMU has\nassociated a callback with the entry, then when the entry is completely\nrewritten, QEMU runs the callback. (OVMF does not rewrite any entries at the\nmoment.)\n\nA number of selector values (keys) are predefined. In particular, key 0x19\nselects (returns) a directory of { name, selector, size } triplets, roughly\nspeaking.\n\nThe firmware can request configuration elements by well-known name as well, by\nlooking up the selector value first in the directory, by name, and then writing\nthe selector to the control port. The number of bytes to read subsequently from\nthe data port is known from the directory entry's \"size\" field.\n\nBy convention, directory entries (well-known symbolic names of configuration\nelements) are formatted as POSIX pathnames. For example, the array selected by\nthe \"etc/system-states\" name indicates (among other things) whether the user\nenabled S3 support in QEMU.\n\nThe above interface is called \"fw_cfg\".\n\nThe binary data associated with a symbolic name is called an \"fw_cfg file\".\n\nOVMF's fw_cfg client library is found in \"OvmfPkg/Library/QemuFwCfgLib\". OVMF\ndiscovers many aspects of the virtual system with it; we refer to a few examples\nbelow.\n\nGuest ACPI tables .................\n\nAn operating system discovers a good amount of its hardware by parsing ACPI\ntables, and by interpreting ACPI objects and methods. On physical hardware, the\nplatform vendor's firmware installs ACPI tables in memory that match both the\nhardware present in the system and the user's firmware configuration (\"BIOS\nsetup\").\n\nUnder qemu/KVM, the owner of the (virtual) hardware configuration is QEMU.\nHardware can easily be reconfigured on the command line. Furthermore, features\nlike CPU hotplug, PCI hotplug, memory hotplug are continuously developed for\nQEMU, and operating systems need direct ACPI support to exploit these features.\n\nFor this reason, QEMU builds its own ACPI tables dynamically, in a\nself-descriptive manner, and exports them to the firmware through a complex,\nmulti-file fw_cfg interface. It is rooted in the \"etc/table-loader\" fw_cfg file.\n(Further details of this interface are out of scope for this report.)\n\nOVMF's AcpiPlatformDxe driver fetches the ACPI tables, and installs them for the\nguest OS with the EFI_ACPI_TABLE_PROTOCOL (which is in turn provided by the\ngeneric \"MdeModulePkg/Universal/Acpi/AcpiTableDxe\" driver).\n\nFor earlier QEMU versions and machine types (which we generally don't recommend\nfor OVMF; see \"Scope\"), the \"OvmfPkg/AcpiTables\" directory contains a few static\nACPI table templates. When the \"etc/table-loader\" fw_cfg file is unavailable,\nAcpiPlatformDxe installs these default tables (with a little bit of dynamic\npatching).\n\nWhen OVMF runs in a Xen domU, AcpiTableDxe also installs ACPI tables that\noriginate from the hypervisor's environment.\n\nGuest SMBIOS tables ...................\n\nQuoting the SMBIOS Reference Specification,\n\n[...] the System Management BIOS Reference Specification addresses how\nmotherboard and system vendors present management information about their\nproducts in a standard format [...]\n\nIn practice SMBIOS tables are just another set of tables that the platform\nvendor's firmware installs in RAM for the operating system, and, importantly,\nfor management applications running on the OS. Without rehashing the \"Guest ACPI\ntables\" section in full, let's map the OVMF roles seen there from ACPI to\nSMBIOS:\n\nrole | ACPI | SMBIOS\n-------------------------+-------------------------+-------------------------\nfw_cfg file | etc/table-loader | etc/smbios/smbios-tables\n-------------------------+-------------------------+-------------------------\nOVMF driver | AcpiPlatformDxe | SmbiosPlatformDxe under \"OvmfPkg\" | |\n-------------------------+-------------------------+-------------------------\nUnderlying protocol, | EFI_ACPI_TABLE_PROTOCOL | EFI_SMBIOS_PROTOCOL implemented\nby generic | | driver under | Acpi/AcpiTableDxe | SmbiosDxe\n\"MdeModulePkg/Universal\" | |\n-------------------------+-------------------------+-------------------------\ndefault tables available | yes | [RHEL] yes, Type0 and for earlier QEMU machine\n| | Type1 tables types, with hot-patching | |\n-------------------------+-------------------------+-------------------------\ntables fetched in Xen | yes | yes domUs | |\n\nPlatform-specific boot policy .............................\n\nOVMF's BDS (Boot Device Selection) phase is implemented by\nIntelFrameworkModulePkg/Universal/BdsDxe. Roughly speaking, this large driver:\n\n- provides the EFI BDS architectural protocol (which DXE transfers control to\n  after dispatching all DXE drivers),\n\n- connects drivers to devices,\n\n- enumerates boot devices,\n\n- auto-generates boot options,\n\n- provides \"BIOS setup\" screens, such as:\n\n  - Boot Manager, for booting an option,\n\n  - Boot Maintenance Manager, for adding, deleting, and reordering boot options,\n    changing console properties etc,\n\n  - Device Manager, where devices can register configuration forms, including\n\n    - Secure Boot configuration forms,\n\n    - OVMF's Platform Driver form (see under PlatformDxe).\n\nFirmware that includes the \"IntelFrameworkModulePkg/Universal/BdsDxe\" driver can\ncustomize its behavior by providing an instance of the PlatformBdsLib library\nclass. The driver links against this platform library, and the platform library\ncan call Intel's BDS utility functions from\n\"IntelFrameworkModulePkg/Library/GenericBdsLib\".\n\nOVMF's PlatformBdsLib instance can be found in \"OvmfPkg/Library/PlatformBdsLib\".\nThe main function where the BdsDxe driver enters the library is\nPlatformBdsPolicyBehavior(). We mention two OVMF particulars here.\n\n(1) OVMF is capable of loading kernel images directly from fw_cfg, matching\nQEMU's -kernel, -initrd, and -append command line options. This feature is\nuseful for rapid, repeated Linux kernel testing, and is implemented in the\nfollowing call tree:\n\n    PlatformBdsPolicyBehavior() [OvmfPkg/Library/PlatformBdsLib/BdsPlatform.c]\n      TryRunningQemuKernel() [OvmfPkg/Library/PlatformBdsLib/QemuKernel.c]\n        LoadLinux*() [OvmfPkg/Library/LoadLinuxLib/Linux.c]\n\n    OvmfPkg/Library/LoadLinuxLib ports the efilinux bootloader project into\n    OvmfPkg.\n\n(2) OVMF seeks to comply with the boot order specification passed down by QEMU\nover fw_cfg.\n\n    (a) About Boot Modes\n\n      During the PEI phase, OVMF determines and stores the Boot Mode in the\n      PHIT HOB (already mentioned in \"S3 (suspend to RAM and resume)\"). The\n      boot mode is supposed to influence the rest of the system, for example it\n      distinguishes S3 resume (BOOT_ON_S3_RESUME) from a \"normal\" boot.\n\n      In general, \"normal\" boots can be further differentiated from each other;\n      for example for speed reasons. When the firmware can tell during PEI that\n      the chassis has not been opened since last power-up, then it might want\n      to save time by not connecting all devices and not enumerating all boot\n      options from scratch; it could just rely on the stored results of the\n      last enumeration. The matching BootMode value, to be set during PEI,\n      would be BOOT_ASSUMING_NO_CONFIGURATION_CHANGES.\n\n      OVMF only sets one of the following two boot modes, based on CMOS\n      contents:\n      - BOOT_ON_S3_RESUME,\n      - BOOT_WITH_FULL_CONFIGURATION.\n\n      For BOOT_ON_S3_RESUME, please refer to \"S3 (suspend to RAM and resume)\".\n      The other boot mode supported by OVMF, BOOT_WITH_FULL_CONFIGURATION, is\n      an appropriate \"catch-all\" for a virtual machine, where hardware can\n      easily change from boot to boot.\n\n    (b) Auto-generation of boot options\n\n      Accordingly, when not resuming from S3 sleep (*), OVMF always connects\n      all devices, and enumerates all bootable devices as new boot options\n      (non-volatile variables called Boot####).\n\n      (*) During S3 resume, DXE is not reached, hence BDS isn't either.\n\n      The auto-enumerated boot options are stored in the BootOrder non-volatile\n      variable after any preexistent options. (Boot options may exist before\n      auto-enumeration eg. because the user added them manually with the Boot\n      Maintenance Manager or the efibootmgr utility. They could also originate\n      from an earlier auto-enumeration.)\n\n      PlatformBdsPolicyBehavior()                   [OvmfPkg/.../BdsPlatform.c]\n        TryRunningQemuKernel()                       [OvmfPkg/.../QemuKernel.c]\n        BdsLibConnectAll()           [IntelFrameworkModulePkg/.../BdsConnect.c]\n        BdsLibEnumerateAllBootOption()  [IntelFrameworkModulePkg/.../BdsBoot.c]\n          BdsLibBuildOptionFromHandle() [IntelFrameworkModulePkg/.../BdsBoot.c]\n            BdsLibRegisterNewOption()   [IntelFrameworkModulePkg/.../BdsMisc.c]\n              //\n              // Append the new option number to the original option order\n              //\n\n    (c) Relative UEFI device paths in boot options\n\n      The handling of relative (\"short-form\") UEFI device paths is best\n      demonstrated through an example, and by quoting the UEFI 2.4A\n      specification.\n\n      A short-form hard drive UEFI device path could be (displaying each device\n      path node on a separate line for readability):\n\n        HD(1,GPT,14DD1CC5-D576-4BBF-8858-BAF877C8DF61,0x800,0x64000)/\n        \\EFI\\fedora\\shim.efi\n\n      This device path lacks prefix nodes (eg. hardware or messaging type\n      nodes) that would lead to the hard drive. During load option processing,\n      the above short-form or relative device path could be matched against the\n      following absolute device path:\n\n        PciRoot(0x0)/\n        Pci(0x4,0x0)/\n        HD(1,GPT,14DD1CC5-D576-4BBF-8858-BAF877C8DF61,0x800,0x64000)/\n        \\EFI\\fedora\\shim.efi\n\n      The motivation for this type of device path matching / completion is to\n      allow the user to move around the hard drive (for example, to plug a\n      controller in a different PCI slot, or to expose the block device on a\n      different iSCSI path) and still enable the firmware to find the hard\n      drive.\n\n      The UEFI specification says,\n\n        9.3.6 Media Device Path\n        9.3.6.1 Hard Drive\n\n          [...] Section 3.1.2 defines special rules for processing the Hard\n          Drive Media Device Path. These special rules enable a disk's location\n          to change and still have the system boot from the disk. [...]\n\n        3.1.2 Load Option Processing\n\n          [...] The boot manager must [...] support booting from a short-form\n          device path that starts with the first element being a hard drive\n          media device path [...]. The boot manager must use the GUID or\n          signature and partition number in the hard drive device path to match\n          it to a device in the system. If the drive supports the GPT\n          partitioning scheme the GUID in the hard drive media device path is\n          compared with the UniquePartitionGuid field of the GUID Partition\n          Entry [...]. If the drive supports the PC-AT MBR scheme the signature\n          in the hard drive media device path is compared with the\n          UniqueMBRSignature in the Legacy Master Boot Record [...]. If a\n          signature match is made, then the partition number must also be\n          matched. The hard drive device path can be appended to the matching\n          hardware device path and normal boot behavior can then be used. If\n          more than one device matches the hard drive device path, the boot\n          manager will pick one arbitrarily. Thus the operating system must\n          ensure the uniqueness of the signatures on hard drives to guarantee\n          deterministic boot behavior.\n\n      Edk2 implements and exposes the device path completion logic in the\n      already referenced \"IntelFrameworkModulePkg/Library/GenericBdsLib\"\n      library, in the BdsExpandPartitionPartialDevicePathToFull() function.\n\n    (d) Filtering and reordering the boot options based on fw_cfg\n\n      Once we have an \"all-inclusive\", partly preexistent, partly freshly\n      auto-generated boot option list from bullet (b), OVMF loads QEMU's\n      requested boot order from fw_cfg, and filters and reorders the list from\n      (b) with it:\n\n      PlatformBdsPolicyBehavior()                   [OvmfPkg/.../BdsPlatform.c]\n        TryRunningQemuKernel()                       [OvmfPkg/.../QemuKernel.c]\n        BdsLibConnectAll()           [IntelFrameworkModulePkg/.../BdsConnect.c]\n        BdsLibEnumerateAllBootOption()  [IntelFrameworkModulePkg/.../BdsBoot.c]\n        SetBootOrderFromQemu()                    [OvmfPkg/.../QemuBootOrder.c]\n\n      According to the (preferred) \"-device ...,bootindex=N\" and the (legacy)\n      '-boot order=drives' command line options, QEMU requests a boot order\n      from the firmware through the \"bootorder\" fw_cfg file. (For a bootindex\n      example, refer to the \"Example qemu invocation\" section.)\n\n      This fw_cfg file consists of OpenFirmware (OFW) device paths -- note: not\n      UEFI device paths! --, one per line. An example list is:\n\n        /pci@i0cf8/scsi@4/disk@0,0\n        /pci@i0cf8/ide@1,1/drive@1/disk@0\n        /pci@i0cf8/ethernet@3/ethernet-phy@0\n\n      OVMF filters and reorders the boot option list from bullet (b) with the\n      following nested loops algorithm:\n\n        new_uefi_order := \u003cempty\u003e\n        for each qemu_ofw_path in QEMU's OpenFirmware device path list:\n          qemu_uefi_path_prefix := translate(qemu_ofw_path)\n\n          for each boot_option in current_uefi_order:\n            full_boot_option := complete(boot_option)\n\n            if match(qemu_uefi_path_prefix, full_boot_option):\n              append(new_uefi_order, boot_option)\n              break\n\n        for each unmatched boot_option in current_uefi_order:\n          if survives(boot_option):\n            append(new_uefi_order, boot_option)\n\n        current_uefi_order := new_uefi_order\n\n      OVMF iterates over QEMU's OFW device paths in order, translates each to a\n      UEFI device path prefix, tries to match the translated prefix against the\n      UEFI boot options (which are completed from relative form to absolute\n      form for the purpose of prefix matching), and if there's a match, the\n      matching boot option is appended to the new boot order (which starts out\n      empty).\n\n      (We elaborate on the translate() function under bullet (e). The\n      complete() function has been explained in bullet (c).)\n\n      In addition, UEFI boot options that remain unmatched after filtering and\n      reordering are post-processed, and some of them \"survive\". Due to the\n      fact that OpenFirmware device paths have less expressive power than their\n      UEFI counterparts, some UEFI boot options are simply inexpressible (hence\n      unmatchable) by the nested loops algorithm.\n\n      An important example is the memory-mapped UEFI shell, whose UEFI device\n      path is inexpressible by QEMU's OFW device paths:\n\n        MemoryMapped(0xB,0x900000,0x10FFFFF)/\n        FvFile(7C04A583-9E3E-4F1C-AD65-E05268D0B4D1)\n\n      (Side remark: notice that the address range visible in the MemoryMapped()\n      node corresponds to DXEFV under \"comprehensive memory map of OVMF\"! In\n      addition, the FvFile() node's GUID originates from the FILE_GUID entry of\n      \"ShellPkg/Application/Shell/Shell.inf\".)\n\n      The UEFI shell can be booted by pressing ESC in OVMF on the TianoCore\n      splash screen, and navigating to Boot Manager | EFI Internal Shell. If\n      the \"survival policy\" was not implemented, the UEFI shell's boot option\n      would always be filtered out.\n\n      The current \"survival policy\" preserves all boot options that start with\n      neither PciRoot() nor HD().\n\n    (e) Translating QEMU's OpenFirmware device paths to UEFI device path\n        prefixes\n\n      In this section we list the (strictly heuristical) mappings currently\n      performed by OVMF.\n\n      The \"prefix only\" nature of the translation output is rooted minimally in\n      the fact that QEMU's OpenFirmware device paths cannot carry pathnames\n      within filesystems. There's no way to specify eg.\n\n        \\EFI\\fedora\\shim.efi\n\n      in an OFW device path, therefore a UEFI device path translated from an\n      OFW device path can at best be a prefix (not a full match) of a UEFI\n      device path that ends with \"\\EFI\\fedora\\shim.efi\".\n\n      - IDE disk, IDE CD-ROM:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/ide@1,1/drive@0/disk@0\n               ^         ^ ^       ^      ^\n               |         | |       |      master or slave\n               |         | |       primary or secondary\n               |         PCI slot \u0026 function holding IDE controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefix:\n\n          PciRoot(0x0)/Pci(0x1,0x1)/Ata(Primary,Master,0x0)\n                                                       ^\n                                                       fixed LUN\n\n      - Floppy disk:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/isa@1/fdc@03f0/floppy@0\n               ^         ^     ^           ^\n               |         |     |           A: or B:\n               |         |     ISA controller io-port (hex)\n               |         PCI slot holding ISA controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefix:\n\n          PciRoot(0x0)/Pci(0x1,0x0)/Floppy(0x0)\n                                           ^\n                                           ACPI UID (A: or B:)\n\n      - Virtio-block disk:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/scsi@6[,3]/disk@0,0\n               ^          ^  ^       ^ ^\n               |          |  |       fixed\n               |          |  PCI function corresponding to disk (optional)\n               |          PCI slot holding disk\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x6,0x0)/HD(\n          PciRoot(0x0)/Pci(0x6,0x3)/HD(\n\n      - Virtio-scsi disk and virtio-scsi passthrough:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/scsi@7[,3]/channel@0/disk@2,3\n               ^          ^             ^      ^ ^\n               |          |             |      | LUN\n               |          |             |      target\n               |          |             channel (unused, fixed 0)\n               |          PCI slot[, function] holding SCSI controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x7,0x0)/Scsi(0x2,0x3)\n          PciRoot(0x0)/Pci(0x7,0x3)/Scsi(0x2,0x3)\n\n      - Emulated and passed-through (physical) network cards:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/ethernet@3[,2]\n               ^              ^\n               |              PCI slot[, function] holding Ethernet card\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x3,0x0)\n          PciRoot(0x0)/Pci(0x3,0x2)\n\nVirtio drivers ..............\n\nUEFI abstracts various types of hardware resources into protocols, and allows\nfirmware developers to implement those protocols in device drivers. The Virtio\nSpecification defines various types of virtual hardware for virtual machines.\nConnecting the two specifications, OVMF provides UEFI drivers for QEMU's\nvirtio-block, virtio-scsi, and virtio-net devices.\n\nThe following diagram presents the protocol and driver stack related to Virtio\ndevices in edk2 and OVMF. Each node in the graph identifies a protocol and/or\nthe edk2 driver that produces it. Nodes on the top are more abstract.\n\nEFI_BLOCK_IO_PROTOCOL EFI_SIMPLE_NETWORK_PROTOCOL [OvmfPkg/VirtioBlkDxe]\n[OvmfPkg/VirtioNetDxe] | | | EFI_EXT_SCSI_PASS_THRU_PROTOCOL | |\n[OvmfPkg/VirtioScsiDxe] | | | |\n+------------------------+--------------------------+ | VIRTIO_DEVICE_PROTOCOL |\n+---------------------+---------------------+ | | [OvmfPkg/VirtioPciDeviceDxe]\n[custom platform drivers] | | | | EFI_PCI_IO_PROTOCOL\n[OvmfPkg/Library/VirtioMmioDeviceLib] [MdeModulePkg/Bus/Pci/PciBusDxe] direct\nMMIO register access\n\nThe top three drivers produce standard UEFI abstractions: the Block IO Protocol,\nthe Extended SCSI Pass Thru Protocol, and the Simple Network Protocol, for\nvirtio-block, virtio-scsi, and virtio-net devices, respectively.\n\nComparing these device-specific virtio drivers to each other, we can determine:\n\n- They all conform to the UEFI Driver Model. This means that their entry point\n  functions don't immediately start to search for devices and to drive them,\n  they only register instances of the EFI_DRIVER_BINDING_PROTOCOL. The UEFI\n  Driver Model then enumerates devices and chains matching drivers\n  automatically.\n\n- They are as minimal as possible, while remaining correct (refer to source code\n  comments for details). For example, VirtioBlkDxe and VirtioScsiDxe both\n  support only one request in flight.\n\n  In theory, VirtioBlkDxe could implement EFI_BLOCK_IO2_PROTOCOL, which allows\n  queueing. Similarly, VirtioScsiDxe does not support the non-blocking mode of\n  EFI_EXT_SCSI_PASS_THRU_PROTOCOL.PassThru(). (Which is permitted by the UEFI\n  specification.) Both VirtioBlkDxe and VirtioScsiDxe delegate synchronous\n  request handling to \"OvmfPkg/Library/VirtioLib\". This limitation helps keep\n  the implementation simple, and testing thus far seems to imply satisfactory\n  performance, for a virtual boot firmware.\n\n  VirtioNetDxe cannot avoid queueing, because EFI_SIMPLE_NETWORK_PROTOCOL\n  requires it on the interface level. Consequently, VirtioNetDxe is\n  significantly more complex than VirtioBlkDxe and VirtioScsiDxe. Technical\n  notes are provided in \"OvmfPkg/VirtioNetDxe/TechNotes.txt\".\n\n- None of these drivers access hardware directly. Instead, the Virtio Device\n  Protocol (OvmfPkg/Include/Protocol/VirtioDevice.h) collects / extracts virtio\n  operations defined in the Virtio Specification, and these backend-independent\n  virtio device drivers go through the abstract VIRTIO_DEVICE_PROTOCOL.\n\n  IMPORTANT: the VIRTIO_DEVICE_PROTOCOL is not a standard UEFI protocol. It is\n  internal to edk2 and not described in the UEFI specification. It should only\n  be used by drivers and applications that live inside the edk2 source tree.\n\nCurrently two providers exist for VIRTIO_DEVICE_PROTOCOL:\n\n- The first one is the \"more traditional\" virtio-pci backend, implemented by\n  OvmfPkg/VirtioPciDeviceDxe. This driver also complies with the UEFI Driver\n  Model. It consumes an instance of the EFI_PCI_IO_PROTOCOL, and, if the PCI\n  device/function under probing appears to be a virtio device, it produces a\n  Virtio Device Protocol instance for it. The driver translates abstract virtio\n  operations to PCI accesses.\n\n- The second provider, the virtio-mmio backend, is a library, not a driver,\n  living in OvmfPkg/Library/VirtioMmioDeviceLib. This library translates\n  abstract virtio operations to MMIO accesses.\n\n  The virtio-mmio backend is only a library -- rather than a standalone, UEFI\n  Driver Model-compliant driver -- because the type of resource it consumes, an\n  MMIO register block base address, is not enumerable.\n\n  In other words, while the PCI root bridge driver and the PCI bus driver\n  produce instances of EFI_PCI_IO_PROTOCOL automatically, thereby enabling the\n  UEFI Driver Model to probe devices and stack up drivers automatically, no such\n  enumeration exists for MMIO register blocks.\n\n  For this reason, VirtioMmioDeviceLib needs to be linked into thin, custom\n  platform drivers that dispose over this kind of information. As soon as a\n  driver knows about the MMIO register block base addresses, it can pass each to\n  the library, and then the VIRTIO_DEVICE_PROTOCOL will be instantiated\n  (assuming a valid virtio-mmio register block of course). From that point on\n  the UEFI Driver Model again takes care of the chaining.\n\n  Typically, such a custom driver does not conform to the UEFI Driver Model\n  (because that would presuppose auto-enumeration for MMIO register blocks).\n  Hence it has the following responsibilities:\n\n  - it shall behave as a \"wrapper\" UEFI driver around the library,\n\n  - it shall know virtio-mmio base addresses,\n\n  - in its entry point function, it shall create a new UEFI handle with an\n    instance of the EFI_DEVICE_PATH_PROTOCOL for each virtio-mmio device it\n    knows the base address for,\n\n  - it shall call VirtioMmioInstallDevice() on those handles, with the\n    corresponding base addresses.\n\n  OVMF itself does not employ VirtioMmioDeviceLib. However, the library is used\n  (or has been tested as Proof-of-Concept) in the following 64-bit and 32-bit\n  ARM emulator setups:\n\n  - in \"RTSM_VE_FOUNDATIONV8_EFI.fd\" and \"FVP_AARCH64_EFI.fd\", on ARM Holdings'\n    ARM(R) v8-A Foundation Model and ARM(R) AEMv8-A Base Platform FVP emulators,\n    respectively:\n\n                           EFI_BLOCK_IO_PROTOCOL\n                           [OvmfPkg/VirtioBlkDxe]\n                                      |\n                           VIRTIO_DEVICE_PROTOCOL\n        [ArmPlatformPkg/ArmVExpressPkg/ArmVExpressDxe/ArmFvpDxe.inf]\n                                      |\n                    [OvmfPkg/Library/VirtioMmioDeviceLib]\n                         direct MMIO register access\n\n  - in \"RTSM_VE_CORTEX-A15_EFI.fd\" and \"RTSM_VE_CORTEX-A15_MPCORE_EFI.fd\", on\n    \"qemu-system-arm -M vexpress-a15\":\n\n        EFI_BLOCK_IO_PROTOCOL            EFI_SIMPLE_NETWORK_PROTOCOL\n        [OvmfPkg/VirtioBlkDxe]             [OvmfPkg/VirtioNetDxe]\n                   |                                  |\n                   +------------------+---------------+\n                                      |\n                           VIRTIO_DEVICE_PROTOCOL\n        [ArmPlatformPkg/ArmVExpressPkg/ArmVExpressDxe/ArmFvpDxe.inf]\n                                      |\n                    [OvmfPkg/Library/VirtioMmioDeviceLib]\n                         direct MMIO register access\n\n  In the above ARM / VirtioMmioDeviceLib configurations, VirtioBlkDxe was tested\n  with booting Linux distributions, while VirtioNetDxe was tested with pinging\n  public IPv4 addresses from the UEFI shell.\n\nPlatform Driver ...............\n\nSometimes, elements of persistent firmware configuration are best exposed to the\nuser in a friendly way. OVMF's platform driver (OvmfPkg/PlatformDxe) presents\nsuch settings on the \"OVMF Platform Configuration\" dialog:\n\n- Press ESC on the TianoCore splash screen,\n- Navigate to Device Manager | OVMF Platform Configuration.\n\nAt the moment, OVMF's platform driver handles only one setting: the preferred\ngraphics resolution. This is useful for two purposes:\n\n- Some UEFI shell commands, like DRIVERS and DEVICES, benefit from a wide\n  display. Using the MODE shell command, the user can switch to a larger text\n  resolution (limited by the graphics resolution), and see the command output in\n  a more easily consumable way.\n\n  [RHEL] The list of text modes available to the MODE command is also limited by\n  ConSplitterDxe (found under MdeModulePkg/Universal/Console). ConSplitterDxe\n  builds an intersection of text modes that are simultaneously supported by all\n  consoles that ConSplitterDxe multiplexes console output to.\n\n         In practice, the strongest text mode restriction comes from\n         TerminalDxe, which provides console I/O on serial ports. TerminalDxe\n         has a very limited built-in list of text modes, heavily pruning the\n         intersection built by ConSplitterDxe, and made available to the MODE\n         command.\n\n         On the Red Hat Enterprise Linux 7.1 host, TerminalDxe's list of modes\n         has been extended with text resolutions that match the Spice QXL GPU's\n         common graphics resolutions. This way a \"full screen\" text mode should\n         always be available in the MODE command.\n\n- The other advantage of controlling the graphics resolution lies with UEFI\n  operating systems that don't (yet) have a native driver for QEMU's virtual\n  video cards -- eg. the Spice QXL GPU. Such OSes may choose to inherit the\n  properties of OVMF's EFI_GRAPHICS_OUTPUT_PROTOCOL (provided by\n  OvmfPkg/QemuVideoDxe, see later).\n\n  Although the display can be used at runtime in such cases, by direct\n  framebuffer access, its properties, for example, the resolution, cannot be\n  modified. The platform driver allows the user to select the preferred GOP\n  resolution, reboot, and let the guest OS inherit that preferred resolution.\n\nThe platform driver has three access points: the \"normal\" driver entry point, a\nset of HII callbacks, and a GOP installation callback.\n\n(1) Driver entry point: the PlatformInit() function.\n\n    (a) First, this function loads any available settings, and makes them take\n        effect. For the preferred graphics resolution in particular, this means\n        setting the following PCDs:\n\n          gEfiMdeModulePkgTokenSpaceGuid.PcdVideoHorizontalResolution\n          gEfiMdeModulePkgTokenSpaceGuid.PcdVideoVerticalResolution\n\n        These PCDs influence the GraphicsConsoleDxe driver (located under\n        MdeModulePkg/Universal/Console), which switches to the preferred\n        graphics mode, and produces EFI_SIMPLE_TEXT_OUTPUT_PROTOCOLs on GOPs:\n\n                    EFI_SIMPLE_TEXT_OUTPUT_PROTOCOL\n          [MdeModulePkg/Universal/Console/GraphicsConsoleDxe]\n                                   |\n                      EFI_GRAPHICS_OUTPUT_PROTOCOL\n                         [OvmfPkg/QemuVideoDxe]\n                                   |\n                          EFI_PCI_IO_PROTOCOL\n                   [MdeModulePkg/Bus/Pci/PciBusDxe]\n\n(b) Second, the driver entry point registers the user interface, including HII\ncallbacks.\n\n(c) Third, the driver entry point registers a GOP installation callback.\n\n(2) HII callbacks and the user interface.\n\n    The Human Interface Infrastructure (HII) \"is a set of protocols that allow\n    a UEFI driver to provide the ability to register user interface and\n    configuration content with the platform firmware\".\n\n    OVMF's platform driver:\n\n    - provides a static, basic, visual form (PlatformForms.vfr), written in the\n      Visual Forms Representation language,\n\n    - includes a UCS-16 encoded message catalog (Platform.uni),\n\n    - includes source code that dynamically populates parts of the form, with\n      the help of MdeModulePkg/Library/UefiHiiLib -- this library simplifies\n      the handling of IFR (Internal Forms Representation) opcodes,\n\n    - processes form actions that the user takes (Callback() function),\n\n    - loads and saves platform configuration in a private, non-volatile\n      variable (ExtractConfig() and RouteConfig() functions).\n\n    The ExtractConfig() HII callback implements the following stack of\n    conversions, for loading configuration and presenting it to the user:\n\n          MultiConfigAltResp       -- form engine / HII communication\n                  ^\n                  |\n           [BlockToConfig]\n                  |\n           MAIN_FORM_STATE         -- binary representation of form/widget\n                  ^                   state\n                  |\n      [PlatformConfigToFormState]\n                  |\n           PLATFORM_CONFIG         -- accessible to DXE and UEFI drivers\n                  ^\n                  |\n         [PlatformConfigLoad]\n                  |\n        UEFI non-volatile variable -- accessible to external utilities\n\n    The layers are very similar for the reverse direction, ie. when taking\n    input from the user, and saving the configuration (RouteConfig() HII\n    callback):\n\n             ConfigResp            -- form engine / HII communication\n                  |\n           [ConfigToBlock]\n                  |\n                  v\n           MAIN_FORM_STATE         -- binary representation of form/widget\n                  |                   state\n      [FormStateToPlatformConfig]\n                  |\n                  v\n           PLATFORM_CONFIG         -- accessible to DXE and UEFI drivers\n                  |\n         [PlatformConfigSave]\n                  |\n                  v\n        UEFI non-volatile variable -- accessible to external utilities\n\n(3) When the platform driver starts, a GOP may not be available yet. Thus the\ndriver entry point registers a callback (the GopInstalled() function) for GOP\ninstallations.\n\n    When the first GOP is produced (usually by QemuVideoDxe, or potentially by\n    a third party video driver), PlatformDxe retrieves the list of graphics\n    modes the GOP supports, and dynamically populates the drop-down list of\n    available resolutions on the form. The GOP installation callback is then\n    removed.\n\nVideo driver ............\n\nOvmfPkg/QemuVideoDxe is OVMF's built-in video driver. We can divide its services\nin two parts: graphics output protocol (primary), and Int10h (VBE) shim\n(secondary).\n\n(1) QemuVideoDxe conforms to the UEFI Driver Model; it produces an instance of\nthe EFI_GRAPHICS_OUTPUT_PROTOCOL (GOP) on each PCI display that it supports and\nis connected to:\n\n                      EFI_GRAPHICS_OUTPUT_PROTOCOL\n                         [OvmfPkg/QemuVideoDxe]\n                                   |\n                          EFI_PCI_IO_PROTOCOL\n                   [MdeModulePkg/Bus/Pci/PciBusDxe]\n\n    It supports the following QEMU video cards:\n\n    - Cirrus 5430 (\"-device cirrus-vga\"),\n    - Standard VGA (\"-device VGA\"),\n    - QXL VGA (\"-device qxl-vga\", \"-device qxl\").\n\n    For Cirrus the following resolutions and color depths are available:\n    640x480x32, 800x600x32, 1024x768x24. On stdvga and QXL a long list of\n    resolutions is available. The list is filtered against the frame buffer\n    size during initialization.\n\n    The size of the QXL VGA compatibility framebuffer can be changed with the\n\n      -device qxl-vga,vgamem_mb=$NUM_MB\n\n    QEMU option. If $NUM_MB exceeds 32, then the following is necessary\n    instead:\n\n      -device qxl-vga,vgamem_mb=$NUM_MB,ram_size_mb=$((NUM_MB*2))\n\n    because the compatibility framebuffer can't cover more than half of PCI BAR\n    #0. The latter defaults to 64MB in size, and is controlled by the\n    \"ram_size_mb\" property.\n\n(2) When QemuVideoDxe binds the first Standard VGA or QXL VGA device, and there\nis no real VGA BIOS present in the C to F segments (which could originate from a\nlegacy PCI option ROM -- refer to \"Compatibility Support Module (CSM)\"), then\nQemuVideoDxe installs a minimal, \"fake\" VGA BIOS -- an Int10h (VBE) \"shim\".\n\n    The shim is implemented in 16-bit assembly in\n    \"OvmfPkg/QemuVideoDxe/VbeShim.asm\". The \"VbeShim.sh\" shell script assembles\n    it and formats it as a C array (\"VbeShim.h\") with the help of the \"nasm\"\n    utility. The driver's InstallVbeShim() function copies the shim in place\n    (the C segment), and fills in the VBE Info and VBE Mode Info structures.\n    The real-mode 10h interrupt vector is pointed to the shim's handler.\n\n    The shim is (correctly) irrelevant and invisible for all UEFI operating\n    systems we know about -- except Windows Server 2008 R2 and other Windows\n    operating systems in that family.\n\n    Namely, the Windows 2008 R2 SP1 (and Windows 7) UEFI guest's default video\n    driver dereferences the real mode Int10h vector, loads the pointed-to\n    handler code, and executes what it thinks to be VGA BIOS services in an\n    internal real-mode emulator. Consequently, video mode switching used not to\n    work in Windows 2008 R2 SP1 when it ran on the \"pure UEFI\" build of OVMF,\n    making the guest uninstallable. Hence the (otherwise optional, non-default)\n    Compatibility Support Module (CSM) ended up a requirement for running such\n    guests.\n\n    The hard dependency on the sophisticated SeaBIOS CSM and the complex\n    supporting edk2 infrastructure, for enabling this family of guests, was\n    considered suboptimal by some members of the upstream community,\n\n    [RHEL] and was certainly considered a serious maintenance disadvantage for\n           Red Hat Enterprise Linux 7.1 hosts.\n\n    Thus, the shim has been collaboratively developed for the Windows 7 /\n    Windows Server 2008 R2 family. The shim provides a real stdvga / QXL\n    implementation for the few services that are in fact necessary for the\n    Windows 2008 R2 SP1 (and Windows 7) UEFI guest, plus some \"fakes\" that the\n    guest invokes but whose effect is not important. The only supported mode is\n    1024x768x32, which is enough to install the guest and then upgrade its\n    video driver to the full-featured QXL XDDM one.\n\n    The C segment is not present in the UEFI memory map prepared by OVMF.\n    Memory space that would cover it is never added (either in PEI, in the form\n    of memory resource descriptor HOBs, or in DXE, via gDS-\u003eAddMemorySpace()).\n    This way the handler body is invisible to all other UEFI guests, and the\n    rest of edk2.\n\n    The Int10h real-mode IVT entry is covered with a Boot Services Code page,\n    making that too inaccessible to the rest of edk2. Due to the allocation\n    type, UEFI guest OSes different from the Windows Server 2008 family can\n    reclaim the page at zero. (The Windows 2008 family accesses that page\n    regardless of the allocation type.)\n\n## Afterword\n\nAfter the bulk of this document was written in July 2014, OVMF development has\nnot stopped. To name two significant code contributions from the community: in\nJanuary 2015, OVMF runs on the \"q35\" machine type of QEMU, and it features a\ndriver for Xen paravirtual block devices (and another for the underlying Xen\nbus).\n\nFurthermore, a dedicated virtualization platform has been contributed to\nArmPlatformPkg that plays a role parallel to OvmfPkg's. It targets the \"virt\"\nmachine type of qemu-system-arm and qemu-system-aarch64. Parts of OvmfPkg are\nbeing refactored and modularized so they can be reused in\n\"ArmPlatformPkg/ArmVirtualizationPkg/ArmVirtualizationQemu.dsc\".","snippets":["#uefi #resource"],"rawContent":"# OVMF Whitepaper\n\n#uefi #resource\n\nI'm making a copy here since this is entirely in text format.\n\n---\n\nOpen Virtual Machine Firmware (OVMF) Status Report July 2014 (with updates in\nAugust 2014 - January 2015)\n\nAuthor: Laszlo Ersek \u003clersek@redhat.com\u003e Copyright (C) 2014-2015, Red Hat, Inc.\nCC BY-SA 4.0 \u003chttp://creativecommons.org/licenses/by-sa/4.0/\u003e\n\n## Abstract\n\nThe Unified Extensible Firmware Interface (UEFI) is a specification that defines\na software interface between an operating system and platform firmware. UEFI is\ndesigned to replace the Basic Input/Output System (BIOS) firmware interface.\n\nHardware platform vendors have been increasingly adopting the UEFI Specification\nto govern their boot firmware developments. OVMF (Open Virtual Machine\nFirmware), a sub-project of Intel's EFI Development Kit II (edk2), enables UEFI\nsupport for Ia32 and X64 Virtual Machines.\n\nThis paper reports on the status of the OVMF project, treats features and\nlimitations, gives end-user hints, and examines some areas in-depth.\n\nKeywords: ACPI, boot options, CSM, edk2, firmware, flash, fw_cfg, KVM, memory\nmap, non-volatile variables, OVMF, PCD, QEMU, reset vector, S3, Secure Boot,\nSmbios, SMM, TianoCore, UEFI, VBE shim, Virtio\n\n## Table of Contents\n\n- Motivation\n- Scope\n- Example qemu invocation\n- Installation of OVMF guests with virt-manager and virt-install\n- Supported guest operating systems\n- Compatibility Support Module (CSM)\n- Phases of the boot process\n- Project structure\n- Platform Configuration Database (PCD)\n- Firmware image structure\n- S3 (suspend to RAM and resume)\n- A comprehensive memory map of OVMF\n- Known Secure Boot limitations\n- Variable store and LockBox in SMRAM\n- Select features\n  - X64-specific reset vector for OVMF\n  - Client library for QEMU's firmware configuration interface\n  - Guest ACPI tables\n  - Guest SMBIOS tables\n  - Platform-specific boot policy\n  - Virtio drivers\n  - Platform Driver\n  - Video driver\n- Afterword\n\n## Motivation\n\nOVMF extends the usual benefits of virtualization to UEFI. Reasons to use OVMF\ninclude:\n\n- Legacy-free guests. A UEFI-based environment eliminates dependencies on legacy\n  address spaces and devices. This is especially beneficial when used with\n  physically assigned devices where the legacy operating mode is troublesome to\n  support, ex. assigned graphics cards operating in legacy-free, non-VGA mode in\n  the guest.\n\n- Future proof guests. The x86 market is steadily moving towards a legacy-free\n  platform and guest operating systems may eventually require a UEFI\n  environment. OVMF provides that next generation firmware support for such\n  applications.\n\n- GUID partition tables (GPTs). MBR partition tables represent partition offsets\n  and sizes with 32-bit integers, in units of 512 byte sectors. This limits the\n  addressable portion of the disk to 2 TB. GPT represents logical block\n  addresses with 64 bits.\n\n- Liberating boot loader binaries from residing in contested and poorly defined\n  space between the partition table and the partitions.\n\n- Support for booting off disks (eg. pass-through physical SCSI devices) with a\n  4kB physical and logical sector size, i.e. which don't have 512-byte block\n  emulation.\n\n- Development and testing of Secure Boot-related features in guest operating\n  systems. Although OVMF's Secure Boot implementation is currently not secure\n  against malicious UEFI drivers, UEFI applications, and guest kernels, trusted\n  guest code that only uses standard UEFI interfaces will find a valid Secure\n  Boot environment under OVMF, with working key enrollment and signature\n  validation. This enables development and testing of portable, Secure\n  Boot-related guest code.\n\n- Presence of non-volatile UEFI variables. This furthers development and testing\n  of OS installers, UEFI boot loaders, and unique, dependent guest OS features.\n  For example, an efivars-backed pstore (persistent storage) file system works\n  under Linux.\n\n- Altogether, a near production-level UEFI environment for virtual machines when\n  Secure Boot is not required.\n\n## Scope\n\nUEFI and especially Secure Boot have been topics fraught with controversy and\npolitical activism. This paper sidesteps these aspects and strives to focus on\nuse cases, hands-on information for end users, and technical details.\n\nUnless stated otherwise, the expression \"X supports Y\" means \"X is technically\ncompatible with interfaces provided or required by Y\". It does not imply support\nas an activity performed by natural persons or companies.\n\nWe discuss the status of OVMF at a state no earlier than edk2 SVN\nrevision 16158. The paper concentrates on upstream projects and communities, but\noccasionally it pans out about OVMF as it is planned to be shipped (as Technical\nPreview) in Red Hat Enterprise Linux 7.1. Such digressions are marked with the\n[RHEL] margin notation.\n\nAlthough other VMMs and accelerators are known to support (or plan to support)\nOVMF to various degrees -- for example, VirtualBox, Xen, BHyVe --, we'll\nemphasize OVMF on qemu/KVM, because QEMU and KVM have always been Red Hat's\nfocus wrt. OVMF.\n\nThe recommended upstream QEMU version is 2.1+. The recommended host Linux kernel\n(KVM) version is 3.10+. The recommended QEMU machine type is \"qemu-system-x86_64\n-M pc-i440fx-2.1\" or later.\n\nThe term \"TianoCore\" is used interchangeably with \"edk2\" in this paper.\n\n## Example qemu invocation\n\nThe following commands give a quick foretaste of installing a UEFI operating\nsystem on OVMF, relying only on upstream edk2 and qemu.\n\n- Clone and build OVMF:\n\n  git clone https://github.com/tianocore/edk2.git cd edk2 nice OvmfPkg/build.sh\n  -a X64 -n $(getconf \\_NPROCESSORS_ONLN)\n\n  (Note that this ad-hoc build will not include the Secure Boot feature.)\n\n- The build output file, \"OVMF.fd\", includes not only the executable firmware\n  code, but the non-volatile variable store as well. For this reason, make a\n  VM-specific copy of the build output (the variable store should be private to\n  the virtual machine):\n\n  cp Build/OvmfX64/DEBUG_GCC4?/FV/OVMF.fd fedora.flash\n\n  (The variable store and the firmware executable are also available in the\n  build output as separate files: \"OVMF_VARS.fd\" and \"OVMF_CODE.fd\". This\n  enables central management and updates of the firmware executable, while each\n  virtual machine can retain its own variable store.)\n\n- Download a Fedora LiveCD:\n\n  wget\n  https://dl.fedoraproject.org/pub/fedora/linux/releases/20/Live/x86_64/Fedora-Live-Xfce-x86_64-20-1.iso\n\n- Create a virtual disk (qcow2 format, 20 GB in size):\n\n  qemu-img create -f qcow2 fedora.img 20G\n\n- Create the following qemu wrapper script under the name \"fedora.sh\":\n\n  # Basic virtual machine properties: a recent i440fx machine type, KVM\n\n  # acceleration, 2048 MB RAM, two VCPUs.\n\n  OPTS=\"-M pc-i440fx-2.1 -enable-kvm -m 2048 -smp 2\"\n\n  # The OVMF binary, including the non-volatile variable store, appears as a\n\n  # \"normal\" qemu drive on the host side, and it is exposed to the guest as a\n\n  # persistent flash device.\n\n  OPTS=\"$OPTS -drive if=pflash,format=raw,file=fedora.flash\"\n\n  # The hard disk is exposed to the guest as a virtio-block device. OVMF has a\n\n  # driver stack that supports such a disk. We specify this disk as first boot\n\n  # option. OVMF recognizes the boot order specification.\n\n  OPTS=\"$OPTS -drive id=disk0,if=none,format=qcow2,file=fedora.img\"\n  OPTS=\"$OPTS\n  -device virtio-blk-pci,drive=disk0,bootindex=0\"\n\n  # The Fedora installer disk appears as an IDE CD-ROM in the guest. This is\n\n  # the 2nd boot option.\n\n  OPTS=\"$OPTS -drive id=cd0,if=none,format=raw,readonly\"\n  OPTS=\"$OPTS,file=Fedora-Live-Xfce-x86_64-20-1.iso\"\n  OPTS=\"$OPTS -device ide-cd,bus=ide.1,drive=cd0,bootindex=1\"\n\n  # The following setting enables S3 (suspend to RAM). OVMF supports S3\n\n  # suspend/resume.\n\n  OPTS=\"$OPTS -global PIIX4_PM.disable_s3=0\"\n\n  # OVMF emits a number of info / debug messages to the QEMU debug console, at\n\n  # ioport 0x402. We configure qemu so that the debug console is indeed\n\n  # available at that ioport. We redirect the host side of the debug console to\n\n  # a file.\n\n  OPTS=\"$OPTS -global isa-debugcon.iobase=0x402 -debugcon file:fedora.ovmf.log\"\n\n  # QEMU accepts various commands and queries from the user on the monitor\n\n  # interface. Connect the monitor with the qemu process's standard input and\n\n  # output.\n\n  OPTS=\"$OPTS -monitor stdio\"\n\n  # A USB tablet device in the guest allows for accurate pointer tracking\n\n  # between the host and the guest.\n\n  OPTS=\"$OPTS -device piix3-usb-uhci -device usb-tablet\"\n\n  # Provide the guest with a virtual network card (virtio-net).\n\n  #\n\n  # Normally, qemu provides the guest with a UEFI-conformant network driver\n\n  # from the iPXE project, in the form of a PCI expansion ROM. For this test,\n\n  # we disable the expansion ROM and allow OVMF's built-in virtio-net driver to\n\n  # take effect.\n\n  #\n\n  # On the host side, we use the SLIRP (\"user\") network backend, which has\n\n  # relatively low performance, but it doesn't require extra privileges from\n\n  # the user executing qemu.\n\n  OPTS=\"$OPTS -netdev id=net0,type=user\"\n  OPTS=\"$OPTS -device\n  virtio-net-pci,netdev=net0,romfile=\"\n\n  # A Spice QXL GPU is recommended as the primary VGA-compatible display\n\n  # device. It is a full-featured virtual video card, with great operating\n\n  # system driver support. OVMF supports it too.\n\n  OPTS=\"$OPTS -device qxl-vga\"\n\n  qemu-system-x86_64 $OPTS\n\n- Start the Fedora guest:\n\n  sh fedora.sh\n\n- The above command can be used for both installation and later boots of the\n  Fedora guest.\n\n- In order to verify basic OVMF network connectivity:\n\n  - Assuming that the non-privileged user running qemu belongs to group G (where\n    G is a numeric identifier), ensure as root on the host that the group range\n    in file \"/proc/sys/net/ipv4/ping_group_range\" includes G.\n\n  - As the non-privileged user, boot the guest as usual.\n\n  - On the TianoCore splash screen, press ESC.\n\n  - Navigate to Boot Manager | EFI Internal Shell\n\n  - In the UEFI Shell, issue the following commands:\n\n    ifconfig -s eth0 dhcp ping A.B.C.D\n\n    where A.B.C.D is a public IPv4 address in dotted decimal notation that your\n    host can reach.\n\n  - Type \"quit\" at the (qemu) monitor prompt.\n\n## Installation of OVMF guests with virt-manager and virt-install\n\n(1) Assuming OVMF has been installed on the host with the following files: -\n/usr/share/OVMF/OVMF_CODE.fd - /usr/share/OVMF/OVMF_VARS.fd\n\n    locate the \"nvram\" stanza in \"/etc/libvirt/qemu.conf\", and edit it as\n    follows:\n\n    nvram = [ \"/usr/share/OVMF/OVMF_CODE.fd:/usr/share/OVMF/OVMF_VARS.fd\" ]\n\n(2) Restart libvirtd with your Linux distribution's service management tool; for\nexample,\n\n    systemctl restart libvirtd\n\n(3) In virt-manager, proceed with the guest installation as usual: - select File\n| New Virtual Machine, - advance to Step 5 of 5, - in Step 5, check \"Customize\nconfiguration before install\", - click Finish; - in the customization dialog,\nselect Overview | Firmware, and choose UEFI, - click Apply and Begin\nInstallation.\n\n(4) With virt-install:\n\n    LDR=\"loader=/usr/share/OVMF/OVMF_CODE.fd,loader_ro=yes,loader_type=pflash\"\n    virt-install \\\n      --name fedora20 \\\n      --memory 2048 \\\n      --vcpus 2 \\\n      --os-variant fedora20 \\\n      --boot hd,cdrom,$LDR \\\n      --disk size=20 \\\n      --disk path=Fedora-Live-Xfce-x86_64-20-1.iso,device=cdrom,bus=scsi\n\n(5) A popular, distribution-independent, bleeding-edge OVMF package is available\nunder \u003chttps://www.kraxel.org/repos/\u003e, courtesy of Gerd Hoffmann.\n\n    The \"edk2.git-ovmf-x64\" package provides the following files, among others:\n    - /usr/share/edk2.git/ovmf-x64/OVMF_CODE-pure-efi.fd\n    - /usr/share/edk2.git/ovmf-x64/OVMF_VARS-pure-efi.fd\n\n    When using this package, adapt steps (1) and (4) accordingly.\n\n(6) Additionally, the \"edk2.git-ovmf-x64\" package seeks to simplify the\nenablement of Secure Boot in a virtual machine (strictly for development and\ntesting purposes).\n\n    - Boot the virtual machine off the CD-ROM image called\n      \"/usr/share/edk2.git/ovmf-x64/UefiShell.iso\"; before or after installing\n      the main guest operating system.\n\n    - When the UEFI shell appears, issue the following commands:\n\n      EnrollDefaultKeys.efi\n      reset -s\n\n    - The EnrollDefaultKeys.efi utility enrolls the following keys:\n\n      - A static example X.509 certificate (CN=TestCommonName) as Platform Key\n        and first Key Exchange Key.\n\n        The private key matching this certificate has been destroyed (but you\n        shouldn't trust this statement).\n\n      - \"Microsoft Corporation KEK CA 2011\" as second Key Exchange Key\n        (SHA1: 31:59:0b:fd:89:c9:d7:4e:d0:87:df:ac:66:33:4b:39:31:25:4b:30).\n\n      - \"Microsoft Windows Production PCA 2011\" as first DB entry\n        (SHA1: 58:0a:6f:4c:c4:e4:b6:69:b9:eb:dc:1b:2b:3e:08:7b:80:d0:67:8d).\n\n      - \"Microsoft Corporation UEFI CA 2011\" as second DB entry\n        (SHA1: 46:de:f6:3b:5c:e6:1c:f8:ba:0d:e2:e6:63:9c:10:19:d0:ed:14:f3).\n\n      These keys suffice to boot released versions of popular Linux\n      distributions (through the shim.efi utility), and Windows 8 and Windows\n      Server 2012 R2, in Secure Boot mode.\n\n## Supported guest operating systems\n\nUpstream OVMF does not favor some guest operating systems over others for\npolitical or ideological reasons. However, some operating systems are harder to\nobtain and/or technically more difficult to support. The general expectation is\nthat recent UEFI OSes should just work. Please consult the \"OvmfPkg/README\"\nfile.\n\nThe following guest OSes were tested with OVMF:\n\n- Red Hat Enterprise Linux 6\n- Red Hat Enterprise Linux 7\n- Fedora 18\n- Fedora 19\n- Fedora 20\n- Windows Server 2008 R2 SP1\n- Windows Server 2012\n- Windows 8\n\nNotes about Windows Server 2008 R2 (paraphrasing the \"OvmfPkg/README\" file):\n\n- QEMU should be started with one of the \"-device qxl-vga\" and \"-device VGA\"\n  options.\n\n- Only one video mode, 1024x768x32, is supported at OS runtime.\n\n  Please refer to the section about QemuVideoDxe (OVMF's built-in video driver)\n  for more details on this limitation.\n\n- The qxl-vga video card is recommended (\"-device qxl-vga\"). After booting the\n  installed guest OS, select the video card in Device Manager, and upgrade the\n  video driver to the QXL XDDM one.\n\n  The QXL XDDM driver can be downloaded from\n  \u003chttp://www.spice-space.org/download.html\u003e, under Guest | Windows binaries.\n\n  This driver enables additional graphics resolutions at OS runtime, and\n  provides S3 (suspend/resume) capability.\n\nNotes about Windows Server 2012 and Windows 8:\n\n- QEMU should be started with the \"-device qxl-vga,revision=4\" option (or a\n  later revision, if available).\n\n- The guest OS's builtin video driver inherits the video mode / frame buffer\n  from OVMF. There's no way to change the resolution at OS runtime.\n\n  For this reason, a platform driver has been developed for OVMF, which allows\n  users to change the preferred video mode in the firmware. Please refer to the\n  section about PlatformDxe for details.\n\n- It is recommended to upgrade the guest OS's video driver to the QXL WDDM one,\n  via Device Manager.\n\n  Binaries for the QXL WDDM driver can be found at\n  \u003chttp://people.redhat.com/~vrozenfe/qxlwddm\u003e (pick a version greater than or\n  equal to 0.6), while the source code resides at\n  \u003chttps://github.com/vrozenfe/qxl-dod\u003e.\n\n  This driver enables additional graphics resolutions at OS runtime, and\n  provides S3 (suspend/resume) capability.\n\n## Compatibility Support Module (CSM)\n\nCollaboration between SeaBIOS and OVMF developers has enabled SeaBIOS to be\nbuilt as a Compatibility Support Module, and OVMF to embed and use it.\n\nBenefits of a SeaBIOS CSM include:\n\n- The ability to boot legacy (non-UEFI) operating systems, such as legacy Linux\n  systems, Windows 7, OpenBSD 5.2, FreeBSD 8/9, NetBSD, DragonflyBSD, Solaris\n  10/11.\n\n- Legacy (non-UEFI-compliant) PCI expansion ROMs, such as a VGA BIOS, mapped by\n  QEMU in emulated devices' ROM BARs, are loaded and executed by OVMF.\n\n  For example, this grants the Windows Server 2008 R2 SP1 guest's native, legacy\n  video driver access to all modes of all QEMU video cards.\n\nBuilding the CSM target of the SeaBIOS source tree is out of scope for this\nreport. Additionally, upstream OVMF does not enable the CSM by default.\n\nInterested users and developers should look for OVMF's \"-D CSM_ENABLE\"\nbuild-time option, and check out the \u003chttps://www.kraxel.org/repos/\u003e continuous\nintegration repository, which provides CSM-enabled OVMF builds.\n\n[RHEL] The \"OVMF_CODE.fd\" firmware image made available on the Red Hat\nEnterprise Linux 7.1 host does not include a Compatibility Support Module, for\nthe following reasons:\n\n       - Virtual machines running officially supported, legacy guest operating\n         systems should just use the standalone SeaBIOS firmware. Firmware\n         selection is flexible in virtualization, see eg. \"Installation of OVMF\n         guests with virt-manager and virt-install\" above.\n\n       - The 16-bit thunking interface between OVMF and SeaBIOS is very complex\n         and presents a large debugging and support burden, based on past\n         experience.\n\n       - Secure Boot is incompatible with CSM.\n\n       - Inter-project dependencies should be minimized whenever possible.\n\n       - Using the default QXL video card, the Windows 2008 R2 SP1 guest can be\n         installed with its built-in, legacy video driver. Said driver will\n         select the only available video mode, 1024x768x32. After installation,\n         the video driver can be upgraded to the full-featured QXL XDDM driver.\n\n## Phases of the boot process\n\nThe PI and UEFI specifications, and Intel's UEFI and EDK II Learning and\nDevelopment materials provide ample information on PI and UEFI concepts. The\nfollowing is an absolutely minimal, rough glossary that is included only to help\nreaders new to PI and UEFI understand references in later, OVMF-specific\nsections. We defer heavily to the official specifications and the training\nmaterials, and frequently quote them below.\n\nA central concept to mention early is the GUID -- globally unique identifier. A\nGUID is a 128-bit number, written as XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX, where\neach X stands for a hexadecimal nibble. GUIDs are used to name everything in PI\nand in UEFI. Programmers introduce new GUIDs with the \"uuidgen\" utility, and\nstandards bodies standardize well-known services by positing their GUIDs.\n\nThe boot process is roughly divided in the following phases:\n\n- Reset vector code.\n\n- SEC: Security phase. This phase is the root of firmware integrity.\n\n- PEI: Pre-EFI Initialization. This phase performs \"minimal processor, chipset\n  and platform configuration for the purpose of discovering memory\". Modules in\n  PEI collectively save their findings about the platform in a list of HOBs\n  (hand-off blocks).\n\n  When developing PEI code, the Platform Initialization (PI) specification\n  should be consulted.\n\n- DXE: Driver eXecution Environment, pronounced as \"Dixie\". This \"is the phase\n  where the bulk of the booting occurs: devices are enumerated and initialized,\n  UEFI services are supported, and protocols and drivers are implemented. Also,\n  the tables that create the UEFI interface are produced\".\n\n  On the PEI/DXE boundary, the HOBs produced by PEI are consumed. For example,\n  this is how the memory space map is configured initially.\n\n- BDS: Boot Device Selection. It is \"responsible for determining how and where\n  you want to boot the operating system\".\n\n  When developing DXE and BDS code, it is mainly the UEFI specification that\n  should be consulted. When speaking about DXE, BDS is frequently considered to\n  be a part of it.\n\nThe following concepts are tied to specific boot process phases:\n\n- PEIM: a PEI Module (pronounced \"PIM\"). A binary module running in the PEI\n  phase, consuming some PPIs and producing other PPIs, and producing HOBs.\n\n- PPI: PEIM-to-PEIM interface. A structure of function pointers and related data\n  members that establishes a PEI service, or an instance of a PEI service. PPIs\n  are identified by GUID.\n\n  An example is EFI_PEI_S3_RESUME2_PPI (6D582DBC-DB85-4514-8FCC-5ADF6227B147).\n\n- DXE driver: a binary module running in the DXE and BDS phases, consuming some\n  protocols and producing other protocols.\n\n- Protocol: A structure of function pointers and related data members that\n  establishes a DXE service, or an instance of a DXE service. Protocols are\n  identified by GUID.\n\n  An example is EFI_BLOCK_IO_PROTOCOL (964E5B21-6459-11D2-8E39-00A0C969723B).\n\n- Architectural protocols: a set of standard protocols that are foundational to\n  the working of a UEFI system. Each architectural protocol has at most one\n  instance. Architectural protocols are implemented by a subset of DXE drivers.\n  DXE drivers explicitly list the set of protocols (including architectural\n  protocols) that they need to work. UEFI drivers can only be loaded once all\n  architectural protocols have become available during the DXE phase.\n\n  An example is EFI_VARIABLE_WRITE_ARCH_PROTOCOL\n  (6441F818-6362-4E44-B570-7DBA31DD2453).\n\n## Project structure\n\nThe term \"OVMF\" usually denotes the project (community and development effort)\nthat provide and maintain the subject matter UEFI firmware for virtual machines.\nHowever the term is also frequently applied to the firmware binary proper that a\nvirtual machine executes.\n\nOVMF emerges as a compilation of several modules from the edk2 source\nrepository. \"edk2\" stands for EFI Development Kit II; it is a \"modern,\nfeature-rich, cross-platform firmware development environment for the UEFI and\nPI specifications\".\n\nThe composition of OVMF is dictated by the following build control files:\n\nOvmfPkg/OvmfPkgIa32.dsc OvmfPkg/OvmfPkgIa32.fdf\n\nOvmfPkg/OvmfPkgIa32X64.dsc OvmfPkg/OvmfPkgIa32X64.fdf\n\nOvmfPkg/OvmfPkgX64.dsc OvmfPkg/OvmfPkgX64.fdf\n\nThe format of these files is described in the edk2 DSC and FDF specifications.\nRoughly, the DSC file determines:\n\n- library instance resolutions for library class requirements presented by the\n  modules to be compiled,\n- the set of modules to compile.\n\nThe FDF file roughly determines:\n\n- what binary modules (compilation output files, precompiled binaries, graphics\n  image files, verbatim binary sections) to include in the firmware image,\n- how to lay out the firmware image.\n\nThe Ia32 flavor of these files builds a firmware where both PEI and DXE phases\nare 32-bit. The Ia32X64 flavor builds a firmware where the PEI phase consists of\n32-bit modules, and the DXE phase is 64-bit. The X64 flavor builds a purely\n64-bit firmware.\n\nThe word size of the DXE phase must match the word size of the runtime OS -- a\n32-bit DXE can't cooperate with a 64-bit OS, and a 64-bit DXE can't work a\n32-bit OS.\n\nOVMF pulls together modules from across the edk2 tree. For example:\n\n- common drivers and libraries that are platform independent are usually located\n  under MdeModulePkg and MdePkg,\n\n- common but hardware-specific drivers and libraries that match QEMU's\n  pc-i440fx-\\* machine type are pulled in from IntelFrameworkModulePkg,\n  PcAtChipsetPkg and UefiCpuPkg,\n\n- the platform independent UEFI Shell is built from ShellPkg,\n\n- OvmfPkg includes drivers and libraries that are useful for virtual machines\n  and may or may not be specific to QEMU's pc-i440fx-\\* machine type.\n\n## Platform Configuration Database (PCD)\n\nLike the \"Phases of the boot process\" section, this one introduces a concept in\nvery raw form. We defer to the PCD related edk2 specifications, and we won't\ndiscuss implementation details here. Our purpose is only to offer the reader a\nusable (albeit possibly inaccurate) definition, so that we can refer to PCDs\nlater on.\n\nColloquially, when we say \"PCD\", we actually mean \"PCD entry\"; that is, an entry\nstored in the Platform Configuration Database.\n\nThe Platform Configuration Database is\n\n- a firmware-wide\n- name-value store\n- of scalars and buffers\n- where each entry may be\n  - build-time constant, or\n  - run-time dynamic, or\n  - theoretically, a middle option: patchable in the firmware file itself, using\n    a dedicated tool. (OVMF does not utilize externally patchable entries.)\n\nA PCD entry is declared in the DEC file of the edk2 top-level Package directory\nwhose modules (drivers and libraries) are the primary consumers of the PCD\nentry. (See for example OvmfPkg/OvmfPkg.dec). Basically, a PCD in a DEC file\nexposes a simple customization point.\n\nInterest in a PCD entry is communicated to the build system by naming the PCD\nentry in the INF file of the interested module (application, driver or library).\nThe module may read and -- dependent on the PCD entry's category -- write the\nPCD entry.\n\nLet's investigate the characteristics of the Database and the PCD entries.\n\n- Firmware-wide: technically, all modules may access all entries they are\n  interested in, assuming they advertise their interest in their INF files. With\n  careful design, PCDs enable inter-driver propagation of (simple) system\n  configuration. PCDs are available in both PEI and DXE.\n\n  (UEFI drivers meant to be portable (ie. from third party vendors) are not\n  supposed to use PCDs, since PCDs qualify internal to the specific edk2\n  firmware in question.)\n\n- Name-value store of scalars and buffers: each PCD has a symbolic name, and a\n  fixed scalar type (UINT16, UINT32 etc), or VOID\\* for buffers. Each PCD entry\n  belongs to a namespace, where a namespace is (obviously) a GUID, defined in\n  the DEC file.\n\n- A DEC file can permit several categories for a PCD:\n  - build-time constant (\"FixedAtBuild\"),\n  - patchable in the firmware image (\"PatchableInModule\", unused in OVMF),\n  - runtime modifiable (\"Dynamic\").\n\nThe platform description file (DSC) of a top-level Package directory may choose\nthe exact category for a given PCD entry that its modules wish to use, and\nassign a default (or constant) initial value to it.\n\nIn addition, the edk2 build system too can initialize PCD entries to values that\nit calculates while laying out the flash device image. Such PCD assignments are\ndescribed in the FDF control file.\n\n## Firmware image structure\n\n(We assume the common X64 choice for both PEI and DXE, and the default DEBUG\nbuild target.)\n\nThe OvmfPkg/OvmfPkgX64.fdf file defines the following layout for the flash\ndevice image \"OVMF.fd\":\n\nDescription Compression type Size\n\n---\n\nNon-volatile data storage open-coded binary data 128 KB Variable store 56 KB\nEvent log 4 KB Working block 4 KB Spare area 64 KB\n\nFVMAIN_COMPACT uncompressed 1712 KB FV Firmware File System file LZMA compressed\nPEIFV uncompressed 896 KB individual PEI modules uncompressed DXEFV uncompressed\n8192 KB individual DXE modules uncompressed\n\nSECFV uncompressed 208 KB SEC driver reset vector code\n\nThe top-level image consists of three regions (three firmware volumes):\n\n- non-volatile data store (128 KB),\n- main firmware volume (FVMAIN_COMPACT, 1712 KB),\n- firmware volume containing the reset vector code and the SEC phase code (208\n  KB).\n\nIn total, the OVMF.fd file has size 128 KB + 1712 KB + 208 KB == 2 MB.\n\n(1) The firmware volume with non-volatile data store (128 KB) has the following\ninternal structure, in blocks of 4 KB:\n\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+  L: event log\n       LIVE | varstore                  |L|W|  W: working block\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      SPARE |                               |\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n    The first half of this firmware volume is \"live\", while the second half is\n    \"spare\". The spare half is important when the variable driver reclaims\n    unused storage and reorganizes the variable store.\n\n    The live half dedicates 14 blocks (56 KB) to the variable store itself. On\n    top of those, one block is set aside for an event log, and one block is\n    used as the working block of the fault tolerant write protocol. Fault\n    tolerant writes are used to recover from an occasional (virtual) power loss\n    during variable updates.\n\n    The blocks in this firmware volume are accessed, in stacking order from\n    least abstract to most abstract, by:\n\n    - EFI_FIRMWARE_VOLUME_BLOCK_PROTOCOL (provided by\n      OvmfPkg/QemuFlashFvbServicesRuntimeDxe),\n\n    - EFI_FAULT_TOLERANT_WRITE_PROTOCOL (provided by\n      MdeModulePkg/Universal/FaultTolerantWriteDxe),\n\n    - architectural protocols instrumental to the runtime UEFI variable\n      services:\n      - EFI_VARIABLE_ARCH_PROTOCOL,\n      - EFI_VARIABLE_WRITE_ARCH_PROTOCOL.\n\n      In a non-secure boot build, the DXE driver providing these architectural\n      protocols is MdeModulePkg/Universal/Variable/RuntimeDxe. In a secure boot\n      build, where authenticated variables are available, the DXE driver\n      offering these protocols is SecurityPkg/VariableAuthenticated/RuntimeDxe.\n\n(2) The main firmware volume (FVMAIN_COMPACT, 1712 KB) embeds further firmware\nvolumes. The outermost layer is a Firmware File System (FFS), carrying a single\nfile. This file holds an LZMA-compressed section, which embeds two firmware\nvolumes: PEIFV (896 KB) with PEIMs, and DXEFV (8192 KB) with DXE and UEFI\ndrivers.\n\n    This scheme enables us to build 896 KB worth of PEI drivers and 8192 KB\n    worth of DXE and UEFI drivers, compress them all with LZMA in one go, and\n    store the compressed result in 1712 KB, saving room in the flash device.\n\n(3) The SECFV firmware volume (208 KB) is not compressed. It carries the \"volume\ntop file\" with the reset vector code, to end at 4 GB in guest-physical address\nspace, and the SEC phase driver (OvmfPkg/Sec).\n\n    The last 16 bytes of the volume top file (mapped directly under 4 GB)\n    contain a NOP slide and a jump instruction. This is where QEMU starts\n    executing the firmware, at address 0xFFFF_FFF0. The reset vector and the\n    SEC driver run from flash directly.\n\n    The SEC driver locates FVMAIN_COMPACT in the flash, and decompresses the\n    main firmware image to RAM. The rest of OVMF (PEI, DXE, BDS phases) run\n    from RAM.\n\nAs already mentioned, the OVMF.fd file is mapped by qemu's\n\"hw/block/pflash_cfi01.c\" device just under 4 GB in guest-physical address\nspace, according to the command line option\n\n-drive if=pflash,format=raw,file=fedora.flash\n\n(refer to the Example qemu invocation). This is a \"ROMD device\", which can\nswitch out of \"ROMD mode\" and back into it.\n\nNamely, in the default ROMD mode, the guest-physical address range backed by the\nflash device reads and executes as ROM (it does not trap from KVM to QEMU). The\nfirst write access in this mode traps to QEMU, and flips the device out of ROMD\nmode.\n\nIn non-ROMD mode, the flash chip is programmed by storing CFI (Common Flash\nInterface) command values at the flash-covered addresses; both reads and writes\ntrap to QEMU, and the flash contents are modified and synchronized to the\nhost-side file. A special CFI command flips the flash device back to ROMD mode.\n\nQemu implements the above based on the KVM_CAP_READONLY_MEM / KVM_MEM_READONLY\nKVM features, and OVMF puts it to use in its EFI_FIRMWARE_VOLUME_BLOCK_PROTOCOL\nimplementation, under \"OvmfPkg/QemuFlashFvbServicesRuntimeDxe\".\n\nIMPORTANT: Never pass OVMF.fd to qemu with the -bios option. That option maps\nthe firmware image as ROM into the guest's address space, and forces OVMF to\nemulate non-volatile variables with a fallback driver that is bound to have\ninsufficient and confusing semantics.\n\nThe 128 KB firmware volume with the variable store, discussed under (1), is also\nbuilt as a separate host-side file, named \"OVMF_VARS.fd\". The \"rest\" is built\ninto a third file, \"OVMF_CODE.fd\", which is only 1920 KB in size. The variable\nstore is mapped into its usual location, at 4 GB - 2 MB = 0xFFE0_0000, through\nthe following qemu options:\n\n-drive if=pflash,format=raw,readonly,file=OVMF_CODE.fd \\\n -drive if=pflash,format=raw,file=fedora.varstore.fd\n\nThis way qemu configures two flash chips consecutively, with start addresses\ngrowing downwards, which is transparent to OVMF.\n\n[RHEL] Red Hat Enterprise Linux 7.1 ships a Secure Boot-enabled, X64, DEBUG\nfirmware only. Furthermore, only the split files (\"OVMF_VARS.fd\" and\n\"OVMF_CODE.fd\") are available.\n\n## S3 (suspend to RAM and resume)\n\nAs noted in Example qemu invocation, the\n\n-global PIIX4_PM.disable_s3=0\n\ncommand line option tells qemu and OVMF if the user would like to enable S3\nsupport. (This is corresponds to the /domain/pm/suspend-to-mem/@enabled libvirt\ndomain XML attribute.)\n\nImplementing / orchestrating S3 was a considerable community effort in OVMF. A\ndetailed description exceeds the scope of this report; we only make a few\nstatements.\n\n(1) S3-related PPIs and protocols are well documented in the PI specification.\n\n(2) Edk2 contains most modules that are needed to implement S3 on a given\nplatform. One abstraction that is central to the porting / extending of the\nS3-related modules to a new platform is the LockBox library interface, which a\nspecific platform can fill in by implementing its own LockBox library instance.\n\n    The LockBox library provides a privileged name-value store (to be addressed\n    by GUIDs). The privilege separation stretches between the firmware and the\n    operating system. That is, the S3-related machinery of the firmware saves\n    some items in the LockBox securely, under well-known GUIDs, before booting\n    the operating system. During resume (which is a form of warm reset), the\n    firmware is activated again, and retrieves items from the LockBox. Before\n    jumping to the OS's resume vector, the LockBox is secured again.\n\n    We'll return to this later when we separately discuss SMRAM and SMM.\n\n(3) During resume, the DXE and later phases are never reached; only the reset\nvector, and the SEC and PEI phases of the firmware run. The platform is supposed\nto detect a resume in progress during PEI, and to store that fact in the\nBootMode field of the Phase Handoff Information Table (PHIT) HOB. OVMF keys this\noff the CMOS, see OvmfPkg/PlatformPei.\n\n    At the end of PEI, the DXE IPL PEIM (Initial Program Load PEI Module, see\n    MdeModulePkg/Core/DxeIplPeim) examines the Boot Mode, and if it says \"S3\n    resume in progress\", then the IPL branches to the PEIM that exports\n    EFI_PEI_S3_RESUME2_PPI (provided by UefiCpuPkg/Universal/Acpi/S3Resume2Pei)\n    rather than loading the DXE core.\n\n    S3Resume2Pei executes the technical steps of the resumption, relying on the\n    contents of the LockBox.\n\n(4) During first boot (or after a normal platform reset), when DXE does run,\nhardware drivers in the DXE phase are encouraged to \"stash\" their hardware\nconfiguration steps (eg. accesses to PCI config space, I/O ports, memory mapped\naddresses, and so on) in a centrally maintained, so called \"S3 boot script\".\nHardware accesses are represented with opcodes of a special binary script\nlanguage.\n\n    This boot script is to be replayed during resume, by S3Resume2Pei. The\n    general goal is to bring back hardware devices -- which have been powered\n    off during suspend -- to their original after-first-boot state, and in\n    particular, to do so quickly.\n\n    At the moment, OVMF saves only one opcode in the S3 resume boot script: an\n    INFORMATION opcode, with contents 0xDEADBEEF (in network byte order). The\n    consensus between Linux developers seems to be that boot firmware is only\n    responsible for restoring basic chipset state, which OVMF does during PEI\n    anyway, independently of S3 vs. normal reset. (One example is the power\n    management registers of the i440fx chipset.) Device and peripheral state is\n    the responsibility of the runtime operating system.\n\n    Although an experimental OVMF S3 boot script was at one point captured for\n    the virtual Cirrus VGA card, such a boot script cannot follow eg. video\n    mode changes effected by the OS. Hence the operating system can never avoid\n    restoring device state, and most Linux display drivers (eg. stdvga, QXL)\n    already cover S3 resume fully.\n\n    The XDDM and WDDM driver models used under Windows OSes seem to recognize\n    this notion of runtime OS responsibility as well. (See the list of OSes\n    supported by OVMF in a separate section.)\n\n(5) The S3 suspend/resume data flow in OVMF is included here tersely, for\ninterested developers.\n\n    (a) BdsLibBootViaBootOption()\n          EFI_ACPI_S3_SAVE_PROTOCOL [AcpiS3SaveDxe]\n          - saves ACPI S3 Context to LockBox  ---------------------+\n            (including FACS address -- FACS ACPI table             |\n            contains OS waking vector)                             |\n                                                                   |\n          - prepares boot script:                                  |\n            EFI_S3_SAVE_STATE_PROTOCOL.Write() [S3SaveStateDxe]    |\n              S3BootScriptLib [PiDxeS3BootScriptLib]               |\n              - opcodes \u0026 arguments are saved in NVS.  --+         |\n                                                         |         |\n          - issues a notification by installing          |         |\n            EFI_DXE_SMM_READY_TO_LOCK_PROTOCOL           |         |\n                                                         |         |\n    (b) EFI_S3_SAVE_STATE_PROTOCOL [S3SaveStateDxe]      |         |\n          S3BootScriptLib [PiDxeS3BootScriptLib]         |         |\n          - closes script with special opcode  \u003c---------+         |\n          - script is available in non-volatile memory             |\n            via PcdS3BootScriptTablePrivateDataPtr  --+            |\n                                                      |            |\n        BootScriptExecutorDxe                         |            |\n          S3BootScriptLib [PiDxeS3BootScriptLib]      |            |\n          - Knows about boot script location by  \u003c----+            |\n            synchronizing with the other library                   |\n            instance via                                           |\n            PcdS3BootScriptTablePrivateDataPtr.                    |\n          - Copies relocated image of itself to                    |\n            reserved memory. --------------------------------+     |\n          - Saved image contains pointer to boot script.  ---|--+  |\n                                                             |  |  |\n    Runtime:                                                 |  |  |\n                                                             |  |  |\n    (c) OS is booted, writes OS waking vector to FACS,       |  |  |\n        suspends machine                                     |  |  |\n                                                             |  |  |\n    S3 Resume (PEI):                                         |  |  |\n                                                             |  |  |\n    (d) PlatformPei sets S3 Boot Mode based on CMOS          |  |  |\n                                                             |  |  |\n    (e) DXE core is skipped and EFI_PEI_S3_RESUME2 is        |  |  |\n        called as last step of PEI                           |  |  |\n                                                             |  |  |\n    (f) S3Resume2Pei retrieves from LockBox:                 |  |  |\n        - ACPI S3 Context (path to FACS)  \u003c------------------|--|--+\n                                          |                  |  |\n                                          +------------------|--|--+\n        - Boot Script Executor Image  \u003c----------------------+  |  |\n                                                                |  |\n    (g) BootScriptExecutorDxe                                   |  |\n          S3BootScriptLib [PiDxeS3BootScriptLib]                |  |\n          - executes boot script  \u003c-----------------------------+  |\n                                                                   |\n    (h) OS waking vector available from ACPI S3 Context / FACS  \u003c--+\n        is called\n\n## A comprehensive memory map of OVMF\n\nThe following section gives a detailed analysis of memory ranges below 4 GB that\nOVMF statically uses.\n\nIn the rightmost column, the PCD entry is identified by which the source refers\nto the address or size in question.\n\nThe flash-covered range has been discussed previously in \"Firmware image\nstructure\", therefore we include it only for completeness. Due to the fact that\nthis range is always backed by a memory mapped device (and never RAM), it is\nunaffected by S3 (suspend to RAM and resume).\n\n+--------------------------+ 4194304 KB | | | SECFV | size: 208 KB | |\n+--------------------------+ 4194096 KB | | | FVMAIN_COMPACT | size: 1712 KB | |\n+--------------------------+ 4192384 KB | | | variable store | size: 64 KB\nPcdFlashNvStorageFtwSpareSize | spare area | | | +--------------------------+\n4192320 KB PcdOvmfFlashNvStorageFtwSpareBase | | | FTW working block | size: 4\nKB PcdFlashNvStorageFtwWorkingSize | | +--------------------------+ 4192316 KB\nPcdOvmfFlashNvStorageFtwWorkingBase | | | Event log of | size: 4 KB\nPcdOvmfFlashNvStorageEventLogSize | non-volatile storage | | |\n+--------------------------+ 4192312 KB PcdOvmfFlashNvStorageEventLogBase | | |\nvariable store | size: 56 KB PcdFlashNvStorageVariableSize | |\n+--------------------------+ 4192256 KB PcdOvmfFlashNvStorageVariableBase\n\nThe flash-mapped image of OVMF.fd covers the entire structure above (2048 KB).\n\nWhen using the split files, the address 4192384 KB\n(PcdOvmfFlashNvStorageFtwSpareBase + PcdFlashNvStorageFtwSpareSize) is the\nboundary between the mapped images of OVMF_VARS.fd (56 KB + 4 KB + 4 KB + 64 KB\n= 128 KB) and OVMF_CODE.fd (1712 KB + 208 KB = 1920 KB).\n\nWith regard to RAM that is statically used by OVMF, S3 (suspend to RAM and\nresume) complicates matters. Many ranges have been introduced only to support\nS3, hence for all ranges below, the following questions will be audited:\n\n(a) when and how a given range is initialized after first boot of the VM, (b)\nhow it is protected from memory allocations during DXE, (c) how it is protected\nfrom the OS, (d) how it is accessed on the S3 resume path, (e) how it is\naccessed on the warm reset path.\n\nImportantly, the term \"protected\" is meant as protection against inadvertent\nreallocations and overwrites by co-operating DXE and OS modules. It does not\nimply security against malicious code.\n\n+--------------------------+ 17408 KB | | |DXEFV from FVMAIN_COMPACT | size:\n8192 KB PcdOvmfDxeMemFvSize | decompressed firmware | | volume with DXE modules\n| | | +--------------------------+ 9216 KB PcdOvmfDxeMemFvBase | | |PEIFV from\nFVMAIN_COMPACT | size: 896 KB PcdOvmfPeiMemFvSize | decompressed firmware | |\nvolume with PEI modules | | | +--------------------------+ 8320 KB\nPcdOvmfPeiMemFvBase | | | permanent PEI memory for | size: 32 KB\nPcdS3AcpiReservedMemorySize | the S3 resume path | | |\n+--------------------------+ 8288 KB PcdS3AcpiReservedMemoryBase | | | temporary\nSEC/PEI heap | size: 32 KB PcdOvmfSecPeiTempRamSize | and stack | | |\n+--------------------------+ 8256 KB PcdOvmfSecPeiTempRamBase | | | unused |\nsize: 32 KB | | +--------------------------+ 8224 KB | | | SEC's table of |\nsize: 4 KB PcdGuidedExtractHandlerTableSize | GUIDed section handlers | | |\n+--------------------------+ 8220 KB PcdGuidedExtractHandlerTableAddress | | |\nLockBox storage | size: 4 KB PcdOvmfLockBoxStorageSize | |\n+--------------------------+ 8216 KB PcdOvmfLockBoxStorageBase | | | early page\ntables on X64 | size: 24 KB PcdOvmfSecPageTablesSize | |\n+--------------------------+ 8192 KB PcdOvmfSecPageTablesBase\n\n(1) Early page tables on X64:\n\n(a) when and how it is initialized after first boot of the VM\n\n    The range is filled in during the SEC phase\n    [OvmfPkg/ResetVector/Ia32/PageTables64.asm]. The CR3 register is verified\n    against the base address in SecCoreStartupWithStack()\n    [OvmfPkg/Sec/SecMain.c].\n\n(b) how it is protected from memory allocations during DXE\n\n    If S3 was enabled on the QEMU command line (see \"-global\n    PIIX4_PM.disable_s3=0\" earlier), then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] protects the range with an AcpiNVS memory\n    allocation HOB, in PEI.\n\n    If S3 was disabled, then this range is not protected. DXE's own page tables\n    are first built while still in PEI (see HandOffToDxeCore()\n    [MdeModulePkg/Core/DxeIplPeim/X64/DxeLoadFunc.c]). Those tables are located\n    in permanent PEI memory. After CR3 is switched over to them (which occurs\n    before jumping to the DXE core entry point), we don't have to preserve the\n    initial tables.\n\n(c) how it is protected from the OS\n\n    If S3 is enabled, then (1b) reserves it from the OS too.\n\n    If S3 is disabled, then the range needs no protection.\n\n(d) how it is accessed on the S3 resume path\n\n    It is rewritten same as in (1a), which is fine because (1c) reserved it.\n\n(e) how it is accessed on the warm reset path\n\n    It is rewritten same as in (1a).\n\n(2) LockBox storage:\n\n(a) when and how it is initialized after first boot of the VM\n\n    InitializeRamRegions() [OvmfPkg/PlatformPei/MemDetect.c] zeroes out the\n    area during PEI. This is correct but not strictly necessary, since on first\n    boot the area is zero-filled anyway.\n\n    The LockBox signature of the area is filled in by the PEI module or DXE\n    driver that has been linked against OVMF's LockBoxLib and is run first. The\n    signature is written in LockBoxLibInitialize()\n    [OvmfPkg/Library/LockBoxLib/LockBoxLib.c].\n\n    Any module calling SaveLockBox() [OvmfPkg/Library/LockBoxLib/LockBoxLib.c]\n    will co-populate this area.\n\n(b) how it is protected from memory allocations during DXE\n\n    If S3 is enabled, then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] protects the range as AcpiNVS.\n\n    Otherwise, the range is covered with a BootServicesData memory allocation\n    HOB.\n\n(c) how it is protected from the OS\n\n    If S3 is enabled, then (2b) protects it sufficiently.\n\n    Otherwise the range requires no runtime protection, and the\n    BootServicesData allocation type from (2b) ensures that the range will be\n    released to the OS.\n\n(d) how it is accessed on the S3 resume path\n\n    The S3 Resume PEIM restores data from the LockBox, which has been correctly\n    protected in (2c).\n\n(e) how it is accessed on the warm reset path\n\n    InitializeRamRegions() [OvmfPkg/PlatformPei/MemDetect.c] zeroes out the\n    range during PEI, effectively emptying the LockBox. Modules will\n    re-populate the LockBox as described in (2a).\n\n(3) SEC's table of GUIDed section handlers\n\n(a) when and how it is initialized after first boot of the VM\n\n    The following two library instances are linked into SecMain:\n    - IntelFrameworkModulePkg/Library/LzmaCustomDecompressLib,\n    - MdePkg/Library/BaseExtractGuidedSectionLib.\n\n    The first library registers its LZMA decompressor plugin (which is a called\n    a \"section handler\") by calling the second library:\n\n    LzmaDecompressLibConstructor() [GuidedSectionExtraction.c]\n      ExtractGuidedSectionRegisterHandlers() [BaseExtractGuidedSectionLib.c]\n\n    The second library maintains its table of registered \"section handlers\", to\n    be indexed by GUID, in this fixed memory area, independently of S3\n    enablement.\n\n    (The decompression of FVMAIN_COMPACT's FFS file section that contains the\n    PEIFV and DXEFV firmware volumes occurs with the LZMA decompressor\n    registered above. See (6) and (7) below.)\n\n(b) how it is protected from memory allocations during DXE\n\n    There is no need to protect this area from DXE: because nothing else in\n    OVMF links against BaseExtractGuidedSectionLib, the area loses its\n    significance as soon as OVMF progresses from SEC to PEI, therefore DXE is\n    allowed to overwrite the region.\n\n(c) how it is protected from the OS\n\n    When S3 is enabled, we cover the range with an AcpiNVS memory allocation\n    HOB in InitializeRamRegions().\n\n    When S3 is disabled, the range is not protected.\n\n(d) how it is accessed on the S3 resume path\n\n    The table of registered section handlers is again managed by\n    BaseExtractGuidedSectionLib linked into SecMain exclusively. Section\n    handler registrations update the table in-place (based on GUID matches).\n\n(e) how it is accessed on the warm reset path\n\n    If S3 is enabled, then the OS won't damage the table (due to (3c)), thus\n    see (3d).\n\n    If S3 is disabled, then the OS has most probably overwritten the range with\n    its own data, hence (3a) -- complete reinitialization -- will come into\n    effect, based on the table signature check in BaseExtractGuidedSectionLib.\n\n(4) temporary SEC/PEI heap and stack\n\n(a) when and how it is initialized after first boot of the VM\n\n    The range is configured in [OvmfPkg/Sec/X64/SecEntry.S] and\n    SecCoreStartupWithStack() [OvmfPkg/Sec/SecMain.c]. The stack half is read \u0026\n    written by the CPU transparently. The heap half is used for memory\n    allocations during PEI.\n\n    Data is migrated out (to permanent PEI stack \u0026 memory) in (or soon after)\n    PublishPeiMemory() [OvmfPkg/PlatformPei/MemDetect.c].\n\n(b) how it is protected from memory allocations during DXE\n\n    It is not necessary to protect this range during DXE because its use ends\n    still in PEI.\n\n(c) how it is protected from the OS\n\n    If S3 is enabled, then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] reserves it as AcpiNVS.\n\n    If S3 is disabled, then the range doesn't require protection.\n\n(d) how it is accessed on the S3 resume path\n\n    Same as in (4a), except the target area of the migration triggered by\n    PublishPeiMemory() [OvmfPkg/PlatformPei/MemDetect.c] is different -- see\n    (5).\n\n(e) how it is accessed on the warm reset path\n\n    Same as in (4a). The stack and heap halves both may contain garbage, but it\n    doesn't matter.\n\n(5) permanent PEI memory for the S3 resume path\n\n(a) when and how it is initialized after first boot of the VM\n\n    No particular initialization or use.\n\n(b) how it is protected from memory allocations during DXE\n\n    We don't need to protect this area during DXE.\n\n(c) how it is protected from the OS\n\n    When S3 is enabled, InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] makes sure the OS stays away by covering\n    the range with an AcpiNVS memory allocation HOB.\n\n    When S3 is disabled, the range needs no protection.\n\n(d) how it is accessed on the S3 resume path\n\n    PublishPeiMemory() installs the range as permanent RAM for PEI. The range\n    will serve as stack and will satisfy allocation requests during the rest of\n    PEI. OS data won't overlap due to (5c).\n\n(e) how it is accessed on the warm reset path\n\n    Same as (5a).\n\n(6) PEIFV -- decompressed firmware volume with PEI modules\n\n(a) when and how it is initialized after first boot of the VM\n\n    DecompressMemFvs() [OvmfPkg/Sec/SecMain.c] populates the area, by\n    decompressing the flash-mapped FVMAIN_COMPACT volume's contents. (Refer to\n    \"Firmware image structure\".)\n\n(b) how it is protected from memory allocations during DXE\n\n    When S3 is disabled, PeiFvInitialization() [OvmfPkg/PlatformPei/Fv.c]\n    covers the range with a BootServicesData memory allocation HOB.\n\n    When S3 is enabled, the same is coverage is ensured, just with the stronger\n    AcpiNVS memory allocation type.\n\n(c) how it is protected from the OS\n\n    When S3 is disabled, it is not necessary to keep the range from the OS.\n\n    Otherwise the AcpiNVS type allocation from (6b) provides coverage.\n\n(d) how it is accessed on the S3 resume path\n\n    Rather than decompressing it again from FVMAIN_COMPACT, GetS3ResumePeiFv()\n    [OvmfPkg/Sec/SecMain.c] reuses the protected area for parsing / execution\n    from (6c).\n\n(e) how it is accessed on the warm reset path\n\n    Same as (6a).\n\n(7) DXEFV -- decompressed firmware volume with DXE modules\n\n(a) when and how it is initialized after first boot of the VM\n\n    Same as (6a).\n\n(b) how it is protected from memory allocations during DXE\n\n    PeiFvInitialization() [OvmfPkg/PlatformPei/Fv.c] covers the range with a\n    BootServicesData memory allocation HOB.\n\n(c) how it is protected from the OS\n\n    The OS is allowed to release and reuse this range.\n\n(d) how it is accessed on the S3 resume path\n\n    It's not; DXE never runs during S3 resume.\n\n(e) how it is accessed on the warm reset path\n\n    Same as in (7a).\n\n## Known Secure Boot limitations\n\nUnder \"Motivation\" we've mentioned that OVMF's Secure Boot implementation is not\nsuitable for production use yet -- it's only good for development and testing of\nstandards-conformant, non-malicious guest code (UEFI and operating system\nalike).\n\nNow that we've examined the persistent flash device, the workings of S3, and the\nmemory map, we can discuss two currently known shortcomings of OVMF's Secure\nBoot that in fact make it insecure. (Clearly problems other than these two might\nexist; the set of issues considered here is not meant to be exhaustive.)\n\nOne trait of Secure Boot is tamper-evidence. Secure Boot may not prevent\nmalicious modification of software components (for example, operating system\ndrivers), but by being the root of integrity on a platform, it can catch (or\nindirectly contribute to catching) unauthorized changes, by way of signature and\ncertificate checks at the earliest phases of boot.\n\nIf an attacker can tamper with key material stored in authenticated and/or\nboot-time only persistent variables (for example, PK, KEK, db, dbt, dbx), then\nthe intended security of this scheme is compromised. The UEFI 2.4A specification\nsays\n\n- in section 28.3.4:\n\n  Platform Keys:\n\n  The public key must be stored in non-volatile storage which is tamper and\n  delete resistant.\n\n  Key Exchange Keys:\n\n  The public key must be stored in non-volatile storage which is tamper\n  resistant.\n\n- in section 28.6.1:\n\n  The signature database variables db, dbt, and dbx must be stored in\n  tamper-resistant non-volatile storage.\n\n(1) The combination of QEMU, KVM, and OVMF does not provide this kind of\nresistance. The variable store in the emulated flash chip is directly accessible\nto, and reprogrammable by, UEFI drivers, applications, and operating systems.\n\n(2) Under \"S3 (suspend to RAM and resume)\" we pointed out that the LockBox\nstorage must be similarly secure and tamper-resistant.\n\n    On the S3 resume path, the PEIM providing EFI_PEI_S3_RESUME2_PPI\n    (UefiCpuPkg/Universal/Acpi/S3Resume2Pei) restores and interprets data from\n    the LockBox that has been saved there during boot. This PEIM, being part of\n    the firmware, has full access to the platform. If an operating system can\n    tamper with the contents of the LockBox, then at the next resume the\n    platform's integrity might be subverted.\n\n    OVMF stores the LockBox in normal guest RAM (refer to the memory map\n    section above). Operating systems and third party UEFI drivers and UEFI\n    applications that respect the UEFI memory map will not inadvertently\n    overwrite the LockBox storage, but there's nothing to prevent eg. a\n    malicious kernel from modifying the LockBox.\n\nOne means to address these issues is SMM and SMRAM (System Management Mode and\nSystem Management RAM).\n\nDuring boot and resume, the firmware can enter and leave SMM and access SMRAM.\nBefore the DXE phase is left, and control is transferred to the BDS phase (when\nthird party UEFI drivers and applications can be loaded, and an operating system\ncan be loaded), SMRAM is locked in hardware, and subsequent modules cannot\naccess it directly. (See EFI_DXE_SMM_READY_TO_LOCK_PROTOCOL.)\n\nOnce SMRAM has been locked, UEFI drivers and the operating system can enter SMM\nby raising a System Management Interrupt (SMI), at which point trusted code\n(part of the platform firmware) takes control. SMRAM is also unlocked by\nplatform reset, at which point the boot firmware takes control again.\n\n## Variable store and LockBox in SMRAM\n\nEdk2 provides almost all components to implement the variable store and the\nLockBox in SMRAM. In this section we summarize ideas for utilizing those\nfacilities.\n\nThe SMRAM and SMM infrastructure in edk2 is built up as follows:\n\n(1) The platform hardware provides SMM / SMI / SMRAM.\n\n    Qemu/KVM doesn't support these features currently and should implement them\n    in the longer term.\n\n(2) The platform vendor (in this case, OVMF developers) implement device drivers\nfor the platform's System Management Mode:\n\n    - EFI_SMM_CONTROL2_PROTOCOL: for raising a synchronous (and/or) periodic\n      SMI(s); that is, for entering SMM.\n\n    - EFI_SMM_ACCESS2_PROTOCOL: for describing and accessing SMRAM.\n\n    These protocols are documented in the PI Specification, Volume 4.\n\n(3) The platform DSC file is to include the following platform-independent\nmodules:\n\n    - MdeModulePkg/Core/PiSmmCore/PiSmmIpl.inf: SMM Initial Program Load\n    - MdeModulePkg/Core/PiSmmCore/PiSmmCore.inf: SMM Core\n\n(4) At this point, modules of type DXE_SMM_DRIVER can be loaded.\n\n    Such drivers are privileged. They run in SMM, have access to SMRAM, and are\n    separated and switched from other drivers through SMIs. Secure\n    communication between unprivileged (non-SMM) and privileged (SMM) drivers\n    happens through EFI_SMM_COMMUNICATION_PROTOCOL (implemented by the SMM\n    Core, see (3)).\n\n    DXE_SMM_DRIVER modules must sanitize their input (coming from unprivileged\n    drivers) carefully.\n\n(5) The authenticated runtime variable services driver (for Secure Boot builds)\nis located under \"SecurityPkg/VariableAuthenticated/RuntimeDxe\". OVMF currently\nbuilds the driver (a DXE_RUNTIME_DRIVER module) with the\n\"VariableRuntimeDxe.inf\" control file (refer to \"OvmfPkg/OvmfPkgX64.dsc\"), which\ndoes not use SMM.\n\n    The directory includes two more INF files:\n\n    - VariableSmm.inf -- module type: DXE_SMM_DRIVER. A privileged driver that\n      runs in SMM and has access to SMRAM.\n\n    - VariableSmmRuntimeDxe.inf -- module type: DXE_RUNTIME_DRIVER. A\n      non-privileged driver that implements the variable runtime services\n      (replacing the current \"VariableRuntimeDxe.inf\" file) by communicating\n      with the above privileged SMM half via EFI_SMM_COMMUNICATION_PROTOCOL.\n\n(6) An SMRAM-based LockBox implementation needs to be discussed in two parts,\nbecause the LockBox is accessed in both PEI and DXE.\n\n    (a) During DXE, drivers save data in the LockBox. A save operation is\n        layered as follows:\n\n        - The unprivileged driver wishing to store data in the LockBox links\n          against the \"MdeModulePkg/Library/SmmLockBoxLib/SmmLockBoxDxeLib.inf\"\n          library instance.\n\n          The library allows the unprivileged driver to format requests for the\n          privileged SMM LockBox driver (see below), and to parse responses.\n\n        - The privileged SMM LockBox driver is built from\n          \"MdeModulePkg/Universal/LockBox/SmmLockBox/SmmLockBox.inf\". This\n          driver has module type DXE_SMM_DRIVER and can access SMRAM.\n\n          The driver delegates command parsing and response formatting to\n          \"MdeModulePkg/Library/SmmLockBoxLib/SmmLockBoxSmmLib.inf\".\n\n        - The above two halves (unprivileged and privileged) mirror what we've\n          seen in case of the variable service drivers, under (5).\n\n    (b) In PEI, the S3 Resume PEIM (UefiCpuPkg/Universal/Acpi/S3Resume2Pei)\n        retrieves data from the LockBox.\n\n        Presumably, S3Resume2Pei should be considered an \"unprivileged PEIM\",\n        and the SMRAM access should be layered as seen in DXE. Unfortunately,\n        edk2 does not implement all of the layers in PEI -- the code either\n        doesn't exist, or it is not open source:\n\nrole | DXE: protocol/module | PEI: PPI/module\n-------------+--------------------------------+------------------------------\nunprivileged | any | S3Resume2Pei.inf driver | |\n-------------+--------------------------------+------------------------------\ncommand | LIBRARY_CLASS = LockBoxLib | LIBRARY_CLASS = LockBoxLib formatting | |\nand response | SmmLockBoxDxeLib.inf | SmmLockBoxPeiLib.inf parsing | |\n-------------+--------------------------------+------------------------------\nprivilege | EFI_SMM_COMMUNICATION_PROTOCOL | EFI_PEI_SMM_COMMUNICATION_PPI\nseparation | | | PiSmmCore.inf | missing!\n-------------+--------------------------------+------------------------------\nplatform SMM | EFI_SMM_CONTROL2_PROTOCOL | PEI_SMM_CONTROL_PPI and SMRAM |\nEFI_SMM_ACCESS2_PROTOCOL | PEI_SMM_ACCESS_PPI access | | | to be done in OVMF |\nto be done in OVMF\n-------------+--------------------------------+------------------------------\ncommand | LIBRARY_CLASS = LockBoxLib | LIBRARY_CLASS = LockBoxLib parsing and |\n| response | SmmLockBoxSmmLib.inf | missing! formatting | |\n-------------+--------------------------------+------------------------------\nprivileged | SmmLockBox.inf | missing! LockBox | | driver | |\n\n        Alternatively, in the future OVMF might be able to provide a LockBoxLib\n        instance (an SmmLockBoxPeiLib substitute) for S3Resume2Pei that\n        accesses SMRAM directly, eliminating the need for deeper layers in the\n        stack (that is, EFI_PEI_SMM_COMMUNICATION_PPI and deeper).\n\n        In fact, a \"thin\" EFI_PEI_SMM_COMMUNICATION_PPI implementation whose\n        sole Communicate() member invariably returns EFI_NOT_STARTED would\n        cause the current SmmLockBoxPeiLib library instance to directly perform\n        full-depth SMRAM access and LockBox search, obviating the \"missing\"\n        cells. (With reference to A Tour Beyond BIOS: Implementing S3 Resume\n        with EDK2, by Jiewen Yao and Vincent Zimmer, October 2014.)\n\n## Select features\n\nIn this section we'll browse the top-level \"OvmfPkg\" package directory, and\ndiscuss the more interesting drivers and libraries that have not been mentioned\nthus far.\n\nX64-specific reset vector for OVMF ..................................\n\nThe \"OvmfPkg/ResetVector\" directory customizes the reset vector (found in\n\"UefiCpuPkg/ResetVector/Vtf0\") for \"OvmfPkgX64.fdf\", that is, when the SEC/PEI\nphases run in 64-bit (ie. long) mode.\n\nThe reset vector's control flow looks roughly like:\n\nresetVector [Ia16/ResetVectorVtf0.asm] EarlyBspInitReal16 [Ia16/Init16.asm]\nMain16 [Main.asm] EarlyInit16 [Ia16/Init16.asm]\n\n    ; Transition the processor from\n    ; 16-bit real mode to 32-bit flat mode\n    TransitionFromReal16To32BitFlat         [Ia16/Real16ToFlat32.asm]\n\n    ; Search for the\n    ; Boot Firmware Volume (BFV)\n    Flat32SearchForBfvBase                  [Ia32/SearchForBfvBase.asm]\n\n    ; Search for the SEC entry point\n    Flat32SearchForSecEntryPoint            [Ia32/SearchForSecEntry.asm]\n\n    %ifdef ARCH_IA32\n      ; Jump to the 32-bit SEC entry point\n    %else\n      ; Transition the processor\n      ; from 32-bit flat mode\n      ; to 64-bit flat mode\n      Transition32FlatTo64Flat              [Ia32/Flat32ToFlat64.asm]\n\n        SetCr3ForPageTables64               [Ia32/PageTables64.asm]\n          ; set CR3 to page tables\n          ; built into the ROM image\n\n        ; enable PAE\n        ; set LME\n        ; enable paging\n\n      ; Jump to the 64-bit SEC entry point\n    %endif\n\nOn physical platforms, the initial page tables referenced by\nSetCr3ForPageTables64 are built statically into the flash device image, and are\npresent in ROM at runtime. This is fine on physical platforms because the\npre-built page table entries have the Accessed and Dirty bits set from the\nstart.\n\nAccordingly, for OVMF running in long mode on qemu/KVM, the initial page tables\nwere mapped as a KVM_MEM_READONLY slot, as part of QEMU's pflash device (refer\nto \"Firmware image structure\" above).\n\nIn spite of the Accessed and Dirty bits being pre-set in the read-only, in-flash\nPTEs, in a virtual machine attempts are made to update said PTE bits,\ndifferently from physical hardware. The component attempting to update the\nread-only PTEs can be one of the following:\n\n- The processor itself, if it supports nested paging, and the user enables that\n  processor feature,\n\n- KVM code implementing shadow paging, otherwise.\n\nThe first case presents no user-visible symptoms, but the second case (KVM,\nshadow paging) used to cause a triple fault, prior to Linux commit ba6a354\n(\"KVM: mmu: allow page tables to be in read-only slots\").\n\nFor compatibility with earlier KVM versions, the OvmfPkg/ResetVector directory\nadapts the generic reset vector code as follows:\n\n      Transition32FlatTo64Flat         [UefiCpuPkg/.../Ia32/Flat32ToFlat64.asm]\n\n        SetCr3ForPageTables64       [OvmfPkg/ResetVector/Ia32/PageTables64.asm]\n\n          ; dynamically build the initial page tables in RAM, at address\n          ; PcdOvmfSecPageTablesBase (refer to the memory map above),\n          ; identity-mapping the first 4 GB of address space\n\n          ; set CR3 to PcdOvmfSecPageTablesBase\n\n        ; enable PAE\n        ; set LME\n        ; enable paging\n\nThis way the PTEs that earlier KVM versions try to update (during shadow paging)\nare located in a read-write memory slot, and the write attempts succeed.\n\nClient library for QEMU's firmware configuration interface\n..........................................................\n\nQEMU provides a write-only, 16-bit wide control port, and a read-write, 8-bit\nwide data port for exchanging configuration elements with the firmware.\n\nThe firmware writes a selector (a key) to the control port (0x510), and then\nreads the corresponding configuration data (produced by QEMU) from the data port\n(0x511).\n\nIf the selected entry is writable, the firmware may overwrite it. If QEMU has\nassociated a callback with the entry, then when the entry is completely\nrewritten, QEMU runs the callback. (OVMF does not rewrite any entries at the\nmoment.)\n\nA number of selector values (keys) are predefined. In particular, key 0x19\nselects (returns) a directory of { name, selector, size } triplets, roughly\nspeaking.\n\nThe firmware can request configuration elements by well-known name as well, by\nlooking up the selector value first in the directory, by name, and then writing\nthe selector to the control port. The number of bytes to read subsequently from\nthe data port is known from the directory entry's \"size\" field.\n\nBy convention, directory entries (well-known symbolic names of configuration\nelements) are formatted as POSIX pathnames. For example, the array selected by\nthe \"etc/system-states\" name indicates (among other things) whether the user\nenabled S3 support in QEMU.\n\nThe above interface is called \"fw_cfg\".\n\nThe binary data associated with a symbolic name is called an \"fw_cfg file\".\n\nOVMF's fw_cfg client library is found in \"OvmfPkg/Library/QemuFwCfgLib\". OVMF\ndiscovers many aspects of the virtual system with it; we refer to a few examples\nbelow.\n\nGuest ACPI tables .................\n\nAn operating system discovers a good amount of its hardware by parsing ACPI\ntables, and by interpreting ACPI objects and methods. On physical hardware, the\nplatform vendor's firmware installs ACPI tables in memory that match both the\nhardware present in the system and the user's firmware configuration (\"BIOS\nsetup\").\n\nUnder qemu/KVM, the owner of the (virtual) hardware configuration is QEMU.\nHardware can easily be reconfigured on the command line. Furthermore, features\nlike CPU hotplug, PCI hotplug, memory hotplug are continuously developed for\nQEMU, and operating systems need direct ACPI support to exploit these features.\n\nFor this reason, QEMU builds its own ACPI tables dynamically, in a\nself-descriptive manner, and exports them to the firmware through a complex,\nmulti-file fw_cfg interface. It is rooted in the \"etc/table-loader\" fw_cfg file.\n(Further details of this interface are out of scope for this report.)\n\nOVMF's AcpiPlatformDxe driver fetches the ACPI tables, and installs them for the\nguest OS with the EFI_ACPI_TABLE_PROTOCOL (which is in turn provided by the\ngeneric \"MdeModulePkg/Universal/Acpi/AcpiTableDxe\" driver).\n\nFor earlier QEMU versions and machine types (which we generally don't recommend\nfor OVMF; see \"Scope\"), the \"OvmfPkg/AcpiTables\" directory contains a few static\nACPI table templates. When the \"etc/table-loader\" fw_cfg file is unavailable,\nAcpiPlatformDxe installs these default tables (with a little bit of dynamic\npatching).\n\nWhen OVMF runs in a Xen domU, AcpiTableDxe also installs ACPI tables that\noriginate from the hypervisor's environment.\n\nGuest SMBIOS tables ...................\n\nQuoting the SMBIOS Reference Specification,\n\n[...] the System Management BIOS Reference Specification addresses how\nmotherboard and system vendors present management information about their\nproducts in a standard format [...]\n\nIn practice SMBIOS tables are just another set of tables that the platform\nvendor's firmware installs in RAM for the operating system, and, importantly,\nfor management applications running on the OS. Without rehashing the \"Guest ACPI\ntables\" section in full, let's map the OVMF roles seen there from ACPI to\nSMBIOS:\n\nrole | ACPI | SMBIOS\n-------------------------+-------------------------+-------------------------\nfw_cfg file | etc/table-loader | etc/smbios/smbios-tables\n-------------------------+-------------------------+-------------------------\nOVMF driver | AcpiPlatformDxe | SmbiosPlatformDxe under \"OvmfPkg\" | |\n-------------------------+-------------------------+-------------------------\nUnderlying protocol, | EFI_ACPI_TABLE_PROTOCOL | EFI_SMBIOS_PROTOCOL implemented\nby generic | | driver under | Acpi/AcpiTableDxe | SmbiosDxe\n\"MdeModulePkg/Universal\" | |\n-------------------------+-------------------------+-------------------------\ndefault tables available | yes | [RHEL] yes, Type0 and for earlier QEMU machine\n| | Type1 tables types, with hot-patching | |\n-------------------------+-------------------------+-------------------------\ntables fetched in Xen | yes | yes domUs | |\n\nPlatform-specific boot policy .............................\n\nOVMF's BDS (Boot Device Selection) phase is implemented by\nIntelFrameworkModulePkg/Universal/BdsDxe. Roughly speaking, this large driver:\n\n- provides the EFI BDS architectural protocol (which DXE transfers control to\n  after dispatching all DXE drivers),\n\n- connects drivers to devices,\n\n- enumerates boot devices,\n\n- auto-generates boot options,\n\n- provides \"BIOS setup\" screens, such as:\n\n  - Boot Manager, for booting an option,\n\n  - Boot Maintenance Manager, for adding, deleting, and reordering boot options,\n    changing console properties etc,\n\n  - Device Manager, where devices can register configuration forms, including\n\n    - Secure Boot configuration forms,\n\n    - OVMF's Platform Driver form (see under PlatformDxe).\n\nFirmware that includes the \"IntelFrameworkModulePkg/Universal/BdsDxe\" driver can\ncustomize its behavior by providing an instance of the PlatformBdsLib library\nclass. The driver links against this platform library, and the platform library\ncan call Intel's BDS utility functions from\n\"IntelFrameworkModulePkg/Library/GenericBdsLib\".\n\nOVMF's PlatformBdsLib instance can be found in \"OvmfPkg/Library/PlatformBdsLib\".\nThe main function where the BdsDxe driver enters the library is\nPlatformBdsPolicyBehavior(). We mention two OVMF particulars here.\n\n(1) OVMF is capable of loading kernel images directly from fw_cfg, matching\nQEMU's -kernel, -initrd, and -append command line options. This feature is\nuseful for rapid, repeated Linux kernel testing, and is implemented in the\nfollowing call tree:\n\n    PlatformBdsPolicyBehavior() [OvmfPkg/Library/PlatformBdsLib/BdsPlatform.c]\n      TryRunningQemuKernel() [OvmfPkg/Library/PlatformBdsLib/QemuKernel.c]\n        LoadLinux*() [OvmfPkg/Library/LoadLinuxLib/Linux.c]\n\n    OvmfPkg/Library/LoadLinuxLib ports the efilinux bootloader project into\n    OvmfPkg.\n\n(2) OVMF seeks to comply with the boot order specification passed down by QEMU\nover fw_cfg.\n\n    (a) About Boot Modes\n\n      During the PEI phase, OVMF determines and stores the Boot Mode in the\n      PHIT HOB (already mentioned in \"S3 (suspend to RAM and resume)\"). The\n      boot mode is supposed to influence the rest of the system, for example it\n      distinguishes S3 resume (BOOT_ON_S3_RESUME) from a \"normal\" boot.\n\n      In general, \"normal\" boots can be further differentiated from each other;\n      for example for speed reasons. When the firmware can tell during PEI that\n      the chassis has not been opened since last power-up, then it might want\n      to save time by not connecting all devices and not enumerating all boot\n      options from scratch; it could just rely on the stored results of the\n      last enumeration. The matching BootMode value, to be set during PEI,\n      would be BOOT_ASSUMING_NO_CONFIGURATION_CHANGES.\n\n      OVMF only sets one of the following two boot modes, based on CMOS\n      contents:\n      - BOOT_ON_S3_RESUME,\n      - BOOT_WITH_FULL_CONFIGURATION.\n\n      For BOOT_ON_S3_RESUME, please refer to \"S3 (suspend to RAM and resume)\".\n      The other boot mode supported by OVMF, BOOT_WITH_FULL_CONFIGURATION, is\n      an appropriate \"catch-all\" for a virtual machine, where hardware can\n      easily change from boot to boot.\n\n    (b) Auto-generation of boot options\n\n      Accordingly, when not resuming from S3 sleep (*), OVMF always connects\n      all devices, and enumerates all bootable devices as new boot options\n      (non-volatile variables called Boot####).\n\n      (*) During S3 resume, DXE is not reached, hence BDS isn't either.\n\n      The auto-enumerated boot options are stored in the BootOrder non-volatile\n      variable after any preexistent options. (Boot options may exist before\n      auto-enumeration eg. because the user added them manually with the Boot\n      Maintenance Manager or the efibootmgr utility. They could also originate\n      from an earlier auto-enumeration.)\n\n      PlatformBdsPolicyBehavior()                   [OvmfPkg/.../BdsPlatform.c]\n        TryRunningQemuKernel()                       [OvmfPkg/.../QemuKernel.c]\n        BdsLibConnectAll()           [IntelFrameworkModulePkg/.../BdsConnect.c]\n        BdsLibEnumerateAllBootOption()  [IntelFrameworkModulePkg/.../BdsBoot.c]\n          BdsLibBuildOptionFromHandle() [IntelFrameworkModulePkg/.../BdsBoot.c]\n            BdsLibRegisterNewOption()   [IntelFrameworkModulePkg/.../BdsMisc.c]\n              //\n              // Append the new option number to the original option order\n              //\n\n    (c) Relative UEFI device paths in boot options\n\n      The handling of relative (\"short-form\") UEFI device paths is best\n      demonstrated through an example, and by quoting the UEFI 2.4A\n      specification.\n\n      A short-form hard drive UEFI device path could be (displaying each device\n      path node on a separate line for readability):\n\n        HD(1,GPT,14DD1CC5-D576-4BBF-8858-BAF877C8DF61,0x800,0x64000)/\n        \\EFI\\fedora\\shim.efi\n\n      This device path lacks prefix nodes (eg. hardware or messaging type\n      nodes) that would lead to the hard drive. During load option processing,\n      the above short-form or relative device path could be matched against the\n      following absolute device path:\n\n        PciRoot(0x0)/\n        Pci(0x4,0x0)/\n        HD(1,GPT,14DD1CC5-D576-4BBF-8858-BAF877C8DF61,0x800,0x64000)/\n        \\EFI\\fedora\\shim.efi\n\n      The motivation for this type of device path matching / completion is to\n      allow the user to move around the hard drive (for example, to plug a\n      controller in a different PCI slot, or to expose the block device on a\n      different iSCSI path) and still enable the firmware to find the hard\n      drive.\n\n      The UEFI specification says,\n\n        9.3.6 Media Device Path\n        9.3.6.1 Hard Drive\n\n          [...] Section 3.1.2 defines special rules for processing the Hard\n          Drive Media Device Path. These special rules enable a disk's location\n          to change and still have the system boot from the disk. [...]\n\n        3.1.2 Load Option Processing\n\n          [...] The boot manager must [...] support booting from a short-form\n          device path that starts with the first element being a hard drive\n          media device path [...]. The boot manager must use the GUID or\n          signature and partition number in the hard drive device path to match\n          it to a device in the system. If the drive supports the GPT\n          partitioning scheme the GUID in the hard drive media device path is\n          compared with the UniquePartitionGuid field of the GUID Partition\n          Entry [...]. If the drive supports the PC-AT MBR scheme the signature\n          in the hard drive media device path is compared with the\n          UniqueMBRSignature in the Legacy Master Boot Record [...]. If a\n          signature match is made, then the partition number must also be\n          matched. The hard drive device path can be appended to the matching\n          hardware device path and normal boot behavior can then be used. If\n          more than one device matches the hard drive device path, the boot\n          manager will pick one arbitrarily. Thus the operating system must\n          ensure the uniqueness of the signatures on hard drives to guarantee\n          deterministic boot behavior.\n\n      Edk2 implements and exposes the device path completion logic in the\n      already referenced \"IntelFrameworkModulePkg/Library/GenericBdsLib\"\n      library, in the BdsExpandPartitionPartialDevicePathToFull() function.\n\n    (d) Filtering and reordering the boot options based on fw_cfg\n\n      Once we have an \"all-inclusive\", partly preexistent, partly freshly\n      auto-generated boot option list from bullet (b), OVMF loads QEMU's\n      requested boot order from fw_cfg, and filters and reorders the list from\n      (b) with it:\n\n      PlatformBdsPolicyBehavior()                   [OvmfPkg/.../BdsPlatform.c]\n        TryRunningQemuKernel()                       [OvmfPkg/.../QemuKernel.c]\n        BdsLibConnectAll()           [IntelFrameworkModulePkg/.../BdsConnect.c]\n        BdsLibEnumerateAllBootOption()  [IntelFrameworkModulePkg/.../BdsBoot.c]\n        SetBootOrderFromQemu()                    [OvmfPkg/.../QemuBootOrder.c]\n\n      According to the (preferred) \"-device ...,bootindex=N\" and the (legacy)\n      '-boot order=drives' command line options, QEMU requests a boot order\n      from the firmware through the \"bootorder\" fw_cfg file. (For a bootindex\n      example, refer to the \"Example qemu invocation\" section.)\n\n      This fw_cfg file consists of OpenFirmware (OFW) device paths -- note: not\n      UEFI device paths! --, one per line. An example list is:\n\n        /pci@i0cf8/scsi@4/disk@0,0\n        /pci@i0cf8/ide@1,1/drive@1/disk@0\n        /pci@i0cf8/ethernet@3/ethernet-phy@0\n\n      OVMF filters and reorders the boot option list from bullet (b) with the\n      following nested loops algorithm:\n\n        new_uefi_order := \u003cempty\u003e\n        for each qemu_ofw_path in QEMU's OpenFirmware device path list:\n          qemu_uefi_path_prefix := translate(qemu_ofw_path)\n\n          for each boot_option in current_uefi_order:\n            full_boot_option := complete(boot_option)\n\n            if match(qemu_uefi_path_prefix, full_boot_option):\n              append(new_uefi_order, boot_option)\n              break\n\n        for each unmatched boot_option in current_uefi_order:\n          if survives(boot_option):\n            append(new_uefi_order, boot_option)\n\n        current_uefi_order := new_uefi_order\n\n      OVMF iterates over QEMU's OFW device paths in order, translates each to a\n      UEFI device path prefix, tries to match the translated prefix against the\n      UEFI boot options (which are completed from relative form to absolute\n      form for the purpose of prefix matching), and if there's a match, the\n      matching boot option is appended to the new boot order (which starts out\n      empty).\n\n      (We elaborate on the translate() function under bullet (e). The\n      complete() function has been explained in bullet (c).)\n\n      In addition, UEFI boot options that remain unmatched after filtering and\n      reordering are post-processed, and some of them \"survive\". Due to the\n      fact that OpenFirmware device paths have less expressive power than their\n      UEFI counterparts, some UEFI boot options are simply inexpressible (hence\n      unmatchable) by the nested loops algorithm.\n\n      An important example is the memory-mapped UEFI shell, whose UEFI device\n      path is inexpressible by QEMU's OFW device paths:\n\n        MemoryMapped(0xB,0x900000,0x10FFFFF)/\n        FvFile(7C04A583-9E3E-4F1C-AD65-E05268D0B4D1)\n\n      (Side remark: notice that the address range visible in the MemoryMapped()\n      node corresponds to DXEFV under \"comprehensive memory map of OVMF\"! In\n      addition, the FvFile() node's GUID originates from the FILE_GUID entry of\n      \"ShellPkg/Application/Shell/Shell.inf\".)\n\n      The UEFI shell can be booted by pressing ESC in OVMF on the TianoCore\n      splash screen, and navigating to Boot Manager | EFI Internal Shell. If\n      the \"survival policy\" was not implemented, the UEFI shell's boot option\n      would always be filtered out.\n\n      The current \"survival policy\" preserves all boot options that start with\n      neither PciRoot() nor HD().\n\n    (e) Translating QEMU's OpenFirmware device paths to UEFI device path\n        prefixes\n\n      In this section we list the (strictly heuristical) mappings currently\n      performed by OVMF.\n\n      The \"prefix only\" nature of the translation output is rooted minimally in\n      the fact that QEMU's OpenFirmware device paths cannot carry pathnames\n      within filesystems. There's no way to specify eg.\n\n        \\EFI\\fedora\\shim.efi\n\n      in an OFW device path, therefore a UEFI device path translated from an\n      OFW device path can at best be a prefix (not a full match) of a UEFI\n      device path that ends with \"\\EFI\\fedora\\shim.efi\".\n\n      - IDE disk, IDE CD-ROM:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/ide@1,1/drive@0/disk@0\n               ^         ^ ^       ^      ^\n               |         | |       |      master or slave\n               |         | |       primary or secondary\n               |         PCI slot \u0026 function holding IDE controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefix:\n\n          PciRoot(0x0)/Pci(0x1,0x1)/Ata(Primary,Master,0x0)\n                                                       ^\n                                                       fixed LUN\n\n      - Floppy disk:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/isa@1/fdc@03f0/floppy@0\n               ^         ^     ^           ^\n               |         |     |           A: or B:\n               |         |     ISA controller io-port (hex)\n               |         PCI slot holding ISA controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefix:\n\n          PciRoot(0x0)/Pci(0x1,0x0)/Floppy(0x0)\n                                           ^\n                                           ACPI UID (A: or B:)\n\n      - Virtio-block disk:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/scsi@6[,3]/disk@0,0\n               ^          ^  ^       ^ ^\n               |          |  |       fixed\n               |          |  PCI function corresponding to disk (optional)\n               |          PCI slot holding disk\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x6,0x0)/HD(\n          PciRoot(0x0)/Pci(0x6,0x3)/HD(\n\n      - Virtio-scsi disk and virtio-scsi passthrough:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/scsi@7[,3]/channel@0/disk@2,3\n               ^          ^             ^      ^ ^\n               |          |             |      | LUN\n               |          |             |      target\n               |          |             channel (unused, fixed 0)\n               |          PCI slot[, function] holding SCSI controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x7,0x0)/Scsi(0x2,0x3)\n          PciRoot(0x0)/Pci(0x7,0x3)/Scsi(0x2,0x3)\n\n      - Emulated and passed-through (physical) network cards:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/ethernet@3[,2]\n               ^              ^\n               |              PCI slot[, function] holding Ethernet card\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x3,0x0)\n          PciRoot(0x0)/Pci(0x3,0x2)\n\nVirtio drivers ..............\n\nUEFI abstracts various types of hardware resources into protocols, and allows\nfirmware developers to implement those protocols in device drivers. The Virtio\nSpecification defines various types of virtual hardware for virtual machines.\nConnecting the two specifications, OVMF provides UEFI drivers for QEMU's\nvirtio-block, virtio-scsi, and virtio-net devices.\n\nThe following diagram presents the protocol and driver stack related to Virtio\ndevices in edk2 and OVMF. Each node in the graph identifies a protocol and/or\nthe edk2 driver that produces it. Nodes on the top are more abstract.\n\nEFI_BLOCK_IO_PROTOCOL EFI_SIMPLE_NETWORK_PROTOCOL [OvmfPkg/VirtioBlkDxe]\n[OvmfPkg/VirtioNetDxe] | | | EFI_EXT_SCSI_PASS_THRU_PROTOCOL | |\n[OvmfPkg/VirtioScsiDxe] | | | |\n+------------------------+--------------------------+ | VIRTIO_DEVICE_PROTOCOL |\n+---------------------+---------------------+ | | [OvmfPkg/VirtioPciDeviceDxe]\n[custom platform drivers] | | | | EFI_PCI_IO_PROTOCOL\n[OvmfPkg/Library/VirtioMmioDeviceLib] [MdeModulePkg/Bus/Pci/PciBusDxe] direct\nMMIO register access\n\nThe top three drivers produce standard UEFI abstractions: the Block IO Protocol,\nthe Extended SCSI Pass Thru Protocol, and the Simple Network Protocol, for\nvirtio-block, virtio-scsi, and virtio-net devices, respectively.\n\nComparing these device-specific virtio drivers to each other, we can determine:\n\n- They all conform to the UEFI Driver Model. This means that their entry point\n  functions don't immediately start to search for devices and to drive them,\n  they only register instances of the EFI_DRIVER_BINDING_PROTOCOL. The UEFI\n  Driver Model then enumerates devices and chains matching drivers\n  automatically.\n\n- They are as minimal as possible, while remaining correct (refer to source code\n  comments for details). For example, VirtioBlkDxe and VirtioScsiDxe both\n  support only one request in flight.\n\n  In theory, VirtioBlkDxe could implement EFI_BLOCK_IO2_PROTOCOL, which allows\n  queueing. Similarly, VirtioScsiDxe does not support the non-blocking mode of\n  EFI_EXT_SCSI_PASS_THRU_PROTOCOL.PassThru(). (Which is permitted by the UEFI\n  specification.) Both VirtioBlkDxe and VirtioScsiDxe delegate synchronous\n  request handling to \"OvmfPkg/Library/VirtioLib\". This limitation helps keep\n  the implementation simple, and testing thus far seems to imply satisfactory\n  performance, for a virtual boot firmware.\n\n  VirtioNetDxe cannot avoid queueing, because EFI_SIMPLE_NETWORK_PROTOCOL\n  requires it on the interface level. Consequently, VirtioNetDxe is\n  significantly more complex than VirtioBlkDxe and VirtioScsiDxe. Technical\n  notes are provided in \"OvmfPkg/VirtioNetDxe/TechNotes.txt\".\n\n- None of these drivers access hardware directly. Instead, the Virtio Device\n  Protocol (OvmfPkg/Include/Protocol/VirtioDevice.h) collects / extracts virtio\n  operations defined in the Virtio Specification, and these backend-independent\n  virtio device drivers go through the abstract VIRTIO_DEVICE_PROTOCOL.\n\n  IMPORTANT: the VIRTIO_DEVICE_PROTOCOL is not a standard UEFI protocol. It is\n  internal to edk2 and not described in the UEFI specification. It should only\n  be used by drivers and applications that live inside the edk2 source tree.\n\nCurrently two providers exist for VIRTIO_DEVICE_PROTOCOL:\n\n- The first one is the \"more traditional\" virtio-pci backend, implemented by\n  OvmfPkg/VirtioPciDeviceDxe. This driver also complies with the UEFI Driver\n  Model. It consumes an instance of the EFI_PCI_IO_PROTOCOL, and, if the PCI\n  device/function under probing appears to be a virtio device, it produces a\n  Virtio Device Protocol instance for it. The driver translates abstract virtio\n  operations to PCI accesses.\n\n- The second provider, the virtio-mmio backend, is a library, not a driver,\n  living in OvmfPkg/Library/VirtioMmioDeviceLib. This library translates\n  abstract virtio operations to MMIO accesses.\n\n  The virtio-mmio backend is only a library -- rather than a standalone, UEFI\n  Driver Model-compliant driver -- because the type of resource it consumes, an\n  MMIO register block base address, is not enumerable.\n\n  In other words, while the PCI root bridge driver and the PCI bus driver\n  produce instances of EFI_PCI_IO_PROTOCOL automatically, thereby enabling the\n  UEFI Driver Model to probe devices and stack up drivers automatically, no such\n  enumeration exists for MMIO register blocks.\n\n  For this reason, VirtioMmioDeviceLib needs to be linked into thin, custom\n  platform drivers that dispose over this kind of information. As soon as a\n  driver knows about the MMIO register block base addresses, it can pass each to\n  the library, and then the VIRTIO_DEVICE_PROTOCOL will be instantiated\n  (assuming a valid virtio-mmio register block of course). From that point on\n  the UEFI Driver Model again takes care of the chaining.\n\n  Typically, such a custom driver does not conform to the UEFI Driver Model\n  (because that would presuppose auto-enumeration for MMIO register blocks).\n  Hence it has the following responsibilities:\n\n  - it shall behave as a \"wrapper\" UEFI driver around the library,\n\n  - it shall know virtio-mmio base addresses,\n\n  - in its entry point function, it shall create a new UEFI handle with an\n    instance of the EFI_DEVICE_PATH_PROTOCOL for each virtio-mmio device it\n    knows the base address for,\n\n  - it shall call VirtioMmioInstallDevice() on those handles, with the\n    corresponding base addresses.\n\n  OVMF itself does not employ VirtioMmioDeviceLib. However, the library is used\n  (or has been tested as Proof-of-Concept) in the following 64-bit and 32-bit\n  ARM emulator setups:\n\n  - in \"RTSM_VE_FOUNDATIONV8_EFI.fd\" and \"FVP_AARCH64_EFI.fd\", on ARM Holdings'\n    ARM(R) v8-A Foundation Model and ARM(R) AEMv8-A Base Platform FVP emulators,\n    respectively:\n\n                           EFI_BLOCK_IO_PROTOCOL\n                           [OvmfPkg/VirtioBlkDxe]\n                                      |\n                           VIRTIO_DEVICE_PROTOCOL\n        [ArmPlatformPkg/ArmVExpressPkg/ArmVExpressDxe/ArmFvpDxe.inf]\n                                      |\n                    [OvmfPkg/Library/VirtioMmioDeviceLib]\n                         direct MMIO register access\n\n  - in \"RTSM_VE_CORTEX-A15_EFI.fd\" and \"RTSM_VE_CORTEX-A15_MPCORE_EFI.fd\", on\n    \"qemu-system-arm -M vexpress-a15\":\n\n        EFI_BLOCK_IO_PROTOCOL            EFI_SIMPLE_NETWORK_PROTOCOL\n        [OvmfPkg/VirtioBlkDxe]             [OvmfPkg/VirtioNetDxe]\n                   |                                  |\n                   +------------------+---------------+\n                                      |\n                           VIRTIO_DEVICE_PROTOCOL\n        [ArmPlatformPkg/ArmVExpressPkg/ArmVExpressDxe/ArmFvpDxe.inf]\n                                      |\n                    [OvmfPkg/Library/VirtioMmioDeviceLib]\n                         direct MMIO register access\n\n  In the above ARM / VirtioMmioDeviceLib configurations, VirtioBlkDxe was tested\n  with booting Linux distributions, while VirtioNetDxe was tested with pinging\n  public IPv4 addresses from the UEFI shell.\n\nPlatform Driver ...............\n\nSometimes, elements of persistent firmware configuration are best exposed to the\nuser in a friendly way. OVMF's platform driver (OvmfPkg/PlatformDxe) presents\nsuch settings on the \"OVMF Platform Configuration\" dialog:\n\n- Press ESC on the TianoCore splash screen,\n- Navigate to Device Manager | OVMF Platform Configuration.\n\nAt the moment, OVMF's platform driver handles only one setting: the preferred\ngraphics resolution. This is useful for two purposes:\n\n- Some UEFI shell commands, like DRIVERS and DEVICES, benefit from a wide\n  display. Using the MODE shell command, the user can switch to a larger text\n  resolution (limited by the graphics resolution), and see the command output in\n  a more easily consumable way.\n\n  [RHEL] The list of text modes available to the MODE command is also limited by\n  ConSplitterDxe (found under MdeModulePkg/Universal/Console). ConSplitterDxe\n  builds an intersection of text modes that are simultaneously supported by all\n  consoles that ConSplitterDxe multiplexes console output to.\n\n         In practice, the strongest text mode restriction comes from\n         TerminalDxe, which provides console I/O on serial ports. TerminalDxe\n         has a very limited built-in list of text modes, heavily pruning the\n         intersection built by ConSplitterDxe, and made available to the MODE\n         command.\n\n         On the Red Hat Enterprise Linux 7.1 host, TerminalDxe's list of modes\n         has been extended with text resolutions that match the Spice QXL GPU's\n         common graphics resolutions. This way a \"full screen\" text mode should\n         always be available in the MODE command.\n\n- The other advantage of controlling the graphics resolution lies with UEFI\n  operating systems that don't (yet) have a native driver for QEMU's virtual\n  video cards -- eg. the Spice QXL GPU. Such OSes may choose to inherit the\n  properties of OVMF's EFI_GRAPHICS_OUTPUT_PROTOCOL (provided by\n  OvmfPkg/QemuVideoDxe, see later).\n\n  Although the display can be used at runtime in such cases, by direct\n  framebuffer access, its properties, for example, the resolution, cannot be\n  modified. The platform driver allows the user to select the preferred GOP\n  resolution, reboot, and let the guest OS inherit that preferred resolution.\n\nThe platform driver has three access points: the \"normal\" driver entry point, a\nset of HII callbacks, and a GOP installation callback.\n\n(1) Driver entry point: the PlatformInit() function.\n\n    (a) First, this function loads any available settings, and makes them take\n        effect. For the preferred graphics resolution in particular, this means\n        setting the following PCDs:\n\n          gEfiMdeModulePkgTokenSpaceGuid.PcdVideoHorizontalResolution\n          gEfiMdeModulePkgTokenSpaceGuid.PcdVideoVerticalResolution\n\n        These PCDs influence the GraphicsConsoleDxe driver (located under\n        MdeModulePkg/Universal/Console), which switches to the preferred\n        graphics mode, and produces EFI_SIMPLE_TEXT_OUTPUT_PROTOCOLs on GOPs:\n\n                    EFI_SIMPLE_TEXT_OUTPUT_PROTOCOL\n          [MdeModulePkg/Universal/Console/GraphicsConsoleDxe]\n                                   |\n                      EFI_GRAPHICS_OUTPUT_PROTOCOL\n                         [OvmfPkg/QemuVideoDxe]\n                                   |\n                          EFI_PCI_IO_PROTOCOL\n                   [MdeModulePkg/Bus/Pci/PciBusDxe]\n\n(b) Second, the driver entry point registers the user interface, including HII\ncallbacks.\n\n(c) Third, the driver entry point registers a GOP installation callback.\n\n(2) HII callbacks and the user interface.\n\n    The Human Interface Infrastructure (HII) \"is a set of protocols that allow\n    a UEFI driver to provide the ability to register user interface and\n    configuration content with the platform firmware\".\n\n    OVMF's platform driver:\n\n    - provides a static, basic, visual form (PlatformForms.vfr), written in the\n      Visual Forms Representation language,\n\n    - includes a UCS-16 encoded message catalog (Platform.uni),\n\n    - includes source code that dynamically populates parts of the form, with\n      the help of MdeModulePkg/Library/UefiHiiLib -- this library simplifies\n      the handling of IFR (Internal Forms Representation) opcodes,\n\n    - processes form actions that the user takes (Callback() function),\n\n    - loads and saves platform configuration in a private, non-volatile\n      variable (ExtractConfig() and RouteConfig() functions).\n\n    The ExtractConfig() HII callback implements the following stack of\n    conversions, for loading configuration and presenting it to the user:\n\n          MultiConfigAltResp       -- form engine / HII communication\n                  ^\n                  |\n           [BlockToConfig]\n                  |\n           MAIN_FORM_STATE         -- binary representation of form/widget\n                  ^                   state\n                  |\n      [PlatformConfigToFormState]\n                  |\n           PLATFORM_CONFIG         -- accessible to DXE and UEFI drivers\n                  ^\n                  |\n         [PlatformConfigLoad]\n                  |\n        UEFI non-volatile variable -- accessible to external utilities\n\n    The layers are very similar for the reverse direction, ie. when taking\n    input from the user, and saving the configuration (RouteConfig() HII\n    callback):\n\n             ConfigResp            -- form engine / HII communication\n                  |\n           [ConfigToBlock]\n                  |\n                  v\n           MAIN_FORM_STATE         -- binary representation of form/widget\n                  |                   state\n      [FormStateToPlatformConfig]\n                  |\n                  v\n           PLATFORM_CONFIG         -- accessible to DXE and UEFI drivers\n                  |\n         [PlatformConfigSave]\n                  |\n                  v\n        UEFI non-volatile variable -- accessible to external utilities\n\n(3) When the platform driver starts, a GOP may not be available yet. Thus the\ndriver entry point registers a callback (the GopInstalled() function) for GOP\ninstallations.\n\n    When the first GOP is produced (usually by QemuVideoDxe, or potentially by\n    a third party video driver), PlatformDxe retrieves the list of graphics\n    modes the GOP supports, and dynamically populates the drop-down list of\n    available resolutions on the form. The GOP installation callback is then\n    removed.\n\nVideo driver ............\n\nOvmfPkg/QemuVideoDxe is OVMF's built-in video driver. We can divide its services\nin two parts: graphics output protocol (primary), and Int10h (VBE) shim\n(secondary).\n\n(1) QemuVideoDxe conforms to the UEFI Driver Model; it produces an instance of\nthe EFI_GRAPHICS_OUTPUT_PROTOCOL (GOP) on each PCI display that it supports and\nis connected to:\n\n                      EFI_GRAPHICS_OUTPUT_PROTOCOL\n                         [OvmfPkg/QemuVideoDxe]\n                                   |\n                          EFI_PCI_IO_PROTOCOL\n                   [MdeModulePkg/Bus/Pci/PciBusDxe]\n\n    It supports the following QEMU video cards:\n\n    - Cirrus 5430 (\"-device cirrus-vga\"),\n    - Standard VGA (\"-device VGA\"),\n    - QXL VGA (\"-device qxl-vga\", \"-device qxl\").\n\n    For Cirrus the following resolutions and color depths are available:\n    640x480x32, 800x600x32, 1024x768x24. On stdvga and QXL a long list of\n    resolutions is available. The list is filtered against the frame buffer\n    size during initialization.\n\n    The size of the QXL VGA compatibility framebuffer can be changed with the\n\n      -device qxl-vga,vgamem_mb=$NUM_MB\n\n    QEMU option. If $NUM_MB exceeds 32, then the following is necessary\n    instead:\n\n      -device qxl-vga,vgamem_mb=$NUM_MB,ram_size_mb=$((NUM_MB*2))\n\n    because the compatibility framebuffer can't cover more than half of PCI BAR\n    #0. The latter defaults to 64MB in size, and is controlled by the\n    \"ram_size_mb\" property.\n\n(2) When QemuVideoDxe binds the first Standard VGA or QXL VGA device, and there\nis no real VGA BIOS present in the C to F segments (which could originate from a\nlegacy PCI option ROM -- refer to \"Compatibility Support Module (CSM)\"), then\nQemuVideoDxe installs a minimal, \"fake\" VGA BIOS -- an Int10h (VBE) \"shim\".\n\n    The shim is implemented in 16-bit assembly in\n    \"OvmfPkg/QemuVideoDxe/VbeShim.asm\". The \"VbeShim.sh\" shell script assembles\n    it and formats it as a C array (\"VbeShim.h\") with the help of the \"nasm\"\n    utility. The driver's InstallVbeShim() function copies the shim in place\n    (the C segment), and fills in the VBE Info and VBE Mode Info structures.\n    The real-mode 10h interrupt vector is pointed to the shim's handler.\n\n    The shim is (correctly) irrelevant and invisible for all UEFI operating\n    systems we know about -- except Windows Server 2008 R2 and other Windows\n    operating systems in that family.\n\n    Namely, the Windows 2008 R2 SP1 (and Windows 7) UEFI guest's default video\n    driver dereferences the real mode Int10h vector, loads the pointed-to\n    handler code, and executes what it thinks to be VGA BIOS services in an\n    internal real-mode emulator. Consequently, video mode switching used not to\n    work in Windows 2008 R2 SP1 when it ran on the \"pure UEFI\" build of OVMF,\n    making the guest uninstallable. Hence the (otherwise optional, non-default)\n    Compatibility Support Module (CSM) ended up a requirement for running such\n    guests.\n\n    The hard dependency on the sophisticated SeaBIOS CSM and the complex\n    supporting edk2 infrastructure, for enabling this family of guests, was\n    considered suboptimal by some members of the upstream community,\n\n    [RHEL] and was certainly considered a serious maintenance disadvantage for\n           Red Hat Enterprise Linux 7.1 hosts.\n\n    Thus, the shim has been collaboratively developed for the Windows 7 /\n    Windows Server 2008 R2 family. The shim provides a real stdvga / QXL\n    implementation for the few services that are in fact necessary for the\n    Windows 2008 R2 SP1 (and Windows 7) UEFI guest, plus some \"fakes\" that the\n    guest invokes but whose effect is not important. The only supported mode is\n    1024x768x32, which is enough to install the guest and then upgrade its\n    video driver to the full-featured QXL XDDM one.\n\n    The C segment is not present in the UEFI memory map prepared by OVMF.\n    Memory space that would cover it is never added (either in PEI, in the form\n    of memory resource descriptor HOBs, or in DXE, via gDS-\u003eAddMemorySpace()).\n    This way the handler body is invisible to all other UEFI guests, and the\n    rest of edk2.\n\n    The Int10h real-mode IVT entry is covered with a Boot Services Code page,\n    making that too inaccessible to the rest of edk2. Due to the allocation\n    type, UEFI guest OSes different from the Windows Server 2008 family can\n    reclaim the page at zero. (The Windows 2008 family accesses that page\n    regardless of the allocation type.)\n\n## Afterword\n\nAfter the bulk of this document was written in July 2014, OVMF development has\nnot stopped. To name two significant code contributions from the community: in\nJanuary 2015, OVMF runs on the \"q35\" machine type of QEMU, and it features a\ndriver for Xen paravirtual block devices (and another for the underlying Xen\nbus).\n\nFurthermore, a dedicated virtualization platform has been contributed to\nArmPlatformPkg that plays a role parallel to OvmfPkg's. It targets the \"virt\"\nmachine type of qemu-system-arm and qemu-system-aarch64. Parts of OvmfPkg are\nbeing refactored and modularized so they can be reused in\n\"ArmPlatformPkg/ArmVirtualizationPkg/ArmVirtualizationQemu.dsc\".\n","wordCount":13697,"tags":["uefi","resource"],"metadata":{},"created":"2023-08-14T02:59:45.103584636Z","modified":"2024-07-03T06:42:45.829012951Z","checksum":"881f79847a794bafcdf0f1b07386b76d62dc112d294126af17d8b631b55e4192"},
    {"filename":"l3lzsza3.md","filenameStem":"l3lzsza3","path":"l3lzsza3.md","absPath":"/home/khadd/mynotes/l3lzsza3.md","title":"Obfuscated execution against Controlled-channel attacks","link":"[[l3lzsza3]]","lead":"#archive","body":"#archive\n\n# Background\n\n# Controlled-channel attacks against confidential computing\n\nControlled-channel attacks [[1yhmh234]]\n\nControlled-channel attacks on SGX are the most well-studied\n\nThere has also been controlled-channel attack studies for AMD SEV.\n\n## Obfuscated execution\n\n### Obfuscated execution for SGX\n\n# Obfuscated execution for confidential VM: What is lacking\n\n### Handling large TCB\n\nDifferent from SGX, the whole OS now has to be included into the TCB. This\nenlarges the attack surfaces for controlled-channel attacks.\n\nHowever, most of the proposed work cannot be scaled to this level.\n\nObfuscuro @ahmad2019obfuscuro requires sensitive code and data to fit into 4KB.\n\nKlotski only evaluated on small applications. Is is not sure how it handles\nlarger one.\n\nOne other issue is that it is not sure how the previous models can be adapted to\na large amount of inter-connected code. For instance, sensitive code/data can\ninduce paging, which may leads to controlled-channel visible by the VMM. This is\nworsen due to the extended interfaces between the OS and VM\n[[#extended-interfaces]].\n\nObliviate @ahmad2018obliviate obfuscates the file system accesses, which may\nleads to\n\n### Extended interfaces\n\nThe interfaces between enlave-OS is significantly smaller than the interfaces\nbetween OS\u003c-\u003eVMM. It is expected that this interface would create other\ncontrolled-channels.\n\n### Under-studied attack vectors\n\nTODO: read these\n[Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization](https://www.usenix.org/conference/usenixsecurity19/presentation/li-mengyuan)\n[The SEVerESt Of Them All: Inference Attacks Against Secure Virtual Enclaves](https://dl.acm.org/doi/10.1145/3321705.3329820)\n\n[Security Analysis of Encrypted Virtual Machines](https://dl.acm.org/doi/10.1145/3140607.3050763)\n\n@li2021crossline @li2021tlb @morbitzer2019extracting\n\nThere lacks a systematic study about side-channel threats in this interface.\n\n### Taming the overheads\n\nOne way forward is to determine all sensitive data-dependent control-flow and\ndata-flow to selectively apply protectionl. This is explored in Constantine\n@borrello2021constantine, but for very fine-grained obfuscated execution. A\nspecialized method for selective data protection for confidential computing\nwould greatly reduces the overheads.\n\nAnother way is to trade-off the granularity of protection. Klotski\n@zhang2020klotski uses caches for data and code that is larger than the 4KB page\nsize, which improve performance, but allows observers to extracts coarse-grained\ninformation.","snippets":["#archive"],"rawContent":"# Obfuscated execution against Controlled-channel attacks\n\n#archive\n\n# Background\n\n# Controlled-channel attacks against confidential computing\n\nControlled-channel attacks [[1yhmh234]]\n\nControlled-channel attacks on SGX are the most well-studied\n\nThere has also been controlled-channel attack studies for AMD SEV.\n\n## Obfuscated execution\n\n### Obfuscated execution for SGX\n\n# Obfuscated execution for confidential VM: What is lacking\n\n### Handling large TCB\n\nDifferent from SGX, the whole OS now has to be included into the TCB. This\nenlarges the attack surfaces for controlled-channel attacks.\n\nHowever, most of the proposed work cannot be scaled to this level.\n\nObfuscuro @ahmad2019obfuscuro requires sensitive code and data to fit into 4KB.\n\nKlotski only evaluated on small applications. Is is not sure how it handles\nlarger one.\n\nOne other issue is that it is not sure how the previous models can be adapted to\na large amount of inter-connected code. For instance, sensitive code/data can\ninduce paging, which may leads to controlled-channel visible by the VMM. This is\nworsen due to the extended interfaces between the OS and VM\n[[#extended-interfaces]].\n\nObliviate @ahmad2018obliviate obfuscates the file system accesses, which may\nleads to\n\n### Extended interfaces\n\nThe interfaces between enlave-OS is significantly smaller than the interfaces\nbetween OS\u003c-\u003eVMM. It is expected that this interface would create other\ncontrolled-channels.\n\n### Under-studied attack vectors\n\nTODO: read these\n[Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization](https://www.usenix.org/conference/usenixsecurity19/presentation/li-mengyuan)\n[The SEVerESt Of Them All: Inference Attacks Against Secure Virtual Enclaves](https://dl.acm.org/doi/10.1145/3321705.3329820)\n\n[Security Analysis of Encrypted Virtual Machines](https://dl.acm.org/doi/10.1145/3140607.3050763)\n\n@li2021crossline @li2021tlb @morbitzer2019extracting\n\nThere lacks a systematic study about side-channel threats in this interface.\n\n### Taming the overheads\n\nOne way forward is to determine all sensitive data-dependent control-flow and\ndata-flow to selectively apply protectionl. This is explored in Constantine\n@borrello2021constantine, but for very fine-grained obfuscated execution. A\nspecialized method for selective data protection for confidential computing\nwould greatly reduces the overheads.\n\nAnother way is to trade-off the granularity of protection. Klotski\n@zhang2020klotski uses caches for data and code that is larger than the 4KB page\nsize, which improve performance, but allows observers to extracts coarse-grained\ninformation.\n","wordCount":335,"tags":["archive"],"metadata":{},"created":"2023-06-12T04:34:51.343761577Z","modified":"2024-06-24T13:52:09.582847511Z","checksum":"cd0fdaa9253c4e9332685f4588c26a834379f9ba261ce71b507d41b26ba098ce"},
    {"filename":"n9bxzpge.md","filenameStem":"n9bxzpge","path":"n9bxzpge.md","absPath":"/home/khadd/mynotes/n9bxzpge.md","title":"Obfuscated execution techniques","link":"[[n9bxzpge]]","lead":"#oblivious","body":"#oblivious\n\nObfuscated execution techniques transform the program such that all code and\nmemory accesses are constant regardless of sensitive input.\n\nThis type of protection commonly has very high overheads, due to the threat\nmodel being too strict (attackers with perfect observation of program counter\nand memory accesses). However, in practice, the observable side channels are\nusually more coarse-grained, at cache-line or page-fault-level. For instance, in\nSGX, attacker side-channels usually need page-fault-level trace before\nperforming more fine-grained cache side-channel attacks. Hence, been works that\nonly target page-fault-level leakage ([[5kzr3hwx]]), for more practical\nprotection.\n\n# Raccoon\n\n[@rane2015raccoon] was the first to propose this idea. It transforms the program\nto use predicated execution to execute _both_ branches of a sensitive-dependent\nbranch. A transactional-like memory\n\nThis type of protection can protect both code and data accesses.\n\nOverheads of this is about 9X @zhang2020klotski.\n\n# Constantine\n\n@borrello2021constantine is currently the state-of-the-art.\n\n```c\nfn handle_pagefault(addr):\n  idx = virt_addr_to_oram_idx(addr);\n  oram_fetch_to_cache(idx);\n  map_vaddr_to_cache(addr, 0x1000);\n  return\n```","snippets":["#oblivious"],"rawContent":"# Obfuscated execution techniques\n\n#oblivious\n\nObfuscated execution techniques transform the program such that all code and\nmemory accesses are constant regardless of sensitive input.\n\nThis type of protection commonly has very high overheads, due to the threat\nmodel being too strict (attackers with perfect observation of program counter\nand memory accesses). However, in practice, the observable side channels are\nusually more coarse-grained, at cache-line or page-fault-level. For instance, in\nSGX, attacker side-channels usually need page-fault-level trace before\nperforming more fine-grained cache side-channel attacks. Hence, been works that\nonly target page-fault-level leakage ([[5kzr3hwx]]), for more practical\nprotection.\n\n# Raccoon\n\n[@rane2015raccoon] was the first to propose this idea. It transforms the program\nto use predicated execution to execute _both_ branches of a sensitive-dependent\nbranch. A transactional-like memory\n\nThis type of protection can protect both code and data accesses.\n\nOverheads of this is about 9X @zhang2020klotski.\n\n# Constantine\n\n@borrello2021constantine is currently the state-of-the-art.\n\n```c\nfn handle_pagefault(addr):\n  idx = virt_addr_to_oram_idx(addr);\n  oram_fetch_to_cache(idx);\n  map_vaddr_to_cache(addr, 0x1000);\n  return\n```\n","wordCount":161,"tags":["oblivious"],"metadata":{},"created":"2023-06-19T03:04:24.903375118Z","modified":"2024-06-24T13:55:49.097088008Z","checksum":"9c0ac67d5a67cfd0221b3bfabd5546aebd34401bfca3b8db4739d2fc025762c5"},
    {"filename":"b4nls7up.md","filenameStem":"b4nls7up","path":"b4nls7up.md","absPath":"/home/khadd/mynotes/b4nls7up.md","title":"Oblivious paging against controlled-channel","link":"[[b4nls7up]]","lead":"#tee #sgx #controlled-channel","body":"#tee #sgx #controlled-channel\n\nOblivious paging is a direction to tackle the paging control-channel in SGX, by\nenabling the enclave with the ability to perform page table management.\n\nPrevious work on this tries to implement _self-paging enclaves_. Self-paging\nenclaves let the enclaves manage their own memory mappings. Page faults to the\nenclave-managed pages are forwarded to the enclave fault handler, so the\nfaulting address is hidden from the OS.\n\n[@aga2019invisipage] uses two page-tables, as inspired by [@costan2016sanctum],\nwhere one table is maintained by the enclave, and the other is maintained by the\nOS. The OS-maintained page table is similar to the traditional one. The enclave\npage table is used for paging of EPC pages. The memory for enclave page table is\nstored in the EPC, and An additional page table base register is added, and when\nan EPC page fault occur, the private page table is walked instead.\n\n[@orenbach2020autarky] argues that ORAM-based oblivious paging requires\nintrusive hardware modifications to the CPU, thus is not practical.\n\n## Challenges\n\n## Supporting for demand paging\n\nDemand paging allows the OS to map the memory page into the address space only\nwhen the process actually touch the page. When it is touch, a page fault will be\nraised, informing the OS to map the page the process's page table.\n\nDemand paging obviously conflict with the goal of hiding page faults from the\nOS.\n\nA simple solution is to statically separate public and private pages, such that\nfault from the enclaves are served by the enclave never served by the OS. This\ndesign creates an additional problem: it rob the ability to perform memory\nmanagement from the OS. Once a private page has been mapped, the OS no longer\nhave the ability to reclaim the page from the enclave. A malicious enclave can\nprevent the OS from ever reusing the page. Moreover, once an enclave page is\nreclaimed, the OS can still learn about accesses on the page\n[@aga2019invisipage].","snippets":["#tee #sgx #controlled-channel"],"rawContent":"# Oblivious paging against controlled-channel\n\n#tee #sgx #controlled-channel\n\nOblivious paging is a direction to tackle the paging control-channel in SGX, by\nenabling the enclave with the ability to perform page table management.\n\nPrevious work on this tries to implement _self-paging enclaves_. Self-paging\nenclaves let the enclaves manage their own memory mappings. Page faults to the\nenclave-managed pages are forwarded to the enclave fault handler, so the\nfaulting address is hidden from the OS.\n\n[@aga2019invisipage] uses two page-tables, as inspired by [@costan2016sanctum],\nwhere one table is maintained by the enclave, and the other is maintained by the\nOS. The OS-maintained page table is similar to the traditional one. The enclave\npage table is used for paging of EPC pages. The memory for enclave page table is\nstored in the EPC, and An additional page table base register is added, and when\nan EPC page fault occur, the private page table is walked instead.\n\n[@orenbach2020autarky] argues that ORAM-based oblivious paging requires\nintrusive hardware modifications to the CPU, thus is not practical.\n\n## Challenges\n\n## Supporting for demand paging\n\nDemand paging allows the OS to map the memory page into the address space only\nwhen the process actually touch the page. When it is touch, a page fault will be\nraised, informing the OS to map the page the process's page table.\n\nDemand paging obviously conflict with the goal of hiding page faults from the\nOS.\n\nA simple solution is to statically separate public and private pages, such that\nfault from the enclaves are served by the enclave never served by the OS. This\ndesign creates an additional problem: it rob the ability to perform memory\nmanagement from the OS. Once a private page has been mapped, the OS no longer\nhave the ability to reclaim the page from the enclave. A malicious enclave can\nprevent the OS from ever reusing the page. Moreover, once an enclave page is\nreclaimed, the OS can still learn about accesses on the page\n[@aga2019invisipage].\n","wordCount":328,"tags":["sgx","tee","controlled-channel"],"metadata":{},"created":"2023-06-12T05:12:49.854971447Z","modified":"2024-07-01T03:20:55.946255404Z","checksum":"fffbb37460bb2551ca30be39bfa1fac955b3f24085e961e793a3a6984c1b6055"},
    {"filename":"gel6dwih.md","filenameStem":"gel6dwih","path":"gel6dwih.md","absPath":"/home/khadd/mynotes/gel6dwih.md","title":"Oblivium: Paging-powered Obfuscated Execution","link":"[[gel6dwih]]","lead":"#archive","body":"#archive\n\n# ORAM operations\n\n## EvictPath\n\nIt look at blocks inside the stash and try to push them to the ORAM tree.\n\n# Page fault handler\n\n```mermaid\nflowchart LR\n  test\n  dec{tet}\n```\n\n# FAQ\n\n## How does malloc interacts with the oblivious paging system?\n\nmalloc only needs to be aware of the memory ranges containing the ORAM storage.\n\nIn traditional malloc, heap memory is expanded on-demand.\n\nWe can grow the tree, following @aga2019invisipage.\n\nOtherwise, malloc is agnostic of the oblivious paging system. `malloc` is just\nan abstraction over the virtual address space. `malloc` takes a piece out of the\nvirtual address space, while `free` returns that piece. Hence, it does not care\nwhich physical backing is used.\n\nOn the other hand, the oblivious paging maintain the physical memory accesses\nand must not change the virtual address maintained by `malloc`.\n\nThe paging system need to maintain two invariants:\n\n1. It must not touch the virtual address maintained by the heap allocator to be\n   compatible.\n2. a virtual address must points to the corresponding content, regardless of the\n   physical address.\n\nIf `0xff100` points to page with content `AAAA`, the oblivious paging system\nmust make sure that the when the `0xff100` is accessed later, the content must\nstill be `AAAA`. This must be done by data copy.\n\n### How do you bootstrap malloc?\n\nThere seem to be a chicken-and-egg problem in unikraft. To add a virtual address\nrange to the memory allocator, the allocator must write its metadata to some\npages within the address range.\n\n### Security tradeoff vs. ORAM\n\nUsing NPF, attacker can probably infer read/write within the stash.\n\nWe cannot intercept read/write after it is mapped to the ORAM, so the frequency\nof access to the stash can be leaked. However, maybe it is not a big deal, since\nit is the same for klotski.\n\n#### Guarantees\n\nAll memory accesses of the application are coming from the stash.\n\nOn-demand accesses\n\n### When do you perform ORAM operations?\n\n#### Update the page mapping\n\nInvariant must be maintained: Every virtual address mapping must either points\nto an address inside the stash, or a path on ORAM.\n\nLet say we initially allocate memory directly within the stash.\n\nOn stash allocation, they must be updated to points to stash.\n\nWhen these are evicted from the stash, the mapping must be updated to a block on\na tree. The blocks can be chosen randomly.\n\n#### Evict path\n\nIn Path ORAM, this is called on every read and write. In Ring ORAM, this is\ncalled deterministically after $G$ accesses.\n\nCan this be called only when the stash reaches certain threshold?\n\n- Possibly. What is the worse that can be inferred? Maybe there is a reason that\n  all ORAM require deterministic.\n- Maybe the information that _the application access to ORAM memory more, given\n  some input_ can be leaked. This can help infer the input. Hence eviction must\n  be deterministic.\n- On the other hand, accesses to the stash already leak similar information,\n  since we cannot capture all accesses to a virtual address when they are\n  mapped, so deterministic eviction cannot be performed.\n  - Does SEV allows the VM to acknowledge NPF? If so, we can perform eviction\n    based on this.\n  - No, VM is not aware of NPF. ~~There seem to be a chicken-and-egg problem in\n    unikraft. To add a virtual address range to the memory allocator, the\n    allocator must write its metadata to some pages within the address range.~~\n- Nope there isn't. Does the block size need to be page size? It don't need to\n  be. ORAM block can be smaller than a page. 2KB blocks works, since accesses to\n  physical memory will be randomized anyway, regardless of block sizes.\n\nMaking block size page size may be easier ot maintain, since frame allocator\nallocates memory at page granularity (not sure if related). Also, memory mapping\nhas page granularity (not sure if related),\n\nAllocating a new page on page faults may even leads to more memory consumption.\nAn address `0x40000fff` may have offset `0x0fff`, which is at the ned of the\npage boundary. If we map it to a new physical page inside stash, say, `0x1000`,\nthen only the end of the page is used. Access to `0x40001000` will continue to\nfault, which leads to alocation of another stash block (e.g., `0x2000`).\n\n### Sub-page block size\n\nTo have sub-page block size, we needs to map two virtual addresses to the same\npage.\n\n# Notes\n\n## 2023-07-06\n\n- Modified `ukvmem` to export the PTE to our fault handler.\n\n## 2023-07-07\n\n- Use a reverse mapping table that map from block_id into vaddr, for _blocks\n  inside tree_\n- Stash-only posmap keeps track of blocks within the stash\n\n## 2023-07-08\n\n```c\n\u003cbbuddy.c @  155\u003e Assertion failure: memr != ((void *) 0)\n```\n\n- This bug is probably caused by wrong address mapping in pte\n- Must FLUSH TLB on any PT UPDATE\n  - Probably not the problem...\n- sanity checks: PTE must exist\n\n- Somehow there is more stash blocks than ORAM blocks\n  - It make sense, since the tree blocks are limited, so blocks must remain in\n    the stash.\n- TODO: `do_unhandled_trap`: need investigation :(\n\n## 2023-07-12\n\n- Can we retrofit page table for reversed mapping?\n- How do we reduce the number of page table update?\n\n## 2023-07-13\n\n- Refactored functions to take contexts.\n- Found that function to get bucket_idx to block_id is completely wrong\n\n## 2023-07-16\n\n- Refactor again, with generalized use cases in mind.\n\n## 2023-07-19\n\n- Fixed problems with ISR. It's probably caused by a missing TLB flush on\n  eviction path.\n- Found some conundrums about stash sizes/stash usage in ORAM. Maybe\n  implementing Ring ORAM from the start would avoid them.\n- We don't need to update the page table entry for every block read (unless you\n  want to keep the block inside the stash).\n\n## 2023-07-20\n\n- Found a bug that cause infinite loop. If two consecutive faults happen due to\n  a single instruction (because of XMM crossing the page boundary), and the\n  second ORAM access evicts the block fetched by the first ORAM access, it will\n  loop forever.\n\n```\n →   0x12a82b \u003cbench_random_access+139\u003e movups XMMWORD PTR [r15], xmm0\n     0x12a82f \u003cbench_random_access+143\u003e movups XMMWORD PTR [r15+0x10], xmm0\n     0x12a834 \u003cbench_random_access+148\u003e movups XMMWORD PTR [r15+0x20], xmm0\n     0x12a839 \u003cbench_random_access+153\u003e movups XMMWORD PTR [r15+0x30], xmm0\n```\n\n- This can be solved by fetching two pages in one ORAM access. Maybe check if\n  the falt address and the next page is smaller than 128 bits (XMM register\n  size). If it is, then fetch the next page.\n- @ren2013design mentions some techniques for improving locality of ORAM.\n\n- Passing a _keep list_ to evict may be a good idea?\n\n## 2023-07-22\n\n- Maybe the title could be Oblivious VMA: an OS-powered defense agaisnt\n  controlled channel attacks\n- For more information about VMAs, could refer to @gupta2021rebooting\n\n## 2023-07-25\n\n- Emulation of instruction is harder than it seems.\n- Probably need to add an emulation engine. Look at\n  [Ceberus](https://github.com/ku-leuven-msec/The-Cerberus-Project/tree/main/cerberus_ReMon)\n  - [ReMon](https://github.com/ReMon-MVEE/ReMon/tree/master/MVEE/Src/arch/amd64/shared_mem)\n  -\n\n## 2023-07-28\n\n- _Reads_ also need to be emulated.\n-\n\n## 2023-07-29\n\n```cpp\n// Old code\nauto* typed_destination = *((uint64_t*)((unsigned long long))monitor_base + offset);\n// New code:\nMAP_FAULTING_PADDR(destination);\nuint64_t* typed_destination = (uint64_t*) destination\n```\n\n[The](2024-05-23_the.md) old code obtains the destination addr from some memory.\nThe new code just map the faulting address and used as destination\n\n## 2023-09-05","snippets":["#archive"],"rawContent":"# Oblivium: Paging-powered Obfuscated Execution\n\n#archive\n\n# ORAM operations\n\n## EvictPath\n\nIt look at blocks inside the stash and try to push them to the ORAM tree.\n\n# Page fault handler\n\n```mermaid\nflowchart LR\n  test\n  dec{tet}\n```\n\n# FAQ\n\n## How does malloc interacts with the oblivious paging system?\n\nmalloc only needs to be aware of the memory ranges containing the ORAM storage.\n\nIn traditional malloc, heap memory is expanded on-demand.\n\nWe can grow the tree, following @aga2019invisipage.\n\nOtherwise, malloc is agnostic of the oblivious paging system. `malloc` is just\nan abstraction over the virtual address space. `malloc` takes a piece out of the\nvirtual address space, while `free` returns that piece. Hence, it does not care\nwhich physical backing is used.\n\nOn the other hand, the oblivious paging maintain the physical memory accesses\nand must not change the virtual address maintained by `malloc`.\n\nThe paging system need to maintain two invariants:\n\n1. It must not touch the virtual address maintained by the heap allocator to be\n   compatible.\n2. a virtual address must points to the corresponding content, regardless of the\n   physical address.\n\nIf `0xff100` points to page with content `AAAA`, the oblivious paging system\nmust make sure that the when the `0xff100` is accessed later, the content must\nstill be `AAAA`. This must be done by data copy.\n\n### How do you bootstrap malloc?\n\nThere seem to be a chicken-and-egg problem in unikraft. To add a virtual address\nrange to the memory allocator, the allocator must write its metadata to some\npages within the address range.\n\n### Security tradeoff vs. ORAM\n\nUsing NPF, attacker can probably infer read/write within the stash.\n\nWe cannot intercept read/write after it is mapped to the ORAM, so the frequency\nof access to the stash can be leaked. However, maybe it is not a big deal, since\nit is the same for klotski.\n\n#### Guarantees\n\nAll memory accesses of the application are coming from the stash.\n\nOn-demand accesses\n\n### When do you perform ORAM operations?\n\n#### Update the page mapping\n\nInvariant must be maintained: Every virtual address mapping must either points\nto an address inside the stash, or a path on ORAM.\n\nLet say we initially allocate memory directly within the stash.\n\nOn stash allocation, they must be updated to points to stash.\n\nWhen these are evicted from the stash, the mapping must be updated to a block on\na tree. The blocks can be chosen randomly.\n\n#### Evict path\n\nIn Path ORAM, this is called on every read and write. In Ring ORAM, this is\ncalled deterministically after $G$ accesses.\n\nCan this be called only when the stash reaches certain threshold?\n\n- Possibly. What is the worse that can be inferred? Maybe there is a reason that\n  all ORAM require deterministic.\n- Maybe the information that _the application access to ORAM memory more, given\n  some input_ can be leaked. This can help infer the input. Hence eviction must\n  be deterministic.\n- On the other hand, accesses to the stash already leak similar information,\n  since we cannot capture all accesses to a virtual address when they are\n  mapped, so deterministic eviction cannot be performed.\n  - Does SEV allows the VM to acknowledge NPF? If so, we can perform eviction\n    based on this.\n  - No, VM is not aware of NPF. ~~There seem to be a chicken-and-egg problem in\n    unikraft. To add a virtual address range to the memory allocator, the\n    allocator must write its metadata to some pages within the address range.~~\n- Nope there isn't. Does the block size need to be page size? It don't need to\n  be. ORAM block can be smaller than a page. 2KB blocks works, since accesses to\n  physical memory will be randomized anyway, regardless of block sizes.\n\nMaking block size page size may be easier ot maintain, since frame allocator\nallocates memory at page granularity (not sure if related). Also, memory mapping\nhas page granularity (not sure if related),\n\nAllocating a new page on page faults may even leads to more memory consumption.\nAn address `0x40000fff` may have offset `0x0fff`, which is at the ned of the\npage boundary. If we map it to a new physical page inside stash, say, `0x1000`,\nthen only the end of the page is used. Access to `0x40001000` will continue to\nfault, which leads to alocation of another stash block (e.g., `0x2000`).\n\n### Sub-page block size\n\nTo have sub-page block size, we needs to map two virtual addresses to the same\npage.\n\n# Notes\n\n## 2023-07-06\n\n- Modified `ukvmem` to export the PTE to our fault handler.\n\n## 2023-07-07\n\n- Use a reverse mapping table that map from block_id into vaddr, for _blocks\n  inside tree_\n- Stash-only posmap keeps track of blocks within the stash\n\n## 2023-07-08\n\n```c\n\u003cbbuddy.c @  155\u003e Assertion failure: memr != ((void *) 0)\n```\n\n- This bug is probably caused by wrong address mapping in pte\n- Must FLUSH TLB on any PT UPDATE\n  - Probably not the problem...\n- sanity checks: PTE must exist\n\n- Somehow there is more stash blocks than ORAM blocks\n  - It make sense, since the tree blocks are limited, so blocks must remain in\n    the stash.\n- TODO: `do_unhandled_trap`: need investigation :(\n\n## 2023-07-12\n\n- Can we retrofit page table for reversed mapping?\n- How do we reduce the number of page table update?\n\n## 2023-07-13\n\n- Refactored functions to take contexts.\n- Found that function to get bucket_idx to block_id is completely wrong\n\n## 2023-07-16\n\n- Refactor again, with generalized use cases in mind.\n\n## 2023-07-19\n\n- Fixed problems with ISR. It's probably caused by a missing TLB flush on\n  eviction path.\n- Found some conundrums about stash sizes/stash usage in ORAM. Maybe\n  implementing Ring ORAM from the start would avoid them.\n- We don't need to update the page table entry for every block read (unless you\n  want to keep the block inside the stash).\n\n## 2023-07-20\n\n- Found a bug that cause infinite loop. If two consecutive faults happen due to\n  a single instruction (because of XMM crossing the page boundary), and the\n  second ORAM access evicts the block fetched by the first ORAM access, it will\n  loop forever.\n\n```\n →   0x12a82b \u003cbench_random_access+139\u003e movups XMMWORD PTR [r15], xmm0\n     0x12a82f \u003cbench_random_access+143\u003e movups XMMWORD PTR [r15+0x10], xmm0\n     0x12a834 \u003cbench_random_access+148\u003e movups XMMWORD PTR [r15+0x20], xmm0\n     0x12a839 \u003cbench_random_access+153\u003e movups XMMWORD PTR [r15+0x30], xmm0\n```\n\n- This can be solved by fetching two pages in one ORAM access. Maybe check if\n  the falt address and the next page is smaller than 128 bits (XMM register\n  size). If it is, then fetch the next page.\n- @ren2013design mentions some techniques for improving locality of ORAM.\n\n- Passing a _keep list_ to evict may be a good idea?\n\n## 2023-07-22\n\n- Maybe the title could be Oblivious VMA: an OS-powered defense agaisnt\n  controlled channel attacks\n- For more information about VMAs, could refer to @gupta2021rebooting\n\n## 2023-07-25\n\n- Emulation of instruction is harder than it seems.\n- Probably need to add an emulation engine. Look at\n  [Ceberus](https://github.com/ku-leuven-msec/The-Cerberus-Project/tree/main/cerberus_ReMon)\n  - [ReMon](https://github.com/ReMon-MVEE/ReMon/tree/master/MVEE/Src/arch/amd64/shared_mem)\n  -\n\n## 2023-07-28\n\n- _Reads_ also need to be emulated.\n-\n\n## 2023-07-29\n\n```cpp\n// Old code\nauto* typed_destination = *((uint64_t*)((unsigned long long))monitor_base + offset);\n// New code:\nMAP_FAULTING_PADDR(destination);\nuint64_t* typed_destination = (uint64_t*) destination\n```\n\n[The](2024-05-23_the.md) old code obtains the destination addr from some memory.\nThe new code just map the faulting address and used as destination\n\n## 2023-09-05\n","wordCount":1224,"tags":["archive"],"metadata":{},"created":"2024-05-22T08:24:03.247579311Z","modified":"2024-11-18T05:55:26.381700035Z","checksum":"762d9dc5d6d4961ad17bb7793d5cfab142cf3e07d3e644a0ce04ac75b09c1b25"},
    {"filename":"adn8i9cz.md","filenameStem":"adn8i9cz","path":"adn8i9cz.md","absPath":"/home/khadd/mynotes/adn8i9cz.md","title":"One sentence paper summary","link":"[[adn8i9cz]]","lead":"#writing #reading","body":"#writing #reading\n\nMost papers can be summarized into one sentence that capture the highest-level\nideas. For instance,\n\n\u003e Obliviate introduces an data-oblivious file system using ORAM primitives.\n\nOr\n\n\u003e Capacity retrofit PAC and MTE primitives to enable capability-based access\n\u003e control for file and memory.\n\nIdeas that cannot be consolidated into one sentence is either over-complicated,\nnot well-defined, and not well-contained.\n\n## Implications\n\nFirst, when reading a paper try to find the main ideas of the paper and\nsummarize it into one sentence.\n\nSecond, when writing papers, identify the core idea of the in one sentence\nfirst. This will determine the scope of the paper and avoid over-complicating\nthings. Moreover, it allows for concise writing. Each sentence/paragraph should\ncontribute to the main idea.","snippets":["#writing #reading"],"rawContent":"# One sentence paper summary\n\n#writing #reading\n\nMost papers can be summarized into one sentence that capture the highest-level\nideas. For instance,\n\n\u003e Obliviate introduces an data-oblivious file system using ORAM primitives.\n\nOr\n\n\u003e Capacity retrofit PAC and MTE primitives to enable capability-based access\n\u003e control for file and memory.\n\nIdeas that cannot be consolidated into one sentence is either over-complicated,\nnot well-defined, and not well-contained.\n\n## Implications\n\nFirst, when reading a paper try to find the main ideas of the paper and\nsummarize it into one sentence.\n\nSecond, when writing papers, identify the core idea of the in one sentence\nfirst. This will determine the scope of the paper and avoid over-complicating\nthings. Moreover, it allows for concise writing. Each sentence/paragraph should\ncontribute to the main idea.\n","wordCount":128,"tags":["reading","writing"],"metadata":{},"created":"2023-05-25T05:38:44.0635008Z","modified":"2024-07-03T06:41:48.578746167Z","checksum":"3d23c0b5f76d6d0ab1f3780e60f5d899a77e12626dc7dba0da12b50feb9a4b60"},
    {"filename":"kwe5ygmo.md","filenameStem":"kwe5ygmo","path":"kwe5ygmo.md","absPath":"/home/khadd/mynotes/kwe5ygmo.md","title":"Operating System Support for Safe and Efficient Auxiliary Execution Operating System Support for Safe and Efficient Auxiliary Execution","link":"[[kwe5ygmo]]","lead":"#literature\n@jing2022operating","body":"#literature\n@jing2022operating\n\n# Questions/Notes during reading\n- [ ] What makes an execution entity? \n- [ ] What does *schedulable* means in this context?\n- [ ] How do you define first-class execution entity?\n- [ ] How address space isolation is achieved? Is it through page table switching/page permissions?\n- [ ] \n-\n\n# Random thoughts\n- Categorize previous works into *groups*, then say that they don't solve a particular problem\n\n# Summary\nThe paper studies the so-called *auxiliary tasks* employed in existing applications. An auxiliary task is a task that performs supporting functionalities aside from the main program logic. For instance, the authors categorize MySQL's deadlock-detecting  `check_and_resolve` as an auxilary task. \nNote that this definition is entirely subjective (as mentioned in section 6). However, the authors did show the prevalence of such auxiliary tasks, used in 6 different production applications. \n\nBased on the characteristics of the auxiliary tasks: (1) need to be isolated from the main process and (2) need good observability of the main process, the authors pointed out the limitations of the existing methods, mainly SFI, Process-based isolation and threads in performing such tasks. Threads lacks memory isolation, processes and SFI lacks observability.\n\nThe authors introduced a new abstraction called the _orbit_ which is specialized for auxiliary tasks. To summarize, an orbit is an OS-schedulable entity (similar to processes and threads) that is address-space isolated from the main process.  The orbit can be invoked synchronously or asynchronously.\n\nFor main-\u003eorbit data synchronization, orbit shares a limited memory area with the main process called the *orbit area*. Those pages are copy-on-write *when there is an orbit invocation* (essentially snapshotting the pages): whenever the orbit or the main process is written into this page, the page will be cloned, and the writer will work on its copy instead.\nNo concurrency control is done on the orbit area page, so snapshotting might not be thread-safe. Application-level synchronization is relied on instead.\n\nFor orbit-\u003emain program data synchronization, the paper proposed a *controlled state alteration* policy. Orbit uses syscall  `orbit_push` to push the changes that they want to make into a *scratchpad memory*. On the main program side, `orbit_pull` is used to bring the updates to the main program's memory.","snippets":["#literature\n@jing2022operating"],"rawContent":"# Operating System Support for Safe and Efficient Auxiliary Execution Operating System Support for Safe and Efficient Auxiliary Execution \n#literature\n@jing2022operating\n\n# Questions/Notes during reading\n- [ ] What makes an execution entity? \n- [ ] What does *schedulable* means in this context?\n- [ ] How do you define first-class execution entity?\n- [ ] How address space isolation is achieved? Is it through page table switching/page permissions?\n- [ ] \n-\n\n# Random thoughts\n- Categorize previous works into *groups*, then say that they don't solve a particular problem\n\n# Summary\nThe paper studies the so-called *auxiliary tasks* employed in existing applications. An auxiliary task is a task that performs supporting functionalities aside from the main program logic. For instance, the authors categorize MySQL's deadlock-detecting  `check_and_resolve` as an auxilary task. \nNote that this definition is entirely subjective (as mentioned in section 6). However, the authors did show the prevalence of such auxiliary tasks, used in 6 different production applications. \n\nBased on the characteristics of the auxiliary tasks: (1) need to be isolated from the main process and (2) need good observability of the main process, the authors pointed out the limitations of the existing methods, mainly SFI, Process-based isolation and threads in performing such tasks. Threads lacks memory isolation, processes and SFI lacks observability.\n\nThe authors introduced a new abstraction called the _orbit_ which is specialized for auxiliary tasks. To summarize, an orbit is an OS-schedulable entity (similar to processes and threads) that is address-space isolated from the main process.  The orbit can be invoked synchronously or asynchronously.\n\nFor main-\u003eorbit data synchronization, orbit shares a limited memory area with the main process called the *orbit area*. Those pages are copy-on-write *when there is an orbit invocation* (essentially snapshotting the pages): whenever the orbit or the main process is written into this page, the page will be cloned, and the writer will work on its copy instead.\nNo concurrency control is done on the orbit area page, so snapshotting might not be thread-safe. Application-level synchronization is relied on instead.\n\nFor orbit-\u003emain program data synchronization, the paper proposed a *controlled state alteration* policy. Orbit uses syscall  `orbit_push` to push the changes that they want to make into a *scratchpad memory*. On the main program side, `orbit_pull` is used to bring the updates to the main program's memory.\n\n\n\n\n\n\n\n\n","wordCount":387,"tags":["literature"],"metadata":{},"created":"2024-05-22T08:24:03.27414627Z","modified":"2024-05-22T08:23:40.666608407Z","checksum":"e8192117831bc66675c9459062c679305dabe7fbe47db6b43afac35f0117c0bd"},
    {"filename":"pqi5jkye.md","filenameStem":"pqi5jkye","path":"pqi5jkye.md","absPath":"/home/khadd/mynotes/pqi5jkye.md","title":"Outlinenew","link":"[[pqi5jkye]]","lead":"```mermaid\ngraph TB\n\tIncognitOS--\u003eunikernel\n\tunikernel[\"Unikernel for Obfuscated CVM\"]:::overview\n    goal_transparent[\"Goal:\\nTransparent obfuscation\"]:::overview\n    goal_adaptive[\"Goal:\\nAdaptive Defense\"]:::overview\n    goal_fullsystem[\"Goal:\\nFull-system obfuscation\"]:::overview\n    feat_directhw[\"Feature:\\nDirect Hardware Access\"]:::overview\n    feat_smalltcb[\"Feature:\\nSmall TCB\"]:::overview","body":"```mermaid\ngraph TB\n\tIncognitOS--\u003eunikernel\n\tunikernel[\"Unikernel for Obfuscated CVM\"]:::overview\n    goal_transparent[\"Goal:\\nTransparent obfuscation\"]:::overview\n    goal_adaptive[\"Goal:\\nAdaptive Defense\"]:::overview\n    goal_fullsystem[\"Goal:\\nFull-system obfuscation\"]:::overview\n    feat_directhw[\"Feature:\\nDirect Hardware Access\"]:::overview\n    feat_smalltcb[\"Feature:\\nSmall TCB\"]:::overview\n\n  %% Previous work comparisions\n  prev_threshold[\"Previous work:\\nhave weak tresholds to \\navoid false positive\"]:::related\n  prev_static_rate[\"Previous work:\\n uses static rerandomization\\n rate\"]:::related\n  prev_compiler[\"Previous work:\\nrequire compiler\"]:::related\n  prev_threatmodel[\"Previous work:\\noverly ideal threat \\nmodel\"]:::related\n\n  prev_compiler--\u003e|contradict|goal_transparent\n  prev_threshold--\u003e|fundamentally incompatible with|obs_high_rates\n  prev_static_rate--\u003e|high overheads in \\nnormal execution|motiv_overheads\n  prev_threatmodel--\u003e|causes|motiv_overheads\n\n\n\t%% Unikernel edges\n\tfeat_directhw--\u003e|No user-kernel switches|tech_mmunative\n\tfeat_smalltcb--\u003e|Make feasible|goal_fullsystem\n    unikernel--\u003efeat_directhw\n    unikernel--\u003efeat_smalltcb\n    unikernel--\u003egoal_transparent\n\tunikernel--\u003egoal_adaptive\n\tunikernel--\u003egoal_fullsystem\n\n\tgoal_transparent--\u003etech_sbi\n\tgoal_adaptive--\u003emotiv_rates\n\tgoal_adaptive--\u003emotiv_overheads\n  goal_transparent--\u003etech_mmunative\n\tgoal_transparent--\u003emotiv_bincompat\n\tgoal_fullsystem--\u003emotiv_tcb\n\tgoal_fullsystem--\u003eobs_gpt\n\n\t%% Motivations\n\tmotiv_rates[\"Motivation:\\nEmpirical attack VMEXIT analysis\"]:::overview\n\tmotiv_overheads[\"Motivation:\\nHigh overheads of\\nobfsuscation\"]:::overview\n\tmotiv_tcb[\"Motivation:\\nNew CVM boundary includes\\nfull-system TCB\"]:::overview\n\tmotiv_bincompat[\"Motivation:\\nBinary compatibility is ongoing\\nunikernel effort\"]:::overview\n\n\n\t%% Motiv edges\n\tmotiv_overheads--\u003eobs_adaptive\n\tmotiv_overheads--\u003eobs_high_rates\n\tmotiv_rates--\u003eobs_vmexit\n\n\t%% Observations\n\tobs_adaptive[\"Observation:\\nRate can be scaled without \\nreducing security\"]:::overview\n\tobs_vmexit[\"Observation:\\nVMExit can be sampled\"]:::overview\n\tobs_gpa[\"Observation:\\nAttacker can only observe GPA \\nwhile gvA is hidden\"]:::overview\n\tobs_gpt[\"Observation:\\nEven when GVA is hidden\\nGPT casn leak access\"]:::overview\n\tobs_high_rates[\"Observation:\\nEven in benign execution there is high \\nexit rates \"]:::overview\n\n\t%% Obs edges\n\tobs_vmexit--\u003echal_untrusted_int\n\tobs_vmexit--\u003echal_rate\n\n  obs_gpt--\u003ereq_gpt_rerand[\"The randomization scheme must\"]\n\n\n\n\t%% Challenges\n\tchal_rate[\"Challenge: \\nRobust and reliable sampling\"]:::overview\n\tchal_untrusted_int[\"Challenge: \\nScheduler that deepends on\\nhypervisor is untrustworthy\"]:::overview\n\n\t%% Edges\n\tchal_rate--\u003esol_sampling\n\tchal_untrusted_int--\u003esol_synctick\n\n\t%% Techniques\n\ttech_sbi[\"Technique:\\nStatic binary instrumentation\"]:::overview\n    tech_mmunative[\"Technique:\\nMMU-native obfuscation\\n only rerand GPA\"]:::overview\n\t%% Edges\n\ttech_mmunative--\u003eobs_gpa\n\ttech_sbi--\u003esol_synctick\n\ttech_sbi--\u003esched_sbi\n\n\n\n\n\n\n\n\n\n\t%% Scheduling\n\tsol_sampling[\"Solution:\\n Robust and transparent Rate sampling\"]:::scheduling\n\tsol_synctick[\"Solution:\\nSynchronous ticks independent of Hyp\"]:::scheduling\n\treq_sampling[\"Requirement:\\nSampling rate sufficiency\"]:::scheduling\n\tsched_policy[\"Details:\\nHigh-level policy\"]:::scheduling\n\tsched_placement[\"Detail:\\nTick placement strategy\"]:::scheduling\n\tsched_kerneltick[\"Kernel tick placmenet\"]:::scheduling\n\tsched_kerneltick_details[\"Technique:\\nPer-function compiler instrumentation\"]:::scheduling\n\tsched_coverage[\"Loop coverage\"]:::scheduling\n\tsched_basicblock[\"Basic block scheme\"]:::scheduling\n\tsched_sbi[\"Details:\\nStatic binary inst\"]:::scheduling\n\tsched_time[\"Instruction as time\"]:::scheduling\n\tsched_scaling[\"Scaling function\"]:::scheduling\n\tsched_window[\"Sliding window\"]:::scheduling\n\tsched_nyquyst[\"Nyquyst theorem\"]:::scheduling\n\tsched_trampoline[\"Trampline design\"]:::scheduling\n\tsched_inst[\"Instruction selection\"]:::scheduling\n\n\t%% Scheduling edges\n\tsol_sampling--\u003ereq_sampling\n\tsol_sampling--\u003esol_synctick\n\tsol_sampling--\u003esched_policy\n\n\tsol_synctick--\u003esched_time\n\tsol_synctick--\u003esched_sbi\n\n\tsched_time--\u003esched_sbi\n\tsched_time--\u003esched_window\n\n\tsched_sbi--\u003esched_trampoline\n\tsched_sbi--\u003esched_inst\n\n\n\treq_sampling--\u003esched_nyquyst\n\treq_sampling--\u003esched_placement\n\tsched_placement--\u003esched_sbi\n\tsched_placement--\u003esched_coverage\n\tsched_placement--\u003esched_basicblock\n\tsched_placement--\u003esched_kerneltick\n\n\tgoal_fullsystem--\u003esched_kerneltick\n\tsched_kerneltick--\u003esched_kerneltick_details\n\n\n\t%% High-level Policy\n\tsched_sbi--\u003esched_policy\n\tsched_placement--\u003esched_policy\n\tsched_policy--\u003esched_window\n\tsched_policy--\u003esched_scaling\n\tsched_policy--\u003e|Command rerandomizations|paging_rerand\n\n\n\t%% Paging\n\tsol_rerand_paging[\"Soluion:\\nRerandomizing page management\\nfor full-CVM\"]:::paging\n\tpaging_rerand[\"Details: Rerandomization strategy\"]:::paging\n\tpaging_layout[\"Details: memory layout\"]:::paging\n\tpaging_activeregion[\"Active regions splited\\ninto (code,data,pt)\"]:::paging\n\tpaging_oram[\"ORAM-backed page pool\\nwith hardened stash\"]:::paging\n\tpaging_pagein[\"Page in/Page out\"]:::paging\n\tpaging_eviction[\"Details:\\nRerandomization through\\neviction\"]:::paging\n\n\t%% Paging edges\n\tsol_rerand_paging--\u003epaging_rerand\n\ttech_mmunative--\u003esol_rerand_paging\n\tpaging_rerand--\u003epaging_layout\n\tpaging_layout--\u003epaging_activeregion\n\tpaging_layout--\u003epaging_oram\n\tpaging_rerand--\u003epaging_eviction\n\tpaging_oram--\u003epaging_pagein\n\n\n\n    classDef overview fill:#f9f\n    classDef scheduling fill:lightblue\n    classDef paging fill:lightgreen\n    classDef related fill:pink\n```","snippets":["```mermaid\ngraph TB\n\tIncognitOS--\u003eunikernel\n\tunikernel[\"Unikernel for Obfuscated CVM\"]:::overview\n    goal_transparent[\"Goal:\\nTransparent obfuscation\"]:::overview\n    goal_adaptive[\"Goal:\\nAdaptive Defense\"]:::overview\n    goal_fullsystem[\"Goal:\\nFull-system obfuscation\"]:::overview\n    feat_directhw[\"Feature:\\nDirect Hardware Access\"]:::overview\n    feat_smalltcb[\"Feature:\\nSmall TCB\"]:::overview"],"rawContent":"# Outlinenew\n\n```mermaid\ngraph TB\n\tIncognitOS--\u003eunikernel\n\tunikernel[\"Unikernel for Obfuscated CVM\"]:::overview\n    goal_transparent[\"Goal:\\nTransparent obfuscation\"]:::overview\n    goal_adaptive[\"Goal:\\nAdaptive Defense\"]:::overview\n    goal_fullsystem[\"Goal:\\nFull-system obfuscation\"]:::overview\n    feat_directhw[\"Feature:\\nDirect Hardware Access\"]:::overview\n    feat_smalltcb[\"Feature:\\nSmall TCB\"]:::overview\n\n  %% Previous work comparisions\n  prev_threshold[\"Previous work:\\nhave weak tresholds to \\navoid false positive\"]:::related\n  prev_static_rate[\"Previous work:\\n uses static rerandomization\\n rate\"]:::related\n  prev_compiler[\"Previous work:\\nrequire compiler\"]:::related\n  prev_threatmodel[\"Previous work:\\noverly ideal threat \\nmodel\"]:::related\n\n  prev_compiler--\u003e|contradict|goal_transparent\n  prev_threshold--\u003e|fundamentally incompatible with|obs_high_rates\n  prev_static_rate--\u003e|high overheads in \\nnormal execution|motiv_overheads\n  prev_threatmodel--\u003e|causes|motiv_overheads\n\n\n\t%% Unikernel edges\n\tfeat_directhw--\u003e|No user-kernel switches|tech_mmunative\n\tfeat_smalltcb--\u003e|Make feasible|goal_fullsystem\n    unikernel--\u003efeat_directhw\n    unikernel--\u003efeat_smalltcb\n    unikernel--\u003egoal_transparent\n\tunikernel--\u003egoal_adaptive\n\tunikernel--\u003egoal_fullsystem\n\n\tgoal_transparent--\u003etech_sbi\n\tgoal_adaptive--\u003emotiv_rates\n\tgoal_adaptive--\u003emotiv_overheads\n  goal_transparent--\u003etech_mmunative\n\tgoal_transparent--\u003emotiv_bincompat\n\tgoal_fullsystem--\u003emotiv_tcb\n\tgoal_fullsystem--\u003eobs_gpt\n\n\t%% Motivations\n\tmotiv_rates[\"Motivation:\\nEmpirical attack VMEXIT analysis\"]:::overview\n\tmotiv_overheads[\"Motivation:\\nHigh overheads of\\nobfsuscation\"]:::overview\n\tmotiv_tcb[\"Motivation:\\nNew CVM boundary includes\\nfull-system TCB\"]:::overview\n\tmotiv_bincompat[\"Motivation:\\nBinary compatibility is ongoing\\nunikernel effort\"]:::overview\n\n\n\t%% Motiv edges\n\tmotiv_overheads--\u003eobs_adaptive\n\tmotiv_overheads--\u003eobs_high_rates\n\tmotiv_rates--\u003eobs_vmexit\n\n\t%% Observations\n\tobs_adaptive[\"Observation:\\nRate can be scaled without \\nreducing security\"]:::overview\n\tobs_vmexit[\"Observation:\\nVMExit can be sampled\"]:::overview\n\tobs_gpa[\"Observation:\\nAttacker can only observe GPA \\nwhile gvA is hidden\"]:::overview\n\tobs_gpt[\"Observation:\\nEven when GVA is hidden\\nGPT casn leak access\"]:::overview\n\tobs_high_rates[\"Observation:\\nEven in benign execution there is high \\nexit rates \"]:::overview\n\n\t%% Obs edges\n\tobs_vmexit--\u003echal_untrusted_int\n\tobs_vmexit--\u003echal_rate\n\n  obs_gpt--\u003ereq_gpt_rerand[\"The randomization scheme must\"]\n\n\n\n\t%% Challenges\n\tchal_rate[\"Challenge: \\nRobust and reliable sampling\"]:::overview\n\tchal_untrusted_int[\"Challenge: \\nScheduler that deepends on\\nhypervisor is untrustworthy\"]:::overview\n\n\t%% Edges\n\tchal_rate--\u003esol_sampling\n\tchal_untrusted_int--\u003esol_synctick\n\n\t%% Techniques\n\ttech_sbi[\"Technique:\\nStatic binary instrumentation\"]:::overview\n    tech_mmunative[\"Technique:\\nMMU-native obfuscation\\n only rerand GPA\"]:::overview\n\t%% Edges\n\ttech_mmunative--\u003eobs_gpa\n\ttech_sbi--\u003esol_synctick\n\ttech_sbi--\u003esched_sbi\n\n\n\n\n\n\n\n\n\n\t%% Scheduling\n\tsol_sampling[\"Solution:\\n Robust and transparent Rate sampling\"]:::scheduling\n\tsol_synctick[\"Solution:\\nSynchronous ticks independent of Hyp\"]:::scheduling\n\treq_sampling[\"Requirement:\\nSampling rate sufficiency\"]:::scheduling\n\tsched_policy[\"Details:\\nHigh-level policy\"]:::scheduling\n\tsched_placement[\"Detail:\\nTick placement strategy\"]:::scheduling\n\tsched_kerneltick[\"Kernel tick placmenet\"]:::scheduling\n\tsched_kerneltick_details[\"Technique:\\nPer-function compiler instrumentation\"]:::scheduling\n\tsched_coverage[\"Loop coverage\"]:::scheduling\n\tsched_basicblock[\"Basic block scheme\"]:::scheduling\n\tsched_sbi[\"Details:\\nStatic binary inst\"]:::scheduling\n\tsched_time[\"Instruction as time\"]:::scheduling\n\tsched_scaling[\"Scaling function\"]:::scheduling\n\tsched_window[\"Sliding window\"]:::scheduling\n\tsched_nyquyst[\"Nyquyst theorem\"]:::scheduling\n\tsched_trampoline[\"Trampline design\"]:::scheduling\n\tsched_inst[\"Instruction selection\"]:::scheduling\n\n\t%% Scheduling edges\n\tsol_sampling--\u003ereq_sampling\n\tsol_sampling--\u003esol_synctick\n\tsol_sampling--\u003esched_policy\n\n\tsol_synctick--\u003esched_time\n\tsol_synctick--\u003esched_sbi\n\n\tsched_time--\u003esched_sbi\n\tsched_time--\u003esched_window\n\n\tsched_sbi--\u003esched_trampoline\n\tsched_sbi--\u003esched_inst\n\n\n\treq_sampling--\u003esched_nyquyst\n\treq_sampling--\u003esched_placement\n\tsched_placement--\u003esched_sbi\n\tsched_placement--\u003esched_coverage\n\tsched_placement--\u003esched_basicblock\n\tsched_placement--\u003esched_kerneltick\n\n\tgoal_fullsystem--\u003esched_kerneltick\n\tsched_kerneltick--\u003esched_kerneltick_details\n\n\n\t%% High-level Policy\n\tsched_sbi--\u003esched_policy\n\tsched_placement--\u003esched_policy\n\tsched_policy--\u003esched_window\n\tsched_policy--\u003esched_scaling\n\tsched_policy--\u003e|Command rerandomizations|paging_rerand\n\n\n\t%% Paging\n\tsol_rerand_paging[\"Soluion:\\nRerandomizing page management\\nfor full-CVM\"]:::paging\n\tpaging_rerand[\"Details: Rerandomization strategy\"]:::paging\n\tpaging_layout[\"Details: memory layout\"]:::paging\n\tpaging_activeregion[\"Active regions splited\\ninto (code,data,pt)\"]:::paging\n\tpaging_oram[\"ORAM-backed page pool\\nwith hardened stash\"]:::paging\n\tpaging_pagein[\"Page in/Page out\"]:::paging\n\tpaging_eviction[\"Details:\\nRerandomization through\\neviction\"]:::paging\n\n\t%% Paging edges\n\tsol_rerand_paging--\u003epaging_rerand\n\ttech_mmunative--\u003esol_rerand_paging\n\tpaging_rerand--\u003epaging_layout\n\tpaging_layout--\u003epaging_activeregion\n\tpaging_layout--\u003epaging_oram\n\tpaging_rerand--\u003epaging_eviction\n\tpaging_oram--\u003epaging_pagein\n\n\n\n    classDef overview fill:#f9f\n    classDef scheduling fill:lightblue\n    classDef paging fill:lightgreen\n    classDef related fill:pink\n```\n","wordCount":310,"tags":[],"metadata":{},"created":"2024-11-09T07:33:07.680789196Z","modified":"2024-11-09T07:11:08.863757311Z","checksum":"4c7fb6295ccfa8174a2458d9088c1ef754f486a15e8ebf52c765596a418c8e96"},
    {"filename":"2k46hfqc.md","filenameStem":"2k46hfqc","path":"2k46hfqc.md","absPath":"/home/khadd/mynotes/2k46hfqc.md","title":"Overview","link":"[[2k46hfqc]]","lead":"### Adaptive obfuscation: Why and what","body":"### Adaptive obfuscation: Why and what\n\n#### Motivations (Why)\n\n##### High exit rates of attacks\n\n- On the other hand, attacks have a very high exit rate, way above normal\n  scenarios.\n\n###### Empirical analysis\n\n- We show this aspect through an empirical analysis (table x)\n  - The collected numbers and why\n- How we did this analysis\n- The results show that the Exit rate may be clearly distinguished between\n  attack and normal execution.\n\n##### High overheads of obfuscation\n\n- Previous work proposed overly ideal attack models leading to high overheads\n- There are practical works that allow security tradeoffs.\n- We extend the practical direction by using the observed high vmexit rate to\n  guide the obfuscation scheme, which enables robustness without compromising\n  security.\n\n#### Our proposal: Rate-adaptive obfuscation (What)\n\n##### Overview of rate-adaptive obfuscation\n\n- We propose an approach that continuously monitors the trend in VMExit rate.\n- The continuous rate measurement is then used to dynamically scale a memory\n  re-randomization rate\n- A memory rerandomization scheme re-randomizes the memory layout of the CVM\n  according to the rate.\n\n##### Why the approach works\n\n- All side-channel attacks require one of two conditions:\n  - Need a minimum temporal resolution\n    - Example 1: Profiling attacks need full page memory access trace when\n      serving one SSH request\n    - Example 2: fine-grained side-channel attacks (cache) must be performed\n      with a specific window of 1\\~100 memory accesses when the sensitive\n      operation is performed.\n  - Have a maximum spatial resolution to be practical.\n    - E.g., performing a ciphertext attack is only practical if performed on a\n      limited number of pages. The overheads and costs of the attack scale\n      exponentially when more pages must be monitored.\n- Our approach works by providing the following two properties during attacks.\n\n###### Principle1: Adaptively minimizing the attacker's temporal resolution\n\n- With frequent rerandomization, the temporal resolution is continuously\n  minimized during attacks.\n  - A round memory rerandomization completely detaches previous side-channel\n    measurements from what is to come next.\n    - This means that the attacker may not carry the information learned from\n      one input (e.g., the CVM page acces frequency) to the next input, as there\n      will be multiple rerandomizations during one round of attack\n  - Even when you can somehow bypass profiling attacks, fine-grained attacks\n    have way higher exit rates, which leads to accelerated rerandomization,\n    throwing attacker back to the profiling before the attack is finished.\n- To overcome frequent randomization, the attacker must obtain more samples,\n  which in turn triggers more rerandomization.\n\n###### Principle2: Adaptively maximizing required spatial resolution (for fine-grained attacks)\n\n- Now that temporal resolution is limited, e.g., memory is essentially performed\n  every few accesses.\n- Memory rerandomization frequently relocates the memory to random different\n  addresses. Thus, it is infeasible just monitor memory accesses to a few pages.\n- This renders these attacks impractical.\n\n##### What is different from previous attempts\n\n- Previously, there were designs for\n  - Memory obfuscation using ORAM/software instrumentation,\n  - Detection of abnormal exit rates (Varys, TSGX)\n\n###### Limitation1 Detection-based approaches suffer from false-positive detections and have to reduce their detection threshold\n\n###### Limitation2 Previous \"static\" obfuscation scheme suffers from high overheads or have to make tradeoffs for practicality (Klotski)\n\n###### Advantage. Our approach overcomes the two limitations by combining the two approaches.\n\n- During normal execution, overheads are kept low, while intense randomization\n  is only during attacks.\n\n### Challenges\n\nTo enable this approach for CVM, two challenges must be solved.\n\n#### Challenge1 How do we build a sampling system that accurately determines exit rates?\n\n- VMxit detection: Unforgeable VMExit occurrence information in VMSA to\n  establish a primitive for in-CVM sampling of VMExits\n- First, a mechanism to periodically invoke VMSA sample collection without a\n  trustworthy interrupt delivery becomes indispensable.\n- Second, even if we do achieve such a periodic invocation, how do we build a\n  sampling system that can accurately determine the current VMExit rate?\n\n#### Challenge2 How do we design a robust rerandomization scaling based on exit rate measurement\n\n- Now, with accurate exit rate tracking, we must design a rerandomization\n  adaptation such that side-channel attacks are rendered much more difficult\n  while normal execution remains usable.\n\n#### Challenge3 How to we randomize memory layout now that the trust boundary contains the whole CVM (kenrel+user)\n\n- Previously, numerous proposals proposed memory randomization schemes (e.g.,\n  ORAM, Permutation, multiplexing), but we found them to be inadequate for whole\n  CVM memory randomization.\n\n##### Limitation3 Limited scalability\n\n- Previous attempts at all have limited scalability when large memory is used.\n  - Obfuscuro, shinde2016preventing, only supports small functions.\n  - DR SGX only reerandomizes data through random permutations, and rerandomize\n    and rerandomized at a at relaxed rate (every 300,000 memory accesses), but\n    still have\n  - Klotski Limits available memory use to 1GB (2^30)\n- This is not to mention these approaches implement a kind of \"SoftMMU\", which\n  would cause compatibility issues when the whole kernel is implemented.\n\n##### Limitation4 Require the application's source code to be available, or manual modifications.\n\n- They are inapplicable to third-party libraries or binary-only server programs.\n- Compiler-based solutions inevitably cause complications regarding software\n  maintenance; a response to a newly discovered attack vector or bugs in the the\n  solution itself requires the recompilation of all target programs.\n\n##### Limitation5 Limited applicability to the OS kernel\n\n- The existing works\\~\\\\cite{ahmad2019obfuscuro,obelix,zhang2020klotski} do not\n  address their applicability to the OS kernel.\n- A full system obfuscation (i.e., including the OS kernel) is crucial in\n  protecting CVM-based workloads.\n- However, a security guarantee through a custom compiler pass is hardly\n  feasible for kernels due to its peculiar programming patterns that involve\n  inline assemblies and complex preprocessor macros.\n- Moreover, the TCB of \\\\gls{cvm} application is significantly increased now\n  that it includes a full OS kernel. Even considering the size of\n  microVMs\\~\\\\cite{agache2020firecracker}, the total memory footprint is\n  magnitudes higher than workloads secured by the SGX userspace enclaves.\n\n## Solution overview\n\n- IncogniTOS is a unikernel for full-system obfuscation.\n- To enforce the adaptive memory obfuscation approach practically for CVM, it\n  retrofits two key OS components: Scheduler and page management\n\n### Goals\n\n#### Goal1: Full-system obfuscation(Challenge3)\n\n#### Goal2: Practicality through binary-only (Limitation4)\n\n- We use binary-comatible techniques to achieve this goal.\n\n#### Goal3: Limiting obfuscation overheads through adaptive obfuscation while retaining robustness during attacks (Challenges1,2)\n\n### Unikernel approach\n\n#### OS-level defense (Goal2)\n\n#### Unikernel (Goal1)\n\n- Unkernel small memory footprint and single-address-space\n- Direct hardware access renders MMU access efficient (used in our page\n  management scheme)\n- Lack of address space switching is also crucial for low-overhead synchronous\n  scheduling\n\n### Scheduling\n\n#### Novelty1: Replace scheduling driven by interrupts from untrusted hypervisor with synchronous tick delivery through binary instrumentation (Goal2,3).\n\n-\n\n#### Novelty2: Sliding window-rate and adaptive scaling policy enable low overheads during normal execution while quickly reacting to (Goal3)\n\n### Page management\n\n#### Novelty3: Our solution to enable practical full-system (Goal1) and binary-compatible (Goal2) memory randomization lies in the OS's ability to control memory address translation.\n\n- MMU access: Keep GVA the same, while only relocating GPA (Goal2)\n\n- Combination of ORAM and randomized active region is the most scalable option\n  (Limitation3)\n\n  - ORAM allows supprt of large amount of memory.\n  - Active region keeps the rerandomization operations to limited locations\n\n- Since ORAM obliviously brings pages into active regions, rerandomzation is\n  simply performed thorough active regions flushing,\n\n#### Novelty4: A requirement for full-system obfuscation (Goal1) is that the page table are also reerandomized","snippets":["### Adaptive obfuscation: Why and what"],"rawContent":"# Overview\n\n### Adaptive obfuscation: Why and what\n\n#### Motivations (Why)\n\n##### High exit rates of attacks\n\n- On the other hand, attacks have a very high exit rate, way above normal\n  scenarios.\n\n###### Empirical analysis\n\n- We show this aspect through an empirical analysis (table x)\n  - The collected numbers and why\n- How we did this analysis\n- The results show that the Exit rate may be clearly distinguished between\n  attack and normal execution.\n\n##### High overheads of obfuscation\n\n- Previous work proposed overly ideal attack models leading to high overheads\n- There are practical works that allow security tradeoffs.\n- We extend the practical direction by using the observed high vmexit rate to\n  guide the obfuscation scheme, which enables robustness without compromising\n  security.\n\n#### Our proposal: Rate-adaptive obfuscation (What)\n\n##### Overview of rate-adaptive obfuscation\n\n- We propose an approach that continuously monitors the trend in VMExit rate.\n- The continuous rate measurement is then used to dynamically scale a memory\n  re-randomization rate\n- A memory rerandomization scheme re-randomizes the memory layout of the CVM\n  according to the rate.\n\n##### Why the approach works\n\n- All side-channel attacks require one of two conditions:\n  - Need a minimum temporal resolution\n    - Example 1: Profiling attacks need full page memory access trace when\n      serving one SSH request\n    - Example 2: fine-grained side-channel attacks (cache) must be performed\n      with a specific window of 1\\~100 memory accesses when the sensitive\n      operation is performed.\n  - Have a maximum spatial resolution to be practical.\n    - E.g., performing a ciphertext attack is only practical if performed on a\n      limited number of pages. The overheads and costs of the attack scale\n      exponentially when more pages must be monitored.\n- Our approach works by providing the following two properties during attacks.\n\n###### Principle1: Adaptively minimizing the attacker's temporal resolution\n\n- With frequent rerandomization, the temporal resolution is continuously\n  minimized during attacks.\n  - A round memory rerandomization completely detaches previous side-channel\n    measurements from what is to come next.\n    - This means that the attacker may not carry the information learned from\n      one input (e.g., the CVM page acces frequency) to the next input, as there\n      will be multiple rerandomizations during one round of attack\n  - Even when you can somehow bypass profiling attacks, fine-grained attacks\n    have way higher exit rates, which leads to accelerated rerandomization,\n    throwing attacker back to the profiling before the attack is finished.\n- To overcome frequent randomization, the attacker must obtain more samples,\n  which in turn triggers more rerandomization.\n\n###### Principle2: Adaptively maximizing required spatial resolution (for fine-grained attacks)\n\n- Now that temporal resolution is limited, e.g., memory is essentially performed\n  every few accesses.\n- Memory rerandomization frequently relocates the memory to random different\n  addresses. Thus, it is infeasible just monitor memory accesses to a few pages.\n- This renders these attacks impractical.\n\n##### What is different from previous attempts\n\n- Previously, there were designs for\n  - Memory obfuscation using ORAM/software instrumentation,\n  - Detection of abnormal exit rates (Varys, TSGX)\n\n###### Limitation1 Detection-based approaches suffer from false-positive detections and have to reduce their detection threshold\n\n###### Limitation2 Previous \"static\" obfuscation scheme suffers from high overheads or have to make tradeoffs for practicality (Klotski)\n\n###### Advantage. Our approach overcomes the two limitations by combining the two approaches.\n\n- During normal execution, overheads are kept low, while intense randomization\n  is only during attacks.\n\n### Challenges\n\nTo enable this approach for CVM, two challenges must be solved.\n\n#### Challenge1 How do we build a sampling system that accurately determines exit rates?\n\n- VMxit detection: Unforgeable VMExit occurrence information in VMSA to\n  establish a primitive for in-CVM sampling of VMExits\n- First, a mechanism to periodically invoke VMSA sample collection without a\n  trustworthy interrupt delivery becomes indispensable.\n- Second, even if we do achieve such a periodic invocation, how do we build a\n  sampling system that can accurately determine the current VMExit rate?\n\n#### Challenge2 How do we design a robust rerandomization scaling based on exit rate measurement\n\n- Now, with accurate exit rate tracking, we must design a rerandomization\n  adaptation such that side-channel attacks are rendered much more difficult\n  while normal execution remains usable.\n\n#### Challenge3 How to we randomize memory layout now that the trust boundary contains the whole CVM (kenrel+user)\n\n- Previously, numerous proposals proposed memory randomization schemes (e.g.,\n  ORAM, Permutation, multiplexing), but we found them to be inadequate for whole\n  CVM memory randomization.\n\n##### Limitation3 Limited scalability\n\n- Previous attempts at all have limited scalability when large memory is used.\n  - Obfuscuro, shinde2016preventing, only supports small functions.\n  - DR SGX only reerandomizes data through random permutations, and rerandomize\n    and rerandomized at a at relaxed rate (every 300,000 memory accesses), but\n    still have\n  - Klotski Limits available memory use to 1GB (2^30)\n- This is not to mention these approaches implement a kind of \"SoftMMU\", which\n  would cause compatibility issues when the whole kernel is implemented.\n\n##### Limitation4 Require the application's source code to be available, or manual modifications.\n\n- They are inapplicable to third-party libraries or binary-only server programs.\n- Compiler-based solutions inevitably cause complications regarding software\n  maintenance; a response to a newly discovered attack vector or bugs in the the\n  solution itself requires the recompilation of all target programs.\n\n##### Limitation5 Limited applicability to the OS kernel\n\n- The existing works\\~\\\\cite{ahmad2019obfuscuro,obelix,zhang2020klotski} do not\n  address their applicability to the OS kernel.\n- A full system obfuscation (i.e., including the OS kernel) is crucial in\n  protecting CVM-based workloads.\n- However, a security guarantee through a custom compiler pass is hardly\n  feasible for kernels due to its peculiar programming patterns that involve\n  inline assemblies and complex preprocessor macros.\n- Moreover, the TCB of \\\\gls{cvm} application is significantly increased now\n  that it includes a full OS kernel. Even considering the size of\n  microVMs\\~\\\\cite{agache2020firecracker}, the total memory footprint is\n  magnitudes higher than workloads secured by the SGX userspace enclaves.\n\n## Solution overview\n\n- IncogniTOS is a unikernel for full-system obfuscation.\n- To enforce the adaptive memory obfuscation approach practically for CVM, it\n  retrofits two key OS components: Scheduler and page management\n\n### Goals\n\n#### Goal1: Full-system obfuscation(Challenge3)\n\n#### Goal2: Practicality through binary-only (Limitation4)\n\n- We use binary-comatible techniques to achieve this goal.\n\n#### Goal3: Limiting obfuscation overheads through adaptive obfuscation while retaining robustness during attacks (Challenges1,2)\n\n### Unikernel approach\n\n#### OS-level defense (Goal2)\n\n#### Unikernel (Goal1)\n\n- Unkernel small memory footprint and single-address-space\n- Direct hardware access renders MMU access efficient (used in our page\n  management scheme)\n- Lack of address space switching is also crucial for low-overhead synchronous\n  scheduling\n\n### Scheduling\n\n#### Novelty1: Replace scheduling driven by interrupts from untrusted hypervisor with synchronous tick delivery through binary instrumentation (Goal2,3).\n\n-\n\n#### Novelty2: Sliding window-rate and adaptive scaling policy enable low overheads during normal execution while quickly reacting to (Goal3)\n\n### Page management\n\n#### Novelty3: Our solution to enable practical full-system (Goal1) and binary-compatible (Goal2) memory randomization lies in the OS's ability to control memory address translation.\n\n- MMU access: Keep GVA the same, while only relocating GPA (Goal2)\n\n- Combination of ORAM and randomized active region is the most scalable option\n  (Limitation3)\n\n  - ORAM allows supprt of large amount of memory.\n  - Active region keeps the rerandomization operations to limited locations\n\n- Since ORAM obliviously brings pages into active regions, rerandomzation is\n  simply performed thorough active regions flushing,\n\n#### Novelty4: A requirement for full-system obfuscation (Goal1) is that the page table are also reerandomized\n","wordCount":1227,"tags":[],"metadata":{},"created":"2024-10-24T03:44:45.959663427Z","modified":"2024-10-24T07:45:46.536073878Z","checksum":"1fa8d50a404138d0adef3b717282ec9f6c775ab8c41b7254bac59e628d3d4f7f"},
    {"filename":"kclrv3h2.md","filenameStem":"kclrv3h2","path":"kclrv3h2.md","absPath":"/home/khadd/mynotes/kclrv3h2.md","title":"PAPER","link":"[[kclrv3h2]]","lead":"- Overview\n- Whole paper outline\n- Scheduling\n  - VMExit detection\n  - Instruction as time\n- Paging\n  - A\n- NPF on GPT:\n  - Leak vaddr","body":"- Overview\n- Whole paper outline\n- Scheduling\n  - VMExit detection\n  - Instruction as time\n- Paging\n  - A\n- NPF on GPT:\n  - Leak vaddr","snippets":["- Overview\n- Whole paper outline\n- Scheduling\n  - VMExit detection\n  - Instruction as time\n- Paging\n  - A\n- NPF on GPT:\n  - Leak vaddr"],"rawContent":"# PAPER\n\n- Overview\n- Whole paper outline\n- Scheduling\n  - VMExit detection\n  - Instruction as time\n- Paging\n  - A\n- NPF on GPT:\n  - Leak vaddr\n","wordCount":28,"tags":[],"metadata":{},"created":"2024-10-22T12:05:08.252714429Z","modified":"2024-10-22T12:20:15.507273432Z","checksum":"65036e2daab59dce38c7f2ec9a802416e4a3e33227f7470f9871972404792e6f"},
    {"filename":"iwu6p0mt.md","filenameStem":"iwu6p0mt","path":"iwu6p0mt.md","absPath":"/home/khadd/mynotes/iwu6p0mt.md","title":"PARA method","link":"[[iwu6p0mt]]","lead":"#organization","body":"#organization\n\nThe PARA method provide a framework to organize your information so that they\ncan be retrieved with less friction.\n\nThe core of PARA is to split your information into categories based how\n_actionable_ they are.\n\n```text\n ◄─────────────   Actionability    ───────────────►\n ┌─────────┐  ┌───────┐  ┌───────────┐  ┌──────────┐\n │ Project │  │ Areas │  │ Resources │  │ Archives │\n └─────────┘  └───────┘  └───────────┘  └──────────┘\n```\n\n- _Projects_ are usually a specific task with a deadline, e.g., writing a\n  thesis.\n- _Areas_ are long terms responsibilities that you wish to maintain, e.g., be a\n  better human.\n- _Resources_. This is not very clearly defined by the PARA system. Most\n  resources say they are topics of interests that you wish to keep for future\n  use.\n  - Interpretation: anything else that are not projects and areas.\n- _Archives_ is literally the trash can.\n\n## Relation to note-taking\n\n- Your notes should be always maintained, so they should be within the \"Area\"\n  category.\n- Tagging notes with #project is useful in quickly finding you projects.\n- I put #resources on content not produced by me, or collection of useful links.","snippets":["#organization"],"rawContent":"# PARA method\n\n#organization\n\nThe PARA method provide a framework to organize your information so that they\ncan be retrieved with less friction.\n\nThe core of PARA is to split your information into categories based how\n_actionable_ they are.\n\n```text\n ◄─────────────   Actionability    ───────────────►\n ┌─────────┐  ┌───────┐  ┌───────────┐  ┌──────────┐\n │ Project │  │ Areas │  │ Resources │  │ Archives │\n └─────────┘  └───────┘  └───────────┘  └──────────┘\n```\n\n- _Projects_ are usually a specific task with a deadline, e.g., writing a\n  thesis.\n- _Areas_ are long terms responsibilities that you wish to maintain, e.g., be a\n  better human.\n- _Resources_. This is not very clearly defined by the PARA system. Most\n  resources say they are topics of interests that you wish to keep for future\n  use.\n  - Interpretation: anything else that are not projects and areas.\n- _Archives_ is literally the trash can.\n\n## Relation to note-taking\n\n- Your notes should be always maintained, so they should be within the \"Area\"\n  category.\n- Tagging notes with #project is useful in quickly finding you projects.\n- I put #resources on content not produced by me, or collection of useful links.\n","wordCount":185,"tags":["project","resources","organization"],"metadata":{},"created":"2024-07-03T06:44:12.061244734Z","modified":"2024-12-12T08:01:12.229880331Z","checksum":"405f59aaccaca9c0a866b4ec4cca54a2b42bc4458b3d1ab8ead5a25876658fe2"},
    {"filename":"2it4soew.md","filenameStem":"2it4soew","path":"2it4soew.md","absPath":"/home/khadd/mynotes/2it4soew.md","title":"Packet Isolation","link":"[[2it4soew]]","lead":"NetBrick [@panda2016netbricks] discussed the property _packet isolation_ in the\ncontext of network functions (NF) [[szlwwqsj]]. Ideally you would want to only\npass the pointer to the packet between the NFs to avoid copying. However, this\nlead to a NF can modify the NF after it has been sent.","body":"NetBrick [@panda2016netbricks] discussed the property _packet isolation_ in the\ncontext of network functions (NF) [[szlwwqsj]]. Ideally you would want to only\npass the pointer to the packet between the NFs to avoid copying. However, this\nlead to a NF can modify the NF after it has been sent.\n\nIn NetBrick, the property is enforced through Rust ownership model [[4ea8wn6r]],\nwhere after the packet's is sent by the NF, Rust prevents further modifications\nto it. RedLeaf [@narayanan2020redleaf] enforces similar property for zero-copy\ndata transfer.","snippets":["NetBrick [@panda2016netbricks] discussed the property _packet isolation_ in the\ncontext of network functions (NF) [[szlwwqsj]]. Ideally you would want to only\npass the pointer to the packet between the NFs to avoid copying. However, this\nlead to a NF can modify the NF after it has been sent."],"rawContent":"# Packet Isolation\n\nNetBrick [@panda2016netbricks] discussed the property _packet isolation_ in the\ncontext of network functions (NF) [[szlwwqsj]]. Ideally you would want to only\npass the pointer to the packet between the NFs to avoid copying. However, this\nlead to a NF can modify the NF after it has been sent.\n\nIn NetBrick, the property is enforced through Rust ownership model [[4ea8wn6r]],\nwhere after the packet's is sent by the NF, Rust prevents further modifications\nto it. RedLeaf [@narayanan2020redleaf] enforces similar property for zero-copy\ndata transfer.\n","wordCount":86,"tags":[],"metadata":{},"created":"2024-12-23T04:22:27.58976133Z","modified":"2024-12-23T04:49:30.679035493Z","checksum":"db591cf2ddb3a3fd1e764e6522103bafad8c2f8c250b4faa5e97257ea5f0f929"},
    {"filename":"5kzr3hwx.md","filenameStem":"5kzr3hwx","path":"5kzr3hwx.md","absPath":"/home/khadd/mynotes/5kzr3hwx.md","title":"Page fault-based Side-channels Protection in SGX","link":"[[5kzr3hwx]]","lead":"#tee #sgx #side-channel","body":"#tee #sgx #side-channel\n\n# Comparision critera\n\n## Code \u0026 data\n\nSome work provides protection to only data accesses, while other protect both\ncode and data accesses.\n\n## Granularity\n\nPerfect trace, Cache-line, Page-level.\n\n# Obfuscated execution techniques\n\nThe first line of defense is obfuscated execution ([[n9bxzpge]]), which\nguarantees that code and data accesses of a program looks the same, given a\nsensitive input. They usually have high overheads and are considered\nimpractical.\n\n# Detecting page faults\n\nOne class of defense is to treat all possible page fault triggered by the OS as\nmalicious. This requires that the enclave pages are statically determined and\nmapped to enclave. Hence, demand paging is not possible in this model.\n\nMost of these defenses uses Intel TSX [[dx7vz8d5]], due to its ability to\nsupress page faults. For more details, see [[fvom56lw]].\n\nSince their introduction, there has been attacks that can leak secrets _without_\nexplicitly triggering page faults #cite-needed. Hence, these defenses are\nincomplete to today's standard.\n\n# Virtualizing Virtual Memory\n\nAnother category of defense is to replace all memory instructions of the enclave\n(through compiler instrumentation) with requests to a reference monitor that\nmake the actual request indistinguishable to attackers (e.g., using ORAM\nprimitives). They have stronger guarantees than\n\nFor instance, the following LLVM IR could be instruments as follows:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n\n---\n%1 = call oblivious_load(%arg1)\n%2 = add %1, 100\ncall obliviou_call(\u0026foo)\ncall oblivious_store(%2, %1)\n```\n\n## Obfuscuro\n\n## Klotski\n\n## CosMIX\n\n## Self-paging enclaves\n\nAnother way to hide page faults from the OS is to the enclave perform its own\npaging. Though, in SGX, this model is not possible without hardware extensions\n[@orenbach2020autarky], [@aga2019invisipage].\n\nThese defenses maintain a separated page table that is exclusively used to map\nEPC pages. This page table can only be updated by the trusted code inside the\nenclave.","snippets":["#tee #sgx #side-channel"],"rawContent":"# Page fault-based Side-channels Protection in SGX\n\n#tee #sgx #side-channel\n\n# Comparision critera\n\n## Code \u0026 data\n\nSome work provides protection to only data accesses, while other protect both\ncode and data accesses.\n\n## Granularity\n\nPerfect trace, Cache-line, Page-level.\n\n# Obfuscated execution techniques\n\nThe first line of defense is obfuscated execution ([[n9bxzpge]]), which\nguarantees that code and data accesses of a program looks the same, given a\nsensitive input. They usually have high overheads and are considered\nimpractical.\n\n# Detecting page faults\n\nOne class of defense is to treat all possible page fault triggered by the OS as\nmalicious. This requires that the enclave pages are statically determined and\nmapped to enclave. Hence, demand paging is not possible in this model.\n\nMost of these defenses uses Intel TSX [[dx7vz8d5]], due to its ability to\nsupress page faults. For more details, see [[fvom56lw]].\n\nSince their introduction, there has been attacks that can leak secrets _without_\nexplicitly triggering page faults #cite-needed. Hence, these defenses are\nincomplete to today's standard.\n\n# Virtualizing Virtual Memory\n\nAnother category of defense is to replace all memory instructions of the enclave\n(through compiler instrumentation) with requests to a reference monitor that\nmake the actual request indistinguishable to attackers (e.g., using ORAM\nprimitives). They have stronger guarantees than\n\nFor instance, the following LLVM IR could be instruments as follows:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n\n---\n%1 = call oblivious_load(%arg1)\n%2 = add %1, 100\ncall obliviou_call(\u0026foo)\ncall oblivious_store(%2, %1)\n```\n\n## Obfuscuro\n\n## Klotski\n\n## CosMIX\n\n## Self-paging enclaves\n\nAnother way to hide page faults from the OS is to the enclave perform its own\npaging. Though, in SGX, this model is not possible without hardware extensions\n[@orenbach2020autarky], [@aga2019invisipage].\n\nThese defenses maintain a separated page table that is exclusively used to map\nEPC pages. This page table can only be updated by the trusted code inside the\nenclave.\n","wordCount":326,"tags":["sgx","tee","side-channel","cite-needed"],"metadata":{},"created":"2023-06-19T03:04:24.876823985Z","modified":"2024-06-27T06:28:05.903686955Z","checksum":"cd79734925dda4fa3e2d595a3a4b22baf59d39b1cb9f8c9b294365381bfd71dd"},
    {"filename":"xpolyx1l.md","filenameStem":"xpolyx1l","path":"xpolyx1l.md","absPath":"/home/khadd/mynotes/xpolyx1l.md","title":"Paging in Unikraft (x86)","link":"[[xpolyx1l]]","lead":"#unikraft #os","body":"#unikraft #os\n\n## Enabling paging\n\nPaging is enabled with the configuration PAGING, enabled by setting Platform\nConfiguration → Platform Interface Option → Virtual memory API in\n`make menuconfig`.\n\n`PAGING` option affects `plat/kvm/x86/setup.c`, where `mem_init()` would call\n`init_paging()`. Then, `ukplat_pt_init` is called to initialize the page table.\n\nIt calls `pgarch_init()` to initialize architectural-dependent info, such as\nchecking 1 GiB pages support, PAT support.\n\n## Initializing paging\n\n### `kernel_pt`\n\nThis global struct stores info for the initialization time kernel page table.\n\nLater, a virtual address space (WAS) is created, which also points to this page\ntable.\n\n### `ukplat_bootinfo`\n\nAt build time, the linker prepares a `boot_info` structure. Boot info contains a\nlist of _physical_ memory regions (kernel image, uninitialized memory, ...).\n\n### `mem_init`\n\nThe function inserts the remaining memory from after the kernel image (after\n`__END`) to the remaining physical memory to the list of memory regions. This\nregion flag is `UKPLAT_MEMRF_UNMAP`, which means that these pages are unmapped\nfrom the kernel page table, and are only mapped on-demand.\n\n```c\nrc = ukplat_memregion_list_insert(\u0026bi-\u003emrds,\n  \u0026(struct ukplat_memregion_desc){\n.vbase = PAGE_ALIGN_UP(__END), .pbase = 0,\n    .len = PLATFORM_MAX_MEM_ADDR - PAGE_ALIGN_UP(__END), .type = 0,\n    .flags = UKPLAT_MEMRF_UNMAP,\n```\n\nIt then calls `paging_init`\n\n### `paging_init`\n\nThe function initializes the kernel's page table. On Linux, there is also the\nsame function, but the process is a bit different ([[cn9u3d79]]).\n\nFirst, it calls `ukplat_pt_init`, which initializes the page table facilities,\nusing a free memory region.\n\n1. `pgarch_init()` setup the CPU features\n2. `pgarch_pt_init` initialize the frame allocator and adds all physical memory\n   to it.\n\nAfter the page table\n\nFor every region with the flag `UKPLAT_MEMRF_UNMAP`, it unmaps them from the\npage table. Finally, it maps regions with the flag `UKPLAT_MEMRF_MAP` to memory.\n\n## `pgarch_pt_init`\n\nArchitectual-specific page table initialization is performed here. On X86, it\nreserves space for the frame allocator (`struct uk_falloc`), initializes the\nallocator, then adds the remaining physical memory to the frame allocator pool\nof memory.\n\n## Page fault handler\n\nThe page fault handler is defined separatedly as `do_page_fault` in\n`common/x86/traps.c`. It calls\n`rc = uk_raise_event(UKARCH_TRAP_PAGE_FAULT, \u0026ctx);` (more details is in\nevent.h).\n\nThe handler for this event is found in `ukvmem/arch/x86_64/pagefault.c`,\nregistered as\n\n```c\nUK_EVENT_HANDLER_PRIO(UKARCH_TRAP_PAGE_FAULT, vmem_arch_pagefault,\n                      CONFIG_LIBUKVMEM_PAGEFAULT_HANDLER_PRIO);\n```\n\nSee [[1k9i1cr3]] for more about Unikraft's interrupt handling.\n\nWith `ukvmem`, different page fault handlers can be registered for different\nVMAs. On a page fault. The VMA for the faulting address is looked up, then the\nVMA's registered page fault handler is called.\n\n## `ukvmem`\n\nukvmem enables APIs for virtual memory management. It creates Virtual Address\nSpaces (VAS), which contains smaller regions called Virtual Memory Areas (VMAs).\n\nThere are APIs that are required for paging that are defined here. For example,\nthe page fault handler above `vmem_arch_pagefault` would call `vmem_pagefault`\ndefined in `vmem.c`.\n\n`pg_page_mapx` (`paging.c`) performs the allocating of page table entries.\n\n## Page table entry\n\n`pg_page_mapx` sets the \"template\" as 0, which is set in the new PTE on a fault.\n\n## Related notes\n\n- [[cn9u3d79]]","snippets":["#unikraft #os"],"rawContent":"# Paging in Unikraft (x86)\n\n#unikraft #os\n\n## Enabling paging\n\nPaging is enabled with the configuration PAGING, enabled by setting Platform\nConfiguration → Platform Interface Option → Virtual memory API in\n`make menuconfig`.\n\n`PAGING` option affects `plat/kvm/x86/setup.c`, where `mem_init()` would call\n`init_paging()`. Then, `ukplat_pt_init` is called to initialize the page table.\n\nIt calls `pgarch_init()` to initialize architectural-dependent info, such as\nchecking 1 GiB pages support, PAT support.\n\n## Initializing paging\n\n### `kernel_pt`\n\nThis global struct stores info for the initialization time kernel page table.\n\nLater, a virtual address space (WAS) is created, which also points to this page\ntable.\n\n### `ukplat_bootinfo`\n\nAt build time, the linker prepares a `boot_info` structure. Boot info contains a\nlist of _physical_ memory regions (kernel image, uninitialized memory, ...).\n\n### `mem_init`\n\nThe function inserts the remaining memory from after the kernel image (after\n`__END`) to the remaining physical memory to the list of memory regions. This\nregion flag is `UKPLAT_MEMRF_UNMAP`, which means that these pages are unmapped\nfrom the kernel page table, and are only mapped on-demand.\n\n```c\nrc = ukplat_memregion_list_insert(\u0026bi-\u003emrds,\n  \u0026(struct ukplat_memregion_desc){\n.vbase = PAGE_ALIGN_UP(__END), .pbase = 0,\n    .len = PLATFORM_MAX_MEM_ADDR - PAGE_ALIGN_UP(__END), .type = 0,\n    .flags = UKPLAT_MEMRF_UNMAP,\n```\n\nIt then calls `paging_init`\n\n### `paging_init`\n\nThe function initializes the kernel's page table. On Linux, there is also the\nsame function, but the process is a bit different ([[cn9u3d79]]).\n\nFirst, it calls `ukplat_pt_init`, which initializes the page table facilities,\nusing a free memory region.\n\n1. `pgarch_init()` setup the CPU features\n2. `pgarch_pt_init` initialize the frame allocator and adds all physical memory\n   to it.\n\nAfter the page table\n\nFor every region with the flag `UKPLAT_MEMRF_UNMAP`, it unmaps them from the\npage table. Finally, it maps regions with the flag `UKPLAT_MEMRF_MAP` to memory.\n\n## `pgarch_pt_init`\n\nArchitectual-specific page table initialization is performed here. On X86, it\nreserves space for the frame allocator (`struct uk_falloc`), initializes the\nallocator, then adds the remaining physical memory to the frame allocator pool\nof memory.\n\n## Page fault handler\n\nThe page fault handler is defined separatedly as `do_page_fault` in\n`common/x86/traps.c`. It calls\n`rc = uk_raise_event(UKARCH_TRAP_PAGE_FAULT, \u0026ctx);` (more details is in\nevent.h).\n\nThe handler for this event is found in `ukvmem/arch/x86_64/pagefault.c`,\nregistered as\n\n```c\nUK_EVENT_HANDLER_PRIO(UKARCH_TRAP_PAGE_FAULT, vmem_arch_pagefault,\n                      CONFIG_LIBUKVMEM_PAGEFAULT_HANDLER_PRIO);\n```\n\nSee [[1k9i1cr3]] for more about Unikraft's interrupt handling.\n\nWith `ukvmem`, different page fault handlers can be registered for different\nVMAs. On a page fault. The VMA for the faulting address is looked up, then the\nVMA's registered page fault handler is called.\n\n## `ukvmem`\n\nukvmem enables APIs for virtual memory management. It creates Virtual Address\nSpaces (VAS), which contains smaller regions called Virtual Memory Areas (VMAs).\n\nThere are APIs that are required for paging that are defined here. For example,\nthe page fault handler above `vmem_arch_pagefault` would call `vmem_pagefault`\ndefined in `vmem.c`.\n\n`pg_page_mapx` (`paging.c`) performs the allocating of page table entries.\n\n## Page table entry\n\n`pg_page_mapx` sets the \"template\" as 0, which is set in the new PTE on a fault.\n\n## Related notes\n\n- [[cn9u3d79]]\n","wordCount":491,"tags":["os","unikraft"],"metadata":{},"created":"2023-07-03T02:43:48.502203262Z","modified":"2024-07-01T03:40:31.627810167Z","checksum":"4877f1db210025384ef631c28249801ce0a01d3c329029b7a65e721820e27c35"},
    {"filename":"enp3wxzj.md","filenameStem":"enp3wxzj","path":"enp3wxzj.md","absPath":"/home/khadd/mynotes/enp3wxzj.md","title":"Paging new outline","link":"[[enp3wxzj]]","lead":"# Memory randomization strategy","body":"# Memory randomization strategy\n\n- Its distinct management strategy does not change the actual GVA of the\n  program, but to reshuffle GPA and the page table mappings.\n- Constraint memory access to to GPA region active region that is continuously\n  rerandomized.\n- Goal is to completely after a rerandomization, GPA memory layout is\n  statistically independent from the new layout.\n- ORAM enable pages brought into the active region to reveal no information.\n\n- Thus, with just a simple full eviction, the new pages brought in becomes\n  randomized.","snippets":["# Memory randomization strategy"],"rawContent":"# Paging new outline\n\n# Memory randomization strategy\n\n- Its distinct management strategy does not change the actual GVA of the\n  program, but to reshuffle GPA and the page table mappings.\n- Constraint memory access to to GPA region active region that is continuously\n  rerandomized.\n- Goal is to completely after a rerandomization, GPA memory layout is\n  statistically independent from the new layout.\n- ORAM enable pages brought into the active region to reveal no information.\n\n- Thus, with just a simple full eviction, the new pages brought in becomes\n  randomized.\n","wordCount":91,"tags":[],"metadata":{},"created":"2024-11-09T07:33:07.677743363Z","modified":"2024-11-09T07:11:08.863757311Z","checksum":"4ad929137077a23a0559468e0ab08a6d4d52ecf1493f0bf5b360795a59158a69"},
    {"filename":"2lyiy9g5.md","filenameStem":"2lyiy9g5","path":"2lyiy9g5.md","absPath":"/home/khadd/mynotes/2lyiy9g5.md","title":"Paraverification","link":"[[2lyiy9g5]]","lead":"#virtualization","body":"#virtualization\n\nParaverfication is discussed by the InkTag [@inktag] system. The goals is to\n_ensure correct OS behavior_ with the least efforts. The approach is to let the\nOS do the work, then verify them later.\n\nThe OS must also participate in the verification. Here it sends the intent to\nhypervisor before doing the work.\n\nIndeed thanks to paraverification, additional the hypervisor are able to enforce\nadditional security properties, for example:\n\n- Additional access control on file systems\n- Consistency","snippets":["#virtualization"],"rawContent":"# Paraverification\n\n#virtualization\n\nParaverfication is discussed by the InkTag [@inktag] system. The goals is to\n_ensure correct OS behavior_ with the least efforts. The approach is to let the\nOS do the work, then verify them later.\n\nThe OS must also participate in the verification. Here it sends the intent to\nhypervisor before doing the work.\n\nIndeed thanks to paraverification, additional the hypervisor are able to enforce\nadditional security properties, for example:\n\n- Additional access control on file systems\n- Consistency\n","wordCount":81,"tags":["virtualization"],"metadata":{},"created":"2024-10-23T07:38:57.243636298Z","modified":"2024-12-24T07:05:39.282136947Z","checksum":"4c3678140339abeb0a8be94beafde76ca6ded26327b2b8045bf0e0f70ff31851"},
    {"filename":"pklz6mg0.md","filenameStem":"pklz6mg0","path":"pklz6mg0.md","absPath":"/home/khadd/mynotes/pklz6mg0.md","title":"Peephole trampoline optimization","link":"[[pklz6mg0]]","lead":"`e9patch` includes a \"peephole\" optimization for trampoline. It not only build\nthe trampoline with the target instruction, but also the surrounding\ninstructions up until the whole of the basic block from the entry until the next\ncontrol flow transfer is encountered. The instructions before the\ninstrumentation point are included in the prologue, and the instructions after\nare included in the epilogue.","body":"`e9patch` includes a \"peephole\" optimization for trampoline. It not only build\nthe trampoline with the target instruction, but also the surrounding\ninstructions up until the whole of the basic block from the entry until the next\ncontrol flow transfer is encountered. The instructions before the\ninstrumentation point are included in the prologue, and the instructions after\nare included in the epilogue.\n\n```asm\n        other trampolines can jump directly here ────────┐     ┌──────────────────────────────────────────────┐\n                                                         └────►│Trampoline prologue                           │\n                    ┌────────────────────────────┐             │    add   $0x70,%rsp                          │\n\t\t    │add    $0x70,%rsp           │   ┌────────►│    ... (trampoline init)                     │\nInstrumented ─────► │mov    %rbx,%rdi  ──────────│───┘         │mov    %rbx,%rdi // hoisted inst              │\ntarget   \t    │pop    %rbx                 │             │Trampoline epilogue:                          │\n\t            │jmp    20d0 \u003csyscall+0x10d0\u003e│             │    ... (trampoline deinit)                   │\n          \t    └────────────────────────────┘             │    pop    %rbx                               │\n                                                               │    jmp    {new offset} // jmp back is skipped│\n                                                               └──────────────────────────────────────────────┘\n\n\n\n```\n\nThis has two benefits.\n\n1. Other trampolines may directly jump to the new prologue without return to the\n   main code.\n2. With the epilogue, we cut one extra jump instruction used to transfer control\n   back to the main code.","snippets":["`e9patch` includes a \"peephole\" optimization for trampoline. It not only build\nthe trampoline with the target instruction, but also the surrounding\ninstructions up until the whole of the basic block from the entry until the next\ncontrol flow transfer is encountered. The instructions before the\ninstrumentation point are included in the prologue, and the instructions after\nare included in the epilogue."],"rawContent":"# Peephole trampoline optimization\n\n`e9patch` includes a \"peephole\" optimization for trampoline. It not only build\nthe trampoline with the target instruction, but also the surrounding\ninstructions up until the whole of the basic block from the entry until the next\ncontrol flow transfer is encountered. The instructions before the\ninstrumentation point are included in the prologue, and the instructions after\nare included in the epilogue.\n\n```asm\n        other trampolines can jump directly here ────────┐     ┌──────────────────────────────────────────────┐\n                                                         └────►│Trampoline prologue                           │\n                    ┌────────────────────────────┐             │    add   $0x70,%rsp                          │\n\t\t    │add    $0x70,%rsp           │   ┌────────►│    ... (trampoline init)                     │\nInstrumented ─────► │mov    %rbx,%rdi  ──────────│───┘         │mov    %rbx,%rdi // hoisted inst              │\ntarget   \t    │pop    %rbx                 │             │Trampoline epilogue:                          │\n\t            │jmp    20d0 \u003csyscall+0x10d0\u003e│             │    ... (trampoline deinit)                   │\n          \t    └────────────────────────────┘             │    pop    %rbx                               │\n                                                               │    jmp    {new offset} // jmp back is skipped│\n                                                               └──────────────────────────────────────────────┘\n\n\n\n```\n\nThis has two benefits.\n\n1. Other trampolines may directly jump to the new prologue without return to the\n   main code.\n2. With the epilogue, we cut one extra jump instruction used to transfer control\n   back to the main code.\n","wordCount":171,"tags":[],"metadata":{},"created":"2024-12-23T08:03:28.80747668Z","modified":"2024-12-23T08:03:49.138620019Z","checksum":"27fcc1b66dd9cd307b35483c7437a9ae015dd4f663c9f2d2d7e3e571344de05c"},
    {"filename":"uikxo3vi.md","filenameStem":"uikxo3vi","path":"uikxo3vi.md","absPath":"/home/khadd/mynotes/uikxo3vi.md","title":"Ploting terminologies","link":"[[uikxo3vi]]","lead":"\u003e I want to plot disconnected ranges in an axis.","body":"\u003e I want to plot disconnected ranges in an axis.\n\nThe type of is called a _Broken Axis_.\n\n\u003e I want to draw a window that zoom in selected ranges in the graph.\n\nTo implement this you need an _Inset_.\n\n\u003e I want to create two plots that is right next to each other (no space in\n\u003e between)\n\nThis is called a \"ganged plot\" or adjacent plot\n[ganged plot](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/ganged_plots.html)","snippets":["\u003e I want to plot disconnected ranges in an axis."],"rawContent":"# Ploting terminologies\n\n\u003e I want to plot disconnected ranges in an axis.\n\nThe type of is called a _Broken Axis_.\n\n\u003e I want to draw a window that zoom in selected ranges in the graph.\n\nTo implement this you need an _Inset_.\n\n\u003e I want to create two plots that is right next to each other (no space in\n\u003e between)\n\nThis is called a \"ganged plot\" or adjacent plot\n[ganged plot](https://matplotlib.org/stable/gallery/subplots_axes_and_figures/ganged_plots.html)\n","wordCount":73,"tags":[],"metadata":{},"created":"2024-09-25T03:27:07.797990613Z","modified":"2024-10-18T15:41:13.088910494Z","checksum":"154068df5aa6538fe9f7bc108f2758f30feeafee693719842d9b44dc9ca5c85d"},
    {"filename":"gcbyost1.md","filenameStem":"gcbyost1","path":"gcbyost1.md","absPath":"/home/khadd/mynotes/gcbyost1.md","title":"Polymorphism in C","link":"[[gcbyost1]]","lead":"#c #programming","body":"#c #programming\n\nWhile not officially supported, you can implement a kind of manual OOP in C by\nplaying with type casting and memory layout.\n\nTo _inherit_ a struct, you define another type with the inherited as the _first_\nmember. The children now have the same layout as the parent for begining\nobjects. This way, the children can safely cast as the parent.\n\n```c\nstruct parent {};\nstruct children {\n\tstruct parent parent;\n\tint a;\n\tint b;\n};\n\n```\n\nA parent object _polymorph_ into the children through `container_of` compiler\nmacro. This gives additional safety by type-checking if the two type can be\ncast.\n\n```c\nstruct children* c = container_of(parent, struct parent, parent);\n```\n\n## KVM example\n\nFor instance, the following can be seen in Linux KVM's source.\n\n```c\nstruct kvm_vcpu {\n  // KVM Generic virtual CPU definition that is architectural independent\n};\n\nstruct vcpu_svm {\n  struct kvm_vcpu vcpu;\n  // SVM-secific definitions of vcpu, e.g., VMSA and GHCB\n};\n\n// Generic x86 interface\nstatic struct kvm_x86_ops svm_x86_ops __initdata = {\n    //...\n    .vcpu_run = svm_vcpu_run,\n    // ...\n};\n\n//\nstatic __no_kcsan fastpath_t svm_vcpu_run(struct kvm_vcpu *vcpu) {\n  struct vcpu_svm *svm = to_svm(vcpu);\n  // SVM-specific implementation using vcpu_svm\n}\n```\n\nWith this pattern, a standard interface for virtualization can be implemented\nwith the `kvm_vcpu` as argument.","snippets":["#c #programming"],"rawContent":"# Polymorphism in C\n\n#c #programming\n\nWhile not officially supported, you can implement a kind of manual OOP in C by\nplaying with type casting and memory layout.\n\nTo _inherit_ a struct, you define another type with the inherited as the _first_\nmember. The children now have the same layout as the parent for begining\nobjects. This way, the children can safely cast as the parent.\n\n```c\nstruct parent {};\nstruct children {\n\tstruct parent parent;\n\tint a;\n\tint b;\n};\n\n```\n\nA parent object _polymorph_ into the children through `container_of` compiler\nmacro. This gives additional safety by type-checking if the two type can be\ncast.\n\n```c\nstruct children* c = container_of(parent, struct parent, parent);\n```\n\n## KVM example\n\nFor instance, the following can be seen in Linux KVM's source.\n\n```c\nstruct kvm_vcpu {\n  // KVM Generic virtual CPU definition that is architectural independent\n};\n\nstruct vcpu_svm {\n  struct kvm_vcpu vcpu;\n  // SVM-secific definitions of vcpu, e.g., VMSA and GHCB\n};\n\n// Generic x86 interface\nstatic struct kvm_x86_ops svm_x86_ops __initdata = {\n    //...\n    .vcpu_run = svm_vcpu_run,\n    // ...\n};\n\n//\nstatic __no_kcsan fastpath_t svm_vcpu_run(struct kvm_vcpu *vcpu) {\n  struct vcpu_svm *svm = to_svm(vcpu);\n  // SVM-specific implementation using vcpu_svm\n}\n```\n\nWith this pattern, a standard interface for virtualization can be implemented\nwith the `kvm_vcpu` as argument.\n","wordCount":215,"tags":["programming","c"],"metadata":{},"created":"2024-08-07T10:39:03.123564082Z","modified":"2024-08-08T04:32:21.313032053Z","checksum":"4e833ff5a15fa3d723462d30780a0103bb35c526d2ba4addaf14190c9635a2d1"},
    {"filename":"qg35n8yb.md","filenameStem":"qg35n8yb","path":"qg35n8yb.md","absPath":"/home/khadd/mynotes/qg35n8yb.md","title":"Porting C programs with macros","link":"[[qg35n8yb]]","lead":"#c #programming","body":"#c #programming\n\nMany times I have to port an existing C/C++ program from one platform/system. I\nfound C macros to be useful in such cases: you can replace APIs from one\nplatform to another, and also making change to the program behavior without\ntouching the code being ported (or just small modifications to the programs).\n\nFor example, you want to port the following function from Linux into Unikraft.\nFirst, you need to bring along the definitions from Linux: `kprobe`, `pt_regs`,\n`kprobe_ctlblk` and also all the called functions. Moving struct definition is\nsimple enough, just copying the files over.\n\n```c\nstatic int reenter_kprobe(struct kprobe *p, struct pt_regs *regs,\n                          struct kprobe_ctlblk *kcb) {\n  switch (kcb-\u003ekprobe_status) {\n  case KPROBE_HIT_SSDONE:\n  case KPROBE_HIT_ACTIVE:\n  case KPROBE_HIT_SS:\n    kprobes_inc_nmissed_count(p);\n    setup_singlestep(p, regs, kcb, 1);\n    break;\n  case KPROBE_REENTER:\n    pr_err(\"Unrecoverable kprobe detected.\\n\");\n    dump_kprobe(p);\n    BUG();\n  default:\n    /* impossible cases */\n    WARN_ON(1);\n    return 0;\n  }\n  return 1;\n}\n```\n\nAs there is no `pr_err`, `WARN_ON`, `BUG()` in Unikraft, one may (1) copy them\nover, or (2) replacing the use with Unikraft-provided ones, e.g., `pr_err`\n→`uk_pr_err`. (2) is more desirable as it reduce the amount of ported code.\n\nNow, while you can change the source code to achieve (2), a better way is to\njust override certain function calls with macros.\n\n```c\n#define pr_err uk_pr_err\n```\n\nAlso, it is useful to redefine integer types:\n\n```c\n#define u64 __u64\n#define u32 __u32\n#define u16 __u16\n#define u8 __u8\n```\n\nYou may also choose to completely ignore certain function / macro to avoid\nporting. For example, `__ro_after_init` is a feature in Linux:\n\n```c\nextern __ro_after_init unsigned long poking_addr;\n```\n\nTo ignore them:\n\n```c\n#define WARN_ON(x)\n#define __force // Ignoring certain macro used in kernel\n```","snippets":["#c #programming"],"rawContent":"# Porting C programs with macros\n\n#c #programming\n\nMany times I have to port an existing C/C++ program from one platform/system. I\nfound C macros to be useful in such cases: you can replace APIs from one\nplatform to another, and also making change to the program behavior without\ntouching the code being ported (or just small modifications to the programs).\n\nFor example, you want to port the following function from Linux into Unikraft.\nFirst, you need to bring along the definitions from Linux: `kprobe`, `pt_regs`,\n`kprobe_ctlblk` and also all the called functions. Moving struct definition is\nsimple enough, just copying the files over.\n\n```c\nstatic int reenter_kprobe(struct kprobe *p, struct pt_regs *regs,\n                          struct kprobe_ctlblk *kcb) {\n  switch (kcb-\u003ekprobe_status) {\n  case KPROBE_HIT_SSDONE:\n  case KPROBE_HIT_ACTIVE:\n  case KPROBE_HIT_SS:\n    kprobes_inc_nmissed_count(p);\n    setup_singlestep(p, regs, kcb, 1);\n    break;\n  case KPROBE_REENTER:\n    pr_err(\"Unrecoverable kprobe detected.\\n\");\n    dump_kprobe(p);\n    BUG();\n  default:\n    /* impossible cases */\n    WARN_ON(1);\n    return 0;\n  }\n  return 1;\n}\n```\n\nAs there is no `pr_err`, `WARN_ON`, `BUG()` in Unikraft, one may (1) copy them\nover, or (2) replacing the use with Unikraft-provided ones, e.g., `pr_err`\n→`uk_pr_err`. (2) is more desirable as it reduce the amount of ported code.\n\nNow, while you can change the source code to achieve (2), a better way is to\njust override certain function calls with macros.\n\n```c\n#define pr_err uk_pr_err\n```\n\nAlso, it is useful to redefine integer types:\n\n```c\n#define u64 __u64\n#define u32 __u32\n#define u16 __u16\n#define u8 __u8\n```\n\nYou may also choose to completely ignore certain function / macro to avoid\nporting. For example, `__ro_after_init` is a feature in Linux:\n\n```c\nextern __ro_after_init unsigned long poking_addr;\n```\n\nTo ignore them:\n\n```c\n#define WARN_ON(x)\n#define __force // Ignoring certain macro used in kernel\n```\n","wordCount":285,"tags":["programming","c"],"metadata":{},"created":"2024-06-26T11:16:09.019215866Z","modified":"2024-06-27T03:37:23.027590362Z","checksum":"57c27a2ae14dc0f8c777608318a6a953cecb74c5c830642e9a5a5713b107b41e"},
    {"filename":"mgz1zmm2.md","filenameStem":"mgz1zmm2","path":"mgz1zmm2.md","absPath":"/home/khadd/mynotes/mgz1zmm2.md","title":"Porting SEV to Unikraft","link":"[[mgz1zmm2]]","lead":"# Notes\n## 2023-08-15\n- Failed to open file \\EFI\\BOOT\\app-helloworld.cmdl, error: 9223372036854775822 \n- Probably need to add cmdl file to boot option\n- EFI kernel","body":"# Notes\n## 2023-08-15\n- Failed to open file \\EFI\\BOOT\\app-helloworld.cmdl, error: 9223372036854775822 \n- Probably need to add cmdl file to boot option\n- EFI kernel","snippets":["# Notes\n## 2023-08-15\n- Failed to open file \\EFI\\BOOT\\app-helloworld.cmdl, error: 9223372036854775822 \n- Probably need to add cmdl file to boot option\n- EFI kernel"],"rawContent":"# Porting SEV to Unikraft\n\n\n\n\n\n# Notes\n## 2023-08-15\n- Failed to open file \\EFI\\BOOT\\app-helloworld.cmdl, error: 9223372036854775822 \n- Probably need to add cmdl file to boot option\n- EFI kernel\n","wordCount":30,"tags":[],"metadata":{},"created":"2023-08-15T08:54:50.284558284Z","modified":"2024-05-20T11:00:29.301946541Z","checksum":"395e6bbebf9c8f70ea731cdb2fc76d7f14f7804e590788b15b46126864d39680"},
    {"filename":"xogiuia9.md","filenameStem":"xogiuia9","path":"xogiuia9.md","absPath":"/home/khadd/mynotes/xogiuia9.md","title":"Position map is a page table","link":"[[xogiuia9]]","lead":"#area #oram","body":"#area #oram\n\nThe position map ($PosMap$) of ORAM and the page table are very similar conceptually. They are both structures that *map* the location of a *logical address* into a *real address*.\n- The $PosMap$ maps an ORAM address $a$ to its corresponding leaf $l$  on the ORAM tree. To access $a$, the ORAM controller read the entire path root to leaf $l$ (for PathORAM) into the stash, and update $PosMap[a]$ to a random leaf.\n- The page table maps an address $a$ to a physical frame $p$. To access $a$, the MMU has to translate $a$ into a real physical address $p$, before sending the request to DRAM for data.\n\n*Hierarchy* is used in both cases to tackle the memory storage issue.\n- PosMap: The $PosMap$ itself is stored in another ORAM ($ORAM_{PosMap}$), where each block contains the translation for $X$ contiguous addresses. $ORAM_{PosMap}$ now only requires its $PosMap$ to map $N/X$ addresses. This can repeat multiple times (i.e., recursion happens). See [[wex0mob4]].\n\t- $leaf_{PosMap_{i-1}} \\gets ORAM_{PosMap_i}.access(leaf_{PosMap_i})$.\n- Page Table: A higher level $PT$ is created that maps the $X$ $PT$s for the lower level. To translate an address $a_{virtual}$, $PT_i$ is looked up using $a_{virtual}$ as the index (only bits in $a_{virtual}$ to be exact) which yields the address of $PT_{i-1}$.\n\t- $a_{PT_{i-1}} \\gets PT_i[a_{virtual}]$\n\nPT does not map every address. Does recursive PosMap need to map every block?\n- ORAM PosMap can also contain dummy blocks. So, if $a$ is not used by the ORAM, $ORAM_{data}[a]$ would contain a dummy block.\n\n# Literature\nThe observation is first found in FreecursiveORAM @fletcher2015freecursive, where they found that similar to the TLB, a similar structure could be implemented to cache the $PosMap$ translation to speed up ORAM accesses.\n\nLater works also make use of this similarity the other way around.\n- InvisiPage [@aga2019invisipage] encodes the value of the $PosMap$ inside the page table, when the PTE does not contain the physical address mapping. This saves space to store the $PosMap$, and since the PT is already consulted at each translation, the leaf value for an address $a$ is obtained without extra costs.\n- Klotski @zhang2020klotski implements a *virtual MMU* using a similar idea. The flat, virtual PT either contains a valid address within the cache (working memory) or encoding for ORAM access.","snippets":["#area #oram"],"rawContent":"# Position map is a page table\n#area #oram\n\nThe position map ($PosMap$) of ORAM and the page table are very similar conceptually. They are both structures that *map* the location of a *logical address* into a *real address*.\n- The $PosMap$ maps an ORAM address $a$ to its corresponding leaf $l$  on the ORAM tree. To access $a$, the ORAM controller read the entire path root to leaf $l$ (for PathORAM) into the stash, and update $PosMap[a]$ to a random leaf.\n- The page table maps an address $a$ to a physical frame $p$. To access $a$, the MMU has to translate $a$ into a real physical address $p$, before sending the request to DRAM for data.\n\n*Hierarchy* is used in both cases to tackle the memory storage issue.\n- PosMap: The $PosMap$ itself is stored in another ORAM ($ORAM_{PosMap}$), where each block contains the translation for $X$ contiguous addresses. $ORAM_{PosMap}$ now only requires its $PosMap$ to map $N/X$ addresses. This can repeat multiple times (i.e., recursion happens). See [[wex0mob4]].\n\t- $leaf_{PosMap_{i-1}} \\gets ORAM_{PosMap_i}.access(leaf_{PosMap_i})$.\n- Page Table: A higher level $PT$ is created that maps the $X$ $PT$s for the lower level. To translate an address $a_{virtual}$, $PT_i$ is looked up using $a_{virtual}$ as the index (only bits in $a_{virtual}$ to be exact) which yields the address of $PT_{i-1}$.\n\t- $a_{PT_{i-1}} \\gets PT_i[a_{virtual}]$\n\nPT does not map every address. Does recursive PosMap need to map every block?\n- ORAM PosMap can also contain dummy blocks. So, if $a$ is not used by the ORAM, $ORAM_{data}[a]$ would contain a dummy block.\n\n# Literature\nThe observation is first found in FreecursiveORAM @fletcher2015freecursive, where they found that similar to the TLB, a similar structure could be implemented to cache the $PosMap$ translation to speed up ORAM accesses.\n\nLater works also make use of this similarity the other way around.\n- InvisiPage [@aga2019invisipage] encodes the value of the $PosMap$ inside the page table, when the PTE does not contain the physical address mapping. This saves space to store the $PosMap$, and since the PT is already consulted at each translation, the leaf value for an address $a$ is obtained without extra costs.\n- Klotski @zhang2020klotski implements a *virtual MMU* using a similar idea. The flat, virtual PT either contains a valid address within the cache (working memory) or encoding for ORAM access.\n\n\n","wordCount":389,"tags":["oram","area"],"metadata":{},"created":"2024-05-22T08:24:03.309827295Z","modified":"2024-05-22T08:23:40.666608407Z","checksum":"35f8a8799cf0fb6f6690bf3bf74c678dc62fbb0b9a8d177917c5745bbb3b08fb"},
    {"filename":"0sk3p5q6.md","filenameStem":"0sk3p5q6","path":"0sk3p5q6.md","absPath":"/home/khadd/mynotes/0sk3p5q6.md","title":"Potential Postdoc Position","link":"[[0sk3p5q6]]","lead":"- [Secure Systems, Univ. of Waterloo, N. Asokan](https://asokan.org/asokan/research/SecureSystems-open-positions-Jul2021.php):\n  The home of Pac it up, PACStack\n- Cambridge: CHERI\n- [Dan Wiliams, Virginia Tech](https://people.cs.vt.edu/djwillia/): Works on OS\n  system call reduction, unikernels\n- [Nikos Vasilakis](https://nikos.vasilak.is/)\n- [Lin Zhong](https://linzhong.org/): OS / confidential computing research","body":"- [Secure Systems, Univ. of Waterloo, N. Asokan](https://asokan.org/asokan/research/SecureSystems-open-positions-Jul2021.php):\n  The home of Pac it up, PACStack\n- Cambridge: CHERI\n- [Dan Wiliams, Virginia Tech](https://people.cs.vt.edu/djwillia/): Works on OS\n  system call reduction, unikernels\n- [Nikos Vasilakis](https://nikos.vasilak.is/)\n- [Lin Zhong](https://linzhong.org/): OS / confidential computing research","snippets":["- [Secure Systems, Univ. of Waterloo, N. Asokan](https://asokan.org/asokan/research/SecureSystems-open-positions-Jul2021.php):\n  The home of Pac it up, PACStack\n- Cambridge: CHERI\n- [Dan Wiliams, Virginia Tech](https://people.cs.vt.edu/djwillia/): Works on OS\n  system call reduction, unikernels\n- [Nikos Vasilakis](https://nikos.vasilak.is/)\n- [Lin Zhong](https://linzhong.org/): OS / confidential computing research"],"rawContent":"# Potential Postdoc Position\n\n- [Secure Systems, Univ. of Waterloo, N. Asokan](https://asokan.org/asokan/research/SecureSystems-open-positions-Jul2021.php):\n  The home of Pac it up, PACStack\n- Cambridge: CHERI\n- [Dan Wiliams, Virginia Tech](https://people.cs.vt.edu/djwillia/): Works on OS\n  system call reduction, unikernels\n- [Nikos Vasilakis](https://nikos.vasilak.is/)\n- [Lin Zhong](https://linzhong.org/): OS / confidential computing research\n","wordCount":45,"tags":[],"metadata":{},"created":"2023-08-22T07:48:40.356007934Z","modified":"2024-12-10T07:00:32.819059143Z","checksum":"50b6663ea3f2d1ec5fee48ce4e329cc296709cbf9c8c85500a3829df21f548c4"},
    {"filename":"4zdjxws6.md","filenameStem":"4zdjxws6","path":"4zdjxws6.md","absPath":"/home/khadd/mynotes/4zdjxws6.md","title":"Practical Program Modularization with Type-Based Dependence Analysis","link":"[[4zdjxws6]]","lead":"#literature #analysis #compartmentalization","body":"#literature #analysis #compartmentalization\n\n[@lu2023practical]\n\n## Main arguments\n\nData-flow-based dependence analyses are impractical on large programs due to\nincorrect results and scalability issues, and A type-based dependence analysis\navoid data-flow analysis.\n\n- See [[dgdvhu1e]]\n- The proposed approach can handle multi-entry, multi-threaded programs, and\n  does not rely on points-to analysis.\n\nModule-aware type-based dependence analysis enables practical dependence\nanalysis.\n\n- If only the module boundaries are analyzed (function arguments and global\n  variables), the inner complexity of module is does not matter.\n- The proposed analysis only analyses the two types of typed-based data-flow,\n  through function arguments and through global variable.\n\nModule-based analysis and type-based analysis are complementary.\n\n- Module-aware analysis complement type-analysis:\n  - Previous type-only approaches @lu2019where are imprecise because they\n       scan the entire program for a particular type.\n  - There are modules in programs that has contain same types, but not\n       related at all\n  - The approach can further refine the CFI targets by using dependent module\n       information\n- Type-aware analysis improves module-aware analysis:\n  - A module-only analysis would be highly imprecise (only identifying if\n       module A can write into B), using the Type of argument further restrict\n       the data flow, making it an effective approach.\n\nThe proposed analysis is effective and sound (as a dependence analysis)\n\n- It is effective (in restricting data-flow) because it is difficult to form the\n  data flow between modules with a given type, and that there are also modules\n  between a module.\n- It is sound (as a dependence analysis), since the approach will catch all\n  cross-module data-flow if there is one.\n\nThe analysis improve upon existing security applications.\n\n- When used for indirect call target reduction, it have high reduction rate on\n  large application (up to 70% on firefox).\n- It identify 90% write instructions in linux as non-sensitive, which can be\n  enforced with techniques such as DFI, WIT. (No enforcement were tested).\n\n# Observation\n\nThere is only two type of data-flow between modules: through function\narguments/return values and through global variables\n\n# Type-based dependence analysis\n\nThe key idea is to perform type-based dependence analysis between modules (i.e.,\ncompilation unit). A _type-based dependence analysis_ determine if modules of\nthe programs may propagate the object of a certain types to a particular module.\n\nThe following types of dependencies are detected:\n\nDirect (through argument):\n\n- If M1 pass argument of type T1 to M2, there is direct data flow M1-\u003eM2.\n\nIndirect (through global)\n\n- If M1 write to global g type T, M2 read global type T, then there is data flow\n  M1-\u003eg-\u003eM2.\n\nTransitive:\n\n- There can be chaining of cross-module data flow, e.g., M1-\u003eM2-\u003eg-\u003eM3-\u003eM4\n\n# The analysis\n\nThe analysis takes a pair of type and module \u003ctype,module\u003e, and automatically\nall dependent modules. There are three main steps.\n\n- The first step collect castable types into a CastMap. This is to handle unsafe\n  casting operations in C/C++, all possible casted types are also considered in\n  the data flow.\n- The second step find out the direction and type of the data flow between two\n  particular modules and store it into a `FlowMap`. Finding out the direction\n  possible data flow ([[#direction]]).\n- The final step compute dependent modules and the dependent types.\n\nIt is also observe that type-based indirect calls can be further refined using\nmodule-awareness. The author use an iterative method to refine the indirect call\ntargets:\n\n- In first iteration, find dependent modules of an indirect call\n- Next, limit the type-based call target matching to only using the dependent\n  modules.\n- Repeat until no more refinement is made\n\n## Finding data flow direction\n\n[]{#direction}\n\nFor two modules $M$, $V$, and a use $U$ of type $T$:\n\n- If the use in $V$ is a _load_ LLVM instruction, then the direction is $M-\u003eV$.\n- If it is a $store$ instruction, then the direction is $V-\u003eM$.\n- If it is the GEP instruction, also analyze the use of the instruction\n- Else, it is bidirectional.\n\nOn struct types and pointer types, the types of the field is also analyzed. This\nis done through recursion on GEP instructions.\n\nThe result is stored in a structure called the $FlowMap$ that record Type,\nDirection of data flow between two modules.\n\n## Type elevation\n\n_Type elevation_ is also proposed to improve the precision. The idea is that\ninstead of using the type of the use site, which might have many false\npossitive, _elevate_ it to the type of the containing struct. For example, when\nan indirect call type $T1$ in a struct $T2$ is called, we first find the set of\ndependent modules using the type $T1$. Then, we find the dependent modules using\nthe struct type $T2$. Finally, we _intersect_ the two set to have a more refined\ndependent module set for the type $T1$.\n\nThis approach is unsound for container types (_base type_) that can be created\nfrom within the module, because cross-module data-flow will not find dependent\nmodule for those types. The paper suggests a simple _externality analysis_: If\nthe base type is ever assigned (through `store` and initilizers), it cannot be\nused for elevation.\n\nEssentially, it is just following chain of GEP instructions to get the outermost\ntype as the _base type_ (section 5)\n\n# Implementation notes\n\n## Type comparison\n\nThe authors found that type comparison in LLVM poses challenges:\n\n- Type may have different underlying memory objects so pointer comparison does\n  not work\n- The same struct type might have different variants, so string comparison may\n  not work.\n- Struct types may or may not have name.\n\n## Unions\n\nUnion types is handled by using the union type itself, instead of the\ninstantiated type. This hurts precision but guarantee soundness.","snippets":["#literature #analysis #compartmentalization"],"rawContent":"# Practical Program Modularization with Type-Based Dependence Analysis\n\n#literature #analysis #compartmentalization\n\n[@lu2023practical]\n\n## Main arguments\n\nData-flow-based dependence analyses are impractical on large programs due to\nincorrect results and scalability issues, and A type-based dependence analysis\navoid data-flow analysis.\n\n- See [[dgdvhu1e]]\n- The proposed approach can handle multi-entry, multi-threaded programs, and\n  does not rely on points-to analysis.\n\nModule-aware type-based dependence analysis enables practical dependence\nanalysis.\n\n- If only the module boundaries are analyzed (function arguments and global\n  variables), the inner complexity of module is does not matter.\n- The proposed analysis only analyses the two types of typed-based data-flow,\n  through function arguments and through global variable.\n\nModule-based analysis and type-based analysis are complementary.\n\n- Module-aware analysis complement type-analysis:\n  - Previous type-only approaches @lu2019where are imprecise because they\n       scan the entire program for a particular type.\n  - There are modules in programs that has contain same types, but not\n       related at all\n  - The approach can further refine the CFI targets by using dependent module\n       information\n- Type-aware analysis improves module-aware analysis:\n  - A module-only analysis would be highly imprecise (only identifying if\n       module A can write into B), using the Type of argument further restrict\n       the data flow, making it an effective approach.\n\nThe proposed analysis is effective and sound (as a dependence analysis)\n\n- It is effective (in restricting data-flow) because it is difficult to form the\n  data flow between modules with a given type, and that there are also modules\n  between a module.\n- It is sound (as a dependence analysis), since the approach will catch all\n  cross-module data-flow if there is one.\n\nThe analysis improve upon existing security applications.\n\n- When used for indirect call target reduction, it have high reduction rate on\n  large application (up to 70% on firefox).\n- It identify 90% write instructions in linux as non-sensitive, which can be\n  enforced with techniques such as DFI, WIT. (No enforcement were tested).\n\n# Observation\n\nThere is only two type of data-flow between modules: through function\narguments/return values and through global variables\n\n# Type-based dependence analysis\n\nThe key idea is to perform type-based dependence analysis between modules (i.e.,\ncompilation unit). A _type-based dependence analysis_ determine if modules of\nthe programs may propagate the object of a certain types to a particular module.\n\nThe following types of dependencies are detected:\n\nDirect (through argument):\n\n- If M1 pass argument of type T1 to M2, there is direct data flow M1-\u003eM2.\n\nIndirect (through global)\n\n- If M1 write to global g type T, M2 read global type T, then there is data flow\n  M1-\u003eg-\u003eM2.\n\nTransitive:\n\n- There can be chaining of cross-module data flow, e.g., M1-\u003eM2-\u003eg-\u003eM3-\u003eM4\n\n# The analysis\n\nThe analysis takes a pair of type and module \u003ctype,module\u003e, and automatically\nall dependent modules. There are three main steps.\n\n- The first step collect castable types into a CastMap. This is to handle unsafe\n  casting operations in C/C++, all possible casted types are also considered in\n  the data flow.\n- The second step find out the direction and type of the data flow between two\n  particular modules and store it into a `FlowMap`. Finding out the direction\n  possible data flow ([[#direction]]).\n- The final step compute dependent modules and the dependent types.\n\nIt is also observe that type-based indirect calls can be further refined using\nmodule-awareness. The author use an iterative method to refine the indirect call\ntargets:\n\n- In first iteration, find dependent modules of an indirect call\n- Next, limit the type-based call target matching to only using the dependent\n  modules.\n- Repeat until no more refinement is made\n\n## Finding data flow direction\n\n[]{#direction}\n\nFor two modules $M$, $V$, and a use $U$ of type $T$:\n\n- If the use in $V$ is a _load_ LLVM instruction, then the direction is $M-\u003eV$.\n- If it is a $store$ instruction, then the direction is $V-\u003eM$.\n- If it is the GEP instruction, also analyze the use of the instruction\n- Else, it is bidirectional.\n\nOn struct types and pointer types, the types of the field is also analyzed. This\nis done through recursion on GEP instructions.\n\nThe result is stored in a structure called the $FlowMap$ that record Type,\nDirection of data flow between two modules.\n\n## Type elevation\n\n_Type elevation_ is also proposed to improve the precision. The idea is that\ninstead of using the type of the use site, which might have many false\npossitive, _elevate_ it to the type of the containing struct. For example, when\nan indirect call type $T1$ in a struct $T2$ is called, we first find the set of\ndependent modules using the type $T1$. Then, we find the dependent modules using\nthe struct type $T2$. Finally, we _intersect_ the two set to have a more refined\ndependent module set for the type $T1$.\n\nThis approach is unsound for container types (_base type_) that can be created\nfrom within the module, because cross-module data-flow will not find dependent\nmodule for those types. The paper suggests a simple _externality analysis_: If\nthe base type is ever assigned (through `store` and initilizers), it cannot be\nused for elevation.\n\nEssentially, it is just following chain of GEP instructions to get the outermost\ntype as the _base type_ (section 5)\n\n# Implementation notes\n\n## Type comparison\n\nThe authors found that type comparison in LLVM poses challenges:\n\n- Type may have different underlying memory objects so pointer comparison does\n  not work\n- The same struct type might have different variants, so string comparison may\n  not work.\n- Struct types may or may not have name.\n\n## Unions\n\nUnion types is handled by using the union type itself, instead of the\ninstantiated type. This hurts precision but guarantee soundness.\n","wordCount":943,"tags":["literature","analysis","compartmentalization","direction"],"metadata":{},"created":"2024-05-22T08:24:03.231633797Z","modified":"2024-06-28T08:37:13.073840941Z","checksum":"8f13c2848491cd867f3fb42b5118e320b6a95308c6f071168e67bb5bf4570407"},
    {"filename":"README.md","filenameStem":"README","path":"presentations/README.md","absPath":"/home/khadd/mynotes/presentations/README.md","title":"Presentations","link":"[[presentations/README]]","lead":"These markdown slides uses marp","body":"These markdown slides uses marp","snippets":["These markdown slides uses marp"],"rawContent":"# Presentations\n\nThese markdown slides uses marp\n","wordCount":7,"tags":[],"metadata":{},"created":"2024-09-13T02:46:49.5110726Z","modified":"2024-09-14T10:44:24.520318927Z","checksum":"740fc3a1d5b77f4953b8d0decf0217b2ed646b80b6f10897845b9c58b3cb0df1"},
    {"filename":"lxm4bklm.md","filenameStem":"lxm4bklm","path":"lxm4bklm.md","absPath":"/home/khadd/mynotes/lxm4bklm.md","title":"Preventing Kernel Hacks with HAKC","link":"[[lxm4bklm]]","lead":"#literature #compartmentalization #os #pointer-authentication #mte","body":"#literature #compartmentalization #os #pointer-authentication #mte\n\n# Summary\n\nThe paper introduces a framework for complementing software called\nHardware-assisted Kernel Compartmentalization (HAKC). The goal is to divide code\nand data into partitions and enforce access control on data access and control\nflow between partitions. The hardware primitives assumed are PA and MTE.\n\nThe paper claims two main contributions, _Compartmentalization Policy_ and\n_Enforcement_ strategy.\n\nRegarding the Policy, a two-level partitioning scheme is proposed. At a high\nlevel, there are Cliques and Compartments. One compartment contains several\nCliques (at most 15 -- MTE number of tags). Two types of policies must be\ndefined by the programmer: Clique Access Policy (CAP) and Compartment Transition\nPolicy (CTP).\n\nCAP is defined per-Cliques. It define data and code from other Cliques, a clique\ncan access. The system enforce that a Clique's code and data accesses always\naccess memory (1) belong to its own compartment and (2) within its permissions.\n\nCTP allows a clique to transfer its control flow outside of the compartment. It\nspecify which other compartment's clique, a clique is able to call. When a\nclique transfer its control outside, data in the argument need to also be\nrecolored to the target.\n\nThe authors argue that such a two-level design enable several advantages:\n\n- First, it overcome the limited number of MTE tags, since all control/data flow\n  outside of the compartment must be explicitly validated.\n- Second, it enable local data optimization. More particular, within a clique,\n  the access control is more light-weight, while other heavy-weight checks and\n  data copies are left to the cross-comartment transitions.\n- Third, it allows fine-grained security boundaries, for performance-security\n  trade-off.\n\n## Enforcement\n\nUsing MTE, all pointer will be encoded with a tag (a.k.a., cojoined metadata\n(CM)), indicating which clique owns the underlying memory. HAKC's strategy is to\ncheck all pointer dereference, to enforce that the pointer access is in\naccordance with the specified policies (the memory belong to the current\ncompartment, and the current clique has the permission to access this data).\n\nAt runtime, a _candidate_ CM is computed to be compared with a pointer's CM. The\ncandiate CM is basically what the CM should looks like, given the current\nclique/compartment permissions.\n\nPAC is used to ensure that p\u003enter is not tamperedwith.\n\nMore particularly, in PA and MTE terms, every pointers is tagged with the\nclique's color. The pointer is then signed with a _signing token_ as the\nmodifier (which is the color of the owning clique _XOR_ the compartment ID).\nI.e., $Tok_{sign} = CompartmantmentID XOR (Pointer's tag)$. Later, when the\npointer is used, an _authentication token_ is reconstructed the pointer's tag\nand the permission bitmask $Tok_{acl}$. Or,\n$Tok_{aut} = CompartmantmentID XOR (Pointer's tag AND Tok_{acl})$.\n\nFor instance, if a pointer's tag is 3, its bitmask is $100$. A $Tok_{acl}$ of\n$111$ means that a clique is able to access cliques of color 1, 2 and 3.\nAssuming compartment ID is 2. Then, $Tok_{sign} = $5 XOR 100$ At the use site,\n$Tok_{aut} = $5 XOR (100 AND 111)$\n\nWhy is MTE/PAC is even needed?","snippets":["#literature #compartmentalization #os #pointer-authentication #mte"],"rawContent":"# Preventing Kernel Hacks with HAKC\n\n#literature #compartmentalization #os #pointer-authentication #mte\n\n# Summary\n\nThe paper introduces a framework for complementing software called\nHardware-assisted Kernel Compartmentalization (HAKC). The goal is to divide code\nand data into partitions and enforce access control on data access and control\nflow between partitions. The hardware primitives assumed are PA and MTE.\n\nThe paper claims two main contributions, _Compartmentalization Policy_ and\n_Enforcement_ strategy.\n\nRegarding the Policy, a two-level partitioning scheme is proposed. At a high\nlevel, there are Cliques and Compartments. One compartment contains several\nCliques (at most 15 -- MTE number of tags). Two types of policies must be\ndefined by the programmer: Clique Access Policy (CAP) and Compartment Transition\nPolicy (CTP).\n\nCAP is defined per-Cliques. It define data and code from other Cliques, a clique\ncan access. The system enforce that a Clique's code and data accesses always\naccess memory (1) belong to its own compartment and (2) within its permissions.\n\nCTP allows a clique to transfer its control flow outside of the compartment. It\nspecify which other compartment's clique, a clique is able to call. When a\nclique transfer its control outside, data in the argument need to also be\nrecolored to the target.\n\nThe authors argue that such a two-level design enable several advantages:\n\n- First, it overcome the limited number of MTE tags, since all control/data flow\n  outside of the compartment must be explicitly validated.\n- Second, it enable local data optimization. More particular, within a clique,\n  the access control is more light-weight, while other heavy-weight checks and\n  data copies are left to the cross-comartment transitions.\n- Third, it allows fine-grained security boundaries, for performance-security\n  trade-off.\n\n## Enforcement\n\nUsing MTE, all pointer will be encoded with a tag (a.k.a., cojoined metadata\n(CM)), indicating which clique owns the underlying memory. HAKC's strategy is to\ncheck all pointer dereference, to enforce that the pointer access is in\naccordance with the specified policies (the memory belong to the current\ncompartment, and the current clique has the permission to access this data).\n\nAt runtime, a _candidate_ CM is computed to be compared with a pointer's CM. The\ncandiate CM is basically what the CM should looks like, given the current\nclique/compartment permissions.\n\nPAC is used to ensure that p\u003enter is not tamperedwith.\n\nMore particularly, in PA and MTE terms, every pointers is tagged with the\nclique's color. The pointer is then signed with a _signing token_ as the\nmodifier (which is the color of the owning clique _XOR_ the compartment ID).\nI.e., $Tok_{sign} = CompartmantmentID XOR (Pointer's tag)$. Later, when the\npointer is used, an _authentication token_ is reconstructed the pointer's tag\nand the permission bitmask $Tok_{acl}$. Or,\n$Tok_{aut} = CompartmantmentID XOR (Pointer's tag AND Tok_{acl})$.\n\nFor instance, if a pointer's tag is 3, its bitmask is $100$. A $Tok_{acl}$ of\n$111$ means that a clique is able to access cliques of color 1, 2 and 3.\nAssuming compartment ID is 2. Then, $Tok_{sign} = $5 XOR 100$ At the use site,\n$Tok_{aut} = $5 XOR (100 AND 111)$\n\nWhy is MTE/PAC is even needed?\n","wordCount":510,"tags":["literature","os","compartmentalization","pointer-authentication","mte"],"metadata":{},"created":"2024-05-22T08:24:03.283498785Z","modified":"2024-11-22T05:20:04.13570815Z","checksum":"521fae9c9b438011e45727cb6e080cd1e7296415887d808c20d765164e525027"},
    {"filename":"inm0wq0q.md","filenameStem":"inm0wq0q","path":"inm0wq0q.md","absPath":"/home/khadd/mynotes/inm0wq0q.md","title":"Problem-solving by Debugging Almost-right Plans","link":"[[inm0wq0q]]","lead":"#problem-solving","body":"#problem-solving\n\nThe concept of problem-solving by debugging the almost-right plan is used in the\nfield of artificial intelligence to model \"skill learning\" to solve complex\nproblems. It is first discussed in the thesis of Gerald Sussman\n[@sussman1973computational] where an AI system called HACKER is proposed that\nautomatically improves its performance with practice, kind of similar to how\nmodern reinforcement learning works.","snippets":["#problem-solving"],"rawContent":"# Problem-solving by Debugging Almost-right Plans\n\n#problem-solving\n\nThe concept of problem-solving by debugging the almost-right plan is used in the\nfield of artificial intelligence to model \"skill learning\" to solve complex\nproblems. It is first discussed in the thesis of Gerald Sussman\n[@sussman1973computational] where an AI system called HACKER is proposed that\nautomatically improves its performance with practice, kind of similar to how\nmodern reinforcement learning works.\n","wordCount":67,"tags":["problem-solving"],"metadata":{},"created":"2024-07-24T05:11:42.236004727Z","modified":"2024-11-18T05:57:03.433292826Z","checksum":"612a7a28dc2db6a920144f9f6188e50ac0a69efc0712e2b315b25b7eefde0421"},
    {"filename":"2w43507r.md","filenameStem":"2w43507r","path":"2w43507r.md","absPath":"/home/khadd/mynotes/2w43507r.md","title":"Programmer Annotation is New Language Syntax","link":"[[2w43507r]]","lead":"#programming #c #programming-language","body":"#programming #c #programming-language\n\nSome research work for the C language requires the programmer's annotations\n[@gudka2015clean]. Essentially, adding program annotation is no different from\ncreating new C syntaxes on the flight. With C rich macro system, some common\nprogramming patterns may be defined in C, e.g., [[l56og3zt]].\n\nSome recent paper goes further and claim to invent new language extension, but\nin the end are just additional C macros [@khan2023ec].\n\nInventing new syntax is harder since it requires more considerations and have a\nwide impact.\n\nDesigning new annotations for C is easy, because they are optional and cam be\nenabled through a library.\n\nHowever, the C syntax is so barebone that almost always you are required to\ncreate some kind of language extensions though macros.","snippets":["#programming #c #programming-language"],"rawContent":"# Programmer Annotation is New Language Syntax\n\n#programming #c #programming-language\n\nSome research work for the C language requires the programmer's annotations\n[@gudka2015clean]. Essentially, adding program annotation is no different from\ncreating new C syntaxes on the flight. With C rich macro system, some common\nprogramming patterns may be defined in C, e.g., [[l56og3zt]].\n\nSome recent paper goes further and claim to invent new language extension, but\nin the end are just additional C macros [@khan2023ec].\n\nInventing new syntax is harder since it requires more considerations and have a\nwide impact.\n\nDesigning new annotations for C is easy, because they are optional and cam be\nenabled through a library.\n\nHowever, the C syntax is so barebone that almost always you are required to\ncreate some kind of language extensions though macros.\n","wordCount":130,"tags":["programming","c","programming-language"],"metadata":{},"created":"2023-08-11T05:58:24.108169946Z","modified":"2024-06-28T07:53:29.212200125Z","checksum":"db237c523d9b672e24f822e5c48e824e277e7487c4685649e54833dd187c97bf"},
    {"filename":"nx37h6lu.md","filenameStem":"nx37h6lu","path":"nx37h6lu.md","absPath":"/home/khadd/mynotes/nx37h6lu.md","title":"Programming paradigms and note taking","link":"[[nx37h6lu]]","lead":"#note-taking #programming","body":"#note-taking #programming\n\n## Inheritance and hierarchical notes\n\nObject-oriented programming revolve around inheritance, which inevitably leads\nto hierarchies. E.g., `animal -\u003e bird-like animals -\u003e duck `.\n\nNote-taking in this model maintain a note for each topic, where each new idea\nbecomes a sub-topic within this.\n\n- Operating system\n  - Process\n  - File systems\n  -\n\nSimilar to operating systems, where hierarchical layering limits flexibility\n[[c4icaua4]], these notes lack flexibility. That is, new ideas are harder to\nemerge.\n\n## Composition and atomic notes\n\nAnother programming paradigm is to prioritize composition to inheritance. In\nthis model, reusable components are abstracted into reusable traits, where\ncomplex objects would be composed of traits. E.g.,\n`duck =  quackable + simmable `\n\nSimilarly, atomic notes follow this idea.","snippets":["#note-taking #programming"],"rawContent":"# Programming paradigms and note taking\n\n#note-taking #programming\n\n## Inheritance and hierarchical notes\n\nObject-oriented programming revolve around inheritance, which inevitably leads\nto hierarchies. E.g., `animal -\u003e bird-like animals -\u003e duck `.\n\nNote-taking in this model maintain a note for each topic, where each new idea\nbecomes a sub-topic within this.\n\n- Operating system\n  - Process\n  - File systems\n  -\n\nSimilar to operating systems, where hierarchical layering limits flexibility\n[[c4icaua4]], these notes lack flexibility. That is, new ideas are harder to\nemerge.\n\n## Composition and atomic notes\n\nAnother programming paradigm is to prioritize composition to inheritance. In\nthis model, reusable components are abstracted into reusable traits, where\ncomplex objects would be composed of traits. E.g.,\n`duck =  quackable + simmable `\n\nSimilarly, atomic notes follow this idea.\n","wordCount":126,"tags":["programming","note-taking"],"metadata":{},"created":"2024-07-03T07:31:59.650944545Z","modified":"2024-07-03T07:46:13.523314368Z","checksum":"2ad0e232447cfc6bb57c27281691fa426fa97ca0a0701562677f9341bf30f006"},
    {"filename":"s16ct1rj.md","filenameStem":"s16ct1rj","path":"s16ct1rj.md","absPath":"/home/khadd/mynotes/s16ct1rj.md","title":"Properties of Virtualization","link":"[[s16ct1rj]]","lead":"#os #virtualization","body":"#os #virtualization\n\nVirtualization gives a subject (process, virtual machine) the illusion of having\naccess to physical resource (memory, CPU time).\n\nVirtualization is characterized through two properties, _interposition_ and\n_transparency_\n\n## Interposition\n\nWhile it is possible for the VMM to perform every operation of the virtualized\nsystem (as seen in legacy emulators), this is not desirable due to the high\noverheads. It is more reasonable to let certain performed execute natively (by\nthe CPU), while \"intercepting\" dangerous operations that overcome isolation.\nThis is the core principle in modern virtualization that enable fast and\nefficient virtualization.\n\nInterposition (aka, trap-and-emulate) let the reference monitor (OS/Hypervisor)\ninterject the control upon a certain action of the virtualized subject. For\ninstance, page faults allows the OS to interpose virtual to physical\ntranslation, and add missing page mapping on-demand.\n\nInterposition give the virtualized system the illusion of hardware access. The\nhypervisor can interpose hardware interrupts, page faults, VM enter and exit,\nand handle them in software (handling them in the actual hardware would affect\nthe entire system). This give the illusion to virtual machine have actual access\nto those hardware resources. See [[d3nt6uix]].\n\nInterposition is achieved commonly through three means.\n\n- Binary translation interprets every executed instruction and interpose on the\n  sensitive instructions (used in QEMU).\n- Para-virtualization requires patching the guest OS to delegate a certain\n  action to the hypervisor.\n- Interposition through hardware events forward the interrupts from the VM to\n  the hypervisor.\n\n## Transparency\n\nTransparency is another property that is desired, but not required, is\ntransparency. In a transparent virtualization, the virtualized subject does not\nhave knowledge it being virtualized.\n\nThis is beneficial in two aspects:\n\nFirst, there need no special adaptation in the machine being virtualized. This\nallows for quick migration of virtualized workloads between different machines.\n\nSecond, certain scenarios such as malware analysis, the program may use\nanti-virtualization techniques to avoid being reverse-engineered.","snippets":["#os #virtualization"],"rawContent":"# Properties of Virtualization\n\n#os #virtualization\n\nVirtualization gives a subject (process, virtual machine) the illusion of having\naccess to physical resource (memory, CPU time).\n\nVirtualization is characterized through two properties, _interposition_ and\n_transparency_\n\n## Interposition\n\nWhile it is possible for the VMM to perform every operation of the virtualized\nsystem (as seen in legacy emulators), this is not desirable due to the high\noverheads. It is more reasonable to let certain performed execute natively (by\nthe CPU), while \"intercepting\" dangerous operations that overcome isolation.\nThis is the core principle in modern virtualization that enable fast and\nefficient virtualization.\n\nInterposition (aka, trap-and-emulate) let the reference monitor (OS/Hypervisor)\ninterject the control upon a certain action of the virtualized subject. For\ninstance, page faults allows the OS to interpose virtual to physical\ntranslation, and add missing page mapping on-demand.\n\nInterposition give the virtualized system the illusion of hardware access. The\nhypervisor can interpose hardware interrupts, page faults, VM enter and exit,\nand handle them in software (handling them in the actual hardware would affect\nthe entire system). This give the illusion to virtual machine have actual access\nto those hardware resources. See [[d3nt6uix]].\n\nInterposition is achieved commonly through three means.\n\n- Binary translation interprets every executed instruction and interpose on the\n  sensitive instructions (used in QEMU).\n- Para-virtualization requires patching the guest OS to delegate a certain\n  action to the hypervisor.\n- Interposition through hardware events forward the interrupts from the VM to\n  the hypervisor.\n\n## Transparency\n\nTransparency is another property that is desired, but not required, is\ntransparency. In a transparent virtualization, the virtualized subject does not\nhave knowledge it being virtualized.\n\nThis is beneficial in two aspects:\n\nFirst, there need no special adaptation in the machine being virtualized. This\nallows for quick migration of virtualized workloads between different machines.\n\nSecond, certain scenarios such as malware analysis, the program may use\nanti-virtualization techniques to avoid being reverse-engineered.\n","wordCount":315,"tags":["os","virtualization"],"metadata":{},"created":"2023-05-24T06:39:32.992715982Z","modified":"2024-07-28T07:41:51.196606077Z","checksum":"90101eb640eebf46a829d7c73072429d2e7a01d07c9a4ac5930d5e5a8c1e2d8d"},
    {"filename":"013pr50f.md","filenameStem":"013pr50f","path":"013pr50f.md","absPath":"/home/khadd/mynotes/013pr50f.md","title":"Pure functions in Rust","link":"[[013pr50f]]","lead":"#rust #pure-function","body":"#rust #pure-function\n\nPure functions are a concept from functional programming languages that marks\nthat a function has no _side effect_. More concretely, in the D programming\nlanguage, Pure functions are functions that cannot access global variables, and\ncannot make changes to their arguments.\n\n[This issue](https://github.com/rust-lang/rfcs/issues/1631) discusses the\npossibility of adding pure function support in Rust a keyword (e.g.,\n`pure fn foo()`). Pure functions were eventually deemed not useful:\n\n- There are rarely any use cases for it, even in the D programming language.\n- There is no agreed-upon definition for pure functions.\n- Rust tried implementing this concept before but removed it.\n- Rust already has something similar to this concept as `const fn`. Those\n  functions can take runtime arguments, but cannot do anything related to\n  runtime execution.","snippets":["#rust #pure-function"],"rawContent":"# Pure functions in Rust\n\n#rust #pure-function\n\nPure functions are a concept from functional programming languages that marks\nthat a function has no _side effect_. More concretely, in the D programming\nlanguage, Pure functions are functions that cannot access global variables, and\ncannot make changes to their arguments.\n\n[This issue](https://github.com/rust-lang/rfcs/issues/1631) discusses the\npossibility of adding pure function support in Rust a keyword (e.g.,\n`pure fn foo()`). Pure functions were eventually deemed not useful:\n\n- There are rarely any use cases for it, even in the D programming language.\n- There is no agreed-upon definition for pure functions.\n- Rust tried implementing this concept before but removed it.\n- Rust already has something similar to this concept as `const fn`. Those\n  functions can take runtime arguments, but cannot do anything related to\n  runtime execution.\n","wordCount":133,"tags":["rust","pure-function"],"metadata":{},"created":"2023-06-15T02:58:33.89539734Z","modified":"2024-11-26T13:31:13.491799356Z","checksum":"b261003498b601b060ea3aa8251f8aa8f79a902b4d9b1429b0121f557406844b"},
    {"filename":"33eujif8.md","filenameStem":"33eujif8","path":"33eujif8.md","absPath":"/home/khadd/mynotes/33eujif8.md","title":"QEMU","link":"[[33eujif8]]","lead":"VM started with `qemu-system-*` has the PID of the qemu process itself","body":"VM started with `qemu-system-*` has the PID of the qemu process itself","snippets":["VM started with `qemu-system-*` has the PID of the qemu process itself"],"rawContent":"# QEMU\n\nVM started with `qemu-system-*` has the PID of the qemu process itself\n","wordCount":14,"tags":[],"metadata":{},"created":"2024-08-05T11:18:15.036598218Z","modified":"2024-08-06T04:39:33.885249494Z","checksum":"ef3b4135b26fa3beb62b317e562d22a431c01be31b2c140549ba31d113613ae2"},
    {"filename":"amyz6o6h.md","filenameStem":"amyz6o6h","path":"amyz6o6h.md","absPath":"/home/khadd/mynotes/amyz6o6h.md","title":"Quotation collection systems","link":"[[amyz6o6h]]","lead":"#writing #learning","body":"#writing #learning\n\nIt's impressive to see people pulling out relavant quotations of things they\nread that are insightful [[msjmb62t]]. In order to achieve this, a system for\nquotation tracking and management should be in place.\n\nThe most challenging part of quotes is to look for a relavant quotation from the\nknowledge base.\n\n## Classical approaches\n\n\u003chttps://www.youtube.com/watch?v=2HCmv6aDYbQ\u0026t=651s\u003e describes some ancient\npractice (since Renaissance) of keeping quotes.\n\n1. A [zibaldone](https://en.wikipedia.org/wiki/Zibaldone) maintains all quotes,\n   like a catch-all notebook of all quotes.\n2. Commonplace notebook [[lqni89fq]] categorize quotes based on categories\n   (commonplaces).\n\nThis may be implemented (roughly) in a ZK system by hoarding quotes torelated to\nrelavant concepts [[8v4evysc]].","snippets":["#writing #learning"],"rawContent":"# Quotation collection systems\n\n#writing #learning\n\nIt's impressive to see people pulling out relavant quotations of things they\nread that are insightful [[msjmb62t]]. In order to achieve this, a system for\nquotation tracking and management should be in place.\n\nThe most challenging part of quotes is to look for a relavant quotation from the\nknowledge base.\n\n## Classical approaches\n\n\u003chttps://www.youtube.com/watch?v=2HCmv6aDYbQ\u0026t=651s\u003e describes some ancient\npractice (since Renaissance) of keeping quotes.\n\n1. A [zibaldone](https://en.wikipedia.org/wiki/Zibaldone) maintains all quotes,\n   like a catch-all notebook of all quotes.\n2. Commonplace notebook [[lqni89fq]] categorize quotes based on categories\n   (commonplaces).\n\nThis may be implemented (roughly) in a ZK system by hoarding quotes torelated to\nrelavant concepts [[8v4evysc]].\n","wordCount":109,"tags":["learning","writing"],"metadata":{},"created":"2024-12-03T05:29:24.943854287Z","modified":"2024-12-10T02:14:33.657839106Z","checksum":"24d75076bacf8e6caa043d5c8085ebba755caa78d3706b951fe1f20f915f3330"},
    {"filename":"msjmb62t.md","filenameStem":"msjmb62t","path":"msjmb62t.md","absPath":"/home/khadd/mynotes/msjmb62t.md","title":"Quotes","link":"[[msjmb62t]]","lead":"A quote is useful in three aspect:","body":"A quote is useful in three aspect:\n\n1. Keeping for later. you may not be able to fully gasp the intentions and\n   insights behind a quote.\n2. Better representation. Sometimes you are not able to immediately come up with\n   a clean explanation of a particular idea.\n3. Credibility. Especially if the quote is from some well-known person. This is\n   immediately effective when making presentation / any form of writing to add\n   insights.","snippets":["A quote is useful in three aspect:"],"rawContent":"# Quotes\n\nA quote is useful in three aspect:\n\n1. Keeping for later. you may not be able to fully gasp the intentions and\n   insights behind a quote.\n2. Better representation. Sometimes you are not able to immediately come up with\n   a clean explanation of a particular idea.\n3. Credibility. Especially if the quote is from some well-known person. This is\n   immediately effective when making presentation / any form of writing to add\n   insights.\n","wordCount":74,"tags":[],"metadata":{},"created":"2024-12-03T05:40:27.951707891Z","modified":"2024-12-04T05:43:25.879860848Z","checksum":"89bec342c0433fce42c15557c12d95a71d3c48dc2c79fc10b8a7b454fb2f7eba"},
    {"filename":"7dzydfim.md","filenameStem":"7dzydfim","path":"7dzydfim.md","absPath":"/home/khadd/mynotes/7dzydfim.md","title":"RLBox Implementation","link":"[[7dzydfim]]","lead":"# Tainted type","body":"# Tainted type\n\nTainted types includes `tainted` and `tainted_volatile`.\n\nThey inherits from the base class `tained_base_impl`\n\n## Signature\n\n## Overriding\n\n### internal_factory\n\n`internal_factory` is used to create new tainted values from the result of\noperators. Why is it \"internal?\" because it is only used internally. Sometimes\nvalues are created from pointers, which is considered dangerous. I guess they\nenforce that only `allocate_in_sandbox` can create pointers or something.\n\n### BinaryOpValAndPtr\n\ni.e., Binary operators for values and pointers. These include + and -.\n`tainted\u003cT, T_Sbx\u003e + T_Rhs -\u003e tainted\u003cT, T_Sbx\u003e`\n\nIf T is ptr (ptr + ptr or ptr + value):\n\n1. T must not be null\n2. Perform the operation\n3. Check if the result is within the sandbox. This check is sandbox-dependent\n4. call `internal_factory` on the result to create a new `tainted` value.\n\n## BinaryOp\n\nBinaryOp contains the remaining binary operations only performed on primitive\ntypes\n\n## Dereference\n\n```cpp\nprivate:\n using T_OpDerefRet = tainted_volatile\u003cstd::remove_pointer_t\u003cT\u003e, T_Sbx\u003e;\n\npublic:\n  inline T_OpDerefRet\u0026 operator*() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e, \"Operator * only allowed on pointers\");\n    auto ret_ptr_const =\n      reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n    // Safe - If T_OpDerefRet is not a const ptr, this is trivially safe\n    //        If T_OpDerefRet is a const ptr, then the const is captured\n    //        inside the wrapper\n    auto ret_ptr = const_cast\u003cT_OpDerefRet*\u003e(ret_ptr_const);\n    return *ret_ptr;\n  }\n\n  // We need to implement the -\u003e operator even if T is not a struct\n  // So that we can support code patterns such as the below\n  // tainted\u003cT*\u003e a;\n  // a-\u003eUNSAFE_unverified();\n  inline const T_OpDerefRet* operator-\u003e() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e,\n                  \"Operator -\u003e only supported for pointer types\");\n    return reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n  }\n```","snippets":["# Tainted type"],"rawContent":"# RLBox Implementation\n\n# Tainted type\n\nTainted types includes `tainted` and `tainted_volatile`.\n\nThey inherits from the base class `tained_base_impl`\n\n## Signature\n\n## Overriding\n\n### internal_factory\n\n`internal_factory` is used to create new tainted values from the result of\noperators. Why is it \"internal?\" because it is only used internally. Sometimes\nvalues are created from pointers, which is considered dangerous. I guess they\nenforce that only `allocate_in_sandbox` can create pointers or something.\n\n### BinaryOpValAndPtr\n\ni.e., Binary operators for values and pointers. These include + and -.\n`tainted\u003cT, T_Sbx\u003e + T_Rhs -\u003e tainted\u003cT, T_Sbx\u003e`\n\nIf T is ptr (ptr + ptr or ptr + value):\n\n1. T must not be null\n2. Perform the operation\n3. Check if the result is within the sandbox. This check is sandbox-dependent\n4. call `internal_factory` on the result to create a new `tainted` value.\n\n## BinaryOp\n\nBinaryOp contains the remaining binary operations only performed on primitive\ntypes\n\n## Dereference\n\n```cpp\nprivate:\n using T_OpDerefRet = tainted_volatile\u003cstd::remove_pointer_t\u003cT\u003e, T_Sbx\u003e;\n\npublic:\n  inline T_OpDerefRet\u0026 operator*() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e, \"Operator * only allowed on pointers\");\n    auto ret_ptr_const =\n      reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n    // Safe - If T_OpDerefRet is not a const ptr, this is trivially safe\n    //        If T_OpDerefRet is a const ptr, then the const is captured\n    //        inside the wrapper\n    auto ret_ptr = const_cast\u003cT_OpDerefRet*\u003e(ret_ptr_const);\n    return *ret_ptr;\n  }\n\n  // We need to implement the -\u003e operator even if T is not a struct\n  // So that we can support code patterns such as the below\n  // tainted\u003cT*\u003e a;\n  // a-\u003eUNSAFE_unverified();\n  inline const T_OpDerefRet* operator-\u003e() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e,\n                  \"Operator -\u003e only supported for pointer types\");\n    return reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n  }\n```\n","wordCount":265,"tags":[],"metadata":{},"created":"2024-12-23T08:03:12.672662609Z","modified":"2024-12-23T08:03:15.025152146Z","checksum":"a1bdd3ea614052f544f52f903631d4274eaa9b633edc660da383ccdf73f28bfd"},
    {"filename":"pp1xznyl.md","filenameStem":"pp1xznyl","path":"pp1xznyl.md","absPath":"/home/khadd/mynotes/pp1xznyl.md","title":"Rationale of descriptor table (virtio)","link":"[[pp1xznyl]]","lead":"#virtualization #io","body":"#virtualization #io\n\nIn virtio, the descriptor table contains information about buffers used for I/O,\nis a separated entity from the available and used rings (split virtqueue\nscenario). This is different from traditional NIC devices [@turtles], where the\ndescriptor is inlined within the rings themselves.\n\nThe answer from the original paper [@russell2008virtio] is not so \"obvious\" at\nall:\n\n\u003e The separation of the descriptors from the available ring is due to the\n\u003e asynchronous nature of the virtqueue: the available ring may circle many times\n\u003e with fast-serviced descriptors while slow descriptors might still await\n\u003e completion. This is obviously useful for implementing block devices, but also\n\u003e turns out to be useful for zero-copy networking.\n\nThe above explanation contains two parts: (1) asynchronism is useful for\nimplementing block devices, and (2) useful for zero-copy networking.\n\n## Asynchronous I/O for block devices\n\nFor block devices like hard drives, different I/O operations might have\ndifferent time to complete. For example, reading from a cached file is fast,\nwhile reading from the disk would take much longer time.\n\nSeparating descriptor table (chaining of buffers) and the virtqueue (descriptor\nchains to be processed) allow entries in the virtqueue to be asynchronously.\n\n- Fast descriptors may be serviced immediately and move on the next, i.e.,\n  circling the virtqueue\n- Slow descriptors that require waiting, would not block other fast descriptors\n- A descriptor may be immediately reused after their processing is done\n\nWithout descriptor table, slow descriptor would block the processing:\n\n```txt\nAvailable Ring:\n[Desc1 -\u003e Desc2 -\u003e Desc3 -\u003e Desc4]\n```\n\nNow with a separated descriptor table, requests are serviced asynchronously:\n\n```txt\nAvailable Ring: [Operation1, Operation2, Operation3, Operation4]\n                     ↓          ↓          ↓          ↓\nDescriptors:    [Desc1]     [Desc2]     [Desc3]     [Desc4]\n```\n\nThis is contrast to traditional NIC devices that inline the descriptor to the\ndata rings [@turtles], so packets are to be processed one-by-one by increasing\nthe ring buffer pointer.\n\n## Zero-copy networking\n\nThe reason it may be useful for zero-copy networking _seems to be_ that when the\nrings are filled up, the network buffer must be copied to another place.","snippets":["#virtualization #io"],"rawContent":"# Rationale of descriptor table (virtio)\n\n#virtualization #io\n\nIn virtio, the descriptor table contains information about buffers used for I/O,\nis a separated entity from the available and used rings (split virtqueue\nscenario). This is different from traditional NIC devices [@turtles], where the\ndescriptor is inlined within the rings themselves.\n\nThe answer from the original paper [@russell2008virtio] is not so \"obvious\" at\nall:\n\n\u003e The separation of the descriptors from the available ring is due to the\n\u003e asynchronous nature of the virtqueue: the available ring may circle many times\n\u003e with fast-serviced descriptors while slow descriptors might still await\n\u003e completion. This is obviously useful for implementing block devices, but also\n\u003e turns out to be useful for zero-copy networking.\n\nThe above explanation contains two parts: (1) asynchronism is useful for\nimplementing block devices, and (2) useful for zero-copy networking.\n\n## Asynchronous I/O for block devices\n\nFor block devices like hard drives, different I/O operations might have\ndifferent time to complete. For example, reading from a cached file is fast,\nwhile reading from the disk would take much longer time.\n\nSeparating descriptor table (chaining of buffers) and the virtqueue (descriptor\nchains to be processed) allow entries in the virtqueue to be asynchronously.\n\n- Fast descriptors may be serviced immediately and move on the next, i.e.,\n  circling the virtqueue\n- Slow descriptors that require waiting, would not block other fast descriptors\n- A descriptor may be immediately reused after their processing is done\n\nWithout descriptor table, slow descriptor would block the processing:\n\n```txt\nAvailable Ring:\n[Desc1 -\u003e Desc2 -\u003e Desc3 -\u003e Desc4]\n```\n\nNow with a separated descriptor table, requests are serviced asynchronously:\n\n```txt\nAvailable Ring: [Operation1, Operation2, Operation3, Operation4]\n                     ↓          ↓          ↓          ↓\nDescriptors:    [Desc1]     [Desc2]     [Desc3]     [Desc4]\n```\n\nThis is contrast to traditional NIC devices that inline the descriptor to the\ndata rings [@turtles], so packets are to be processed one-by-one by increasing\nthe ring buffer pointer.\n\n## Zero-copy networking\n\nThe reason it may be useful for zero-copy networking _seems to be_ that when the\nrings are filled up, the network buffer must be copied to another place.\n","wordCount":350,"tags":["virtualization","io"],"metadata":{},"created":"2024-12-10T08:35:07.674221089Z","modified":"2024-12-10T10:24:44.545718879Z","checksum":"870d3c1d43f048ff914531223d04b2b75d9b3af545f05ffea216f639c6520c9d"},
    {"filename":"k0wjwjhg.md","filenameStem":"k0wjwjhg","path":"k0wjwjhg.md","absPath":"/home/khadd/mynotes/k0wjwjhg.md","title":"Reading in passes","link":"[[k0wjwjhg]]","lead":"#reading #learning #zettelkasten","body":"#reading #learning #zettelkasten\n\nAn article/paper/book should be read in multiple passes. The point is to\nmaximize the time efficiency when reading. This is similar to how compiler\npasses works.\n\n## The three passes\n\nTaken from [@keshav2007how]\n\n### First pass\n\nIt is also important to remember the [[b740rhio]], so spend more time on the\nbeginning and the end of the section.\n\nChecklist:\n\n- [ ] What are the related papers\n- [ ] Main contributions of this paper\n\n### Second pass\n\nChecklist:\n\n- [ ] Summarize main technical details of the paper\n- [ ] Understand the ideas\n- [ ] Give evidences for the claims\n\n### Synthesis\n\nChecklist:\n\n- [ ] With the same assumptions of the authors, recreate the work\n- [ ] Reconstruct the structure of the paper from memory.\n- [ ] Identify strong and weak points.\n- [ ] Identify implicit assumptions.","snippets":["#reading #learning #zettelkasten"],"rawContent":"# Reading in passes\n\n#reading #learning #zettelkasten\n\nAn article/paper/book should be read in multiple passes. The point is to\nmaximize the time efficiency when reading. This is similar to how compiler\npasses works.\n\n## The three passes\n\nTaken from [@keshav2007how]\n\n### First pass\n\nIt is also important to remember the [[b740rhio]], so spend more time on the\nbeginning and the end of the section.\n\nChecklist:\n\n- [ ] What are the related papers\n- [ ] Main contributions of this paper\n\n### Second pass\n\nChecklist:\n\n- [ ] Summarize main technical details of the paper\n- [ ] Understand the ideas\n- [ ] Give evidences for the claims\n\n### Synthesis\n\nChecklist:\n\n- [ ] With the same assumptions of the authors, recreate the work\n- [ ] Reconstruct the structure of the paper from memory.\n- [ ] Identify strong and weak points.\n- [ ] Identify implicit assumptions.\n","wordCount":150,"tags":["zettelkasten","reading","learning"],"metadata":{},"created":"2023-05-05T06:32:39.659000588Z","modified":"2024-06-28T08:32:30.799271047Z","checksum":"2dd78865953b64c3de884575784525811690bcae1c7451fcfa3c4c76c03558cd"},
    {"filename":"2cy5uaeo.md","filenameStem":"2cy5uaeo","path":"2cy5uaeo.md","absPath":"/home/khadd/mynotes/2cy5uaeo.md","title":"Real-time TEE","link":"[[2cy5uaeo]]","lead":"#realtime #tee","body":"#realtime #tee\n\nAvailability is usually not the concern for current TEEs, whose focuses is on\nconfidentiality and integrity. However, in certain safety-critical system such\nas drones, availability is also important.\n\nChallenges in bringing availability into TEEs is to minimize the TCB-sizes.\nReal-time OSes require complex scheduler designs that maintain real-time\nconstraints. Another issue is maintaining availability of I/O while there is\nuntrusted OS.\n\nRT-TEE [@wang2022rttee] introduces a real-time-aware TEE on ARM trustzone that\naims to to minimize TCB.","snippets":["#realtime #tee"],"rawContent":"# Real-time TEE\n\n#realtime #tee\n\nAvailability is usually not the concern for current TEEs, whose focuses is on\nconfidentiality and integrity. However, in certain safety-critical system such\nas drones, availability is also important.\n\nChallenges in bringing availability into TEEs is to minimize the TCB-sizes.\nReal-time OSes require complex scheduler designs that maintain real-time\nconstraints. Another issue is maintaining availability of I/O while there is\nuntrusted OS.\n\nRT-TEE [@wang2022rttee] introduces a real-time-aware TEE on ARM trustzone that\naims to to minimize TCB.\n","wordCount":81,"tags":["tee","realtime"],"metadata":{},"created":"2024-06-17T06:46:46.680072759Z","modified":"2024-06-17T06:54:55.713176484Z","checksum":"9516217ae6691b12c39affbb9df4f30b9c84d4e30e245d279a0d6e331763eec4"},
    {"filename":"wex0mob4.md","filenameStem":"wex0mob4","path":"wex0mob4.md","absPath":"/home/khadd/mynotes/wex0mob4.md","title":"Recursion in ORAM","link":"[[wex0mob4]]","lead":"#area #oram","body":"#area #oram\n\n## Recursion\n\nIn ORAM, the recursion technique helps reduce the client storage for the\nposition map by storing them inside smaller ORAMs in hierarchical order. The\nhigher-level ORAM needs to store less data than the lower-level ones to fit the\nhighest-level ORAM into the client storage. ORAM at level $i$ would contain the\nposition map data for ORAM at level $i-1$, and ORAM at level 0 is the actual\ndata ORAM.\n\nLet's say 1 level of recursion is used. The $PosMap$ itself is stored in another\nORAM ($ORAM_{PosMap}$), where each block contains the translation for $X$\ncontiguous addresses. $ORAM_{PosMap}$ now only requires its $PosMap$\n($PosMap_{PosMap}$) to map $N/X$ addresses. Data is still stored in the original\nORAM ($ORAM_{Data}$).\n\nTo request the leaf of a block address $a_0$, the ORAM controller must look up\n$PosMap_{PosMap}$ that is stored in the client. To put simply:\n$leaf_{PosMap} \\gets PosMap_{PosMap}[a_0]$\n$block_{PosMap} \\gets ORAM_{PosMap}.access(leaf_{PosMap})$\n$leaf_{Data} \\gets block_{PosMap}[a_0]$\n$block_{ORAM} \\gets ORAM_{Data}.access(leaf_{Data})$\n\n## Ambiguity\n\nPapers that mention recursion in Path ORAM often describe it very ambiguously\n(e.g., described by previous works). They make it seems like only one pass of\naccess through the hierarchy is needed. E.g., you only need to get the leaf of\nthe current address through recursion. For example,\n\u003chttps://people.csail.mit.edu/devadas/pubs/PathORam.pdf\u003e says that you just have\nto replace lines 1-2 with ORAM $access$. @fletcher2015freecursive mentioned\nnothing of how to get the leafs of stash blocks.\n\nHowever, actually, recursion must be performed on _all_ position map accesses\nfor any addresses. In ORAM, there are actually two places where position map is\naccessed, at the start of the access to remap the current block (line 1-2), and\non eviction, when choosing for blocks to evict (line 11).\n\nIt is easier to see the \"recursion\" happening, by imagining position map as a\nclass that expose a `get` function\n([see this](https://github.com/epsolute/path-oram/blob/master/path-oram/src/position-map-adapter.cpp)),\nwhere all access must be done through this accessor. When recursion is active,\nthe map function is implemented as an ORAM access:\n\n```cpp\nint ORAM::access(int id){\n int leaf = this.PosMap.get(id);\n}\n\nint PosMap.get(int id){\n this.ORAM.access(int id); /* Goes on to call this.posmap.get */\n}\n```\n\nWith this in mind, it is easier to imagine the \"recursion\" happening,\n`PosMap.get` calls `ORAM.access`, which would calls `PosMap.get` and so on.\n\n_NOTE_: Another method to avoid performing an ORAM access on line 11 is to store\nthe path information _along_ with the data block. This way, where the block is\nactually mapped to is known when it is fetched with the block. Maybe recursive\nORAM papers _assume_ this, so they don't consider eviction as a PosMap access.","snippets":["#area #oram"],"rawContent":"# Recursion in ORAM\n\n#area #oram\n\n## Recursion\n\nIn ORAM, the recursion technique helps reduce the client storage for the\nposition map by storing them inside smaller ORAMs in hierarchical order. The\nhigher-level ORAM needs to store less data than the lower-level ones to fit the\nhighest-level ORAM into the client storage. ORAM at level $i$ would contain the\nposition map data for ORAM at level $i-1$, and ORAM at level 0 is the actual\ndata ORAM.\n\nLet's say 1 level of recursion is used. The $PosMap$ itself is stored in another\nORAM ($ORAM_{PosMap}$), where each block contains the translation for $X$\ncontiguous addresses. $ORAM_{PosMap}$ now only requires its $PosMap$\n($PosMap_{PosMap}$) to map $N/X$ addresses. Data is still stored in the original\nORAM ($ORAM_{Data}$).\n\nTo request the leaf of a block address $a_0$, the ORAM controller must look up\n$PosMap_{PosMap}$ that is stored in the client. To put simply:\n$leaf_{PosMap} \\gets PosMap_{PosMap}[a_0]$\n$block_{PosMap} \\gets ORAM_{PosMap}.access(leaf_{PosMap})$\n$leaf_{Data} \\gets block_{PosMap}[a_0]$\n$block_{ORAM} \\gets ORAM_{Data}.access(leaf_{Data})$\n\n## Ambiguity\n\nPapers that mention recursion in Path ORAM often describe it very ambiguously\n(e.g., described by previous works). They make it seems like only one pass of\naccess through the hierarchy is needed. E.g., you only need to get the leaf of\nthe current address through recursion. For example,\n\u003chttps://people.csail.mit.edu/devadas/pubs/PathORam.pdf\u003e says that you just have\nto replace lines 1-2 with ORAM $access$. @fletcher2015freecursive mentioned\nnothing of how to get the leafs of stash blocks.\n\nHowever, actually, recursion must be performed on _all_ position map accesses\nfor any addresses. In ORAM, there are actually two places where position map is\naccessed, at the start of the access to remap the current block (line 1-2), and\non eviction, when choosing for blocks to evict (line 11).\n\nIt is easier to see the \"recursion\" happening, by imagining position map as a\nclass that expose a `get` function\n([see this](https://github.com/epsolute/path-oram/blob/master/path-oram/src/position-map-adapter.cpp)),\nwhere all access must be done through this accessor. When recursion is active,\nthe map function is implemented as an ORAM access:\n\n```cpp\nint ORAM::access(int id){\n int leaf = this.PosMap.get(id);\n}\n\nint PosMap.get(int id){\n this.ORAM.access(int id); /* Goes on to call this.posmap.get */\n}\n```\n\nWith this in mind, it is easier to imagine the \"recursion\" happening,\n`PosMap.get` calls `ORAM.access`, which would calls `PosMap.get` and so on.\n\n_NOTE_: Another method to avoid performing an ORAM access on line 11 is to store\nthe path information _along_ with the data block. This way, where the block is\nactually mapped to is known when it is fetched with the block. Maybe recursive\nORAM papers _assume_ this, so they don't consider eviction as a PosMap access.\n","wordCount":431,"tags":["oram","area"],"metadata":{},"created":"2024-05-22T08:24:03.307619963Z","modified":"2024-07-12T10:36:03.870333334Z","checksum":"8c892ed7cacec66a4cf0e1486a90217f3632e28b047bb4e080be1195bce590a7"},
    {"filename":"2dw6pwrd.md","filenameStem":"2dw6pwrd","path":"2dw6pwrd.md","absPath":"/home/khadd/mynotes/2dw6pwrd.md","title":"Research Ideas","link":"[[2dw6pwrd]]","lead":"#research","body":"#research\n\n- [[douswvq0]]\n\n- Carat Cake @suchy2022carat propose getting rid of paging, and use software\n  instrumentation to provide OS-like abstractions. Capacity may be adaptable to\n  this.\n- Light-weight capabilities and their applications","snippets":["#research"],"rawContent":"# Research Ideas\n\n#research\n\n- [[douswvq0]]\n\n- Carat Cake @suchy2022carat propose getting rid of paging, and use software\n  instrumentation to provide OS-like abstractions. Capacity may be adaptable to\n  this.\n- Light-weight capabilities and their applications\n","wordCount":35,"tags":["research"],"metadata":{},"created":"2023-05-22T02:06:14.447571155Z","modified":"2024-07-28T07:41:51.193272729Z","checksum":"343b994393fee2849a63438c1e0678787ac1f4123d06c5839ef78915597e6e14"},
    {"filename":"8ep2tsil.md","filenameStem":"8ep2tsil","path":"8ep2tsil.md","absPath":"/home/khadd/mynotes/8ep2tsil.md","title":"Research Log","link":"[[8ep2tsil]]","lead":"# 2024-11-06","body":"# 2024-11-06\n\nLIBVFSCORE_CFLAGS-$(CONFIG_OBLIVIUM_SCHED_KERNEL_TICKS) +=\n-finstrument-functions-once\n\n- instrument ramfs + vfscore\n- lwip instrumentation\n\n- problem: boot vcpu cannot access its own VMSA (VMPL0).\n- -\u003e must launch\n\n1. boot VCPU allocate a new VMSA page\n2. make the VMSA private and also initialize the states (e.g., )\n3. request\n\n# 08/11/2024\n\n- Each round of rerandomization disrupts the chain of side-channel attacks.\n\n# Security Eval\n\nagaisnt different side-channel attacks.\n\n## RQ1 : Is \\thename scheduling scheme effective in regulaing rerandomization rate\n\n- Accuracy of VMExit sampling and Promptness of rerandomization rate escalation\n- We track the actual exit, the measured rate using window\n\n- Accuracy of vmexit sampling:\n\n  - The results show that the scheduler can closely track the trend in VMExit.\n  - Note, rate measured from sliding window is different from the actual exit\n    rate (about 5 times less), due to siding window measurement effect.\n  - Maximum sampled rate is about XXX, which maximizes when the acutal VMExit\n    rate is between L4 and L5.\n\n- Rerandomization rate escalation\n  - As shown in figure, rerandomization rate stay about the same during normal\n    I/O (L2), and quickly raised during attacks.\n\n## RQ2: Can \\thename avoid false-positive with its grace period?\n\nWe perform tests on normal workloads (same as previous. Observe no termination\non normal workloads, while the attack scenarios quickly terminate the VM.\n\n## RQ3: what is the effect of rate-adaptive rerandomization on realworld attacks.\n\n- We repeat 2 attacks and confirm that (1) a lot of rerandomization are\n  performed (high exit rate), and (2) it add significant noises to the attacks\n  to the point of unrecognizable.\n\n# Impact of rate adaptive\n\n## Inversion of attacker's sampling rate and attacker's advantage\n\n\u003e Key idea: More VMExit normally means more samples or higher resolution but, it\n\u003e is inverted in our design.\n\n- Most attacks have a minimum length of undisrupted trace that must be\n  accumulated to be useful, and \\thename adaptive scheme prevents this\n  accumulation.\n\n  - This is because they must maintain consistently abnormally high rate\n  - Must also avoid termination due to grace period\n\n- Adaptive rerandomization appropriately to react to all types of attacks to\n  inverse their temporal resolution:\n\n  - Coarse-grained provide less temporal resolution and require making more\n    samples; Fine-grained require provide finer temporal resolution -\u003e less\n    samples, but significantly increase VMExit rate.\n\n- Attempts to subvert rerandomization, like tracking pages movement, requires\n  making more sampling, but ultimately lead to more rerandomizations\n\n## Disruption of attack phases\n\n- Stage 1 + Stage 2 description, previous attacks ...\n- We mitigate both stages simultaneously when (Klotski -\u003e focuses on 1st stage,\n  Varys -\u003e 2nd)\n- Attack is reset (attacker must repeat everything) if rerandomization is\n  performed in between, which is very likely.\n\n## Passive attacks\n\n- Passive attacks monitor the access bit in the NPT without triggering an\n  explicit exit.\n\n- Still, it is also very difficult due to the normal rerand rate.\n-\n- Some passive attack improves the temporal resolution with timer interrupt but\n  it would lead to more errands (as discussed before.)\n\n# Active region size vs. ciphertext discussion\n\n- Active region size has an impact on ciphertext attacks by increasing entropy\n  of page locations.\n\n- Alternatives:\n\n  - Salting is too expensive\n  - Infinite amount of pages\n  - Still, this is only SEV SNP issue (much harder to perform on TDX,CCA), and\n    maybe it will fixed in future releases\n\n- We currently use 8192 pages but can increase the size of active regions to add\n  more entropy.\n\n- Alternatives:\n\n  - Salting is too expensive\n\n  - Infinite amount of pages\n\n  - Still, this is only SEV SNP issue (much harder to perform on TDX,CCA), and\n    maybe fixed in future releases\n\n- We currently use 8192 pages, but can increase the size of active region to add\n  more entropy.\n\n- If havee space: Box plot that show overlap\n- Highest we can measure\n- Std wings of\n- Must be shown in figuree (paging)\n  - should be High level\n  - Show GVA GPA HPA\n  - Some actions like PAge-in-out, ORAM","snippets":["# 2024-11-06"],"rawContent":"# Research Log\n\n# 2024-11-06\n\nLIBVFSCORE_CFLAGS-$(CONFIG_OBLIVIUM_SCHED_KERNEL_TICKS) +=\n-finstrument-functions-once\n\n- instrument ramfs + vfscore\n- lwip instrumentation\n\n- problem: boot vcpu cannot access its own VMSA (VMPL0).\n- -\u003e must launch\n\n1. boot VCPU allocate a new VMSA page\n2. make the VMSA private and also initialize the states (e.g., )\n3. request\n\n# 08/11/2024\n\n- Each round of rerandomization disrupts the chain of side-channel attacks.\n\n# Security Eval\n\nagaisnt different side-channel attacks.\n\n## RQ1 : Is \\thename scheduling scheme effective in regulaing rerandomization rate\n\n- Accuracy of VMExit sampling and Promptness of rerandomization rate escalation\n- We track the actual exit, the measured rate using window\n\n- Accuracy of vmexit sampling:\n\n  - The results show that the scheduler can closely track the trend in VMExit.\n  - Note, rate measured from sliding window is different from the actual exit\n    rate (about 5 times less), due to siding window measurement effect.\n  - Maximum sampled rate is about XXX, which maximizes when the acutal VMExit\n    rate is between L4 and L5.\n\n- Rerandomization rate escalation\n  - As shown in figure, rerandomization rate stay about the same during normal\n    I/O (L2), and quickly raised during attacks.\n\n## RQ2: Can \\thename avoid false-positive with its grace period?\n\nWe perform tests on normal workloads (same as previous. Observe no termination\non normal workloads, while the attack scenarios quickly terminate the VM.\n\n## RQ3: what is the effect of rate-adaptive rerandomization on realworld attacks.\n\n- We repeat 2 attacks and confirm that (1) a lot of rerandomization are\n  performed (high exit rate), and (2) it add significant noises to the attacks\n  to the point of unrecognizable.\n\n# Impact of rate adaptive\n\n## Inversion of attacker's sampling rate and attacker's advantage\n\n\u003e Key idea: More VMExit normally means more samples or higher resolution but, it\n\u003e is inverted in our design.\n\n- Most attacks have a minimum length of undisrupted trace that must be\n  accumulated to be useful, and \\thename adaptive scheme prevents this\n  accumulation.\n\n  - This is because they must maintain consistently abnormally high rate\n  - Must also avoid termination due to grace period\n\n- Adaptive rerandomization appropriately to react to all types of attacks to\n  inverse their temporal resolution:\n\n  - Coarse-grained provide less temporal resolution and require making more\n    samples; Fine-grained require provide finer temporal resolution -\u003e less\n    samples, but significantly increase VMExit rate.\n\n- Attempts to subvert rerandomization, like tracking pages movement, requires\n  making more sampling, but ultimately lead to more rerandomizations\n\n## Disruption of attack phases\n\n- Stage 1 + Stage 2 description, previous attacks ...\n- We mitigate both stages simultaneously when (Klotski -\u003e focuses on 1st stage,\n  Varys -\u003e 2nd)\n- Attack is reset (attacker must repeat everything) if rerandomization is\n  performed in between, which is very likely.\n\n## Passive attacks\n\n- Passive attacks monitor the access bit in the NPT without triggering an\n  explicit exit.\n\n- Still, it is also very difficult due to the normal rerand rate.\n-\n- Some passive attack improves the temporal resolution with timer interrupt but\n  it would lead to more errands (as discussed before.)\n\n# Active region size vs. ciphertext discussion\n\n- Active region size has an impact on ciphertext attacks by increasing entropy\n  of page locations.\n\n- Alternatives:\n\n  - Salting is too expensive\n  - Infinite amount of pages\n  - Still, this is only SEV SNP issue (much harder to perform on TDX,CCA), and\n    maybe it will fixed in future releases\n\n- We currently use 8192 pages but can increase the size of active regions to add\n  more entropy.\n\n- Alternatives:\n\n  - Salting is too expensive\n\n  - Infinite amount of pages\n\n  - Still, this is only SEV SNP issue (much harder to perform on TDX,CCA), and\n    maybe fixed in future releases\n\n- We currently use 8192 pages, but can increase the size of active region to add\n  more entropy.\n\n- If havee space: Box plot that show overlap\n- Highest we can measure\n- Std wings of\n- Must be shown in figuree (paging)\n  - should be High level\n  - Show GVA GPA HPA\n  - Some actions like PAge-in-out, ORAM\n","wordCount":675,"tags":[],"metadata":{},"created":"2024-11-06T08:04:39.397387736Z","modified":"2024-11-09T09:19:16.864789434Z","checksum":"59b17741d8b0ea4bfa2adaf48b965e2d682595f3837f89c17ed65ad45a04f9b0"},
    {"filename":"2f8urcvf.md","filenameStem":"2f8urcvf","path":"2f8urcvf.md","absPath":"/home/khadd/mynotes/2f8urcvf.md","title":"Research Patterns","link":"[[2f8urcvf]]","lead":"Research is hard. However, it is not impossible. Every research follows certain\npatterns.","body":"Research is hard. However, it is not impossible. Every research follows certain\npatterns.\n\n[[kfs6h55d]]\n\n[[dlvrfm5i]]","snippets":["Research is hard. However, it is not impossible. Every research follows certain\npatterns."],"rawContent":"# Research Patterns\n\nResearch is hard. However, it is not impossible. Every research follows certain\npatterns.\n\n[[kfs6h55d]]\n\n[[dlvrfm5i]]\n","wordCount":18,"tags":[],"metadata":{},"created":"2024-07-28T08:04:46.42391336Z","modified":"2024-07-28T07:41:51.193272729Z","checksum":"01b8bcba2c7cd6a484e5cb55e1083a24e1078e3e7a95b7761ea2b0ba9e2dbc44"},
    {"filename":"p3dz33u7.md","filenameStem":"p3dz33u7","path":"p3dz33u7.md","absPath":"/home/khadd/mynotes/p3dz33u7.md","title":"Research pattern: Do one thing and do it well","link":"[[p3dz33u7]]","lead":"#research-pattern","body":"#research-pattern\n\nMany research often aim to retrofit functionalities into a more complex system\nfor less work.\n\nFor example, works such as InkTag retrofit enclaved execution functionalities\ninto the hypervisor. BlackBox @blackbox, a more recent suggests implementing an\nentirely new system from ground up (Container Security Monitor) to support\nenclaved containers. This leads to smaller TCB compared to hypervisor.","snippets":["#research-pattern"],"rawContent":"# Research pattern: Do one thing and do it well\n\n#research-pattern\n\nMany research often aim to retrofit functionalities into a more complex system\nfor less work.\n\nFor example, works such as InkTag retrofit enclaved execution functionalities\ninto the hypervisor. BlackBox @blackbox, a more recent suggests implementing an\nentirely new system from ground up (Container Security Monitor) to support\nenclaved containers. This leads to smaller TCB compared to hypervisor.\n","wordCount":68,"tags":["research-pattern"],"metadata":{},"created":"2024-10-23T07:38:57.249414998Z","modified":"2024-10-23T07:38:19.22105693Z","checksum":"8703da7a5dcc386a1ee96d42779e02147382637064951e1911764b592519bb53"},
    {"filename":"b63h10sx.md","filenameStem":"b63h10sx","path":"b63h10sx.md","absPath":"/home/khadd/mynotes/b63h10sx.md","title":"Retrofitting type safety in C","link":"[[b63h10sx]]","lead":"#programming #cxx","body":"#programming #cxx\n\nC is known for its type safety issues, so achieving type safety in C may seem\nlike a crazy idea. However, there are tricks to bring a bit more safety into\nyour code. For instance, even when the two data representations are identical, a\nfunction can be made so that it expect certain types.\n\nTo do this in C, you may retrofit enum and structs. Compiler will generally\nraise warning when mismatched `struct`/`enum` types are used. This is very\nlimited compared to other languages.\n\n## Struct-based\n\n### Generic wrapper struct\n\nThis approach implements a runtime-type-like system. It requires more memory for\nstoring type per struct instances.\n\n```c\ntypedef struct {\n  type_t type;\n  unsigned int data;\n} wrapper_t;\n\nvoid foo(wrapper_t data) {\n  if (data.type == TYPE_A) {\n    /* do something */\n  }\n}\n```\n\n### New struct per variants\n\nThis approach just leverage different wrapper struct types to force type safety.\n\nIt cannot determine action based on type, but can trigger warnings when\nmismatched type is used.\n\n```c\ntypedef struct {\n  unsigned int v;\n} type_a;\n\ntypedef struct {\n  unsigned int v;\n} type_b;\n\nvoid foo(type_a in) { /* DO something*/ }\n\nint main() {\n  type_a a = {.v = 50};\n  type_b b = {.v = 50};\n  foo(a); /* OK */\n  foo(b); /* Raise warning */\n}\n```\n\n## Generic (C11)\n\nG11 provides a `_Generic` keyword\n[Generic](https://en.cppreference.com/w/c/language/generic) that can be used to\nderive different implementations based on the input types. This requires less\ncode than the previous struct-baseed implementation. A caveat is that the\ncompiler must support C11.\n\n```c\ntypedef enum { A } type_a;\ntypedef enum { B } type_b;\n\nint foo(type_a data) {}\n#define type_safe_foo(input) _Generic(input, type_a: calc(input))\n\nint main() {\n  type_a a = 50;\n  type_b b = 100;\n  type_safe_foo(a); /* OK */\n  type_safe_foo(b); /* Raise warning */\n}\n```\n\n## Reference\n\n- \u003chttps://stackoverflow.com/questions/36351496/type-safety-in-c\u003e","snippets":["#programming #cxx"],"rawContent":"# Retrofitting type safety in C\n\n#programming #cxx\n\nC is known for its type safety issues, so achieving type safety in C may seem\nlike a crazy idea. However, there are tricks to bring a bit more safety into\nyour code. For instance, even when the two data representations are identical, a\nfunction can be made so that it expect certain types.\n\nTo do this in C, you may retrofit enum and structs. Compiler will generally\nraise warning when mismatched `struct`/`enum` types are used. This is very\nlimited compared to other languages.\n\n## Struct-based\n\n### Generic wrapper struct\n\nThis approach implements a runtime-type-like system. It requires more memory for\nstoring type per struct instances.\n\n```c\ntypedef struct {\n  type_t type;\n  unsigned int data;\n} wrapper_t;\n\nvoid foo(wrapper_t data) {\n  if (data.type == TYPE_A) {\n    /* do something */\n  }\n}\n```\n\n### New struct per variants\n\nThis approach just leverage different wrapper struct types to force type safety.\n\nIt cannot determine action based on type, but can trigger warnings when\nmismatched type is used.\n\n```c\ntypedef struct {\n  unsigned int v;\n} type_a;\n\ntypedef struct {\n  unsigned int v;\n} type_b;\n\nvoid foo(type_a in) { /* DO something*/ }\n\nint main() {\n  type_a a = {.v = 50};\n  type_b b = {.v = 50};\n  foo(a); /* OK */\n  foo(b); /* Raise warning */\n}\n```\n\n## Generic (C11)\n\nG11 provides a `_Generic` keyword\n[Generic](https://en.cppreference.com/w/c/language/generic) that can be used to\nderive different implementations based on the input types. This requires less\ncode than the previous struct-baseed implementation. A caveat is that the\ncompiler must support C11.\n\n```c\ntypedef enum { A } type_a;\ntypedef enum { B } type_b;\n\nint foo(type_a data) {}\n#define type_safe_foo(input) _Generic(input, type_a: calc(input))\n\nint main() {\n  type_a a = 50;\n  type_b b = 100;\n  type_safe_foo(a); /* OK */\n  type_safe_foo(b); /* Raise warning */\n}\n```\n\n## Reference\n\n- \u003chttps://stackoverflow.com/questions/36351496/type-safety-in-c\u003e\n","wordCount":313,"tags":["programming","cxx"],"metadata":{},"created":"2024-06-26T03:22:03.792462495Z","modified":"2024-06-28T07:59:21.623887983Z","checksum":"e62b392cbcbb6ce910dd229a1c5eab4c1a7561b01f167c0dc9355f8b0179e191"},
    {"filename":"fswawlk9.md","filenameStem":"fswawlk9","path":"fswawlk9.md","absPath":"/home/khadd/mynotes/fswawlk9.md","title":"Run ELF with custom libraries","link":"[[fswawlk9]]","lead":"#elf #linux","body":"#elf #linux\n\n## LD_LIBRARY_PATH\n\nTo execute an ELF with custom-built libraries, you may overwrites environent\nvariables that will be used by the dynamic loader.\n\n`LD_LIBRARY_PATH` will append your custom path in the search path when executing\nthe ELF file.\n\n```bash\nls /your/libpath\na.so  b.so  c.so\n\nLD_LIBRARY_PATH=/your/libpath ./youreflf\n```\n\n## LD_PRELOAD trick\n\n`LD_PRELOAD` works similarly, but it forces certain dynamic libraries to be\nloaded first. While it is intended \"preloading\", not for for overwriting\nlibraries, it achieves the intended results.\n\n```bash\nLD_PRELOAD=/path/to/mymalloc.so ./yourelf\n```\n\n## Dynamic loader\n\nTo run with custom dynamic loader is not as simple. You may directly invoke the\ndynamic loader:\n\n```bash\n/path/to/ld-linux-x86-64.so.2 ./yourelf`\n```\n\nThis will not work for binaries that need root access. For these you may use\nchroot [[q8xx4lfz]].","snippets":["#elf #linux"],"rawContent":"# Run ELF with custom libraries\n\n#elf #linux\n\n## LD_LIBRARY_PATH\n\nTo execute an ELF with custom-built libraries, you may overwrites environent\nvariables that will be used by the dynamic loader.\n\n`LD_LIBRARY_PATH` will append your custom path in the search path when executing\nthe ELF file.\n\n```bash\nls /your/libpath\na.so  b.so  c.so\n\nLD_LIBRARY_PATH=/your/libpath ./youreflf\n```\n\n## LD_PRELOAD trick\n\n`LD_PRELOAD` works similarly, but it forces certain dynamic libraries to be\nloaded first. While it is intended \"preloading\", not for for overwriting\nlibraries, it achieves the intended results.\n\n```bash\nLD_PRELOAD=/path/to/mymalloc.so ./yourelf\n```\n\n## Dynamic loader\n\nTo run with custom dynamic loader is not as simple. You may directly invoke the\ndynamic loader:\n\n```bash\n/path/to/ld-linux-x86-64.so.2 ./yourelf`\n```\n\nThis will not work for binaries that need root access. For these you may use\nchroot [[q8xx4lfz]].\n","wordCount":130,"tags":["linux","elf"],"metadata":{},"created":"2024-09-10T05:26:42.06689117Z","modified":"2024-09-13T02:49:38.9569347Z","checksum":"da4d91fcb20da3bd49b4e83822b0b6e75ec5514421d787d1a823eda06422db44"},
    {"filename":"q8xx4lfz.md","filenameStem":"q8xx4lfz","path":"q8xx4lfz.md","absPath":"/home/khadd/mynotes/q8xx4lfz.md","title":"Run program in custom root","link":"[[q8xx4lfz]]","lead":"Sometimes you want to run a certain program in an isolated environments, e.g.,\none with custom libraries. For example, we want `nginx` to be executed entirely\nin a directory `./mynginx/` so that it ngixn will treat the content of\n`./mynginx/` as root (`/`). This allows you to control over all the environments\nof the executable.","body":"Sometimes you want to run a certain program in an isolated environments, e.g.,\none with custom libraries. For example, we want `nginx` to be executed entirely\nin a directory `./mynginx/` so that it ngixn will treat the content of\n`./mynginx/` as root (`/`). This allows you to control over all the environments\nof the executable.\n\n```bash\nsudo chroot . ./your/executable`\n```\n\nIf you just want to link with custom libraries, you can use `LD_LIBRARY_PATH`\n[[fswawlk9]]","snippets":["Sometimes you want to run a certain program in an isolated environments, e.g.,\none with custom libraries. For example, we want `nginx` to be executed entirely\nin a directory `./mynginx/` so that it ngixn will treat the content of\n`./mynginx/` as root (`/`). This allows you to control over all the environments\nof the executable."],"rawContent":"# Run program in custom root\n\nSometimes you want to run a certain program in an isolated environments, e.g.,\none with custom libraries. For example, we want `nginx` to be executed entirely\nin a directory `./mynginx/` so that it ngixn will treat the content of\n`./mynginx/` as root (`/`). This allows you to control over all the environments\nof the executable.\n\n```bash\nsudo chroot . ./your/executable`\n```\n\nIf you just want to link with custom libraries, you can use `LD_LIBRARY_PATH`\n[[fswawlk9]]\n","wordCount":81,"tags":[],"metadata":{},"created":"2024-09-10T05:23:05.765739146Z","modified":"2024-09-10T05:35:44.18361673Z","checksum":"d86f6274f7832c9a6cce0da1b851d043adcbfb91d63cfb05de233f2e5a47ab3e"},
    {"filename":"llh2ly47.md","filenameStem":"llh2ly47","path":"llh2ly47.md","absPath":"/home/khadd/mynotes/llh2ly47.md","title":"Run to completion scheduling","link":"[[llh2ly47]]","lead":"- Improve throughput and latency becauses the stages mostly accessing the same\n  data, leading to better locality [@belay2014ix]","body":"- Improve throughput and latency becauses the stages mostly accessing the same\n  data, leading to better locality [@belay2014ix]\n\n- Caveat: In this model, scaling is not easy since bottleneck is the whole stack\n  [@pierre2020run]. One approach is to _batch_ the packets before passing them\n  through the stack [@li2023bifrost,@belay2014ix].\n\n## Related concepts\n\n- Cooporative scheduling","snippets":["- Improve throughput and latency becauses the stages mostly accessing the same\n  data, leading to better locality [@belay2014ix]"],"rawContent":"# Run to completion scheduling\n\n- Improve throughput and latency becauses the stages mostly accessing the same\n  data, leading to better locality [@belay2014ix]\n\n- Caveat: In this model, scaling is not easy since bottleneck is the whole stack\n  [@pierre2020run]. One approach is to _batch_ the packets before passing them\n  through the stack [@li2023bifrost,@belay2014ix].\n\n## Related concepts\n\n- Cooporative scheduling\n","wordCount":59,"tags":[],"metadata":{},"created":"2024-12-04T07:23:19.618257079Z","modified":"2024-12-04T07:58:44.040779044Z","checksum":"f434eab09b38ea7df0ee943037b1dc13db27f2895540f3cf9dccdb78fbe0624d"},
    {"filename":"kx6k8mh5.md","filenameStem":"kx6k8mh5","path":"kx6k8mh5.md","absPath":"/home/khadd/mynotes/kx6k8mh5.md","title":"Running VMs on Linux","link":"[[kx6k8mh5]]","lead":"## First thing first","body":"## First thing first\n\nCheck if your user group is within `libvirt`\n\n```txt\ngroups \u003cuserid\u003e\nsys network power ollama docker lp wheel autologin khadd plugdev libvrit\n```\n\nIf `libvirt` is not there, add yourself to it\n\n```\nsudo usermod -a -G libvirt \u003cname\u003e\n```\n\n## Networking\n\nhttps://wiki.libvirt.org/Networking.html","snippets":["## First thing first"],"rawContent":"# Running VMs on Linux\n\n## First thing first\n\nCheck if your user group is within `libvirt`\n\n```txt\ngroups \u003cuserid\u003e\nsys network power ollama docker lp wheel autologin khadd plugdev libvrit\n```\n\nIf `libvirt` is not there, add yourself to it\n\n```\nsudo usermod -a -G libvirt \u003cname\u003e\n```\n\n## Networking\n\nhttps://wiki.libvirt.org/Networking.html\n","wordCount":52,"tags":[],"metadata":{},"created":"2024-12-19T06:16:57.60044694Z","modified":"2024-12-19T06:23:08.636220202Z","checksum":"76319e949e59099e34316fecc43d4d1bd6431f2a69585941a136c4d90bad735c"},
    {"filename":"0wijbapr.md","filenameStem":"0wijbapr","path":"0wijbapr.md","absPath":"/home/khadd/mynotes/0wijbapr.md","title":"RustSan data flow analysis example","link":"[[0wijbapr]]","lead":"#archive #fleeting","body":"#archive #fleeting\n\nGodbolt flags\n\n```bash\n -C llvm-args=\"--opaque-pointers=0\"  -Z mir-opt-level=0\n```\n\n```rust\nuse std::*;\n\nfn foo(arg: \u0026mut i32, arg2: \u0026i32){\n    let mut x: i32 = 0;\n    let y: i32 = *arg2;\n\n    unsafe {\n        x = 20;\n        *arg = y + x;\n    }\n\n}\n\n\n\npub fn main() {\n    let mut x: i32 = 5;\n    let y: i32 = 6;\n    hint::black_box(foo(\u0026mut x, \u0026y));\n}\n\n```\n\n```llvm\ndefine internal void @_ZN7example3foo17h16d9ab8665c1c250E(i32* align 4 %arg, i32* align 4 %arg2) unnamed_addr #1 !dbg !15 {\nstart:\n  %x = alloca i32, align 4\n  store i32 0, i32* %x, align 4, !dbg !18\n  %y = load i32, i32* %arg2, align 4, !dbg !19, !noundef !11\n  store i32 20, i32* %x, align 4, !dbg !21\n  %_6 = load i32, i32* %x, align 4, !dbg !24, !noundef !11\n  %0 = call { i32, i1 } @llvm.sadd.with.overflow.i32(i32 %y, i32 %_6), !dbg !25\n  %_7.0 = extractvalue { i32, i1 } %0, 0, !dbg !25\n  %_7.1 = extractvalue { i32, i1 } %0, 1, !dbg !25\n  %1 = call i1 @llvm.expect.i1(i1 %_7.1, i1 false), !dbg !25\n  br i1 %1, label %panic, label %bb1, !dbg !25\n\nbb1:                                              ; preds = %start\n  store i32 %_7.0, i32* %arg, align 4, !dbg !26\n  ret void, !dbg !27\n\npanic:                                            ; preds = %start\n  call void @_ZN4core9panicking5panic17hcaff1f3d20618491E([0 x i8]* align 1 bitcast ([28 x i8]* @str.0 to [0 x i8]*), i64 28, %\"core::panic::location::Location\u003c'_\u003e\"* align 8 bitcast (\u003c{ i8*, [16 x i8] }\u003e* @alloc_9bc9feaf68b8c234019a4170dc48b236 to %\"core::panic::location::Location\u003c'_\u003e\"*)) #5, !dbg !25\n  unreachable, !dbg !25\n}\n```","snippets":["#archive #fleeting"],"rawContent":"# RustSan data flow analysis example\n\n#archive #fleeting\n\nGodbolt flags\n\n```bash\n -C llvm-args=\"--opaque-pointers=0\"  -Z mir-opt-level=0\n```\n\n```rust\nuse std::*;\n\nfn foo(arg: \u0026mut i32, arg2: \u0026i32){\n    let mut x: i32 = 0;\n    let y: i32 = *arg2;\n\n    unsafe {\n        x = 20;\n        *arg = y + x;\n    }\n\n}\n\n\n\npub fn main() {\n    let mut x: i32 = 5;\n    let y: i32 = 6;\n    hint::black_box(foo(\u0026mut x, \u0026y));\n}\n\n```\n\n```llvm\ndefine internal void @_ZN7example3foo17h16d9ab8665c1c250E(i32* align 4 %arg, i32* align 4 %arg2) unnamed_addr #1 !dbg !15 {\nstart:\n  %x = alloca i32, align 4\n  store i32 0, i32* %x, align 4, !dbg !18\n  %y = load i32, i32* %arg2, align 4, !dbg !19, !noundef !11\n  store i32 20, i32* %x, align 4, !dbg !21\n  %_6 = load i32, i32* %x, align 4, !dbg !24, !noundef !11\n  %0 = call { i32, i1 } @llvm.sadd.with.overflow.i32(i32 %y, i32 %_6), !dbg !25\n  %_7.0 = extractvalue { i32, i1 } %0, 0, !dbg !25\n  %_7.1 = extractvalue { i32, i1 } %0, 1, !dbg !25\n  %1 = call i1 @llvm.expect.i1(i1 %_7.1, i1 false), !dbg !25\n  br i1 %1, label %panic, label %bb1, !dbg !25\n\nbb1:                                              ; preds = %start\n  store i32 %_7.0, i32* %arg, align 4, !dbg !26\n  ret void, !dbg !27\n\npanic:                                            ; preds = %start\n  call void @_ZN4core9panicking5panic17hcaff1f3d20618491E([0 x i8]* align 1 bitcast ([28 x i8]* @str.0 to [0 x i8]*), i64 28, %\"core::panic::location::Location\u003c'_\u003e\"* align 8 bitcast (\u003c{ i8*, [16 x i8] }\u003e* @alloc_9bc9feaf68b8c234019a4170dc48b236 to %\"core::panic::location::Location\u003c'_\u003e\"*)) #5, !dbg !25\n  unreachable, !dbg !25\n}\n```\n","wordCount":250,"tags":["fleeting","archive"],"metadata":{},"created":"2024-05-23T06:27:21.341230953Z","modified":"2024-06-20T07:40:44.393136673Z","checksum":"0184aac749e0be2f9d87e87f48f1f1d43983030d31bfcb3a6e484b31682ae09f"},
    {"filename":"0kmxhvf5.md","filenameStem":"0kmxhvf5","path":"0kmxhvf5.md","absPath":"/home/khadd/mynotes/0kmxhvf5.md","title":"S\u0026P 2023","link":"[[0kmxhvf5]]","lead":"#conference #archive\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)","body":"#conference #archive\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)\n\n# System-ish papers\n\nNew architecture\n\n- SecureCells: A Secure Compartmentalized Architecture\n- Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture\n\nSecure System\n\n- WaVe: A Verifiably Secure WebAssembly Sandboxing Runtime\n- uSWITCH: Fast Kernel Context Isolation with Implicit Context Switches\n\nSystem for ML\n\n- ShadowNet: A Secure and Efficient On-device Model Inference System for\n  Convolutional Neural Networks\n\nExploits\n\n- WarpAttack: Bypassing CFI through Compiler-Introduced Double-Fetches\n\nKernel bugs\n\n- Precise Detection of Kernel Data Races with Probabilistic Lockset Analysis\n- When Top-down Meets Bottom-up: Detecting and Exploiting Use-After-Cleanup Bugs\n  in Linux Kernel\n- AEM: Facilitating Cross-Version Exploitability Assessment of Linux Kernel\n  Vulnerabilities\n\nProgram analysis, compartmentalization\n\n- Practical Program Modularization with Type-Based Dependence Analysis\n- EC: Embedded Systems Compartmentalization via Intra-Kernel Isolation\n- Low-Cost Privilege Separation with Compile Time Compartmentalization for\n  Embedded Systems","snippets":["#conference #archive\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)"],"rawContent":"# S\u0026P 2023\n\n#conference #archive\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)\n\n# System-ish papers\n\nNew architecture\n\n- SecureCells: A Secure Compartmentalized Architecture\n- Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture\n\nSecure System\n\n- WaVe: A Verifiably Secure WebAssembly Sandboxing Runtime\n- uSWITCH: Fast Kernel Context Isolation with Implicit Context Switches\n\nSystem for ML\n\n- ShadowNet: A Secure and Efficient On-device Model Inference System for\n  Convolutional Neural Networks\n\nExploits\n\n- WarpAttack: Bypassing CFI through Compiler-Introduced Double-Fetches\n\nKernel bugs\n\n- Precise Detection of Kernel Data Races with Probabilistic Lockset Analysis\n- When Top-down Meets Bottom-up: Detecting and Exploiting Use-After-Cleanup Bugs\n  in Linux Kernel\n- AEM: Facilitating Cross-Version Exploitability Assessment of Linux Kernel\n  Vulnerabilities\n\nProgram analysis, compartmentalization\n\n- Practical Program Modularization with Type-Based Dependence Analysis\n- EC: Embedded Systems Compartmentalization via Intra-Kernel Isolation\n- Low-Cost Privilege Separation with Compile Time Compartmentalization for\n  Embedded Systems\n","wordCount":142,"tags":["conference","archive"],"metadata":{},"created":"2023-05-22T02:06:14.446281169Z","modified":"2024-07-05T06:52:15.198535924Z","checksum":"b4c86f97d68907f94a7041fe162749a2f57331949f177e54a474783e87bfbc1a"},
    {"filename":"9m2ai0ih.md","filenameStem":"9m2ai0ih","path":"9m2ai0ih.md","absPath":"/home/khadd/mynotes/9m2ai0ih.md","title":"SGX remote attestation","link":"[[9m2ai0ih]]","lead":"The example from\nhttps://github.com/intel/sgx-ra-sample/tree/master?tab=readme-ov-file#build-linux\nseems overly bloated.","body":"The example from\nhttps://github.com/intel/sgx-ra-sample/tree/master?tab=readme-ov-file#build-linux\nseems overly bloated.\n\n- https://github.com/Azure-Samples/microsoft-azure-attestation/tree/master/sgx.attest.sample.intel.sdk\n\nThe proper way seems to be integrating remote attestation into the TLS\nhandshaking\n\n- https://github.com/inclavare-containers/rats-tls/tree/master","snippets":["The example from\nhttps://github.com/intel/sgx-ra-sample/tree/master?tab=readme-ov-file#build-linux\nseems overly bloated."],"rawContent":"# SGX remote attestation\n\nThe example from\nhttps://github.com/intel/sgx-ra-sample/tree/master?tab=readme-ov-file#build-linux\nseems overly bloated.\n\n- https://github.com/Azure-Samples/microsoft-azure-attestation/tree/master/sgx.attest.sample.intel.sdk\n\nThe proper way seems to be integrating remote attestation into the TLS\nhandshaking\n\n- https://github.com/inclavare-containers/rats-tls/tree/master\n","wordCount":28,"tags":[],"metadata":{},"created":"2024-12-16T08:27:43.590816543Z","modified":"2024-12-16T09:54:24.313806137Z","checksum":"1424829578954da3b405392cf37dea54721536a2d806c6a70ff92fef3d93a0e1"},
    {"filename":"w57bcbla.md","filenameStem":"w57bcbla","path":"w57bcbla.md","absPath":"/home/khadd/mynotes/w57bcbla.md","title":"SSLAB Things","link":"[[w57bcbla]]","lead":"- Grammarly : `hojoon.lee@skku.edu`/`Tltmxpa-l33t!`","body":"- Grammarly : `hojoon.lee@skku.edu`/`Tltmxpa-l33t!`\n\n## IP Addresses\n\n| IP              | Owner       |\n| --------------- | ----------- |\n| 115.145.173.173 | X           |\n| 115.145.173.174 |             |\n| 115.145.173.175 | 김주영      |\n| 115.145.173.176 | 김종윤      |\n| 115.145.173.177 | 조규원      |\n| 115.145.173.178 | 김성수      |\n| 115.145.173.179 | 임하정      |\n| 115.145.173.180 | 김지훈      |\n| 115.145.173.181 | 김재윤      |\n| 115.145.173.182 | 김재윤-mac  |\n| 115.145.173.183 | Kha         |\n| 115.145.173.184 | Mac Mini M1 |\n| 115.145.173.185 |             |\n| 115.145.173.186 |             |\n| 115.145.173.187 | jetson      |\n| 115.145.173.188 | SSONE-BMC   |\n| 115.145.173.189 | SSSEV-BMC   |\n| 115.145.173.190 | SSSEV       |\n| 115.145.173.191 | Printer     |\n| 115.145.173.192 | Router      |\n\n- 173: External network blocked for some reason\n- 185~187: left\n\nTo set up, set:\n\n- Gateway: `115.145.173.1`\n- Netmask: `24` (`255.255.255.0`)","snippets":["- Grammarly : `hojoon.lee@skku.edu`/`Tltmxpa-l33t!`"],"rawContent":"# SSLAB Things\n\n- Grammarly : `hojoon.lee@skku.edu`/`Tltmxpa-l33t!`\n\n## IP Addresses\n\n| IP              | Owner       |\n| --------------- | ----------- |\n| 115.145.173.173 | X           |\n| 115.145.173.174 |             |\n| 115.145.173.175 | 김주영      |\n| 115.145.173.176 | 김종윤      |\n| 115.145.173.177 | 조규원      |\n| 115.145.173.178 | 김성수      |\n| 115.145.173.179 | 임하정      |\n| 115.145.173.180 | 김지훈      |\n| 115.145.173.181 | 김재윤      |\n| 115.145.173.182 | 김재윤-mac  |\n| 115.145.173.183 | Kha         |\n| 115.145.173.184 | Mac Mini M1 |\n| 115.145.173.185 |             |\n| 115.145.173.186 |             |\n| 115.145.173.187 | jetson      |\n| 115.145.173.188 | SSONE-BMC   |\n| 115.145.173.189 | SSSEV-BMC   |\n| 115.145.173.190 | SSSEV       |\n| 115.145.173.191 | Printer     |\n| 115.145.173.192 | Router      |\n\n- 173: External network blocked for some reason\n- 185~187: left\n\nTo set up, set:\n\n- Gateway: `115.145.173.1`\n- Netmask: `24` (`255.255.255.0`)\n","wordCount":141,"tags":[],"metadata":{},"created":"2024-12-23T04:09:16.384955408Z","modified":"2024-12-23T04:10:56.413825462Z","checksum":"88f0ea6d2bdfe84d76e4411efb34389bef6a7bd067a195e6325cf98d3c32e2c7"},
    {"filename":"u2y7lspt.md","filenameStem":"u2y7lspt","path":"u2y7lspt.md","absPath":"/home/khadd/mynotes/u2y7lspt.md","title":"Safe and Fast Confidential IO Stack","link":"[[u2y7lspt]]","lead":"#project","body":"#project\n\n## Related work\n\n### Fined-grained kernel comparmentalization\n\nMultiple systems have been in proposed for fine-grained compartmentalization in\nthe kernel.\n\n- LXD, LVD used virtualization to isolate driver code. They also deal with\n  automatic data marshalling through IDL design. ksplit automate the process of\n  IDL generation.\n- More recent work, HAKC, BULKHEAD utilize fast isolation primities like PKU and\n  ARM PAC/MTE to add lightweight compartments into the kernel.\n\nMost focuses on the isolation of kernel modules from the core kernel. Virtio\ndriver is minimal (in LoC), so there is less incentive to isolate the driver.\nOur focus of should be shifted to the transport layer.\n\nInterface design is not the focus of these works, but the retrofitting of\nisolation into existing kernel interfaces. While some do raise the interface\nconcerns, the validation logic is left to developers.\n\n### Security and performance of CVM I/O\n\n- [gramine-tdx] proposes extreme attack surface minimization by offloading much\n  of the networking/fs stack into to the untrusted hypervisor and relying on\n  payload-level encryption for confidentiality. For hardening the interfaces,\n  - Limits the interfaces with the untrusted hypervisor (no. of virtqueues).\n  - Still relies on manual sanitizations\n  - Proposed some check for protocol adherence, a kind of interface ordering\n    check.\n- [bifrost] optimizes the I/O path of confidential I/O to reduce redundant\n  copies and packet processing times. For security, it suggests a \"one-time\n  trusted read\" hardening that only read the packet metadata once when receiving\n  packets. Since payload is already encrypted by TLS, it is\n  authenticity-protected.\n- [bridge] optimize the I/O path for SR-IOV devices with in-CVM DPDK. It also\n  had some security considerations, e.g., always copy packets into private\n  memory before processing.\n  - DPDK-specific\n  - Assume SR-IOV\n\n### Previous networking stacks for trusted execution\n\n- SafeBrick, rktio, LightBox, ...\n- We expect they will suffers from intervface vulnerabilities too.\n\n## Motivations\n\n### Existing efforts: Attack surface minimization\n\n- Offloading most of the stack into the host ([gramine-tdx]) exposes\n  fine-grained observability into in-CVM operations.\n  - This leaks system call timing, ...\n  - \u003e Makes resource accounting tricky\n- A patchset by Intel instead minimize TCB by limiting the features\n  [virtio-hardening], e.g., only allowing split virtqueues.\n  - Also, trying to limit the feature set leads to performance degradation (not\n    quantified).\n\n\u003e - Related:\n\u003e   - Network stack as a service\n\n\u003e [!IMPORTANT]\n\u003e\n\u003e Our approach is to keep much of the stack within the CVM boundary, but instead\n\u003e establish multiple security domains with safety-first interfaces. This limit\n\u003e observability, while maintaining performance.\n\n### Existing efforts: ad hoc hardening\n\n- Hardening is error-prone\n  - e.g., notification hardening is introduced in a patch, made an optional\n    feature in another, and finally marked as broken.\n\n\u003e In the VirtIO case for example, over 40 commits, 12 either revert or amend\n\u003e previous hardening changes, some of them never to be re-applied.\n\u003e [confidential-io]\n\n\u003e [!IMPORTANT]\n\u003e\n\u003e We propose that the interface itself should be redesigned for future\n\u003e confidential computing workloads. We explore principles that enable secure\n\u003e interface design, and propose primitives that make hardening easier.\n\n## Virtio for confidential computing: the good, the bad and the ugly\n\nWhat do we want to keep/remove in the virtio interface?\n\n### The good\n\n#### Universality and generality\n\n- This not only reduce the driver development efforts, but also reduce the TCB\n  (remove the need for all kinds of drivers in the trusted guest).\n- We want to retain this to support a wide range of deployment scenarios\n- We also want existing driver to be easily ported to our new interfaces\n\n#### Performance-oriented\n\n- The design is optimized for high speed I/O.\n- The new design should not significantly reduce I/O performance.\n\n#### Descriptor table\n\n- The descriptors are a kind of safety-aware resource handle that reduces\n  programming mistakes. Its wrap-around index, combined with power-of-two\n  virtqueue sizes, by design prevent out-of-bound accesses.\n  - It's not fool-proof. The host can pass out-of-bound indexes in the rings.\n- We want to keep this aspect\n\n### The bad\n\n#### Not built with mutual distrust in mind\n\n- A large amount of control data / metadata is expected to be in shared memory,\n  which open up attack vectors for double fetches.\n\n#### Large configuration space\n\n- Need to quantify how large is this space.\n\n#### DMA quirk\n\n- Due to the distinction between shared and private memory, allowing the device\n  to access random memory does not make sense anymore, and also make virtio\n  fundamentally difficult to harden.\n- Bounce buffers is required for I/O in confidential VMs, making DMA less of a\n  requirement.\n- Instead of expecting unrestricted DMA accesses in the specification, a better\n  design is to have reserved fixed size regions for data exchanges.\n  - This also avoid overheads associated with I/O memory management\n\n### The ugly\n\n#### The large scope of the standard\n\n- Need to support legacy devices and drivers, resulting in hardening breaks\n  existing drivers and devices\n- Need to support both hardware and para-virtual scenarios.\n\n\u003e Backward compatibility not that important, as drivers are relatively\n\u003e transparent to customer anyway\n\n## Design space\n\n### Interface re-architecting\n\nThese are just a draft of what I want in the interface.\n\n- **Consistent a cross the stack** We want the validation/enforcement scheme, if\n  existed, to be consistent across the networking stack.\n  - For example, virtio core may perform some checks, while the driver may\n    perform other checks\n  - Interesting discussion:\n    \u003chttps://lore.kernel.org/lkml/CACGkMEsW1+BFtMoLg4c_FyxYTZJcSVh4BoEdJ-Q9_WGg_DcReA@mail.gmail.com/\u003e\n  - \u003e \u003e Michael S. Tsirkin: I don't really understand. We already iterate when\n    \u003e \u003e we unmap - all that is necessary is to subtract it from used length, if\n    \u003e \u003e at the end of the process it is \u003e0 then we know used length is too\n    \u003e \u003e large.\n    \u003e\n    \u003e Jason Wang: Yes, but it is the job that is done in the driver level not\n    \u003e the virtio core. Validation in virtio core is still necessary since\n    \u003e they're working at different levels and it's hard to force the validation\n    \u003e in all drivers by codes. Last version introduces a\n    \u003e\n    \u003e \u003e Why do we? If driver validates length virtio_ring does not need to\n    \u003e \u003e validate. If driver does not use length virtio_ring does not need to\n    \u003e \u003e validate. core can provide this service for the gazillion non\n    \u003e \u003e performance critical drivers that just want to keep things simple, but\n    \u003e \u003e the 4-5 critical ones can do their own validation if they want to.\n    \u003e\n    \u003e To be more safe, there's no guarantee that there's no bug in the driver.\n- **Zero (re)negotiation**. Most negotiation should be performed at device\n  startup.\n  - This limit the control data exchanges into one place that is easy to harden.\n- **Zero surprises**. All control data must be checked against valid value\n  ranges according to the specification. This applies to both L2 and L5.\n- **Avoid the need to decide whether to copy or not**.\n  - Letting the developers making this decision is both error-prone and may\n    introduce inefficiencies.\n  - Ideally the decision should be made clear by the specification, and enforced\n    automatically (continued in next point).\n- **Read-once to control data \u0026 metadata**. L2) Virtio device configurations,\n  control messages, descriptor table L5) packet headers.\n  - More generally, we want to avoid double fetch vulnerabilities\n  - For L2: A naive approach is copying the control data into the local stack\n    before use [virtio-console2]. This may miss cross-function double fetches\n    (if exist).\n    - A more systematic approach can be achieved with page table permissions\n      [midas], e.g., automatically ensuring the page is copied before being\n      used,\n  - L5: Previous papers suggests read-once the packet headers ([bifrost]), or\n    copying the entire packets before use (bridging).\n    - This does not apply to runtime metadata exchanges, e.g., `vring[idx].len`,\n      `vring[idx].len`.\n- **Avoid the need for (manual) pointer validations and bounds checking.**\n  Preferably, all the check should be done ASAP, at the interface boundary.\n  Pointer validation is extremely error-prone, and very easy to miss.\n  - The use of some type of handles (file/virtqueue descriptors) may be useful\n    here.\n  - Now, existing L2, L5 interfaces are already (kinda) designed this way.\n    - For L2, I/O are performed on vring indexes instead of direct pointers.\n    - For L5, network IO are performed on socket file descriptors.\n  - Even with bound checks, speculative execution\n- **Separation of data and metadata**. I/O Data is always encrypted by software\n  in confidential computing (TLS, other FS protocols), so it is better to keep\n  them in-place to avoid copying ([bifrost]).\n  - Because of this, it may be better to keep them separated, so that it is\n    easier to enforce certain policy (e.g., zero-copy for data, read-once for\n    metadata)\n  - This may be difficult to do in the case of network packets due to packet\n    encapsulation.\n\nOther bits from HotOS'23 Paper.\n\n- **Stateless interfaces \u0026 thread safety**. I don't fully get the implications\n  of this. What are the states that can be removed?\n- **Revocation**. [bifrost] mentioned that toggling the sharing state between\n  Hypervisor and CVM at runtime is not possible due to memory encryption.\n  However, it should be possible at the L2 boundary, but is it faster than\n  copying?\n\n### Trusted proxies \u0026 resource handles\n\nOne design is to force all cross-domain communication to go through trusted\nproxies that perform data validation, bound checking, etc... ([redleaf]).\n\n- Instead of passing pointers, handles are passed across the interfaces, which\n  makes it less likely to make mistake.\n- Design choices: Centralized monitor vs. inline monitor\n\n### Capabilities\n\n- The previous design point is what capabilities-based security achieves.\n- Capabilities model is a valid consideration for security-first from-scratch\n  designs, but can also be retrofitted into unexpected places.\n- Challenge: deciding what to abstract into capabilities\n\n### Mutual distrust\n\n- While confidential computing threat models focuses on trusting only the\n  protected application, in real world attacks may also come from the protected\n  application.\n- Ideally our interface design should account for this mutual distrust.\n\n### Low-overhead isolation primitives\n\n- AMD SEV-SNP provides 4 VMPL levels to enforce hierarchical in-CVM isolation of\n  memory. A similar feature is also supported in TDX 1.5.\n- Note, VMPL switching is costly due to the need of VMExits ([veil]), so\n  asynchronous RPC communication should be considered across the domains.\n- Exploiting this to build isolation boundaries is a source of novelty.\n\n### Flexible data path\n\nAside from the traditional networking stack, we should ideally support other\ndata paths e.g., DPDK, or at least make it not so hard to port them to our\nframework.\n\n### Attack surface minimization with performance considerations\n\n- **Minimizing TCB** Instead of minimizing attack surfaces, we should instead\n  minimize the TCB that interacts with untrusted input.\n  - E.g., [gramine-tdx] minimized the no. of virtqueues to be used that I don't\n    think make sense. Each virtqueue is essentially accessed by the same code\n    base.\n- **No notification / Poll first** Notifications are fundamentally difficult to\n  harden due to races, while does not contribute much to performance.\n  - Are there cases where they are a must?\n- **Performance** Other optimizations, e.g., packed virtqueues, indirection,\n  that meaningfully impact performance, should still be compatible with this new\n  interface.\n\n### Speculative execution mitigations\n\n- [speculative] mentioned hypervisor-given indexes in the vrings might be used\n  for speculative execution.\n- Ideally all indexes / pointers should be masked before use.\n- May be Related: paper from David [secret-free-hypervisor]\n\n### Fine-grained compartmentalization of the TCP stack\n\n- The TCP stack is organized in layers, but there haven't been discussions to\n  split it.\n\n## Sketch design: I/O Monitor\n\n[Src](https://excalidraw.com/#json=GHAbzT6Lub5UbvPPiHY7c,oxBzneS8cORp1zgLn8-jzQ)\n![image](https://hackmd.io/_uploads/H1m8hNKNJg.png)\n\nWe introduce an entity called \"I/O Monitor (IOMon)\" that interposes all\ncommunication between guest and host.\n\n- The goal of IOMon is not to deprivilege the main kernel (e.g., NestedKernel),\n  but to shepherd safe I/O:\n  - Discouraging unsafe interactions (e.g., direct shared memory access).\n  - Provide safe abstraction for the stacks to do their job.\n  - We want to make hardening IOMon as simple as possible (minimizing TCB,\n    automatic checks, safe-by-default primitives).\n- Mutual distrust: IOMon has two ends, the in-CVM one that handle CVM-side I/O\n  and in-hypervisor one that handle hypervisor-side I/O.\n- CVM interfaces:\n  - IO memory allocation. Enforce \"trusted component allocate\"\n  - Metadata management. Enforce one-time read \u0026 sanitization\n  - Feature negotiation and transaction\n- Hypervisor interfaces. TBD.\n- Capabilities. TBD.\n  - Considering using capabilities.\n  - Related: LXD, LVD used a microkernel architecture to manage asynchronous\n    communication between isolated driver and core kernel.\n  - Capabilities makes the verification for some operations simple, and\n    minimizing TCB.\n  - May be hard to retrofit into existing interfaces.\n\n### Issues\n\n- I expect cutting the networking stack from the kernel is not easy. But do we\n  need to at all? An approach may be to run two versions of linux\n\n---\n\n[confidential-io]: https://dl.acm.org/doi/10.1145/3593856.3595913\n[gramine-tdx]:\n\thttps://dse.in.tum.de/wp-content/uploads/2024/10/Gramine_TDX-CCS24.pdf\n[bridge]: http://arxiv.org/abs/2403.03360\n[redleaf]:\n\thttps://www.usenix.org/conference/osdi20/presentation/narayanan-vikram\n[virtio-hardening]: https://lwn.net/Articles/865216/\n[bifrost]: https://www.usenix.org/conference/atc23/presentation/li-dingji\n[midas]:\n\thttps://www.usenix.org/conference/usenixsecurity22/presentation/bhattacharyya\n[virtio-console1]:\n\thttps://lore.kernel.org/lkml/87a62eqo4h.fsf@ubik.fi.intel.com/T/#m2eab864030afd60f309ffa23909defd54b7dc426\n[virtio-console2]:\n\thttps://github.com/intel/tdx/commit/a89bbb3f3701e8c9efb8333882ca4cc923e3b1e4\n[speculative]:\n\thttps://github.com/intel/tdx/commit/7ad4a0fc9bfa762c3c44b011caf4d277abd3d9d1\n[secret-free-hypervisor]:\n\thttps://www.microsoft.com/en-us/research/uploads/prod/2022/07/sf-hypervisor.pdf\n[veil]: https://dl.acm.org/doi/pdf/10.1145/3623278.3624763#page=10.46","snippets":["#project"],"rawContent":"# Safe and Fast Confidential IO Stack\n\n#project\n\n## Related work\n\n### Fined-grained kernel comparmentalization\n\nMultiple systems have been in proposed for fine-grained compartmentalization in\nthe kernel.\n\n- LXD, LVD used virtualization to isolate driver code. They also deal with\n  automatic data marshalling through IDL design. ksplit automate the process of\n  IDL generation.\n- More recent work, HAKC, BULKHEAD utilize fast isolation primities like PKU and\n  ARM PAC/MTE to add lightweight compartments into the kernel.\n\nMost focuses on the isolation of kernel modules from the core kernel. Virtio\ndriver is minimal (in LoC), so there is less incentive to isolate the driver.\nOur focus of should be shifted to the transport layer.\n\nInterface design is not the focus of these works, but the retrofitting of\nisolation into existing kernel interfaces. While some do raise the interface\nconcerns, the validation logic is left to developers.\n\n### Security and performance of CVM I/O\n\n- [gramine-tdx] proposes extreme attack surface minimization by offloading much\n  of the networking/fs stack into to the untrusted hypervisor and relying on\n  payload-level encryption for confidentiality. For hardening the interfaces,\n  - Limits the interfaces with the untrusted hypervisor (no. of virtqueues).\n  - Still relies on manual sanitizations\n  - Proposed some check for protocol adherence, a kind of interface ordering\n    check.\n- [bifrost] optimizes the I/O path of confidential I/O to reduce redundant\n  copies and packet processing times. For security, it suggests a \"one-time\n  trusted read\" hardening that only read the packet metadata once when receiving\n  packets. Since payload is already encrypted by TLS, it is\n  authenticity-protected.\n- [bridge] optimize the I/O path for SR-IOV devices with in-CVM DPDK. It also\n  had some security considerations, e.g., always copy packets into private\n  memory before processing.\n  - DPDK-specific\n  - Assume SR-IOV\n\n### Previous networking stacks for trusted execution\n\n- SafeBrick, rktio, LightBox, ...\n- We expect they will suffers from intervface vulnerabilities too.\n\n## Motivations\n\n### Existing efforts: Attack surface minimization\n\n- Offloading most of the stack into the host ([gramine-tdx]) exposes\n  fine-grained observability into in-CVM operations.\n  - This leaks system call timing, ...\n  - \u003e Makes resource accounting tricky\n- A patchset by Intel instead minimize TCB by limiting the features\n  [virtio-hardening], e.g., only allowing split virtqueues.\n  - Also, trying to limit the feature set leads to performance degradation (not\n    quantified).\n\n\u003e - Related:\n\u003e   - Network stack as a service\n\n\u003e [!IMPORTANT]\n\u003e\n\u003e Our approach is to keep much of the stack within the CVM boundary, but instead\n\u003e establish multiple security domains with safety-first interfaces. This limit\n\u003e observability, while maintaining performance.\n\n### Existing efforts: ad hoc hardening\n\n- Hardening is error-prone\n  - e.g., notification hardening is introduced in a patch, made an optional\n    feature in another, and finally marked as broken.\n\n\u003e In the VirtIO case for example, over 40 commits, 12 either revert or amend\n\u003e previous hardening changes, some of them never to be re-applied.\n\u003e [confidential-io]\n\n\u003e [!IMPORTANT]\n\u003e\n\u003e We propose that the interface itself should be redesigned for future\n\u003e confidential computing workloads. We explore principles that enable secure\n\u003e interface design, and propose primitives that make hardening easier.\n\n## Virtio for confidential computing: the good, the bad and the ugly\n\nWhat do we want to keep/remove in the virtio interface?\n\n### The good\n\n#### Universality and generality\n\n- This not only reduce the driver development efforts, but also reduce the TCB\n  (remove the need for all kinds of drivers in the trusted guest).\n- We want to retain this to support a wide range of deployment scenarios\n- We also want existing driver to be easily ported to our new interfaces\n\n#### Performance-oriented\n\n- The design is optimized for high speed I/O.\n- The new design should not significantly reduce I/O performance.\n\n#### Descriptor table\n\n- The descriptors are a kind of safety-aware resource handle that reduces\n  programming mistakes. Its wrap-around index, combined with power-of-two\n  virtqueue sizes, by design prevent out-of-bound accesses.\n  - It's not fool-proof. The host can pass out-of-bound indexes in the rings.\n- We want to keep this aspect\n\n### The bad\n\n#### Not built with mutual distrust in mind\n\n- A large amount of control data / metadata is expected to be in shared memory,\n  which open up attack vectors for double fetches.\n\n#### Large configuration space\n\n- Need to quantify how large is this space.\n\n#### DMA quirk\n\n- Due to the distinction between shared and private memory, allowing the device\n  to access random memory does not make sense anymore, and also make virtio\n  fundamentally difficult to harden.\n- Bounce buffers is required for I/O in confidential VMs, making DMA less of a\n  requirement.\n- Instead of expecting unrestricted DMA accesses in the specification, a better\n  design is to have reserved fixed size regions for data exchanges.\n  - This also avoid overheads associated with I/O memory management\n\n### The ugly\n\n#### The large scope of the standard\n\n- Need to support legacy devices and drivers, resulting in hardening breaks\n  existing drivers and devices\n- Need to support both hardware and para-virtual scenarios.\n\n\u003e Backward compatibility not that important, as drivers are relatively\n\u003e transparent to customer anyway\n\n## Design space\n\n### Interface re-architecting\n\nThese are just a draft of what I want in the interface.\n\n- **Consistent a cross the stack** We want the validation/enforcement scheme, if\n  existed, to be consistent across the networking stack.\n  - For example, virtio core may perform some checks, while the driver may\n    perform other checks\n  - Interesting discussion:\n    \u003chttps://lore.kernel.org/lkml/CACGkMEsW1+BFtMoLg4c_FyxYTZJcSVh4BoEdJ-Q9_WGg_DcReA@mail.gmail.com/\u003e\n  - \u003e \u003e Michael S. Tsirkin: I don't really understand. We already iterate when\n    \u003e \u003e we unmap - all that is necessary is to subtract it from used length, if\n    \u003e \u003e at the end of the process it is \u003e0 then we know used length is too\n    \u003e \u003e large.\n    \u003e\n    \u003e Jason Wang: Yes, but it is the job that is done in the driver level not\n    \u003e the virtio core. Validation in virtio core is still necessary since\n    \u003e they're working at different levels and it's hard to force the validation\n    \u003e in all drivers by codes. Last version introduces a\n    \u003e\n    \u003e \u003e Why do we? If driver validates length virtio_ring does not need to\n    \u003e \u003e validate. If driver does not use length virtio_ring does not need to\n    \u003e \u003e validate. core can provide this service for the gazillion non\n    \u003e \u003e performance critical drivers that just want to keep things simple, but\n    \u003e \u003e the 4-5 critical ones can do their own validation if they want to.\n    \u003e\n    \u003e To be more safe, there's no guarantee that there's no bug in the driver.\n- **Zero (re)negotiation**. Most negotiation should be performed at device\n  startup.\n  - This limit the control data exchanges into one place that is easy to harden.\n- **Zero surprises**. All control data must be checked against valid value\n  ranges according to the specification. This applies to both L2 and L5.\n- **Avoid the need to decide whether to copy or not**.\n  - Letting the developers making this decision is both error-prone and may\n    introduce inefficiencies.\n  - Ideally the decision should be made clear by the specification, and enforced\n    automatically (continued in next point).\n- **Read-once to control data \u0026 metadata**. L2) Virtio device configurations,\n  control messages, descriptor table L5) packet headers.\n  - More generally, we want to avoid double fetch vulnerabilities\n  - For L2: A naive approach is copying the control data into the local stack\n    before use [virtio-console2]. This may miss cross-function double fetches\n    (if exist).\n    - A more systematic approach can be achieved with page table permissions\n      [midas], e.g., automatically ensuring the page is copied before being\n      used,\n  - L5: Previous papers suggests read-once the packet headers ([bifrost]), or\n    copying the entire packets before use (bridging).\n    - This does not apply to runtime metadata exchanges, e.g., `vring[idx].len`,\n      `vring[idx].len`.\n- **Avoid the need for (manual) pointer validations and bounds checking.**\n  Preferably, all the check should be done ASAP, at the interface boundary.\n  Pointer validation is extremely error-prone, and very easy to miss.\n  - The use of some type of handles (file/virtqueue descriptors) may be useful\n    here.\n  - Now, existing L2, L5 interfaces are already (kinda) designed this way.\n    - For L2, I/O are performed on vring indexes instead of direct pointers.\n    - For L5, network IO are performed on socket file descriptors.\n  - Even with bound checks, speculative execution\n- **Separation of data and metadata**. I/O Data is always encrypted by software\n  in confidential computing (TLS, other FS protocols), so it is better to keep\n  them in-place to avoid copying ([bifrost]).\n  - Because of this, it may be better to keep them separated, so that it is\n    easier to enforce certain policy (e.g., zero-copy for data, read-once for\n    metadata)\n  - This may be difficult to do in the case of network packets due to packet\n    encapsulation.\n\nOther bits from HotOS'23 Paper.\n\n- **Stateless interfaces \u0026 thread safety**. I don't fully get the implications\n  of this. What are the states that can be removed?\n- **Revocation**. [bifrost] mentioned that toggling the sharing state between\n  Hypervisor and CVM at runtime is not possible due to memory encryption.\n  However, it should be possible at the L2 boundary, but is it faster than\n  copying?\n\n### Trusted proxies \u0026 resource handles\n\nOne design is to force all cross-domain communication to go through trusted\nproxies that perform data validation, bound checking, etc... ([redleaf]).\n\n- Instead of passing pointers, handles are passed across the interfaces, which\n  makes it less likely to make mistake.\n- Design choices: Centralized monitor vs. inline monitor\n\n### Capabilities\n\n- The previous design point is what capabilities-based security achieves.\n- Capabilities model is a valid consideration for security-first from-scratch\n  designs, but can also be retrofitted into unexpected places.\n- Challenge: deciding what to abstract into capabilities\n\n### Mutual distrust\n\n- While confidential computing threat models focuses on trusting only the\n  protected application, in real world attacks may also come from the protected\n  application.\n- Ideally our interface design should account for this mutual distrust.\n\n### Low-overhead isolation primitives\n\n- AMD SEV-SNP provides 4 VMPL levels to enforce hierarchical in-CVM isolation of\n  memory. A similar feature is also supported in TDX 1.5.\n- Note, VMPL switching is costly due to the need of VMExits ([veil]), so\n  asynchronous RPC communication should be considered across the domains.\n- Exploiting this to build isolation boundaries is a source of novelty.\n\n### Flexible data path\n\nAside from the traditional networking stack, we should ideally support other\ndata paths e.g., DPDK, or at least make it not so hard to port them to our\nframework.\n\n### Attack surface minimization with performance considerations\n\n- **Minimizing TCB** Instead of minimizing attack surfaces, we should instead\n  minimize the TCB that interacts with untrusted input.\n  - E.g., [gramine-tdx] minimized the no. of virtqueues to be used that I don't\n    think make sense. Each virtqueue is essentially accessed by the same code\n    base.\n- **No notification / Poll first** Notifications are fundamentally difficult to\n  harden due to races, while does not contribute much to performance.\n  - Are there cases where they are a must?\n- **Performance** Other optimizations, e.g., packed virtqueues, indirection,\n  that meaningfully impact performance, should still be compatible with this new\n  interface.\n\n### Speculative execution mitigations\n\n- [speculative] mentioned hypervisor-given indexes in the vrings might be used\n  for speculative execution.\n- Ideally all indexes / pointers should be masked before use.\n- May be Related: paper from David [secret-free-hypervisor]\n\n### Fine-grained compartmentalization of the TCP stack\n\n- The TCP stack is organized in layers, but there haven't been discussions to\n  split it.\n\n## Sketch design: I/O Monitor\n\n[Src](https://excalidraw.com/#json=GHAbzT6Lub5UbvPPiHY7c,oxBzneS8cORp1zgLn8-jzQ)\n![image](https://hackmd.io/_uploads/H1m8hNKNJg.png)\n\nWe introduce an entity called \"I/O Monitor (IOMon)\" that interposes all\ncommunication between guest and host.\n\n- The goal of IOMon is not to deprivilege the main kernel (e.g., NestedKernel),\n  but to shepherd safe I/O:\n  - Discouraging unsafe interactions (e.g., direct shared memory access).\n  - Provide safe abstraction for the stacks to do their job.\n  - We want to make hardening IOMon as simple as possible (minimizing TCB,\n    automatic checks, safe-by-default primitives).\n- Mutual distrust: IOMon has two ends, the in-CVM one that handle CVM-side I/O\n  and in-hypervisor one that handle hypervisor-side I/O.\n- CVM interfaces:\n  - IO memory allocation. Enforce \"trusted component allocate\"\n  - Metadata management. Enforce one-time read \u0026 sanitization\n  - Feature negotiation and transaction\n- Hypervisor interfaces. TBD.\n- Capabilities. TBD.\n  - Considering using capabilities.\n  - Related: LXD, LVD used a microkernel architecture to manage asynchronous\n    communication between isolated driver and core kernel.\n  - Capabilities makes the verification for some operations simple, and\n    minimizing TCB.\n  - May be hard to retrofit into existing interfaces.\n\n### Issues\n\n- I expect cutting the networking stack from the kernel is not easy. But do we\n  need to at all? An approach may be to run two versions of linux\n\n---\n\n[confidential-io]: https://dl.acm.org/doi/10.1145/3593856.3595913\n[gramine-tdx]:\n\thttps://dse.in.tum.de/wp-content/uploads/2024/10/Gramine_TDX-CCS24.pdf\n[bridge]: http://arxiv.org/abs/2403.03360\n[redleaf]:\n\thttps://www.usenix.org/conference/osdi20/presentation/narayanan-vikram\n[virtio-hardening]: https://lwn.net/Articles/865216/\n[bifrost]: https://www.usenix.org/conference/atc23/presentation/li-dingji\n[midas]:\n\thttps://www.usenix.org/conference/usenixsecurity22/presentation/bhattacharyya\n[virtio-console1]:\n\thttps://lore.kernel.org/lkml/87a62eqo4h.fsf@ubik.fi.intel.com/T/#m2eab864030afd60f309ffa23909defd54b7dc426\n[virtio-console2]:\n\thttps://github.com/intel/tdx/commit/a89bbb3f3701e8c9efb8333882ca4cc923e3b1e4\n[speculative]:\n\thttps://github.com/intel/tdx/commit/7ad4a0fc9bfa762c3c44b011caf4d277abd3d9d1\n[secret-free-hypervisor]:\n\thttps://www.microsoft.com/en-us/research/uploads/prod/2022/07/sf-hypervisor.pdf\n[veil]: https://dl.acm.org/doi/pdf/10.1145/3623278.3624763#page=10.46\n","wordCount":2151,"tags":["project"],"metadata":{},"created":"2024-12-03T07:29:41.802124209Z","modified":"2024-12-23T04:12:46.564151614Z","checksum":"8913588dd4ba2627b8d15276c6b6859e01b4a21947965c437e2ff69537e11be8"},
    {"filename":"zmxk4kdo.md","filenameStem":"zmxk4kdo","path":"zmxk4kdo.md","absPath":"/home/khadd/mynotes/zmxk4kdo.md","title":"Safely Handle Interleaving Code and Data in Disassembly","link":"[[zmxk4kdo]]","lead":"Most disassembly tool that use linear scan from the entries cannot handle data\nin between code, due to the problem of unintended instruction [[njh7pnzn]].","body":"Most disassembly tool that use linear scan from the entries cannot handle data\nin between code, due to the problem of unintended instruction [[njh7pnzn]].\n\nTo take this, an approach is to treat every possible byte offset as potential\ninstruction boundary (superset disassembly [@bauman2018superset]). This is\ncombined with runtime address translation by looking at the target of control\ntransfer to determine the correct candidate. This may bloat the binary size of\nup to 5 times [@priyadarshan2023safer], so some heuristics may be used to\noptimize the process.","snippets":["Most disassembly tool that use linear scan from the entries cannot handle data\nin between code, due to the problem of unintended instruction [[njh7pnzn]]."],"rawContent":"# Safely Handle Interleaving Code and Data in Disassembly\n\nMost disassembly tool that use linear scan from the entries cannot handle data\nin between code, due to the problem of unintended instruction [[njh7pnzn]].\n\nTo take this, an approach is to treat every possible byte offset as potential\ninstruction boundary (superset disassembly [@bauman2018superset]). This is\ncombined with runtime address translation by looking at the target of control\ntransfer to determine the correct candidate. This may bloat the binary size of\nup to 5 times [@priyadarshan2023safer], so some heuristics may be used to\noptimize the process.\n","wordCount":94,"tags":[],"metadata":{},"created":"2024-07-22T01:54:41.390320939Z","modified":"2024-07-22T02:04:47.125311956Z","checksum":"68eb2b33dd455fda610b74887d9d20ca1249cdb54c8ee3daf6a18b3e0f077595"},
    {"filename":"rvh8w3tb.md","filenameStem":"rvh8w3tb","path":"rvh8w3tb.md","absPath":"/home/khadd/mynotes/rvh8w3tb.md","title":"Saving status flags in x86","link":"[[rvh8w3tb]]","lead":"When dealing with static instrumentation it is important to save the status\nflags and restore them for correct execution.","body":"When dealing with static instrumentation it is important to save the status\nflags and restore them for correct execution.\n\n`pushf`/`popf` [c9x](https://c9x.me/x86/html/file_module_x86_id_271.html) can be\nused to push and pop the flag register, but they are very slow for some reason.\n\n- \u003chttps://reverseengineering.stackexchange.com/questions/9348/why-are-pushf-and-popf-so-slow\u003e\n- \u003chttps://reviews.llvm.org/D6629\u003e\n\nThe preferred way used in LLVM is `LAHF` and `SAHF` (Load status flags into AH\nand store AH into status flags)\n\nNote: These instructions do not deal with overflow flag `OF`, which much be\nbacked up somehow.\n\nThis procedure can be seen in binary instrumentation:\n\n```asm\npush %rax \t; Backup rax\nlahf \t\t; Load flags into higher ax 8 bits (ah)\nseto %al \t; set overflow flag to lower ax 8 bits (al)\npush rax \t; backup rax\n...\npop %rax\nadd 0x7f,%al \t; restore overflow flags by manually trigger an overflow\nsahf \t\t; Restore ah -\u003e flag register\npop %rax \t; Restore actual xrax\n\n```","snippets":["When dealing with static instrumentation it is important to save the status\nflags and restore them for correct execution."],"rawContent":"# Saving status flags in x86\n\nWhen dealing with static instrumentation it is important to save the status\nflags and restore them for correct execution.\n\n`pushf`/`popf` [c9x](https://c9x.me/x86/html/file_module_x86_id_271.html) can be\nused to push and pop the flag register, but they are very slow for some reason.\n\n- \u003chttps://reverseengineering.stackexchange.com/questions/9348/why-are-pushf-and-popf-so-slow\u003e\n- \u003chttps://reviews.llvm.org/D6629\u003e\n\nThe preferred way used in LLVM is `LAHF` and `SAHF` (Load status flags into AH\nand store AH into status flags)\n\nNote: These instructions do not deal with overflow flag `OF`, which much be\nbacked up somehow.\n\nThis procedure can be seen in binary instrumentation:\n\n```asm\npush %rax \t; Backup rax\nlahf \t\t; Load flags into higher ax 8 bits (ah)\nseto %al \t; set overflow flag to lower ax 8 bits (al)\npush rax \t; backup rax\n...\npop %rax\nadd 0x7f,%al \t; restore overflow flags by manually trigger an overflow\nsahf \t\t; Restore ah -\u003e flag register\npop %rax \t; Restore actual xrax\n\n```\n","wordCount":155,"tags":[],"metadata":{},"created":"2024-07-24T11:27:25.318318317Z","modified":"2024-07-25T05:23:05.649333012Z","checksum":"4c27545ed222fb31274433ea26bd9c66e37a50bedaf02a21394162391b92141b"},
    {"filename":"2i45v7qf.md","filenameStem":"2i45v7qf","path":"2i45v7qf.md","absPath":"/home/khadd/mynotes/2i45v7qf.md","title":"Scaling Networking Stack","link":"[[2i45v7qf]]","lead":"The main ideas to scaling networking","body":"The main ideas to scaling networking\n\n1. Packet from the same flow [[vbeb82fs]] must be processed together, e.g,.,\n   aranged in the smame ring buffer. This avoid complexities with out-of-order\n   packet reordering and also the need for looking for packets all over the\n   places ([[vtn586yc]]).\n2. Packets should be processed from start to finish by the same stack, e.g.,\n   [[llh2ly47]], to reduce bottle necks with scheduling, kernel crossing\n   [[471vf8vr]]","snippets":["The main ideas to scaling networking"],"rawContent":"# Scaling Networking Stack\n\nThe main ideas to scaling networking\n\n1. Packet from the same flow [[vbeb82fs]] must be processed together, e.g,.,\n   aranged in the smame ring buffer. This avoid complexities with out-of-order\n   packet reordering and also the need for looking for packets all over the\n   places ([[vtn586yc]]).\n2. Packets should be processed from start to finish by the same stack, e.g.,\n   [[llh2ly47]], to reduce bottle necks with scheduling, kernel crossing\n   [[471vf8vr]]\n","wordCount":72,"tags":[],"metadata":{},"created":"2024-12-16T03:56:49.069901041Z","modified":"2024-12-16T03:56:38.548890167Z","checksum":"916378cd27021404ea353e3c29346ca8b841f3ac6072f2ad95431855ab2acc9c"},
    {"filename":"hds749uu.md","filenameStem":"hds749uu","path":"hds749uu.md","absPath":"/home/khadd/mynotes/hds749uu.md","title":"Scheduling your life like a CPU","link":"[[hds749uu]]","lead":"Managing personal tasks and time has become a significant challenge in our increasingly complex world. Traditional to-do lists often fall short, needing more sophisticated methods for prioritizing and selecting the most suitable task to tackle next.","body":"Managing personal tasks and time has become a significant challenge in our increasingly complex world. Traditional to-do lists often fall short, needing more sophisticated methods for prioritizing and selecting the most suitable task to tackle next.\n\nCPU scheduling, one of the core functions of operating systems, offers intriguing parallels to human task management. Both goals are maximizing productivity (CPU utilization) within a limited time budget. Unfortunately, concepts and principles from CPU scheduling, which have been honed for decades, are less explored in the context of personal task management.\n\nBy understanding how computers efficiently manage multiple tasks and resources and by recognizing the unique aspects of human cognition and behavior, we can finally have a systematic solution to the problem of deciding which to cross off on your to-do list, avoid decision fatigue, and work on your personal goals in a \"fair\" manner.\n\n## Issues with to-do lists\n\nWhile ubiquitous, to-do lists often fail to address the nuances of modern productivity needs. The core issue lies in their lack of sophisticated methods for prioritizing and selecting the most suitable task to tackle next. Now, this issue is nothing new, so to-do list users often additionally assign priorities like high, medium, or low to tasks as an effort to prioritize.\n\nWhile this approach seems logical on the surface, I argue that it does little to help the user decide what to do next due to several core issues:\n\n- Inflation: Over time, users tend to mark an increasing number of tasks as having high priority, defeating the purpose of categorization.\n- Static nature: Priorities are often static, but task importance and urgency can change rapidly based on new information or circumstances. Updating priorities for numerous tasks takes time, adding to rather than reducing cognitive load.\n- Limited context: Simple tags like deadlines and priority often fail to account for nuanced factors like the user's current energy levels and available time.\n- Decision fatigue: Despite the added information, users can still face difficulty deciding which task to tackle next when many tasks must be considered. This mental exhaustion from repeated decisions can paradoxically lead to procrastination or poor choices in task selection.\n\nAs a result, many people stare at long to-do lists, feeling overwhelmed and unsure where to start, despite having dutifully assigned priorities and deadlines to their tasks.\n\nThe situation calls for a more intelligent and dynamic approach to task management - one that can adapt to changing circumstances, account for various factors, and reduce the cognitive load of constant decision-making and system maintenance.\n\n## A primer on CPU scheduling\n\nWe now turn to an unexpected source of inspiration: the world of computer science and, more specifically, CPU scheduling algorithms. In operating systems, the job of a CPU scheduler is to guarantee that every piece of software is given a \"slice\" of execution time on the CPUs without one program overwhelming the others (i.e., fairness).\n\nTo better understand why schedulers exist, imagine you're a chef in a busy restaurant kitchen. Your job is to prepare multiple dishes for different customers. Still, you only have one stove. \"fairness\" is essential here: you don't want to keep any particular customer from waiting too long. This scenario is similar to how a scheduler (the chef) has to manage multiple tasks (dishes) on a CPU (a single stove).\n\nHere's how a simple CPU scheduling algorithm called Round Robin might work in this kitchen scenario. Imagine that you have four orders coming:\n\n1. Pasta (15 minutes)\n2. Stir-fry (15 mins)\n3. Soup (10 mins)\n4. Salad (5 minutes).\n\nUsing Round Robin, you spend 5 minutes on each dish before moving to the next one. The process goes like this:\n\n1. Spend 5 minutes on Pasta\n2. Switch to Stir-fry for 5 minutes\n3. Move to Soup for 5 minutes\n4. Prepare Salad for 5 minutes\n5. Then back to Pasta for another 5 minutes\n6. You keep rotating through the dishes until all is complete.\n\nNote that this approach is by no means optimal. For instance, while waiting for the soup to cook on the stove, you can make the Salad. However, it achieves the desired \"fairness\": all dishes get attention, and no single dish monopolizes the stove.\n\n## Toward scheduling your life like a CPU\n\nAs we've seen, CPU scheduling offers intriguing parallels to personal task management. By adapting these concepts to our daily lives, we can create a more efficient and balanced approach to productivity. Let's explore how an automatic personal scheduler could work, discussing both the similarities where CPU scheduling concepts can be directly applied and the differences that require\nadjustment.\n\n### Selecting what to do next\n\nOne of the core strengths of CPU scheduling is its ability to manage multiple tasks fairly and efficiently. This concept can be directly applied to personal task management. Like a CPU using Round Robin scheduling, we can allocate time slices to different life areas or tasks, ensuring that all important aspects of our lives receive attention. This prevents the common problem of neglecting important but non-urgent tasks in favor of seemingly pressing matters.\n\n\nAdditionally, CPU schedulers are adept at handling deadline constraints, a feature in real-time operating systems that translates well to personal task management. We can balance urgent tasks with ongoing responsibilities by implementing a deadline-aware system.\n\nPrioritization, another critical aspect of modern CPU schedulers, is equally crucial in personal task management. In fact, By assigning priorities to our tasks, we can ensure that high-importance items receive adequate attention while maintaining overall fairness in our schedule.\n\n### Human context switching\n\nWhile CPUs excel at rapid switching between tasks (context switching), humans face more significant challenges in this area. Efficient multitasking is a myth [multitasking], and most researches show that humans perform better when focusing on one context at a time.\n\nTasks within one context, like a programming project, require less effort to switch between. Indeed, research has shown that context-switching within different aspects of a task is necessary to achieve better learning. One strategy is to group similar tasks, much like CPU scheduling puts similar tasks on a dedicated CPU to better utilize its cache. Batching of related tasks can reduce the cognitive load associated with context switching. For example, you might group email-related tasks or tasks in your ongoing projects such that they are not\nscheduled together.\n\nMoreover, humans typically require more time to disengage from current tasks and may resist frequent interruptions. To address this, we can implement a system of controlled task switching. Techniques like the Pomodoro method, which creates natural break points between focused work sessions, can be incorporated into our personal scheduling system. This approach allows for necessary fairness between tasks while respecting the human need for sustained focus.\n\n### Human resource management\n\nWhile CPU resource management primarily focuses on allocating processing power and memory, human resource management in personal scheduling is far more complex and nuanced. Let's briefly go over human resources that may impact task selection.\n\nPerformance throughout the day: Unlike CPUs that maintain consistent performance until powered off, human energy levels and focus fluctuate throughout the day. This variation is influenced by circadian rhythms, diet, sleep quality, and physical activity. One way a scheduler considers this is to schedule high-impact tasks during the peak of your performance, typically at the start of the day (unless you are a night owl), while delegating less-important tasks toward the end.\n\nMotivation and Emotional state: Our emotional state significantly impacts our productivity and decision-making abilities. Unlike CPUs, humans can't simply ignore or override emotional factors. This means that sometimes, you are in the mood for irrational schedules, like putting all your time and resources toward a particular project. While taking into account this factor is challenging, it may be achieved through human feedback.\n\n## What's next?\n\nThis article discusses a rather simple framework in which CPU scheduling algorithms might be adapted for task management. While the content of the article is highly hypothetical, I plan to realize such a system soon. It is important to remember that you are only human. Hence, the goal is not to push yourself to CPU-like consistency but rather to help you reduce decision fatigue while respecting your uniquely human resources.\n\n\n- [multitasking]: https://asana.com/resources/multitasking","snippets":["Managing personal tasks and time has become a significant challenge in our increasingly complex world. Traditional to-do lists often fall short, needing more sophisticated methods for prioritizing and selecting the most suitable task to tackle next."],"rawContent":"# Scheduling your life like a CPU\n\nManaging personal tasks and time has become a significant challenge in our increasingly complex world. Traditional to-do lists often fall short, needing more sophisticated methods for prioritizing and selecting the most suitable task to tackle next.\n\nCPU scheduling, one of the core functions of operating systems, offers intriguing parallels to human task management. Both goals are maximizing productivity (CPU utilization) within a limited time budget. Unfortunately, concepts and principles from CPU scheduling, which have been honed for decades, are less explored in the context of personal task management.\n\nBy understanding how computers efficiently manage multiple tasks and resources and by recognizing the unique aspects of human cognition and behavior, we can finally have a systematic solution to the problem of deciding which to cross off on your to-do list, avoid decision fatigue, and work on your personal goals in a \"fair\" manner.\n\n## Issues with to-do lists\n\nWhile ubiquitous, to-do lists often fail to address the nuances of modern productivity needs. The core issue lies in their lack of sophisticated methods for prioritizing and selecting the most suitable task to tackle next. Now, this issue is nothing new, so to-do list users often additionally assign priorities like high, medium, or low to tasks as an effort to prioritize.\n\nWhile this approach seems logical on the surface, I argue that it does little to help the user decide what to do next due to several core issues:\n\n- Inflation: Over time, users tend to mark an increasing number of tasks as having high priority, defeating the purpose of categorization.\n- Static nature: Priorities are often static, but task importance and urgency can change rapidly based on new information or circumstances. Updating priorities for numerous tasks takes time, adding to rather than reducing cognitive load.\n- Limited context: Simple tags like deadlines and priority often fail to account for nuanced factors like the user's current energy levels and available time.\n- Decision fatigue: Despite the added information, users can still face difficulty deciding which task to tackle next when many tasks must be considered. This mental exhaustion from repeated decisions can paradoxically lead to procrastination or poor choices in task selection.\n\nAs a result, many people stare at long to-do lists, feeling overwhelmed and unsure where to start, despite having dutifully assigned priorities and deadlines to their tasks.\n\nThe situation calls for a more intelligent and dynamic approach to task management - one that can adapt to changing circumstances, account for various factors, and reduce the cognitive load of constant decision-making and system maintenance.\n\n## A primer on CPU scheduling\n\nWe now turn to an unexpected source of inspiration: the world of computer science and, more specifically, CPU scheduling algorithms. In operating systems, the job of a CPU scheduler is to guarantee that every piece of software is given a \"slice\" of execution time on the CPUs without one program overwhelming the others (i.e., fairness).\n\nTo better understand why schedulers exist, imagine you're a chef in a busy restaurant kitchen. Your job is to prepare multiple dishes for different customers. Still, you only have one stove. \"fairness\" is essential here: you don't want to keep any particular customer from waiting too long. This scenario is similar to how a scheduler (the chef) has to manage multiple tasks (dishes) on a CPU (a single stove).\n\nHere's how a simple CPU scheduling algorithm called Round Robin might work in this kitchen scenario. Imagine that you have four orders coming:\n\n1. Pasta (15 minutes)\n2. Stir-fry (15 mins)\n3. Soup (10 mins)\n4. Salad (5 minutes).\n\nUsing Round Robin, you spend 5 minutes on each dish before moving to the next one. The process goes like this:\n\n1. Spend 5 minutes on Pasta\n2. Switch to Stir-fry for 5 minutes\n3. Move to Soup for 5 minutes\n4. Prepare Salad for 5 minutes\n5. Then back to Pasta for another 5 minutes\n6. You keep rotating through the dishes until all is complete.\n\nNote that this approach is by no means optimal. For instance, while waiting for the soup to cook on the stove, you can make the Salad. However, it achieves the desired \"fairness\": all dishes get attention, and no single dish monopolizes the stove.\n\n## Toward scheduling your life like a CPU\n\nAs we've seen, CPU scheduling offers intriguing parallels to personal task management. By adapting these concepts to our daily lives, we can create a more efficient and balanced approach to productivity. Let's explore how an automatic personal scheduler could work, discussing both the similarities where CPU scheduling concepts can be directly applied and the differences that require\nadjustment.\n\n### Selecting what to do next\n\nOne of the core strengths of CPU scheduling is its ability to manage multiple tasks fairly and efficiently. This concept can be directly applied to personal task management. Like a CPU using Round Robin scheduling, we can allocate time slices to different life areas or tasks, ensuring that all important aspects of our lives receive attention. This prevents the common problem of neglecting important but non-urgent tasks in favor of seemingly pressing matters.\n\n\nAdditionally, CPU schedulers are adept at handling deadline constraints, a feature in real-time operating systems that translates well to personal task management. We can balance urgent tasks with ongoing responsibilities by implementing a deadline-aware system.\n\nPrioritization, another critical aspect of modern CPU schedulers, is equally crucial in personal task management. In fact, By assigning priorities to our tasks, we can ensure that high-importance items receive adequate attention while maintaining overall fairness in our schedule.\n\n### Human context switching\n\nWhile CPUs excel at rapid switching between tasks (context switching), humans face more significant challenges in this area. Efficient multitasking is a myth [multitasking], and most researches show that humans perform better when focusing on one context at a time.\n\nTasks within one context, like a programming project, require less effort to switch between. Indeed, research has shown that context-switching within different aspects of a task is necessary to achieve better learning. One strategy is to group similar tasks, much like CPU scheduling puts similar tasks on a dedicated CPU to better utilize its cache. Batching of related tasks can reduce the cognitive load associated with context switching. For example, you might group email-related tasks or tasks in your ongoing projects such that they are not\nscheduled together.\n\nMoreover, humans typically require more time to disengage from current tasks and may resist frequent interruptions. To address this, we can implement a system of controlled task switching. Techniques like the Pomodoro method, which creates natural break points between focused work sessions, can be incorporated into our personal scheduling system. This approach allows for necessary fairness between tasks while respecting the human need for sustained focus.\n\n### Human resource management\n\nWhile CPU resource management primarily focuses on allocating processing power and memory, human resource management in personal scheduling is far more complex and nuanced. Let's briefly go over human resources that may impact task selection.\n\nPerformance throughout the day: Unlike CPUs that maintain consistent performance until powered off, human energy levels and focus fluctuate throughout the day. This variation is influenced by circadian rhythms, diet, sleep quality, and physical activity. One way a scheduler considers this is to schedule high-impact tasks during the peak of your performance, typically at the start of the day (unless you are a night owl), while delegating less-important tasks toward the end.\n\nMotivation and Emotional state: Our emotional state significantly impacts our productivity and decision-making abilities. Unlike CPUs, humans can't simply ignore or override emotional factors. This means that sometimes, you are in the mood for irrational schedules, like putting all your time and resources toward a particular project. While taking into account this factor is challenging, it may be achieved through human feedback.\n\n## What's next?\n\nThis article discusses a rather simple framework in which CPU scheduling algorithms might be adapted for task management. While the content of the article is highly hypothetical, I plan to realize such a system soon. It is important to remember that you are only human. Hence, the goal is not to push yourself to CPU-like consistency but rather to help you reduce decision fatigue while respecting your uniquely human resources.\n\n\n- [multitasking]: https://asana.com/resources/multitasking\n","wordCount":1374,"tags":[],"metadata":{},"created":"2024-07-23T07:05:02.008522648Z","modified":"2024-07-23T06:54:21.43995099Z","checksum":"f368457e3c901bca9ac7b43a7d2e2093403f324bd219fb9db125f0f2332649d3"},
    {"filename":"oilqk2v8.md","filenameStem":"oilqk2v8","path":"oilqk2v8.md","absPath":"/home/khadd/mynotes/oilqk2v8.md","title":"Scientists discover the world that exists; engineers create the world that never was","link":"[[oilqk2v8]]","lead":"#quote","body":"#quote\n\nby Theodore Von Karman\n\n- [from]: https://www.linzhong.org/opinions/sciencesofsystembuilding.html","snippets":["#quote"],"rawContent":"# Scientists discover the world that exists; engineers create the world that never was\n\n#quote\n\nby Theodore Von Karman\n\n- [from]: https://www.linzhong.org/opinions/sciencesofsystembuilding.html\n","wordCount":22,"tags":["quote"],"metadata":{},"created":"2024-12-10T06:35:53.347021288Z","modified":"2024-12-10T08:09:20.212063781Z","checksum":"63eaa0cd4d2dcb81ce0285aee672cc0ec483eaccceb8f97099bced519cf95280"},
    {"filename":"c6n7ric2.md","filenameStem":"c6n7ric2","path":"c6n7ric2.md","absPath":"/home/khadd/mynotes/c6n7ric2.md","title":"Scratch","link":"[[c6n7ric2]]","lead":"-","body":"-","snippets":["-"],"rawContent":"# Scratch\n\n-\n","wordCount":3,"tags":[],"metadata":{},"created":"2024-07-25T10:42:45.622285893Z","modified":"2024-12-09T08:51:50.551597963Z","checksum":"90110c54f2044f90f026a5ebcdaf0d4538c2be1d1f1ccd22648a684e995bc4ea"},
    {"filename":"8bxl41ng.md","filenameStem":"8bxl41ng","path":"8bxl41ng.md","absPath":"/home/khadd/mynotes/8bxl41ng.md","title":"Securing time in TEEs","link":"[[8bxl41ng]]","lead":"#tee #sgx","body":"#tee #sgx\n\nTime is an often overlooked properties in confidential computation. However, it\nis crucial for certain operations, e.g., certificate expiration.\n\n[@alder2023time] categorize 5 different levels of time security in TEEs. In all,\na secure timer must be concerned with 4 properties:\n\n1. **Rollback** protection (or monoticity) (kernel/hypervisor cannot just\n   overwrite the timer with another value)\n2. **Frequency** the untrusted software cannot tamper at the rate where the\n   timer is updated.\n3. **Delay**: some timer relies on a remote connection (e.g., PSW and SGX) that\n   goes through the untrusted software, thus susceptible to delays.\n4. **Interrupt** (or _atomicity_): To be resistant against TOCTOU type of\n   attack. After timer is read, the enclave can be interrupted constantly to\n   delay the timer use indefinitely. One way to overcome this is to disable\n   interruptions after the timer is obtained.\n\n## On external time source\n\nWhile an external secure time source may be obtained through encrypted channel,\nit usually has high overheads and requires external connection, so a local time\nsource is preferable. Another issue mentioned by [@alder2023time] ($T_2$) is\nthat the time request to an external source may be delayed (weak availability).\n\nThe use of this external time is also not _atomic_, in that when it is obtained\nand it is used, the time passed may be different (a kind of TOCTOU?). For\nexample, the attacker can interrupt right after the time is obtained, and delay\nthe enclave until the time is used (while the actual time has been passed is\nlong gone).\n\n[@duan2019lightbox] protect middle box in SGX uses the packet timestamp as a\nsource for trusted source of clock. As packets frequently arrive, the clock is\nupdated quite frequently. The source of time is also trusted as the aim is to\nprotect all packet metadata. Maybe one potential problem is cross-user attacks.","snippets":["#tee #sgx"],"rawContent":"# Securing time in TEEs\n\n#tee #sgx\n\nTime is an often overlooked properties in confidential computation. However, it\nis crucial for certain operations, e.g., certificate expiration.\n\n[@alder2023time] categorize 5 different levels of time security in TEEs. In all,\na secure timer must be concerned with 4 properties:\n\n1. **Rollback** protection (or monoticity) (kernel/hypervisor cannot just\n   overwrite the timer with another value)\n2. **Frequency** the untrusted software cannot tamper at the rate where the\n   timer is updated.\n3. **Delay**: some timer relies on a remote connection (e.g., PSW and SGX) that\n   goes through the untrusted software, thus susceptible to delays.\n4. **Interrupt** (or _atomicity_): To be resistant against TOCTOU type of\n   attack. After timer is read, the enclave can be interrupted constantly to\n   delay the timer use indefinitely. One way to overcome this is to disable\n   interruptions after the timer is obtained.\n\n## On external time source\n\nWhile an external secure time source may be obtained through encrypted channel,\nit usually has high overheads and requires external connection, so a local time\nsource is preferable. Another issue mentioned by [@alder2023time] ($T_2$) is\nthat the time request to an external source may be delayed (weak availability).\n\nThe use of this external time is also not _atomic_, in that when it is obtained\nand it is used, the time passed may be different (a kind of TOCTOU?). For\nexample, the attacker can interrupt right after the time is obtained, and delay\nthe enclave until the time is used (while the actual time has been passed is\nlong gone).\n\n[@duan2019lightbox] protect middle box in SGX uses the packet timestamp as a\nsource for trusted source of clock. As packets frequently arrive, the clock is\nupdated quite frequently. The source of time is also trusted as the aim is to\nprotect all packet metadata. Maybe one potential problem is cross-user attacks.\n","wordCount":306,"tags":["sgx","tee"],"metadata":{},"created":"2024-05-30T03:02:28.538392297Z","modified":"2024-12-09T09:48:17.129292239Z","checksum":"c7fc9e94b64fd76a25ee45083261ebbf1b4c3c8813bc7b8e5fe2a0432f37e653"},
    {"filename":"rbahtbk5.md","filenameStem":"rbahtbk5","path":"rbahtbk5.md","absPath":"/home/khadd/mynotes/rbahtbk5.md","title":"Security analsyis rerandomization","link":"[[rbahtbk5]]","lead":"Consider a program accessing a working set $\\mathcal{W}$ of n pages based on\nsome secret value s. The attacker knows both the complete access sequence and\ntiming of accesses. For each rerandomization cycle, the number of possible\narrangements of n pages is given by n!. Even with known access patterns, the\nattacker must consider all possible mappings between logical and physical\naddresses at each cycle.","body":"Consider a program accessing a working set $\\mathcal{W}$ of n pages based on\nsome secret value s. The attacker knows both the complete access sequence and\ntiming of accesses. For each rerandomization cycle, the number of possible\narrangements of n pages is given by n!. Even with known access patterns, the\nattacker must consider all possible mappings between logical and physical\naddresses at each cycle.\n\n# Security Analysis\n\nWhen attempting to infer the location of a specific logical page across\nrerandomization cycles, an attacker faces exponentially growing uncertainty.\nGiven p possible positions within each physical frame, after each\nrerandomization, the potential locations for any given logical page multiply by\nfactor p. After r rerandomization cycles, a single logical page could reside in\nany of p^r possible positions. For typical values (p=32, r=3), this expansion\nquickly encompasses the entire address space, making any inference attempt\ncomputationally infeasible.\n\n# Practical Security Guarantees\n\nThe adaptive rerandomization strategy ensures sufficient frequency of\nrerandomization cycles to achieve full address space coverage before an attacker\ncould meaningfully reduce the search space. Through empirical analysis, we found\nthat with typical parameters, full coverage is achieved within [X] milliseconds,\nwell within our minimum rerandomization window of [Y] milliseconds. Even if an\nattacker can determine which logical page is being accessed at a given moment\n(due to known access patterns), the randomization of physical locations ensures\nthat this knowledge becomes obsolete after each rerandomization cycle. The\nattacker must restart their analysis with each new cycle, facing the same\nexponential growth in possibilities.","snippets":["Consider a program accessing a working set $\\mathcal{W}$ of n pages based on\nsome secret value s. The attacker knows both the complete access sequence and\ntiming of accesses. For each rerandomization cycle, the number of possible\narrangements of n pages is given by n!. Even with known access patterns, the\nattacker must consider all possible mappings between logical and physical\naddresses at each cycle."],"rawContent":"# Security analsyis rerandomization\n\nConsider a program accessing a working set $\\mathcal{W}$ of n pages based on\nsome secret value s. The attacker knows both the complete access sequence and\ntiming of accesses. For each rerandomization cycle, the number of possible\narrangements of n pages is given by n!. Even with known access patterns, the\nattacker must consider all possible mappings between logical and physical\naddresses at each cycle.\n\n# Security Analysis\n\nWhen attempting to infer the location of a specific logical page across\nrerandomization cycles, an attacker faces exponentially growing uncertainty.\nGiven p possible positions within each physical frame, after each\nrerandomization, the potential locations for any given logical page multiply by\nfactor p. After r rerandomization cycles, a single logical page could reside in\nany of p^r possible positions. For typical values (p=32, r=3), this expansion\nquickly encompasses the entire address space, making any inference attempt\ncomputationally infeasible.\n\n# Practical Security Guarantees\n\nThe adaptive rerandomization strategy ensures sufficient frequency of\nrerandomization cycles to achieve full address space coverage before an attacker\ncould meaningfully reduce the search space. Through empirical analysis, we found\nthat with typical parameters, full coverage is achieved within [X] milliseconds,\nwell within our minimum rerandomization window of [Y] milliseconds. Even if an\nattacker can determine which logical page is being accessed at a given moment\n(due to known access patterns), the randomization of physical locations ensures\nthat this knowledge becomes obsolete after each rerandomization cycle. The\nattacker must restart their analysis with each new cycle, facing the same\nexponential growth in possibilities.\n","wordCount":257,"tags":[],"metadata":{},"created":"2024-10-30T04:46:02.318918144Z","modified":"2024-11-22T05:20:04.13570815Z","checksum":"ea18e7a80586f8577cd35cda5317c651737e9f324cdd685fa24f80bb5b8c222e"},
    {"filename":"8113ygxd.md","filenameStem":"8113ygxd","path":"8113ygxd.md","absPath":"/home/khadd/mynotes/8113ygxd.md","title":"Separating mechanism and policy","link":"[[8113ygxd]]","lead":"This is principle in systems design that advocates for separating the mechanism\n(parts of the system that enforce authorization, resource allocation) and the\npolicy (how and when to authorize a resource, which resource to allocate).","body":"This is principle in systems design that advocates for separating the mechanism\n(parts of the system that enforce authorization, resource allocation) and the\npolicy (how and when to authorize a resource, which resource to allocate).\n\nThe principle is mostly discussed in the context of computer security, where a\nseparation of mechanism and policy would greatly improve flexibility and\nsecurity of the system [[c4icaua4]].\n\n## Microkernels\n\nThis is one of the principles behind microkernels [[sn99wrm0]]. More\nparticularly, in microkernel, the principle is instantiated as the _law of\nminimality_:\n\n\u003e A concept is tolerated inside the μ-kernel only if moving it outside the\n\u003e kernel, i.e. permitting competing implementations, would prevent the\n\u003e implementation of the system’s required functionality\n\n## Capability systems\n\nCapability systems [[khi9ihj9]] fundamentally implements separation of mechanism\nand policy, which is why it is used in many microkernels [[sn99wrm0]] designs.\n\nIn the system, the main TCB (kernel) implements the _mechanism_ layer that\nenforces properties of the capabilities, like capability storage, invocation,\ndelegation, [[y0z8fhtd]].\n\nThe _policies_ are left to be defined by the users. E.g., who initially get the\ncapabilities, how they are propagated through the system.","snippets":["This is principle in systems design that advocates for separating the mechanism\n(parts of the system that enforce authorization, resource allocation) and the\npolicy (how and when to authorize a resource, which resource to allocate)."],"rawContent":"# Separating mechanism and policy\n\nThis is principle in systems design that advocates for separating the mechanism\n(parts of the system that enforce authorization, resource allocation) and the\npolicy (how and when to authorize a resource, which resource to allocate).\n\nThe principle is mostly discussed in the context of computer security, where a\nseparation of mechanism and policy would greatly improve flexibility and\nsecurity of the system [[c4icaua4]].\n\n## Microkernels\n\nThis is one of the principles behind microkernels [[sn99wrm0]]. More\nparticularly, in microkernel, the principle is instantiated as the _law of\nminimality_:\n\n\u003e A concept is tolerated inside the μ-kernel only if moving it outside the\n\u003e kernel, i.e. permitting competing implementations, would prevent the\n\u003e implementation of the system’s required functionality\n\n## Capability systems\n\nCapability systems [[khi9ihj9]] fundamentally implements separation of mechanism\nand policy, which is why it is used in many microkernels [[sn99wrm0]] designs.\n\nIn the system, the main TCB (kernel) implements the _mechanism_ layer that\nenforces properties of the capabilities, like capability storage, invocation,\ndelegation, [[y0z8fhtd]].\n\nThe _policies_ are left to be defined by the users. E.g., who initially get the\ncapabilities, how they are propagated through the system.\n","wordCount":192,"tags":[],"metadata":{},"created":"2024-12-16T03:56:49.107995794Z","modified":"2024-12-23T06:18:46.803502272Z","checksum":"64d63ae5bdfa5af4feecd95a4a6ffdb11b361bb71d8dbe52384020851b602f42"},
    {"filename":"8igqoq32.md","filenameStem":"8igqoq32","path":"8igqoq32.md","absPath":"/home/khadd/mynotes/8igqoq32.md","title":"Single address space operating systems","link":"[[8igqoq32]]","lead":"#os #compartmentalization","body":"#os #compartmentalization\n\nSingle-address-space systems removes the kernel/userspace separation, which\nleads to better performance due to lack of content switching.\n\nHowever, this approach weaken the isolation provided by the privilege levels,\nwhich motivates them to adapt lighter-weight isolation mechanisms.\n\n## Approaches\n\n### Unikernels\n\nSee [[e7p8xpz4]].\n\n[@flexos] discusses automatic isolation unikernels.\n\n[@sartakov2021cubicleos]\n\n## Compiler/language-based\n\nAn OS requires isolation between different processes [[7t4jlnaq]]. Traditional\nOSes achieve this through the page table that virtualize each process's memory\nview [[eqbigndi]].\n\nThere has been researches that replace this the page-table-based isolation in\nsingle-address spaces OSes with programming language constraints, or\nsoftware-inserted access controls (SFI).\n\n### Redleaf\n\n[@narayanan2020redleaf] isolate domains used for device drivers in a\nmicrokernel. Memory safety of Rust (without `unsafe`) guarantee the isolation\nbetween subsystems.\n\n### CARAT\n\nCARAT [@suchy2020carat], [@suchy2022carat], explore removing paging abstraction\nand the reliance on paging hardware (Page table walker, MMU, TLB). Instead, all\nsoftware need to be compiled by a trusted compiler to use physical addressing.\nMemory protection is achieved by compiler-inserted guards.","snippets":["#os #compartmentalization"],"rawContent":"# Single address space operating systems\n\n#os #compartmentalization\n\nSingle-address-space systems removes the kernel/userspace separation, which\nleads to better performance due to lack of content switching.\n\nHowever, this approach weaken the isolation provided by the privilege levels,\nwhich motivates them to adapt lighter-weight isolation mechanisms.\n\n## Approaches\n\n### Unikernels\n\nSee [[e7p8xpz4]].\n\n[@flexos] discusses automatic isolation unikernels.\n\n[@sartakov2021cubicleos]\n\n## Compiler/language-based\n\nAn OS requires isolation between different processes [[7t4jlnaq]]. Traditional\nOSes achieve this through the page table that virtualize each process's memory\nview [[eqbigndi]].\n\nThere has been researches that replace this the page-table-based isolation in\nsingle-address spaces OSes with programming language constraints, or\nsoftware-inserted access controls (SFI).\n\n### Redleaf\n\n[@narayanan2020redleaf] isolate domains used for device drivers in a\nmicrokernel. Memory safety of Rust (without `unsafe`) guarantee the isolation\nbetween subsystems.\n\n### CARAT\n\nCARAT [@suchy2020carat], [@suchy2022carat], explore removing paging abstraction\nand the reliance on paging hardware (Page table walker, MMU, TLB). Instead, all\nsoftware need to be compiled by a trusted compiler to use physical addressing.\nMemory protection is achieved by compiler-inserted guards.\n","wordCount":169,"tags":["os","compartmentalization"],"metadata":{},"created":"2023-06-19T03:04:24.886303372Z","modified":"2024-11-28T12:18:04.780680138Z","checksum":"9b308193aa2ed3778c10dbe4667264eff9dfbf5558a810f992e6db1d8bc9fef7"},
    {"filename":"iwfcxxfi.md","filenameStem":"iwfcxxfi","path":"iwfcxxfi.md","absPath":"/home/khadd/mynotes/iwfcxxfi.md","title":"Software-based Timers in SGX","link":"[[iwfcxxfi]]","lead":"#sgx #tee #area #side-channel","body":"#sgx #tee #area #side-channel\n\nIdeally, TEE should be provided access to hardware-enforced time [[8bxl41ng]].\nHowever, SGX lacks this feature (or it is removed). Still, timing is useful in\nsome tasks, like detecting whether enclave exits happened.\n\nA class of side-channel mitigation for SGX implement _software-based timers_\n[@chen2017detecting],[@oleksenko2018varys]. They implement a counting thread\nwithin the enclave that continuously incrementing a global variable in a loop.\nSince the loop includes a few instructions, it the global variable increases at\napproximately the CPU clock rate.\n\nTo guarantee that the clock counting thread is not interrupted by the OS, Déjà\nvu [@chen2017detecting] uses TSX to detect such interruption. [@lefeuvre2024sok]","snippets":["#sgx #tee #area #side-channel"],"rawContent":"# Software-based Timers in SGX\n\n#sgx #tee #area #side-channel\n\nIdeally, TEE should be provided access to hardware-enforced time [[8bxl41ng]].\nHowever, SGX lacks this feature (or it is removed). Still, timing is useful in\nsome tasks, like detecting whether enclave exits happened.\n\nA class of side-channel mitigation for SGX implement _software-based timers_\n[@chen2017detecting],[@oleksenko2018varys]. They implement a counting thread\nwithin the enclave that continuously incrementing a global variable in a loop.\nSince the loop includes a few instructions, it the global variable increases at\napproximately the CPU clock rate.\n\nTo guarantee that the clock counting thread is not interrupted by the OS, Déjà\nvu [@chen2017detecting] uses TSX to detect such interruption. [@lefeuvre2024sok]\n","wordCount":110,"tags":["sgx","tee","side-channel","area"],"metadata":{},"created":"2024-06-10T08:29:56.848569621Z","modified":"2024-11-29T09:10:46.662401404Z","checksum":"2f288cf4b9adc4dd0f8384a2503525b40cb8794cbb2487f4d85a0cc326ca900e"},
    {"filename":"u5rnsnt1.md","filenameStem":"u5rnsnt1","path":"u5rnsnt1.md","absPath":"/home/khadd/mynotes/u5rnsnt1.md","title":"Spiral/Clockwise Rule","link":"[[u5rnsnt1]]","lead":"#c #go #programming","body":"#c #go #programming\n\nC declaration syntax is quite confusing, especially with function pointers. The\nSpiral rule is an interesting technique to wrap your head around C declarations.\n\nUsing the spiral rule, you parse a statement (in your head) by moving from\ndeclared name e.g., `str`, clockwise e.g., up, right, down, left, etc. Note,\nthings within a parenthesis should be visited first\n\nYou start with a statement:\n\n\u003e `str` is a ...\n\nWhen you meet an element, use the following rule to add the description of the\nstatement:\n\n- `[X]`: is an \"Array of size X (X can be undefined)\" of ...\n- `(type1, type2)`: function passing type `type1` and `type2` and returning ...\n- `*`: pointer(s) to ...\n\n```c\n     ┌───────┐\n     │ ┌─┐   │\n 3   2 ^ ▼   ▼\nchar *str[10];\n ▲   ▲   1   │\n │   └───┘   │\n └───────────┘\n```\n\nIn this example:\n\n\u003e `str` is an 1(array size of 10) 2(of pointer(s) to) 3(char).\n\n```c\n     ┌─────────────────┐\n     │ ┌───┐           │\n     │ │┌─┐│           │\n 4   3 1│ ▼▼           ▼\nchar *(*fp)(int,float*);\n ▲   ▲ ▲  │2           │\n │   │ └──┘│           │\n │   └─────┘           │\n └─────────────────────┘\n```\n\n\u003e `fp` is a 1(pointer) of type 2(function passing type `int` and `float*`) tat\n\u003e returns 3(pointer(s)) to 4(`char`).\n\n## Go\n\nGo instead goes for a more human-readable style that can be read left-to-right.\n\n```go\nvar str [10]*string\n     1  2   34\n     ────────────►\n```\n\nThis declaration in Go reads:\n\n\u003e `str` is a array of size 10 of poitners to `string`","snippets":["#c #go #programming"],"rawContent":"# Spiral/Clockwise Rule\n\n#c #go #programming\n\nC declaration syntax is quite confusing, especially with function pointers. The\nSpiral rule is an interesting technique to wrap your head around C declarations.\n\nUsing the spiral rule, you parse a statement (in your head) by moving from\ndeclared name e.g., `str`, clockwise e.g., up, right, down, left, etc. Note,\nthings within a parenthesis should be visited first\n\nYou start with a statement:\n\n\u003e `str` is a ...\n\nWhen you meet an element, use the following rule to add the description of the\nstatement:\n\n- `[X]`: is an \"Array of size X (X can be undefined)\" of ...\n- `(type1, type2)`: function passing type `type1` and `type2` and returning ...\n- `*`: pointer(s) to ...\n\n```c\n     ┌───────┐\n     │ ┌─┐   │\n 3   2 ^ ▼   ▼\nchar *str[10];\n ▲   ▲   1   │\n │   └───┘   │\n └───────────┘\n```\n\nIn this example:\n\n\u003e `str` is an 1(array size of 10) 2(of pointer(s) to) 3(char).\n\n```c\n     ┌─────────────────┐\n     │ ┌───┐           │\n     │ │┌─┐│           │\n 4   3 1│ ▼▼           ▼\nchar *(*fp)(int,float*);\n ▲   ▲ ▲  │2           │\n │   │ └──┘│           │\n │   └─────┘           │\n └─────────────────────┘\n```\n\n\u003e `fp` is a 1(pointer) of type 2(function passing type `int` and `float*`) tat\n\u003e returns 3(pointer(s)) to 4(`char`).\n\n## Go\n\nGo instead goes for a more human-readable style that can be read left-to-right.\n\n```go\nvar str [10]*string\n     1  2   34\n     ────────────►\n```\n\nThis declaration in Go reads:\n\n\u003e `str` is a array of size 10 of poitners to `string`\n","wordCount":246,"tags":["programming","c","go"],"metadata":{},"created":"2024-07-01T05:43:28.356492302Z","modified":"2024-07-01T06:04:57.516707733Z","checksum":"725bd8d7bee44e9a5bdf31962f4ba10167e5231b9556f839ce501d671a4972d9"},
    {"filename":"2j6s9zpm.md","filenameStem":"2j6s9zpm","path":"2j6s9zpm.md","absPath":"/home/khadd/mynotes/2j6s9zpm.md","title":"State spill in software systems","link":"[[2j6s9zpm]]","lead":"#area #os #microkernel","body":"#area #os #microkernel\n\nState spills happen when a seemingly isolated and modularized software component\nchanges its state due to interactions with other components, such that future\ncorrectness depends on such a state.\n\n- [@boos2017characterization]: Introduce the term state spill and provides its\n  classification.\n\n## State spill hurts extensibility\n\nExtensibility issues happen when an entity provides an abstraction layer for\nother entities.\n\n- For example, on Linux, the OS process abstraction stores state into members of\n  `task_struct`, which might also contain objects from other OS entities. This\n  prevents _process mitigation_, since the OS must keep track of all changes\n  made to other OS entities.\n- In microkernels, the abstraction layer is provided by the userspace server.\n  State spills into the userspace servers prevent their live update and\n  hot-swapping since other applications are dependent on those implicit states.\n\n## State spill hurts availability\n\nState spills hurt the availability of systems (it breaks fault isolation and\nfault tolerance). This happens when an entity acts as a _multiplexer_ that\nallows multiple clients to access an underlying resource.\n\n- Corruptions caused by state spills in _Process management_ entities in OS\n  cause all process to be affected.\n- _Recovery_ of servers is also hindered due to state spill, recovery on behalf\n  of one client can affect other clients.\n\n## Tackling state spill\n\nSolving state spill issues require that either\n\n1. All modules in the system keep track of which state that they require, and\n   which state that they own. This is difficult in practice if the interface is\n   not built with this in mind (e.g., kernel modules).\n2. All modules follow a set of rules that avoid state spill in the first place.\n   For example, states that are exported to other modules must be allocated by\n   the caller. This may be enforced through programming language invariants\n   [@boos2020theseus].\n\nRemoving state spill forces the caller to memory to allocate the context used\nfor cross-compartment interaction. In a sense, it also improves the security of\nthe per-compartment interface. See 1 and 4 in [[qti6u06p]].\n\n- [@boos2020theseus] (see [[jfm8ud28]]): An operating system design that aim to\n  minimize state spill.","snippets":["#area #os #microkernel"],"rawContent":"# State spill in software systems\n\n#area #os #microkernel\n\nState spills happen when a seemingly isolated and modularized software component\nchanges its state due to interactions with other components, such that future\ncorrectness depends on such a state.\n\n- [@boos2017characterization]: Introduce the term state spill and provides its\n  classification.\n\n## State spill hurts extensibility\n\nExtensibility issues happen when an entity provides an abstraction layer for\nother entities.\n\n- For example, on Linux, the OS process abstraction stores state into members of\n  `task_struct`, which might also contain objects from other OS entities. This\n  prevents _process mitigation_, since the OS must keep track of all changes\n  made to other OS entities.\n- In microkernels, the abstraction layer is provided by the userspace server.\n  State spills into the userspace servers prevent their live update and\n  hot-swapping since other applications are dependent on those implicit states.\n\n## State spill hurts availability\n\nState spills hurt the availability of systems (it breaks fault isolation and\nfault tolerance). This happens when an entity acts as a _multiplexer_ that\nallows multiple clients to access an underlying resource.\n\n- Corruptions caused by state spills in _Process management_ entities in OS\n  cause all process to be affected.\n- _Recovery_ of servers is also hindered due to state spill, recovery on behalf\n  of one client can affect other clients.\n\n## Tackling state spill\n\nSolving state spill issues require that either\n\n1. All modules in the system keep track of which state that they require, and\n   which state that they own. This is difficult in practice if the interface is\n   not built with this in mind (e.g., kernel modules).\n2. All modules follow a set of rules that avoid state spill in the first place.\n   For example, states that are exported to other modules must be allocated by\n   the caller. This may be enforced through programming language invariants\n   [@boos2020theseus].\n\nRemoving state spill forces the caller to memory to allocate the context used\nfor cross-compartment interaction. In a sense, it also improves the security of\nthe per-compartment interface. See 1 and 4 in [[qti6u06p]].\n\n- [@boos2020theseus] (see [[jfm8ud28]]): An operating system design that aim to\n  minimize state spill.\n","wordCount":355,"tags":["microkernel","os","area"],"metadata":{},"created":"2023-05-17T03:51:43.216766843Z","modified":"2024-12-23T05:33:50.596034875Z","checksum":"9e9cbf18eb6c6c199f855f5fb3843283737173289fa7804c59d9d561b14c2dc3"},
    {"filename":"95a1f773.md","filenameStem":"95a1f773","path":"95a1f773.md","absPath":"/home/khadd/mynotes/95a1f773.md","title":"Stimulations","link":"[[95a1f773]]","lead":"#fleeting Speed Force patterns Try to vary the three parameters like fuzzing","body":"#fleeting Speed Force patterns Try to vary the three parameters like fuzzing","snippets":["#fleeting Speed Force patterns Try to vary the three parameters like fuzzing"],"rawContent":"---\ncreated: 2024-12-08T12:50:50+09:00\nmodified: 2024-12-08T13:13:28+09:00\n---\n\n# Stimulations\n\n#fleeting Speed Force patterns Try to vary the three parameters like fuzzing\n","wordCount":20,"tags":["fleeting"],"metadata":{"created":"2024-12-08T12:50:50+09:00","modified":"2024-12-08T13:13:28+09:00"},"created":"2024-12-09T04:21:46.902456479Z","modified":"2024-12-16T04:03:31.237008811Z","checksum":"5c2b00827bbb11c54970e3d04b4b7a4634a06f990013b39b33cef82e74336ef5"},
    {"filename":"mt8zp6w4.md","filenameStem":"mt8zp6w4","path":"mt8zp6w4.md","absPath":"/home/khadd/mynotes/mt8zp6w4.md","title":"Strict/strong typedef","link":"[[mt8zp6w4]]","lead":"#c #cxx #programming","body":"#c #cxx #programming\n\n_Strict typedef_, or _Strong typedef_, enable strict checking of the aliased\ntype. This is sometimes useful when you want to differentiate same underlying\ntype, but different classes. For instance, different type of index all have the\nsame int type. C and C++ does not support this at the language level.\n\nHowever, there are tricks to achieve this, by defining each type as a separated\nstruct [[b63h10sx]].\n\nIn c++, there is the boost library `BOOST_STRONG_TYPEDEF`, which enable the\nstrong typedef checking.\n\n# Reference\n\n- [enforce-strong-type-checking-in-c-type-strictness-for-typedefs](https://stackoverflow.com/questions/376452/enforce-strong-type-checking-in-c-type-strictness-for-typedefs)","snippets":["#c #cxx #programming"],"rawContent":"# Strict/strong typedef\n\n#c #cxx #programming\n\n_Strict typedef_, or _Strong typedef_, enable strict checking of the aliased\ntype. This is sometimes useful when you want to differentiate same underlying\ntype, but different classes. For instance, different type of index all have the\nsame int type. C and C++ does not support this at the language level.\n\nHowever, there are tricks to achieve this, by defining each type as a separated\nstruct [[b63h10sx]].\n\nIn c++, there is the boost library `BOOST_STRONG_TYPEDEF`, which enable the\nstrong typedef checking.\n\n# Reference\n\n- [enforce-strong-type-checking-in-c-type-strictness-for-typedefs](https://stackoverflow.com/questions/376452/enforce-strong-type-checking-in-c-type-strictness-for-typedefs)\n","wordCount":90,"tags":["programming","c","cxx"],"metadata":{},"created":"2023-07-12T06:13:13.193249148Z","modified":"2024-06-28T08:00:29.170864858Z","checksum":"306afcbef6921c8ce58234cab53b52c0b0bee3d38e7d537665ff72fe519b1fdb"},
    {"filename":"s5jv9kdc.md","filenameStem":"s5jv9kdc","path":"s5jv9kdc.md","absPath":"/home/khadd/mynotes/s5jv9kdc.md","title":"Studying dynamic linker","link":"[[s5jv9kdc]]","lead":"#project","body":"#project\n\nLibc source code\n\n- [libc]: https://github.com/lastweek/source-glibc","snippets":["#project"],"rawContent":"# Studying dynamic linker\n\n#project\n\nLibc source code\n\n- [libc]: https://github.com/lastweek/source-glibc\n","wordCount":11,"tags":["project"],"metadata":{},"created":"2024-07-02T06:35:52.960990389Z","modified":"2024-07-02T06:36:24.044390375Z","checksum":"63284fc92f7f7d8882346a8438fa6db93032be32395d50ee72f0d0d3c3743f40"},
    {"filename":"e7av7btu.md","filenameStem":"e7av7btu","path":"e7av7btu.md","absPath":"/home/khadd/mynotes/e7av7btu.md","title":"Symbol for computer sciences","link":"[[e7av7btu]]","lead":"It's amazing that CS many concepts widely accepted like process, Unix file\ndescriptor, does not have a dedicate symbol. However, in a way, it is difficult\nto visualize them in a widely understandable manner.","body":"It's amazing that CS many concepts widely accepted like process, Unix file\ndescriptor, does not have a dedicate symbol. However, in a way, it is difficult\nto visualize them in a widely understandable manner.\n\nConcepts with a symbol:\n\n- Disk: Database\n- AI: the Brain\n- Hardware: Disk, mouse, monitor, USB, router, CPU\n- Power off\n- Bluetooth\n- Connectivity\n- Files\n\nSome more obscured concept with a symbol:\n\n- Threads: wiggly line\n\nConcept without a symbol:\n\n- Process\n- Scheduler\n- System calls\n- Race condition","snippets":["It's amazing that CS many concepts widely accepted like process, Unix file\ndescriptor, does not have a dedicate symbol. However, in a way, it is difficult\nto visualize them in a widely understandable manner."],"rawContent":"# Symbol for computer sciences\n\nIt's amazing that CS many concepts widely accepted like process, Unix file\ndescriptor, does not have a dedicate symbol. However, in a way, it is difficult\nto visualize them in a widely understandable manner.\n\nConcepts with a symbol:\n\n- Disk: Database\n- AI: the Brain\n- Hardware: Disk, mouse, monitor, USB, router, CPU\n- Power off\n- Bluetooth\n- Connectivity\n- Files\n\nSome more obscured concept with a symbol:\n\n- Threads: wiggly line\n\nConcept without a symbol:\n\n- Process\n- Scheduler\n- System calls\n- Race condition\n","wordCount":92,"tags":[],"metadata":{},"created":"2024-12-17T09:04:10.337534729Z","modified":"2024-12-18T03:08:54.130479303Z","checksum":"df00468f74054a1babe2ef3d7fa1f806448987ed56740a8e5ab04a8612dd3971"},
    {"filename":"awlfkl73.md","filenameStem":"awlfkl73","path":"awlfkl73.md","absPath":"/home/khadd/mynotes/awlfkl73.md","title":"System Design","link":"[[awlfkl73]]","lead":"- [[xxn0pki0]]","body":"- [[xxn0pki0]]\n\n# Reference\n\n- [What we talk about when we talk about System Design](https://maheshba.bitbucket.io/blog/2023/07/12/Design.html):\n  Awesome blog about experiences in system design by a distributed system\n  designer.","snippets":["- [[xxn0pki0]]"],"rawContent":"# System Design\n\n- [[xxn0pki0]]\n\n# Reference\n\n- [What we talk about when we talk about System Design](https://maheshba.bitbucket.io/blog/2023/07/12/Design.html):\n  Awesome blog about experiences in system design by a distributed system\n  designer.\n","wordCount":30,"tags":[],"metadata":{},"created":"2023-08-11T08:47:56.544351934Z","modified":"2024-06-28T08:18:13.715516951Z","checksum":"0b5f76de2932c6e1fdbfba36c231cd8ce87cd295a3b65d75c050c4857aa9de62"},
    {"filename":"4wbu7wwz.md","filenameStem":"4wbu7wwz","path":"4wbu7wwz.md","absPath":"/home/khadd/mynotes/4wbu7wwz.md","title":"TCB Minimization","link":"[[4wbu7wwz]]","lead":"Untrustworthy TCB is the root of all evil. That is, software bugs made by human\nare inevitable that makes the code untrustworthy.","body":"Untrustworthy TCB is the root of all evil. That is, software bugs made by human\nare inevitable that makes the code untrustworthy.","snippets":["Untrustworthy TCB is the root of all evil. That is, software bugs made by human\nare inevitable that makes the code untrustworthy."],"rawContent":"# TCB Minimization\n\nUntrustworthy TCB is the root of all evil. That is, software bugs made by human\nare inevitable that makes the code untrustworthy.\n","wordCount":25,"tags":[],"metadata":{},"created":"2024-12-11T02:10:14.765392251Z","modified":"2024-12-11T02:12:05.529320765Z","checksum":"c2a9ce4e56444c1716cfefd751b3327adbc19e769660dc5579796583675ae5ff"},
    {"filename":"765f6vzr.md","filenameStem":"765f6vzr","path":"765f6vzr.md","absPath":"/home/khadd/mynotes/765f6vzr.md","title":"TDX Guest Boot","link":"[[765f6vzr]]","lead":"TDX boot (guest side) seems to be different from that of AMD SEV. It uses a\nmailbox protocol to allow the guest to communicate directly with the BIOS.","body":"TDX boot (guest side) seems to be different from that of AMD SEV. It uses a\nmailbox protocol to allow the guest to communicate directly with the BIOS.\n\n\u003e From\n\u003e https://patchwork.kernel.org/project/linux-mm/patch/20210820155918.7518-45-brijesh.singh@amd.com/ \u003e\n\u003e Honestly, why should KVM even support guest-provided VMSAs? It's far, far\n\u003e simpler to handle this fully in the guest with a BIOS\u003c=\u003ekernel mailbox; see\n\u003e the MP wakeup protocol being added for TDX. That would allow improving the\n\u003e security for SEV-ES as well, though I'm guessing no one actually cares about\n\u003e that in practice.\n\nMore on TDX boot\n\n\u003e From\n\u003e \u003chttps://lore.kernel.org/lkml/20220405232939.73860-21-kirill.shutemov@linux.intel.com/\u003e\n\u003e Historically, x86 platforms have booted secondary processors (APs) using INIT\n\u003e followed by the start up IPI (SIPI) messages. In regular VMs, this boot\n\u003e sequence is supported by the VMM emulation. But such a wakeup model is fatal\n\u003e for secure VMs like TDX in which VMM is an untrusted entity. To address this\n\u003e issue, a new wakeup model was added in ACPI v6.4, in which firmware (like TDX\n\u003e virtual BIOS) will help boot the APs. More details about this wakeup model can\n\u003e be found in ACPI specification v6.4, the section titled \"Multiprocessor Wakeup\n\u003e Structure\".\n\u003e\n\u003e Since the existing trampoline code requires processors to boot in real mode\n\u003e with 16-bit addressing, it will not work for this wakeup model (because it\n\u003e boots the AP in 64-bit mode). To handle it, extend the trampoline code to\n\u003e support 64-bit mode firmware handoff. Also, extend IDT and GDT pointers to\n\u003e support 64-bit mode hand off.\n\u003e\n\u003e There is no TDX-specific detection for this new boot method. The kernel will\n\u003e rely on it as the sole boot method whenever the new ACPI structure is present.\n\u003e\n\u003e The ACPI table parser for the MADT multiprocessor wake up structure and the\n\u003e wakeup method that uses this structure will be added by the following patch in\n\u003e this series.\n\nOn the other hand, SEV boot is more involved. The guest is in charge of\ninitiating its own VMSA and sending AP creation.","snippets":["TDX boot (guest side) seems to be different from that of AMD SEV. It uses a\nmailbox protocol to allow the guest to communicate directly with the BIOS."],"rawContent":"# TDX Guest Boot\n\nTDX boot (guest side) seems to be different from that of AMD SEV. It uses a\nmailbox protocol to allow the guest to communicate directly with the BIOS.\n\n\u003e From\n\u003e https://patchwork.kernel.org/project/linux-mm/patch/20210820155918.7518-45-brijesh.singh@amd.com/ \u003e\n\u003e Honestly, why should KVM even support guest-provided VMSAs? It's far, far\n\u003e simpler to handle this fully in the guest with a BIOS\u003c=\u003ekernel mailbox; see\n\u003e the MP wakeup protocol being added for TDX. That would allow improving the\n\u003e security for SEV-ES as well, though I'm guessing no one actually cares about\n\u003e that in practice.\n\nMore on TDX boot\n\n\u003e From\n\u003e \u003chttps://lore.kernel.org/lkml/20220405232939.73860-21-kirill.shutemov@linux.intel.com/\u003e\n\u003e Historically, x86 platforms have booted secondary processors (APs) using INIT\n\u003e followed by the start up IPI (SIPI) messages. In regular VMs, this boot\n\u003e sequence is supported by the VMM emulation. But such a wakeup model is fatal\n\u003e for secure VMs like TDX in which VMM is an untrusted entity. To address this\n\u003e issue, a new wakeup model was added in ACPI v6.4, in which firmware (like TDX\n\u003e virtual BIOS) will help boot the APs. More details about this wakeup model can\n\u003e be found in ACPI specification v6.4, the section titled \"Multiprocessor Wakeup\n\u003e Structure\".\n\u003e\n\u003e Since the existing trampoline code requires processors to boot in real mode\n\u003e with 16-bit addressing, it will not work for this wakeup model (because it\n\u003e boots the AP in 64-bit mode). To handle it, extend the trampoline code to\n\u003e support 64-bit mode firmware handoff. Also, extend IDT and GDT pointers to\n\u003e support 64-bit mode hand off.\n\u003e\n\u003e There is no TDX-specific detection for this new boot method. The kernel will\n\u003e rely on it as the sole boot method whenever the new ACPI structure is present.\n\u003e\n\u003e The ACPI table parser for the MADT multiprocessor wake up structure and the\n\u003e wakeup method that uses this structure will be added by the following patch in\n\u003e this series.\n\nOn the other hand, SEV boot is more involved. The guest is in charge of\ninitiating its own VMSA and sending AP creation.\n","wordCount":353,"tags":[],"metadata":{},"created":"2024-11-14T06:26:13.260708506Z","modified":"2024-11-18T05:51:50.736835284Z","checksum":"b6b155649fa4de57249cea7598bb155f99a7455b4bd20dcd1eb30ceb93c98dd8"},
    {"filename":"eczmc02q.md","filenameStem":"eczmc02q","path":"eczmc02q.md","absPath":"/home/khadd/mynotes/eczmc02q.md","title":"TEEs world switching","link":"[[eczmc02q]]","lead":"In TEEs, or _world switches_ occurs when the trusted application is required to\npass the control to untrusted privileged software.","body":"In TEEs, or _world switches_ occurs when the trusted application is required to\npass the control to untrusted privileged software.\n\nThis may be different, or the same as traditional context switching. For SGX, it\nis different, the cost of context switching consists of world switches + User/OS\nswitches. For CVMs, it is the same, CVM to hypervisor.\n\n## Costs\n\nWorld switching are inherently more expensive in TEEs than in traditional\ncontext switching, due to the microarchitectural/architectural\nsanitization/checks.\n\n- Certain registers must be scrubbed.\n- Some memory regions (VMSA) must be encrypted.\n- Some state checks are made.\n\nThe cost of switching generally 5x more (10,170 vs. 1800 for SGX\n[@thalheim2021rktio], 7,476 vs. 1,643 for CVMs [@li2023bifrost]). The overheads\ncontributes a lot to the costs of confidential I/O [[68nms906]].","snippets":["In TEEs, or _world switches_ occurs when the trusted application is required to\npass the control to untrusted privileged software."],"rawContent":"# TEEs world switching\n\nIn TEEs, or _world switches_ occurs when the trusted application is required to\npass the control to untrusted privileged software.\n\nThis may be different, or the same as traditional context switching. For SGX, it\nis different, the cost of context switching consists of world switches + User/OS\nswitches. For CVMs, it is the same, CVM to hypervisor.\n\n## Costs\n\nWorld switching are inherently more expensive in TEEs than in traditional\ncontext switching, due to the microarchitectural/architectural\nsanitization/checks.\n\n- Certain registers must be scrubbed.\n- Some memory regions (VMSA) must be encrypted.\n- Some state checks are made.\n\nThe cost of switching generally 5x more (10,170 vs. 1800 for SGX\n[@thalheim2021rktio], 7,476 vs. 1,643 for CVMs [@li2023bifrost]). The overheads\ncontributes a lot to the costs of confidential I/O [[68nms906]].\n","wordCount":132,"tags":[],"metadata":{},"created":"2024-12-04T06:05:59.843195201Z","modified":"2024-12-04T06:16:27.023925257Z","checksum":"96ec084c825bae105ed1f80ee93d478634759838064add1337d6a954309cdcf2"},
    {"filename":"tiifq1bc.md","filenameStem":"tiifq1bc","path":"tiifq1bc.md","absPath":"/home/khadd/mynotes/tiifq1bc.md","title":"TLB management","link":"[[tiifq1bc]]","lead":"#area #architecture #os","body":"#area #architecture #os\n\nLB is a data structure maintained for each processor core by _hardware_. It\ncaches the address translation result by the MMU, such that the translated\naddress is directly served by the TLB, instead of performing another address\ntranslation.\n\nHowever, CPUs support no coherency mechanism between the page table TLB. Hence,\nwhen a page table is updated, TLB might be keeping the _stale_ address\ntranslation, and an old translation is used, resulting in incorrect execution.\nFor this reason, _TLB Flush/Invalidation_ has to be performed by the OS,\nwhenever the page table is updated. After TLB flush, the MMU loads the new\ntranslation from the page table into the TLB in the next access.\n\nTLB can either be flushed per-mapping, or as a whole. By writing into the CR3\nregister, the entire TLB of the current core is flushed. On the other hand, the\ninstruction `invlpg` can invalidate a single 4KB mapping.\n\n## Shootdowns\n\nSince TLBs are maintained per-core, TLB flushes must be synchronized across\ncore. This is called the _TLB Shootdown_. To perform the TLB shootdown, an\ninitiating core must invoke _inter-processor interrupt (IPI)_ to inform all\nother cores about the TLB shoot-down. All cores acknowledge the request by\nexecuting the TLB shoot-down handler, which shootdown its local TLB entry.\n\nBecause of frequent context switches required, TLB shootdown is generally not\ndesirable.\n\n## Reducing TLB shootdown\n\nTLB shootdown can be omitted, the OS can know if the PTE entry is not used ever\nother cores. In this scenario, only the TLB flush of the current core is\nrequired.\n\n[@amit2017optimizing] uses page access tracking to avoid TLB shootdown. The idea\nis to directly insert the mapping into the TLB of a core, so that the\ntranslation of the core is served without setting the access bit. Note that when\nthe MMU visit a page during page table walk, it will set the access bit of the\nPTE.\n\nWhen other cores access the mapping, the MMU walks the page table, which will\nset the access bit, and the mapping is brought into the TLB. By checking for the\naccess bit, the OS can detect if the mapping is used cross-core.\n\nSince this is not supported by x86 natively, the paper introduces techniques to\ndo this using ASID.","snippets":["#area #architecture #os"],"rawContent":"# TLB management\n\n#area #architecture #os\n\nLB is a data structure maintained for each processor core by _hardware_. It\ncaches the address translation result by the MMU, such that the translated\naddress is directly served by the TLB, instead of performing another address\ntranslation.\n\nHowever, CPUs support no coherency mechanism between the page table TLB. Hence,\nwhen a page table is updated, TLB might be keeping the _stale_ address\ntranslation, and an old translation is used, resulting in incorrect execution.\nFor this reason, _TLB Flush/Invalidation_ has to be performed by the OS,\nwhenever the page table is updated. After TLB flush, the MMU loads the new\ntranslation from the page table into the TLB in the next access.\n\nTLB can either be flushed per-mapping, or as a whole. By writing into the CR3\nregister, the entire TLB of the current core is flushed. On the other hand, the\ninstruction `invlpg` can invalidate a single 4KB mapping.\n\n## Shootdowns\n\nSince TLBs are maintained per-core, TLB flushes must be synchronized across\ncore. This is called the _TLB Shootdown_. To perform the TLB shootdown, an\ninitiating core must invoke _inter-processor interrupt (IPI)_ to inform all\nother cores about the TLB shoot-down. All cores acknowledge the request by\nexecuting the TLB shoot-down handler, which shootdown its local TLB entry.\n\nBecause of frequent context switches required, TLB shootdown is generally not\ndesirable.\n\n## Reducing TLB shootdown\n\nTLB shootdown can be omitted, the OS can know if the PTE entry is not used ever\nother cores. In this scenario, only the TLB flush of the current core is\nrequired.\n\n[@amit2017optimizing] uses page access tracking to avoid TLB shootdown. The idea\nis to directly insert the mapping into the TLB of a core, so that the\ntranslation of the core is served without setting the access bit. Note that when\nthe MMU visit a page during page table walk, it will set the access bit of the\nPTE.\n\nWhen other cores access the mapping, the MMU walks the page table, which will\nset the access bit, and the mapping is brought into the TLB. By checking for the\naccess bit, the OS can detect if the mapping is used cross-core.\n\nSince this is not supported by x86 natively, the paper introduces techniques to\ndo this using ASID.\n","wordCount":380,"tags":["os","architecture","area"],"metadata":{},"created":"2024-05-22T08:24:03.298290932Z","modified":"2024-12-12T05:43:27.882307681Z","checksum":"d5cc50f9248ecaeb17482f72bfe7a146ada6a2169c7d167a9ebb1c30b29f9031"},
    {"filename":"zm5o3a8m.md","filenameStem":"zm5o3a8m","path":"zm5o3a8m.md","absPath":"/home/khadd/mynotes/zm5o3a8m.md","title":"TODO","link":"[[zm5o3a8m]]","lead":"## Some experimental definition language for tasks","body":"## Some experimental definition language for tasks\n\n```graphviz\nproject instrumentation {\n\ttask trampoline_code {\n\t\tduration=60min\n\t\tstatus=done\n\t\ttask trampoline_call_func\n\t}\n\ttask test_performance {}\n\ttast optimize {}\n\ttask integrate {}\n\n\ttrampoline_code-\u003etest_performance-\u003eoptimize-\u003eintegrate\n}\nproject writing {\n\n}\n```\n\n- [ ] Write \u0026 run eval\n- [ ] Fix section 5\n- [ ] Fix section 6\n- [ ]\n\n```\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=34, tv_nsec=86238750}) = OK\naccept4(0x6, 0x4185df850, ...) = 0x8\nepoll_ctl(0x3, 0x1, ...) = 0x0\nepoll_wait(0x3, 0x40242d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=34, tv_nsec=98329314}) = OK\nrecvfrom(0x8, 0x4185df8c0, ...) = 0x1\nsetsockopt(0x8, 0x6, ...) = 0x0\nread(fd:8, \u003cout\u003e\"\\x16\\x03\\x01\\x00\\xB7\\x01\\x00\\x00\\xB3\\x03\\x03\\xA8\\x94L\\xAB\\xD8\\xCB(\\x95\\x9C\\xFF'\\xD3\\x92\"..., 16709) = 188\ntime(0x0, 0x0, ...) = 0x670e754a\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40244beb8, ...) = 0x670e754a\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x402449d80, ...) = 0x670e754a\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x402449e10, ...) = 0x670e754a\nwrite(fd:8, \"\\x16\\x03\\x03\\x00A\\x02\\x00\\x00=\\x03\\x03/\\xABMH\\x1C\\xBBe\\x87\\x09v\\xC1\\x12z\"..., 2218) = 2218\nread(fd:8, \u003cout\u003ebuf:0x402464753, 16709) = Resource temporarily unavailable (-11)\nepoll_wait(0x3, 0x40242d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=34, tv_nsec=172999953}) = OK\nread(fd:8, \u003cout\u003e\"\\x16\\x03\\x03\\x00%\\x10\\x00\\x00! \\x89\\x08\\xC6\\xB4\\xA5\\x83Pb\\xFE,J\\xA8\\x96\\x99\"..., 16709) = 93\ntime(0x0, 0x0, ...) = 0x670e754a\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x4185df680, ...) = 0x670e754a\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40245b2dc, ...) = 0x670e754a\nwrite(fd:8, \"\\x16\\x03\\x03\\x00\\xBA\\x04\\x00\\x00\\xB6\\x00\\x00\\x01,\\x00\\xB0\"\\xB3\\xCE6G\\x8C\\xA1Q\\x8C\"..., 242) = 242\nread(fd:8, \u003cout\u003ebuf:0x402453fc3, 16709) = Resource temporarily unavailable (-11)\nepoll_wait(0x3, 0x40242d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=34, tv_nsec=187778845}) = OK\nread(fd:8, \u003cout\u003e\"\\x17\\x03\\x03\\x00m\\x9F\\xFE\\x9Bd6{\\xCB\\xBCY\\xA1\\xB8]\\x9F\\xAB,|\\xB1\\x06\\xC6\"..., 16709) = 114\nread(fd:8, \u003cout\u003ebuf:0x402453fc3, 16709) = Resource temporarily unavailable (-11)\nopenat(AT_FDCWD, \"/wwwroot/1k.html\", O_RDONLY|O_NONBLOCK) = fd:9\nfstat(fd:9, \u003cout\u003estat:{st_size=1024, st_mode=0100664, ...}) = OK\npread64(fd:9, \u003cout\u003e\"\\xA7\\x7F\\xA8\\xB4\\x0F\\xF6\\xA3\\xCA\\x85z\\xF0XHVI3RX\\xC3I\\xC3b\\x9D\\x16\"..., 1024, 0) = 1024\nwrite(fd:8, \"\\x17\\x03\\x03\\x05\\x0B\\xFF)\\xDE\\xA9\\xFF\\xE6\\xB5\\xC06\u003c\\T\\x8C!\\xFB\\x94\\x98\\x97\\xD2\"..., 1296) = 1296\nwrite(fd:8, \"\\x15\\x03\\x03\\x00\\x1A\\xFF)\\xDE\\xA9\\xFF\\xE6\\xB5\\xC1/\\x80f\\xD2\\xA8\\x05bA\\x16\\x98a\"..., 31) = 31\nclose(fd:8) = OK\n```\n\n```\nepoll_wait[0xe8]         count: 138      avg_inst_count: 33605767.89130435\nbrk[0xc]         count: 10       avg_inst_count: 43982.9\nwrite[0x1]       count: 427      avg_inst_count: 13077.585480093678\nclose[0x3]       count: 112      avg_inst_count: 12396.61607142857\nopenat[0x101]    count: 1        avg_inst_count: 7740.0\naccept4[0x120]   count: 113      avg_inst_count: 3415.849557522124\nread[0x0]        count: 665      avg_inst_count: 1183.3172932330826\nepoll_ctl[0xe9]  count: 115      avg_inst_count: 1111.6434782608696\npread64[0x11]    count: 100      avg_inst_count: 1076.12\nrecvfrom[0x2d]   count: 113      avg_inst_count: 923.0\nfstat[0x5]       count: 1        avg_inst_count: 482.0\nsetsockopt[0x36]         count: 113      avg_inst_count: 421.0\ngettimeofday[0x60]       count: 139      avg_inst_count: 163.0\nclock_gettime[0xe4]      count: 138      avg_inst_count: 157.0\ntime[0xc9]       count: 801      avg_inst_count: 157.0\ngetpid[0x27]     count: 1150     avg_inst_count: 120.0\ngettid[0xba]     count: 1        avg_inst_count: 117.0\n```\n\n## 2024-10-22 11:13\n\n- [ ] Nbench\n  - Tick only vs. adaptive with small rerand rate.\n- [ ] nginx + redis\n\n  - Use graph instead.\n  - Configurations: percentage of ticks only + adaptive + Adjusting RerandRate\n    Normal\n\n- [ ] Implement \u0026 measure basic block sampling\n  - Basic block sampling may not be reliable since we skip a lot of basic\n    blocks.\n  - Overheads is kind of low without page faults, so we may turn off\n    optimization and choose basic-block sampling\n- [ ] Integrate rewritten binaries to Unikraft\n  - [ ] XXX","snippets":["## Some experimental definition language for tasks"],"rawContent":"# TODO\n\n## Some experimental definition language for tasks\n\n```graphviz\nproject instrumentation {\n\ttask trampoline_code {\n\t\tduration=60min\n\t\tstatus=done\n\t\ttask trampoline_call_func\n\t}\n\ttask test_performance {}\n\ttast optimize {}\n\ttask integrate {}\n\n\ttrampoline_code-\u003etest_performance-\u003eoptimize-\u003eintegrate\n}\nproject writing {\n\n}\n```\n\n- [ ] Write \u0026 run eval\n- [ ] Fix section 5\n- [ ] Fix section 6\n- [ ]\n\n```\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=34, tv_nsec=86238750}) = OK\naccept4(0x6, 0x4185df850, ...) = 0x8\nepoll_ctl(0x3, 0x1, ...) = 0x0\nepoll_wait(0x3, 0x40242d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=34, tv_nsec=98329314}) = OK\nrecvfrom(0x8, 0x4185df8c0, ...) = 0x1\nsetsockopt(0x8, 0x6, ...) = 0x0\nread(fd:8, \u003cout\u003e\"\\x16\\x03\\x01\\x00\\xB7\\x01\\x00\\x00\\xB3\\x03\\x03\\xA8\\x94L\\xAB\\xD8\\xCB(\\x95\\x9C\\xFF'\\xD3\\x92\"..., 16709) = 188\ntime(0x0, 0x0, ...) = 0x670e754a\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40244beb8, ...) = 0x670e754a\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x402449d80, ...) = 0x670e754a\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x402449e10, ...) = 0x670e754a\nwrite(fd:8, \"\\x16\\x03\\x03\\x00A\\x02\\x00\\x00=\\x03\\x03/\\xABMH\\x1C\\xBBe\\x87\\x09v\\xC1\\x12z\"..., 2218) = 2218\nread(fd:8, \u003cout\u003ebuf:0x402464753, 16709) = Resource temporarily unavailable (-11)\nepoll_wait(0x3, 0x40242d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=34, tv_nsec=172999953}) = OK\nread(fd:8, \u003cout\u003e\"\\x16\\x03\\x03\\x00%\\x10\\x00\\x00! \\x89\\x08\\xC6\\xB4\\xA5\\x83Pb\\xFE,J\\xA8\\x96\\x99\"..., 16709) = 93\ntime(0x0, 0x0, ...) = 0x670e754a\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x4185df680, ...) = 0x670e754a\ngetpid() = pid:2\ngetpid() = pid:2\ntime(0x0, 0x40245b2dc, ...) = 0x670e754a\nwrite(fd:8, \"\\x16\\x03\\x03\\x00\\xBA\\x04\\x00\\x00\\xB6\\x00\\x00\\x01,\\x00\\xB0\"\\xB3\\xCE6G\\x8C\\xA1Q\\x8C\"..., 242) = 242\nread(fd:8, \u003cout\u003ebuf:0x402453fc3, 16709) = Resource temporarily unavailable (-11)\nepoll_wait(0x3, 0x40242d190, ...) = 0x1\ngettimeofday(0x4185df8b0, 0x0, ...) = 0x0\nclock_gettime(CLOCK_0x6, \u003cout\u003etimespec:{tv_sec=34, tv_nsec=187778845}) = OK\nread(fd:8, \u003cout\u003e\"\\x17\\x03\\x03\\x00m\\x9F\\xFE\\x9Bd6{\\xCB\\xBCY\\xA1\\xB8]\\x9F\\xAB,|\\xB1\\x06\\xC6\"..., 16709) = 114\nread(fd:8, \u003cout\u003ebuf:0x402453fc3, 16709) = Resource temporarily unavailable (-11)\nopenat(AT_FDCWD, \"/wwwroot/1k.html\", O_RDONLY|O_NONBLOCK) = fd:9\nfstat(fd:9, \u003cout\u003estat:{st_size=1024, st_mode=0100664, ...}) = OK\npread64(fd:9, \u003cout\u003e\"\\xA7\\x7F\\xA8\\xB4\\x0F\\xF6\\xA3\\xCA\\x85z\\xF0XHVI3RX\\xC3I\\xC3b\\x9D\\x16\"..., 1024, 0) = 1024\nwrite(fd:8, \"\\x17\\x03\\x03\\x05\\x0B\\xFF)\\xDE\\xA9\\xFF\\xE6\\xB5\\xC06\u003c\\T\\x8C!\\xFB\\x94\\x98\\x97\\xD2\"..., 1296) = 1296\nwrite(fd:8, \"\\x15\\x03\\x03\\x00\\x1A\\xFF)\\xDE\\xA9\\xFF\\xE6\\xB5\\xC1/\\x80f\\xD2\\xA8\\x05bA\\x16\\x98a\"..., 31) = 31\nclose(fd:8) = OK\n```\n\n```\nepoll_wait[0xe8]         count: 138      avg_inst_count: 33605767.89130435\nbrk[0xc]         count: 10       avg_inst_count: 43982.9\nwrite[0x1]       count: 427      avg_inst_count: 13077.585480093678\nclose[0x3]       count: 112      avg_inst_count: 12396.61607142857\nopenat[0x101]    count: 1        avg_inst_count: 7740.0\naccept4[0x120]   count: 113      avg_inst_count: 3415.849557522124\nread[0x0]        count: 665      avg_inst_count: 1183.3172932330826\nepoll_ctl[0xe9]  count: 115      avg_inst_count: 1111.6434782608696\npread64[0x11]    count: 100      avg_inst_count: 1076.12\nrecvfrom[0x2d]   count: 113      avg_inst_count: 923.0\nfstat[0x5]       count: 1        avg_inst_count: 482.0\nsetsockopt[0x36]         count: 113      avg_inst_count: 421.0\ngettimeofday[0x60]       count: 139      avg_inst_count: 163.0\nclock_gettime[0xe4]      count: 138      avg_inst_count: 157.0\ntime[0xc9]       count: 801      avg_inst_count: 157.0\ngetpid[0x27]     count: 1150     avg_inst_count: 120.0\ngettid[0xba]     count: 1        avg_inst_count: 117.0\n```\n\n## 2024-10-22 11:13\n\n- [ ] Nbench\n  - Tick only vs. adaptive with small rerand rate.\n- [ ] nginx + redis\n\n  - Use graph instead.\n  - Configurations: percentage of ticks only + adaptive + Adjusting RerandRate\n    Normal\n\n- [ ] Implement \u0026 measure basic block sampling\n  - Basic block sampling may not be reliable since we skip a lot of basic\n    blocks.\n  - Overheads is kind of low without page faults, so we may turn off\n    optimization and choose basic-block sampling\n- [ ] Integrate rewritten binaries to Unikraft\n  - [ ] XXX\n","wordCount":457,"tags":[],"metadata":{},"created":"2024-07-24T06:00:16.659168935Z","modified":"2024-10-23T07:39:18.797975937Z","checksum":"a0f01185cce9b116336ea793338be1c4a6ee075f659f2a88c030ee3f987280f5"},
    {"filename":"97452826.md","filenameStem":"97452826","path":"97452826.md","absPath":"/home/khadd/mynotes/97452826.md","title":"TODO","link":"[[97452826]]","lead":"- [ ] safety education\n- vinh's brother  CV","body":"- [ ] safety education\n- vinh's brother  CV","snippets":["- [ ] safety education\n- vinh's brother  CV"],"rawContent":"---\ncreated: 2024-12-09T11:37:58+09:00\nmodified: 2024-12-09T11:39:45+09:00\n---\n\n# TODO\n\n- [ ] safety education\n- vinh's brother  CV\n","wordCount":17,"tags":[],"metadata":{"created":"2024-12-09T11:37:58+09:00","modified":"2024-12-09T11:39:45+09:00"},"created":"2024-12-09T04:21:46.907182471Z","modified":"2024-12-09T04:15:06.172051626Z","checksum":"695dc94634c0d957840e779698955110debd55e9e7196d584f3711d4afc0f928"},
    {"filename":"fvom56lw.md","filenameStem":"fvom56lw","path":"fvom56lw.md","absPath":"/home/khadd/mynotes/fvom56lw.md","title":"TSX-based control-channel defenses","link":"[[fvom56lw]]","lead":"#tsx #controlled-channel","body":"#tsx #controlled-channel\n\nFor more context, see [[5kzr3hwx]].\n\n## T-SGX\n\n@test\n\nT-SGX [@tsgx] uses Intel TSX to prevent the OS from knowing the page fault,\nsince TSX supresses page faults on during a transaction. The system transform\nthe program such that (almost) all code is executed in a TSX transaction. Any\npage fault is treated as an attack attempt by the OS. Reported overheads of the\nsystem is about 50%.\n\n## Deja Vu\n\n[@chen2017detecting] uses TSX to _detect_ whether an AEX has occurred during the\nexecution of critical code. The program is instrumented to periodically measure\nits execution time, and if the execution time deviate too much from its expected\ntime, an AEX is detected.\n\n```c\nwhile (1) {\n  // update counter\n  if (_xbegin() == _XBEGIN_STARTED)\n  {\n      int rand = random();\n      for (int i =0; i \u003c rand; i++){\n        // rand cycles is performed\n      }\n      _xend();\n  }\n  else {\n    interrupted += 1;\n    continue;\n  }\n  timer += rand;\n}\n```\n\nA thread is used to continuously update a global timer variable. The program is\nthen instrumented to uses this timer to detect attacks (e.g., if a basic block\ntakes too long to complete and the there was an interrupt, then there is a high\nchance that an AEX occurred). The counter thread uses TSX to determine whether\nan interrupt happened.","snippets":["#tsx #controlled-channel"],"rawContent":"# TSX-based control-channel defenses\n\n#tsx #controlled-channel\n\nFor more context, see [[5kzr3hwx]].\n\n## T-SGX\n\n@test\n\nT-SGX [@tsgx] uses Intel TSX to prevent the OS from knowing the page fault,\nsince TSX supresses page faults on during a transaction. The system transform\nthe program such that (almost) all code is executed in a TSX transaction. Any\npage fault is treated as an attack attempt by the OS. Reported overheads of the\nsystem is about 50%.\n\n## Deja Vu\n\n[@chen2017detecting] uses TSX to _detect_ whether an AEX has occurred during the\nexecution of critical code. The program is instrumented to periodically measure\nits execution time, and if the execution time deviate too much from its expected\ntime, an AEX is detected.\n\n```c\nwhile (1) {\n  // update counter\n  if (_xbegin() == _XBEGIN_STARTED)\n  {\n      int rand = random();\n      for (int i =0; i \u003c rand; i++){\n        // rand cycles is performed\n      }\n      _xend();\n  }\n  else {\n    interrupted += 1;\n    continue;\n  }\n  timer += rand;\n}\n```\n\nA thread is used to continuously update a global timer variable. The program is\nthen instrumented to uses this timer to detect attacks (e.g., if a basic block\ntakes too long to complete and the there was an interrupt, then there is a high\nchance that an AEX occurred). The counter thread uses TSX to determine whether\nan interrupt happened.\n","wordCount":222,"tags":["controlled-channel","tsx"],"metadata":{},"created":"2023-06-19T03:04:24.89591636Z","modified":"2024-07-01T02:49:49.767128641Z","checksum":"06c803c2489df0ed4a995164b671101e5f42cae596767dc05b11795d74e4d81c"},
    {"filename":"vtn586yc.md","filenameStem":"vtn586yc","path":"vtn586yc.md","absPath":"/home/khadd/mynotes/vtn586yc.md","title":"The Scalable Commutative Rule","link":"[[vtn586yc]]","lead":"The scalable commutative rule is a guideline for designing scalable interfaces.\nIt allow the accessment of a the scalability of an interface by how well its\noperation _commutes_. Operations commutes when the order that they are performed\ndoes not affect the result (system states, return values). For example, the\noutcome of writing into a global variable is dependent of the result, so they\nare commute.","body":"The scalable commutative rule is a guideline for designing scalable interfaces.\nIt allow the accessment of a the scalability of an interface by how well its\noperation _commutes_. Operations commutes when the order that they are performed\ndoes not affect the result (system states, return values). For example, the\noutcome of writing into a global variable is dependent of the result, so they\nare commute.\n\nMore particularly, the rule is:\n\n\u003e whenever interface operations commute, they can be implemented in a way that\n\u003e scales\n\nAn example from the paper:\n\n\u003e For example, imagine that multiple processes are creating files in the same\n\u003e directory at the same time. Can the creation system calls be made to scale?\n\u003e Our first answer was “obviously not”: the system calls modify the same\n\u003e directory, so surely the implementation must serialize access to the\n\u003e directory. But it turns out these operations commute if the two files have\n\u003e different names (and no hard or symbolic links are involved) and, therefore,\n\u003e have an implementation that scales for such names. One such implementation\n\u003e represents each directory as a hash table indexed by file name, with an\n\u003e independent lock per bucket, so that creation of differently named files is\n\u003e conflict free, barring hash collisions.\n\u003e\n\u003e Before the rule, we tried to determine if these operations could scale by\n\u003e analyzing all the implementations we could think of. This process—difficult,\n\u003e unguided, and appropriate only for simple interfaces—motivated us to reason\n\u003e about scalability in terms of interfaces.\n\n## Networking stack design\n\n[[2i45v7qf]] Following the rule, a networking interface is scalable if its\noperations does not commute. Network processing on packets of the same flow\n[[vbeb82fs]] (e.g., same IP) are commute, so they can be implemented scalably if\neach interface process a packet from start to finish [@belay2014ix]. NICs also\ntry to follow this [@turtles] to avoid collecting packets and reordering across\nring buffers. More: [[2i45v7qf]].\n\n## Related\n\n- Amdahl law","snippets":["The scalable commutative rule is a guideline for designing scalable interfaces.\nIt allow the accessment of a the scalability of an interface by how well its\noperation _commutes_. Operations commutes when the order that they are performed\ndoes not affect the result (system states, return values). For example, the\noutcome of writing into a global variable is dependent of the result, so they\nare commute."],"rawContent":"# The Scalable Commutative Rule\n\nThe scalable commutative rule is a guideline for designing scalable interfaces.\nIt allow the accessment of a the scalability of an interface by how well its\noperation _commutes_. Operations commutes when the order that they are performed\ndoes not affect the result (system states, return values). For example, the\noutcome of writing into a global variable is dependent of the result, so they\nare commute.\n\nMore particularly, the rule is:\n\n\u003e whenever interface operations commute, they can be implemented in a way that\n\u003e scales\n\nAn example from the paper:\n\n\u003e For example, imagine that multiple processes are creating files in the same\n\u003e directory at the same time. Can the creation system calls be made to scale?\n\u003e Our first answer was “obviously not”: the system calls modify the same\n\u003e directory, so surely the implementation must serialize access to the\n\u003e directory. But it turns out these operations commute if the two files have\n\u003e different names (and no hard or symbolic links are involved) and, therefore,\n\u003e have an implementation that scales for such names. One such implementation\n\u003e represents each directory as a hash table indexed by file name, with an\n\u003e independent lock per bucket, so that creation of differently named files is\n\u003e conflict free, barring hash collisions.\n\u003e\n\u003e Before the rule, we tried to determine if these operations could scale by\n\u003e analyzing all the implementations we could think of. This process—difficult,\n\u003e unguided, and appropriate only for simple interfaces—motivated us to reason\n\u003e about scalability in terms of interfaces.\n\n## Networking stack design\n\n[[2i45v7qf]] Following the rule, a networking interface is scalable if its\noperations does not commute. Network processing on packets of the same flow\n[[vbeb82fs]] (e.g., same IP) are commute, so they can be implemented scalably if\neach interface process a packet from start to finish [@belay2014ix]. NICs also\ntry to follow this [@turtles] to avoid collecting packets and reordering across\nring buffers. More: [[2i45v7qf]].\n\n## Related\n\n- Amdahl law\n","wordCount":336,"tags":[],"metadata":{},"created":"2024-12-16T03:56:49.148807459Z","modified":"2024-12-16T03:56:38.552223511Z","checksum":"49e81ac1009ae96360544f680ccf9baaca1ac29bfe62beb40d9fa979b4843cfa"},
    {"filename":"jsygj3tb.md","filenameStem":"jsygj3tb","path":"jsygj3tb.md","absPath":"/home/khadd/mynotes/jsygj3tb.md","title":"The Second-system Effect","link":"[[jsygj3tb]]","lead":"#programming","body":"#programming\n\n[@brooks1975mythical] coins the term *the Second-System effect*: The second system that a system architect builds is the most *dangerous* (i.e., over-designed) one. The reasons are as follows. The first system ought to be carefully designed and clean. The designer would leave all the crazy ideas until \"next time\". With the confidence of the first successful system, the architect would go on and design the second system without any restriction.\n\nAs for third and later systems, the architect gains experience and generalized knowledge of what would work and would not work for the type of system.\n\nTo avoid this effect, @brooks1975mythical suggests designing the second system with self-discipline.","snippets":["#programming"],"rawContent":"# The Second-system Effect\n#programming\n\n[@brooks1975mythical] coins the term *the Second-System effect*: The second system that a system architect builds is the most *dangerous* (i.e., over-designed) one. The reasons are as follows. The first system ought to be carefully designed and clean. The designer would leave all the crazy ideas until \"next time\". With the confidence of the first successful system, the architect would go on and design the second system without any restriction.\n\nAs for third and later systems, the architect gains experience and generalized knowledge of what would work and would not work for the type of system.\n\nTo avoid this effect, @brooks1975mythical suggests designing the second system with self-discipline.\n","wordCount":112,"tags":["programming"],"metadata":{},"created":"2023-05-22T06:09:03.041943041Z","modified":"2024-05-22T08:23:40.666608407Z","checksum":"010ca452592401fa91388613a0b1281d09a803ddadd5669695c3037c3b99a569"},
    {"filename":"7t4jlnaq.md","filenameStem":"7t4jlnaq","path":"7t4jlnaq.md","absPath":"/home/khadd/mynotes/7t4jlnaq.md","title":"The goals of an Operating System","link":"[[7t4jlnaq]]","lead":"#os","body":"#os\n\nThere are two main goals of an OS: abstraction and resource management.\n\n## Abstraction\n\nFrom the top-down view of the user, the OS provides abstraction over complex\ninteractions with the hardware. It turns an impossible task (write applications\nthat interacts with the hardware directly) in to two manageable tasks: (1)\ndesign and implement the abstraction, and (2) use the abstraction to do useful\nworks. Two most fundamental abstractions provided by most OSes are _files_ and\n_processes_. Files and file-related system calls abstract away the communication\nand management of data stored on the disk. Process is a unit of execution that\nenable multitasking (1.1, [@tanenbaum2015modern]) [[a0g41kid]].\n\n## Resource management\n\nFrom a bottom-up view, an operating system enable fair resource sharing among\nmultiple users. This is called _multiplexing_.\n\nThere can be _space multiplexing_, sharing a part of a resource between users\n(e.g., memory), and _time multiplexing_, sharing time slices of a resource\n(e.g., CPU time) between users.\n\nAlso, from the user point of view, the resources are being _virtualized_: the OS\ngive the user an _illusion_ of having access to entire system (e.g., all of\nphysical memory).\n\n## See also\n\n- [[k60yjf6q]]","snippets":["#os"],"rawContent":"# The goals of an Operating System\n\n#os\n\nThere are two main goals of an OS: abstraction and resource management.\n\n## Abstraction\n\nFrom the top-down view of the user, the OS provides abstraction over complex\ninteractions with the hardware. It turns an impossible task (write applications\nthat interacts with the hardware directly) in to two manageable tasks: (1)\ndesign and implement the abstraction, and (2) use the abstraction to do useful\nworks. Two most fundamental abstractions provided by most OSes are _files_ and\n_processes_. Files and file-related system calls abstract away the communication\nand management of data stored on the disk. Process is a unit of execution that\nenable multitasking (1.1, [@tanenbaum2015modern]) [[a0g41kid]].\n\n## Resource management\n\nFrom a bottom-up view, an operating system enable fair resource sharing among\nmultiple users. This is called _multiplexing_.\n\nThere can be _space multiplexing_, sharing a part of a resource between users\n(e.g., memory), and _time multiplexing_, sharing time slices of a resource\n(e.g., CPU time) between users.\n\nAlso, from the user point of view, the resources are being _virtualized_: the OS\ngive the user an _illusion_ of having access to entire system (e.g., all of\nphysical memory).\n\n## See also\n\n- [[k60yjf6q]]\n","wordCount":198,"tags":["os"],"metadata":{},"created":"2023-05-22T02:06:14.448908623Z","modified":"2024-12-17T04:44:50.348171539Z","checksum":"c3e8f5378192da13fb34aaed1f3ed72edb2a864f589e8f0e98bf9fb70f8eae85"},
    {"filename":"5md2g07d.md","filenameStem":"5md2g07d","path":"5md2g07d.md","absPath":"/home/khadd/mynotes/5md2g07d.md","title":"The overall performance improvement gained by optimizing a single part of a system is limited by the fraction of time that the improved part is actually used","link":"[[5md2g07d]]","lead":"#quote","body":"#quote\n\nAlso called the _Amdahl's law_, which is often cited in parallel computing to\nemphasize the importance of parallelism. In this context, can be interpreted as\nthe performance gain of optimizations on a subsystem is limited by the amount\nthat can be executed concurrently.\n\n- [wiki]: https://en.wikipedia.org/wiki/Amdahl%27s_law","snippets":["#quote"],"rawContent":"# The overall performance improvement gained by optimizing a single part of a system is limited by the fraction of time that the improved part is actually used\n\n#quote\n\nAlso called the _Amdahl's law_, which is often cited in parallel computing to\nemphasize the importance of parallelism. In this context, can be interpreted as\nthe performance gain of optimizations on a subsystem is limited by the amount\nthat can be executed concurrently.\n\n- [wiki]: https://en.wikipedia.org/wiki/Amdahl%27s_law\n","wordCount":75,"tags":["quote"],"metadata":{},"created":"2024-12-05T04:28:50.010128834Z","modified":"2024-12-09T04:17:59.535870836Z","checksum":"c02751bca3713063c6ff604f20ffae6347bc1d8b79729b0b4295f06e2b32a53c"},
    {"filename":"l6tidpzy.md","filenameStem":"l6tidpzy","path":"l6tidpzy.md","absPath":"/home/khadd/mynotes/l6tidpzy.md","title":"The planes (data vs control) of networking","link":"[[l6tidpzy]]","lead":"#networking #os","body":"#networking #os\n\n## Networking\n\n- Control plane refer to the routing of packets across notes in the network. For\n  example, creating the routing table is the task of the control plane.\n- Data-plane, or forwarding plane, decides _how_ the packets should be\n  processed.\n\nAn analogy is the control-plane is the brain, while the data plane is your arm.\nThe brain decide that you should pick up something, while it is the arm that\nperform the job. Another analogy: control-plane is the traffic lights, data\nplane is the cars.\n\nMore indepth:\n\n- [planes]: https://chrisjhart.com/Understanding-Data-Control-Management-Planes/\n\n## OS\n\nIn operating system designs, there also exists the distinction between control\nanI data planes [@belay2014ix, @peter2014arrakis,@marty2019snap]. In this\ncontext:\n\n- Data plane decides how the network packets are handled, i.e., Networking\n  stack, packet parsing, encryption.\n- Control plane decide _when_ processing should be performed and the necessary\n  setup, tasks scheduling, multiplexing of hardware devices, memory allocation.\n\nTraditionally, the OS performs a mixes between control and data plane, by\nproviding packet processing infrastructures in the kernel, and providing\nabstractions to the userspace. However, this split model results in overheads\n[[471vf8vr]].\n\nDirect I/O [[qctx04tc]] removes the data plane from the OS, leaving it solely in\ncharge of the control plane.","snippets":["#networking #os"],"rawContent":"# The planes (data vs control) of networking\n\n#networking #os\n\n## Networking\n\n- Control plane refer to the routing of packets across notes in the network. For\n  example, creating the routing table is the task of the control plane.\n- Data-plane, or forwarding plane, decides _how_ the packets should be\n  processed.\n\nAn analogy is the control-plane is the brain, while the data plane is your arm.\nThe brain decide that you should pick up something, while it is the arm that\nperform the job. Another analogy: control-plane is the traffic lights, data\nplane is the cars.\n\nMore indepth:\n\n- [planes]: https://chrisjhart.com/Understanding-Data-Control-Management-Planes/\n\n## OS\n\nIn operating system designs, there also exists the distinction between control\nanI data planes [@belay2014ix, @peter2014arrakis,@marty2019snap]. In this\ncontext:\n\n- Data plane decides how the network packets are handled, i.e., Networking\n  stack, packet parsing, encryption.\n- Control plane decide _when_ processing should be performed and the necessary\n  setup, tasks scheduling, multiplexing of hardware devices, memory allocation.\n\nTraditionally, the OS performs a mixes between control and data plane, by\nproviding packet processing infrastructures in the kernel, and providing\nabstractions to the userspace. However, this split model results in overheads\n[[471vf8vr]].\n\nDirect I/O [[qctx04tc]] removes the data plane from the OS, leaving it solely in\ncharge of the control plane.\n","wordCount":211,"tags":["os","networking"],"metadata":{},"created":"2024-12-09T08:06:41.57517883Z","modified":"2024-12-16T03:56:38.548890167Z","checksum":"703ab2a02e01e5d33e1f02fce22c3444172fe338a29e5847db79285d2f0e1ed6"},
    {"filename":"kp9kr1qi.md","filenameStem":"kp9kr1qi","path":"kp9kr1qi.md","absPath":"/home/khadd/mynotes/kp9kr1qi.md","title":"The renaissance of Capabilities","link":"[[kp9kr1qi]]","lead":"#blog #wip","body":"#blog #wip\n\nCapability is a security model discussed long ago.\n\n## Why capabilities exists\n\n[[y9wu5ut7]]","snippets":["#blog #wip"],"rawContent":"# The renaissance of Capabilities\n\n#blog #wip\n\nCapability is a security model discussed long ago.\n\n## Why capabilities exists\n\n[[y9wu5ut7]]\n","wordCount":20,"tags":["blog","wip"],"metadata":{},"created":"2024-12-12T05:36:36.025333789Z","modified":"2024-12-12T05:37:49.467710038Z","checksum":"e00c2a83ac545f3d51e9d9384cca97a4a3ede9caaf34d4a54ab66587e2aa3a90"},
    {"filename":"65y4syoj.md","filenameStem":"65y4syoj","path":"65y4syoj.md","absPath":"/home/khadd/mynotes/65y4syoj.md","title":"The shorter the name, the higher the impact","link":"[[65y4syoj]]","lead":"While this heuristic may not be applied to all cases, it can be observed for (1)\nprogramming and (2) research papers.","body":"While this heuristic may not be applied to all cases, it can be observed for (1)\nprogramming and (2) research papers.\n\nIn programming, this happens because of specialization of functionalities, where\nsubfunctions are created that contain implementation for more specialized code.\nE.g., a function called `system_init` is obviously more important than a\n`system_init_keyboard` function. This is not always true. Some supporting\nfunctions may have short names, e.g., `add_num(x,y)`.\n\nSo, when studying some implementations, look for function with shorter names.\n\nWhen reading research papers, I also find these phenomena. Papers with short\nnames often introduce new concepts does not exist before. The concept is usually\nalso naturally align with existing literatures such that it can be described\nwithin a few words. Papers names like \"Attribute-based Encryption\" introduce a\nbrand-new subdomain of encryption not discussed before.\n\nSo, maybe be concise with the naming.","snippets":["While this heuristic may not be applied to all cases, it can be observed for (1)\nprogramming and (2) research papers."],"rawContent":"# The shorter the name, the higher the impact\n\nWhile this heuristic may not be applied to all cases, it can be observed for (1)\nprogramming and (2) research papers.\n\nIn programming, this happens because of specialization of functionalities, where\nsubfunctions are created that contain implementation for more specialized code.\nE.g., a function called `system_init` is obviously more important than a\n`system_init_keyboard` function. This is not always true. Some supporting\nfunctions may have short names, e.g., `add_num(x,y)`.\n\nSo, when studying some implementations, look for function with shorter names.\n\nWhen reading research papers, I also find these phenomena. Papers with short\nnames often introduce new concepts does not exist before. The concept is usually\nalso naturally align with existing literatures such that it can be described\nwithin a few words. Papers names like \"Attribute-based Encryption\" introduce a\nbrand-new subdomain of encryption not discussed before.\n\nSo, maybe be concise with the naming.\n","wordCount":150,"tags":[],"metadata":{},"created":"2024-08-08T09:30:51.249343907Z","modified":"2024-08-09T02:58:53.873715527Z","checksum":"866d38ebae79e33b3e45524afff33ee49d38c34c38bfa3d17d8f11b97cf85f3a"},
    {"filename":"x9e8o7v3.md","filenameStem":"x9e8o7v3","path":"x9e8o7v3.md","absPath":"/home/khadd/mynotes/x9e8o7v3.md","title":"The world is a jungle in general, and the networking game contributes many animals.","link":"[[x9e8o7v3]]","lead":"#quote","body":"#quote\n\n(from RFC 826, ARP, 1982)","snippets":["#quote"],"rawContent":"# The world is a jungle in general, and the networking game contributes many animals.\n\n#quote\n\n(from RFC 826, ARP, 1982)\n","wordCount":21,"tags":["quote"],"metadata":{},"created":"2024-12-18T10:11:45.583875324Z","modified":"2024-12-18T10:15:00.275749945Z","checksum":"fe8dd37edb811bca4b44706572c1392e0466c8ad75c955d1e05407380fa8474c"},
    {"filename":"5370nxug.md","filenameStem":"5370nxug","path":"5370nxug.md","absPath":"/home/khadd/mynotes/5370nxug.md","title":"There is no prize to perfection, only an end pursuit.","link":"[[5370nxug]]","lead":"#quote","body":"#quote\n\n- Viktor, in Arcane","snippets":["#quote"],"rawContent":"# There is no prize to perfection, only an end pursuit.\n\n#quote\n\n- Viktor, in Arcane\n","wordCount":16,"tags":["quote"],"metadata":{},"created":"2024-12-13T01:34:49.121817107Z","modified":"2024-12-13T01:35:48.017639558Z","checksum":"8ec60de4f96f60dbd4f9e592c032056a5b26d1a5738194f815ba7223effd0cc5"},
    {"filename":"74lcf2b2.md","filenameStem":"74lcf2b2","path":"74lcf2b2.md","absPath":"/home/khadd/mynotes/74lcf2b2.md","title":"There is no way to nirvana, nirvana is the way.","link":"[[74lcf2b2]]","lead":"- Thich Nhat Hanh","body":"- Thich Nhat Hanh","snippets":["- Thich Nhat Hanh"],"rawContent":"# There is no way to nirvana, nirvana is the way.\n\n- Thich Nhat Hanh\n","wordCount":15,"tags":[],"metadata":{},"created":"2024-12-12T11:26:45.592220949Z","modified":"2024-12-12T11:26:52.423159293Z","checksum":"f17e1a951bf250ce511b070391a2c36014e65cac3aec3e3a1728f1316cc3ba39"},
    {"filename":"24t7ope8.md","filenameStem":"24t7ope8","path":"24t7ope8.md","absPath":"/home/khadd/mynotes/24t7ope8.md","title":"There is nothing new under the sun","link":"[[24t7ope8]]","lead":"\u003e There is nothing new under the sun, but there are a lot of old things we don't\n\u003e know","body":"\u003e There is nothing new under the sun, but there are a lot of old things we don't\n\u003e know\n\n-- Ambrose Bierce, The Devil's Dictionary\n\nPlato's thery of forms?\n\n- Because [[itd1o3ic]]\n- and [[kfs6h55d]]","snippets":["\u003e There is nothing new under the sun, but there are a lot of old things we don't\n\u003e know"],"rawContent":"# There is nothing new under the sun\n\n\u003e There is nothing new under the sun, but there are a lot of old things we don't\n\u003e know\n\n-- Ambrose Bierce, The Devil's Dictionary\n\nPlato's thery of forms?\n\n- Because [[itd1o3ic]]\n- and [[kfs6h55d]]\n","wordCount":44,"tags":[],"metadata":{},"created":"2024-07-05T02:16:58.747054612Z","modified":"2024-07-05T05:05:26.953773457Z","checksum":"6af45ee2e08027ab68b542ff615cbfbded90ff3c241894bcd49685fef2734496"},
    {"filename":"jfm8ud28.md","filenameStem":"jfm8ud28","path":"jfm8ud28.md","absPath":"/home/khadd/mynotes/jfm8ud28.md","title":"Theseus: an Experiment in Operating System Structure and State Management","link":"[[jfm8ud28]]","lead":"#literature #os #rust","body":"#literature #os #rust\n\n[@boos2020theseus]\n\n# Main arguments\n\nState spill harms availability and evolvability of system software (see\n[[2j6s9zpm]]).\n\nTo mitigate state spills, it is necessary to restructure the OS architecture\n\n- The proposed system rearchitect OS components into Cells that has\n  _runtime-persistent_ bound [[#cells]].\n- It then avoid state spill through exporting states to the clients in similar\n  way to RESTful APIs [[#state-management]]\n\nProgramming language can statically ensure certain correctness invariants in the\nOS.\n\n- Theseus incorporates resource-specific invariants into Rust compiler checks.\n  For instance, memory management is implemented via the `MappedPages` types\n  that also introduce new static invariants for mapping memory (see 4.3).\n\nIt is necessary to match runtime execution environment with that of the\nlanguage's runtime model (i.e., _intralingual_ design) to take advantages of\nRust\n\n- Cells in Theseus are single-address space, single-privilege level, and use a\n  single allocator instance.\n- It enable compiler to assist resource management,\n- It enables compiler to assert safety checks without gaps in code behaviors.\n\n## Cells\n\nAll OS components are splitted into minimal cells, to be executed in\nsingle-address space (SAS), single privilege level (SPL), and are isolated using\nRust. Cells in Theseus have _runtime-persistent_ bounds, in that the bounds are\npersisted throughout compile time (crate bound), load time (memory regions), and\nruntime (by keeping track of dependency metadata).\n\n- This idea is opposite to the intertwined bounds introduces in monolithic\n  kernels. Takes kernel modules as an example, they don't have clearly defined\n  bounds; kernel module can access other OS entities in the code, and at\n  runtime.\n- Persistent cell bounds allows for clean cell-swapping (aka migration) and cell\n  evolution (aka live update) and fault recovery.\n\n## State management\n\nState spill is avoided by _opaque exportation_, which essentially means that the\nclient owns the state for client, but cannot read, or modify the state due to\nType safety.\n\n- This is similar to Object-capability systems, the callee might hold the\n  capabilities to invoke a function, but not using the capabilities by themself.\n  Due to Rust's type safety, variables are akin to capabilities.\n- Similarly, RESTful web architectures also employ a similar kind of _stateless\n  communication_, where the client pass everything that is needed to handle the\n  request to the server.\n- This is only possible when the client is enforced with Rust type safety.\n\nTheseus also enables _soft states_ that can be discarded without error and\n_unavoidable states_ (clientless state required by the hardware and states\ninvoked by hardware). Those states are stored into a unique cell call\n`state_db`.\n\n- Static states are moved into state_db, and only a weak reference is used. This\n  decouple the server cells that use hardware states from the hardware state\n  lifetime, so they can be swapped.\n- state_db cell must be serialized into non-volatile storage when swapping.\n\n## Cell swapping \u0026 evolution\n\nTODO","snippets":["#literature #os #rust"],"rawContent":"# Theseus: an Experiment in Operating System Structure and State Management\n\n#literature #os #rust\n\n[@boos2020theseus]\n\n# Main arguments\n\nState spill harms availability and evolvability of system software (see\n[[2j6s9zpm]]).\n\nTo mitigate state spills, it is necessary to restructure the OS architecture\n\n- The proposed system rearchitect OS components into Cells that has\n  _runtime-persistent_ bound [[#cells]].\n- It then avoid state spill through exporting states to the clients in similar\n  way to RESTful APIs [[#state-management]]\n\nProgramming language can statically ensure certain correctness invariants in the\nOS.\n\n- Theseus incorporates resource-specific invariants into Rust compiler checks.\n  For instance, memory management is implemented via the `MappedPages` types\n  that also introduce new static invariants for mapping memory (see 4.3).\n\nIt is necessary to match runtime execution environment with that of the\nlanguage's runtime model (i.e., _intralingual_ design) to take advantages of\nRust\n\n- Cells in Theseus are single-address space, single-privilege level, and use a\n  single allocator instance.\n- It enable compiler to assist resource management,\n- It enables compiler to assert safety checks without gaps in code behaviors.\n\n## Cells\n\nAll OS components are splitted into minimal cells, to be executed in\nsingle-address space (SAS), single privilege level (SPL), and are isolated using\nRust. Cells in Theseus have _runtime-persistent_ bounds, in that the bounds are\npersisted throughout compile time (crate bound), load time (memory regions), and\nruntime (by keeping track of dependency metadata).\n\n- This idea is opposite to the intertwined bounds introduces in monolithic\n  kernels. Takes kernel modules as an example, they don't have clearly defined\n  bounds; kernel module can access other OS entities in the code, and at\n  runtime.\n- Persistent cell bounds allows for clean cell-swapping (aka migration) and cell\n  evolution (aka live update) and fault recovery.\n\n## State management\n\nState spill is avoided by _opaque exportation_, which essentially means that the\nclient owns the state for client, but cannot read, or modify the state due to\nType safety.\n\n- This is similar to Object-capability systems, the callee might hold the\n  capabilities to invoke a function, but not using the capabilities by themself.\n  Due to Rust's type safety, variables are akin to capabilities.\n- Similarly, RESTful web architectures also employ a similar kind of _stateless\n  communication_, where the client pass everything that is needed to handle the\n  request to the server.\n- This is only possible when the client is enforced with Rust type safety.\n\nTheseus also enables _soft states_ that can be discarded without error and\n_unavoidable states_ (clientless state required by the hardware and states\ninvoked by hardware). Those states are stored into a unique cell call\n`state_db`.\n\n- Static states are moved into state_db, and only a weak reference is used. This\n  decouple the server cells that use hardware states from the hardware state\n  lifetime, so they can be swapped.\n- state_db cell must be serialized into non-volatile storage when swapping.\n\n## Cell swapping \u0026 evolution\n\nTODO\n","wordCount":479,"tags":["literature","os","rust"],"metadata":{},"created":"2024-05-22T08:24:03.256578199Z","modified":"2024-12-12T06:14:16.625953455Z","checksum":"cf784a84d6a06be00f6cf4d4abf61b80885981dd64a245708d183c53dd86596d"},
    {"filename":"xxn0pki0.md","filenameStem":"xxn0pki0","path":"xxn0pki0.md","absPath":"/home/khadd/mynotes/xxn0pki0.md","title":"Thinking in parallel, design together","link":"[[xxn0pki0]]","lead":"#project-management #team-working #system-design","body":"#project-management #team-working #system-design\n\nTrying to balance creativity and coordination in a team is difficult.\n\n## Thinking in parallel\n\nThinking should not be restricted or coordinated.\n\nEspecially, brainstorming should be done in parallel. It is difficult for a\nsingle person to foresee all aspects of the design space.\n\n## Design together\n\nAfter the design space is mapped out, it is crutial that major design decision\nmust be performed together.\n\nThis is to avoid fragmentation in the design.\n\nMoreover, we make should everyone get the big picture of how every parts fit\ntogether.\n\nTime and time again I try to decide a design by myself.\n\n# Reference\n\n- [Design]: https://maheshba.bitbucket.io/blog/2023/07/12/Design.html","snippets":["#project-management #team-working #system-design"],"rawContent":"# Thinking in parallel, design together\n\n#project-management #team-working #system-design\n\nTrying to balance creativity and coordination in a team is difficult.\n\n## Thinking in parallel\n\nThinking should not be restricted or coordinated.\n\nEspecially, brainstorming should be done in parallel. It is difficult for a\nsingle person to foresee all aspects of the design space.\n\n## Design together\n\nAfter the design space is mapped out, it is crutial that major design decision\nmust be performed together.\n\nThis is to avoid fragmentation in the design.\n\nMoreover, we make should everyone get the big picture of how every parts fit\ntogether.\n\nTime and time again I try to decide a design by myself.\n\n# Reference\n\n- [Design]: https://maheshba.bitbucket.io/blog/2023/07/12/Design.html\n","wordCount":114,"tags":["team-working","project-management","system-design"],"metadata":{},"created":"2023-08-11T08:42:20.819648413Z","modified":"2024-07-28T07:41:51.196606077Z","checksum":"ac185482b2057f752f32b9584572cf8c9752f85224456413c4a23d11f33b67c4"},
    {"filename":"k60yjf6q.md","filenameStem":"k60yjf6q","path":"k60yjf6q.md","absPath":"/home/khadd/mynotes/k60yjf6q.md","title":"Three pieces of an Operating System","link":"[[k60yjf6q]]","lead":"#os","body":"#os\n\nThere are three main pieces in achieving an operating system: _virtualization_,\n_concurrency_ and _persistent_ [@arpaci-dusseauoperating].\n\n## Virtualization\n\nVirtualization give an process an illusion of having access to the whole\nunderlying resource. To do so, the OS take physical resources and transform them\ninto virtual resources, and hand them out to the users.\n\nThis is the key in maximizing resource usage, since a single job rarely utilize\nall of the available hardware resource. Virtualization also make the system\neasier to use.\n\nThe key problem with virtualization is how to do it efficiently, how to attain\nfairness, and what hardware support is needed.\n\n## Concurrency\n\nConcurrency allows multiple jobs/tasks to execute at once. This is especially\nimportant in maximizing CPU efficiency: when waiting for slow I/O jobs, the CPU\ntime is better used executing other tasks.\n\nOS provides threads and processes [[a0g41kid]] abstractions to conveniently\nmanage multiple concurrent tasks.\n\nGiven multiple concurrent tasks safe access to the underlying resource, the OS\nalso gives synchronization privimites.\n\nThe main problems with concurrency is correctness for multiple tasks that access\nto the same underlying resources. Problems such as data race and deadlocks might\noccurs.\n\n## Persistent\n\nFinally, persistent deals with how to reliably store and retrieve data in a\npersistent storage (e.g., disk). This is provided by the _file system_.\n\nThe main problems is how manage information on the disk efficiently, and how\ndeal with failures.\n\n## Security\n\n## Other\n\n- [[7t4jlnaq]]","snippets":["#os"],"rawContent":"# Three pieces of an Operating System\n\n#os\n\nThere are three main pieces in achieving an operating system: _virtualization_,\n_concurrency_ and _persistent_ [@arpaci-dusseauoperating].\n\n## Virtualization\n\nVirtualization give an process an illusion of having access to the whole\nunderlying resource. To do so, the OS take physical resources and transform them\ninto virtual resources, and hand them out to the users.\n\nThis is the key in maximizing resource usage, since a single job rarely utilize\nall of the available hardware resource. Virtualization also make the system\neasier to use.\n\nThe key problem with virtualization is how to do it efficiently, how to attain\nfairness, and what hardware support is needed.\n\n## Concurrency\n\nConcurrency allows multiple jobs/tasks to execute at once. This is especially\nimportant in maximizing CPU efficiency: when waiting for slow I/O jobs, the CPU\ntime is better used executing other tasks.\n\nOS provides threads and processes [[a0g41kid]] abstractions to conveniently\nmanage multiple concurrent tasks.\n\nGiven multiple concurrent tasks safe access to the underlying resource, the OS\nalso gives synchronization privimites.\n\nThe main problems with concurrency is correctness for multiple tasks that access\nto the same underlying resources. Problems such as data race and deadlocks might\noccurs.\n\n## Persistent\n\nFinally, persistent deals with how to reliably store and retrieve data in a\npersistent storage (e.g., disk). This is provided by the _file system_.\n\nThe main problems is how manage information on the disk efficiently, and how\ndeal with failures.\n\n## Security\n\n## Other\n\n- [[7t4jlnaq]]\n","wordCount":245,"tags":["os"],"metadata":{},"created":"2023-05-24T06:21:06.186090369Z","modified":"2024-12-17T04:42:55.720876534Z","checksum":"bf02755b72ec3b7d9e1754db7447342fe837d76e06c66111b32f10c5f9724ad7"},
    {"filename":"u6datkss.md","filenameStem":"u6datkss","path":"u6datkss.md","absPath":"/home/khadd/mynotes/u6datkss.md","title":"Tolerating disassembly errors","link":"[[u6datkss]]","lead":"Disassembly is an error-prone process due to the challenges in disassembly\n[[fps6sygk]]. Disassembly tools often make the assumptions about the\ndisassembled binary to make the process easier. These assumptions include:","body":"Disassembly is an error-prone process due to the challenges in disassembly\n[[fps6sygk]]. Disassembly tools often make the assumptions about the\ndisassembled binary to make the process easier. These assumptions include:\n\n- A1. There is no data interleaving with code\n- A2. The binary is 64-bit position-independent\n- A3. Control flow/code pointers can be accurately recovered\n\nHowever, these assumptions sometimes do not hold, leading to incorrect\ndisassembly. Thus, many work aims to challenge or remove these assumptions\n[@priyadarshan2023safer,@bauman2018superset].\n\n- A1: Simple solution includees treating every possbile offsets as potential\n  instruction bounrary [[zmxk4kdo]].\n- A3:\n  - One approach is to not rey on recovered control flow at all [[4yeegysq]].\n  - Another approach is inspired by dynamic binary translation, to intercept\n    indirect control flow transfers and perform address translation to map\n    original code location to the instrumented code [@bauman2018superset]. This\n    may incur high overheads, which can be reduced through encoding code\n    pointers that need translation [@priyadarshan2023safer].\n\nYou can also do trail-and-error inalong with","snippets":["Disassembly is an error-prone process due to the challenges in disassembly\n[[fps6sygk]]. Disassembly tools often make the assumptions about the\ndisassembled binary to make the process easier. These assumptions include:"],"rawContent":"# Tolerating disassembly errors\n\nDisassembly is an error-prone process due to the challenges in disassembly\n[[fps6sygk]]. Disassembly tools often make the assumptions about the\ndisassembled binary to make the process easier. These assumptions include:\n\n- A1. There is no data interleaving with code\n- A2. The binary is 64-bit position-independent\n- A3. Control flow/code pointers can be accurately recovered\n\nHowever, these assumptions sometimes do not hold, leading to incorrect\ndisassembly. Thus, many work aims to challenge or remove these assumptions\n[@priyadarshan2023safer,@bauman2018superset].\n\n- A1: Simple solution includees treating every possbile offsets as potential\n  instruction bounrary [[zmxk4kdo]].\n- A3:\n  - One approach is to not rey on recovered control flow at all [[4yeegysq]].\n  - Another approach is inspired by dynamic binary translation, to intercept\n    indirect control flow transfers and perform address translation to map\n    original code location to the instrumented code [@bauman2018superset]. This\n    may incur high overheads, which can be reduced through encoding code\n    pointers that need translation [@priyadarshan2023safer].\n\nYou can also do trail-and-error inalong with\n","wordCount":164,"tags":[],"metadata":{},"created":"2024-07-22T01:28:37.921167185Z","modified":"2024-07-22T05:24:35.732851693Z","checksum":"dd35e9a898fe283db65f6eaf2e9fdf8a0438aae6b57ace7d1834cd8f726b41fc"},
    {"filename":"cosmdjej.md","filenameStem":"cosmdjej","path":"cosmdjej.md","absPath":"/home/khadd/mynotes/cosmdjej.md","title":"Transactional memory","link":"[[cosmdjej]]","lead":"#conccurency","body":"#conccurency\n\nTransactional memory is a technique that simplify concurrent programming by\nallowing critical sections to execute _optimistically_ (i.e.,\n[optimistic concurrency control](https://en.wikipedia.org/wiki/Optimistic_concurrency_control)).\n\nA transaction consists of series of intermediate _atomic_ read and writes to\nsome memory location. A transaction can be _committed_, as long as there are no\nconflicts. On the other hand, if there is any conflict during a transaction, it\nis rolled back, and an error handler is invoked (e.g., to retry the\ntransaction).\n\nA section of critical code marked as transactional can execute with minimal\ninterventions (e.g., acquiring lock). This leads to a much simpler programming\nmodel, and also less error-prone (e.g., deadlocks), since the validity of\ntransactions is guaranteed by transactional memory mechanisms.\n\nTransactional memory can be supported by the ISA, e.g., Intel TSX [[dx7vz8d5]],\nthat improve performance and make it easier to develop.","snippets":["#conccurency"],"rawContent":"# Transactional memory\n\n#conccurency\n\nTransactional memory is a technique that simplify concurrent programming by\nallowing critical sections to execute _optimistically_ (i.e.,\n[optimistic concurrency control](https://en.wikipedia.org/wiki/Optimistic_concurrency_control)).\n\nA transaction consists of series of intermediate _atomic_ read and writes to\nsome memory location. A transaction can be _committed_, as long as there are no\nconflicts. On the other hand, if there is any conflict during a transaction, it\nis rolled back, and an error handler is invoked (e.g., to retry the\ntransaction).\n\nA section of critical code marked as transactional can execute with minimal\ninterventions (e.g., acquiring lock). This leads to a much simpler programming\nmodel, and also less error-prone (e.g., deadlocks), since the validity of\ntransactions is guaranteed by transactional memory mechanisms.\n\nTransactional memory can be supported by the ISA, e.g., Intel TSX [[dx7vz8d5]],\nthat improve performance and make it easier to develop.\n","wordCount":140,"tags":["conccurency"],"metadata":{},"created":"2023-06-19T03:04:24.889404158Z","modified":"2024-07-01T03:00:34.616807479Z","checksum":"5005343f2b6cc781bb8dfed0979c6f47fab2cfcc4cd5090a90db48ec00c4655b"},
    {"filename":"l0jjwlte.md","filenameStem":"l0jjwlte","path":"l0jjwlte.md","absPath":"/home/khadd/mynotes/l0jjwlte.md","title":"Translating C to Rust","link":"[[l0jjwlte]]","lead":"C is known to be unsafe, and Rust is known for its safety. For this reason,\ntranslating C to Rust is appealing.","body":"C is known to be unsafe, and Rust is known for its safety. For this reason,\ntranslating C to Rust is appealing.\n\nTranslating C to _unsafe_ rust is easy enough, using transpiration rules. Tools\nlike [c2rust](https://c2rust.com/) does a pretty good job translating most C\nprograms into _semantically equivalent_ rust code. That is, the input program\nstatements are mapped one-to-one into unsafe rust statements with the same\nmeaning. This quickly give a piece of Rust code that you can plug into your\ncodebase that can be refined into Safe Rust.\n\nHowever, this does not introduce any benefits in terms of security. We want to\nhave the equivalent program in _safe_ Rust.\n\nThis immediately poses challenges, as the ways of programming C and Rust are\ncompletely different. It is very unclear how to map unsafe C semantics (e.g.,\npointers) into safe Rust primitives (`Box`, `Cell`, ownership principles), while\nalso keeping the function structures, general program layout.\n\nWhile compilation remove high-level details from the program and add low-level\ndetails, C-to-Rust translation must do the reversed, adding high-level semantics\ninto low-level programs. Similar challenges be seen in binary lifting,\ndecompilation.\n\n## LLM translation\n\nSimilar to binary decompilation, a recent trend is to use LLM to account for the\ngap between language.\n\n## Testing for correctness\n\nRust translation using unreliable methods like heuristics and LLM, require some\nway to validate the translated program.\n\n- _Differential fuzzing_ feeds different inputs into the original and translated\n  program and check for behavior mismatches.\n- Static analysis on the generated code.\n\n## Equivalencies for correctness measurement\n\nWe want some metric to guide the translation process. Commonly we want some kind\nof _property_ to be preserved between the original and the translated program.\n\n### Semantic equivalences\n\nSemantically equivalent translations means the original statements are literally\ntranslated into the target language.\n\nWe don't need differential testing to make sure that the program is correct.\n\nIt is clear that **semantic equivalence** is not what we want in C-to-Rust\ntranslations.\n\nStill, it provides a useful baseline to work on.\n\n### I/O equivalence\n\nI/O equivalence only require that input (arguments) and output (return values)\nof a function remain the same.\n\nFuzz testing is usually used for to test this without a complete set of test\ncases.\n\n### Other metrics\n\nWe can employ our creativity to\n\nSome ideas:\n\n- Memory consumption equivalency: Ensure two implementaiton consume the same\n  ideas.\n- Procedural equivalency: break down a function into smaller steps and make sure\n  they are equivalent\n- Function size equivalency","snippets":["C is known to be unsafe, and Rust is known for its safety. For this reason,\ntranslating C to Rust is appealing."],"rawContent":"# Translating C to Rust\n\nC is known to be unsafe, and Rust is known for its safety. For this reason,\ntranslating C to Rust is appealing.\n\nTranslating C to _unsafe_ rust is easy enough, using transpiration rules. Tools\nlike [c2rust](https://c2rust.com/) does a pretty good job translating most C\nprograms into _semantically equivalent_ rust code. That is, the input program\nstatements are mapped one-to-one into unsafe rust statements with the same\nmeaning. This quickly give a piece of Rust code that you can plug into your\ncodebase that can be refined into Safe Rust.\n\nHowever, this does not introduce any benefits in terms of security. We want to\nhave the equivalent program in _safe_ Rust.\n\nThis immediately poses challenges, as the ways of programming C and Rust are\ncompletely different. It is very unclear how to map unsafe C semantics (e.g.,\npointers) into safe Rust primitives (`Box`, `Cell`, ownership principles), while\nalso keeping the function structures, general program layout.\n\nWhile compilation remove high-level details from the program and add low-level\ndetails, C-to-Rust translation must do the reversed, adding high-level semantics\ninto low-level programs. Similar challenges be seen in binary lifting,\ndecompilation.\n\n## LLM translation\n\nSimilar to binary decompilation, a recent trend is to use LLM to account for the\ngap between language.\n\n## Testing for correctness\n\nRust translation using unreliable methods like heuristics and LLM, require some\nway to validate the translated program.\n\n- _Differential fuzzing_ feeds different inputs into the original and translated\n  program and check for behavior mismatches.\n- Static analysis on the generated code.\n\n## Equivalencies for correctness measurement\n\nWe want some metric to guide the translation process. Commonly we want some kind\nof _property_ to be preserved between the original and the translated program.\n\n### Semantic equivalences\n\nSemantically equivalent translations means the original statements are literally\ntranslated into the target language.\n\nWe don't need differential testing to make sure that the program is correct.\n\nIt is clear that **semantic equivalence** is not what we want in C-to-Rust\ntranslations.\n\nStill, it provides a useful baseline to work on.\n\n### I/O equivalence\n\nI/O equivalence only require that input (arguments) and output (return values)\nof a function remain the same.\n\nFuzz testing is usually used for to test this without a complete set of test\ncases.\n\n### Other metrics\n\nWe can employ our creativity to\n\nSome ideas:\n\n- Memory consumption equivalency: Ensure two implementaiton consume the same\n  ideas.\n- Procedural equivalency: break down a function into smaller steps and make sure\n  they are equivalent\n- Function size equivalency\n","wordCount":419,"tags":[],"metadata":{},"created":"2024-12-13T08:15:20.933819803Z","modified":"2024-12-24T07:06:19.902307091Z","checksum":"5c0b49006d78c1f53d008a5b658085a0b409761181c1b8955f34863e3bc34dc2"},
    {"filename":"cv3peid6.md","filenameStem":"cv3peid6","path":"cv3peid6.md","absPath":"/home/khadd/mynotes/cv3peid6.md","title":"Turning reading notes to permanent notes","link":"[[cv3peid6]]","lead":"#note-taking #zettelkasten","body":"#note-taking #zettelkasten\n\n\n# Steps\n\n## While reading\nIt is useful to keep a physical notes.\n\n## After reading\n[create-zettel-from-reading-notes] suggested using three phases:\n- Pull all the notes out. The order do not matter.\n- Cluster the notes. What are the big ideas that emerges?\n- Write notes about the clusters that emerges.\n\n# References\n[create-zettel-from-reading-notes](https://zettelkasten.de/posts/create-zettel-from-reading-notes/)\n\n[How to process reading annotations into evergreen notes](https://notes.andymatuschak.org/z2PJ51tCXuPFxnfFVUxxgwjvZ1geu4YnYm7hK)\n\u003e\n1. Write a broad note which captures the “big idea” of one of your clusters.\n  - Are there multiple big ideas? Write multiple broad notes to maintain Evergreen notes should be atomic.\n2. Write finer-grained notes: Look through the individual scraps in that cluster. Write notes which capture more nuanced atomic ideas within that cluster.\n3. Connect: Search for relevant past notes which relate to these new notes. Link, merge, and revise as necessary to represent your new, synthesized conception of those ideas.\n  - See Evergreen notes should be densely linked and Create speculative outlines while you write.\n4. Revise: Return to the broad note and improve your summary based on what you’ve learned writing the detailed notes and the details you’ve unpacked, if it’s possible to do so without muddying their focus. Remove detailed notes that are no longer necessary; update others based on what you learned writing your updated broad note if appropriate.\n5. Loop","snippets":["#note-taking #zettelkasten"],"rawContent":"# Turning reading notes to permanent notes\n#note-taking #zettelkasten\n\n\n# Steps\n\n## While reading\nIt is useful to keep a physical notes.\n\n## After reading\n[create-zettel-from-reading-notes] suggested using three phases:\n- Pull all the notes out. The order do not matter.\n- Cluster the notes. What are the big ideas that emerges?\n- Write notes about the clusters that emerges.\n\n# References\n[create-zettel-from-reading-notes](https://zettelkasten.de/posts/create-zettel-from-reading-notes/)\n\n[How to process reading annotations into evergreen notes](https://notes.andymatuschak.org/z2PJ51tCXuPFxnfFVUxxgwjvZ1geu4YnYm7hK)\n\u003e\n1. Write a broad note which captures the “big idea” of one of your clusters.\n  - Are there multiple big ideas? Write multiple broad notes to maintain Evergreen notes should be atomic.\n2. Write finer-grained notes: Look through the individual scraps in that cluster. Write notes which capture more nuanced atomic ideas within that cluster.\n3. Connect: Search for relevant past notes which relate to these new notes. Link, merge, and revise as necessary to represent your new, synthesized conception of those ideas.\n  - See Evergreen notes should be densely linked and Create speculative outlines while you write.\n4. Revise: Return to the broad note and improve your summary based on what you’ve learned writing the detailed notes and the details you’ve unpacked, if it’s possible to do so without muddying their focus. Remove detailed notes that are no longer necessary; update others based on what you learned writing your updated broad note if appropriate.\n5. Loop\n\n\n","wordCount":229,"tags":["zettelkasten","note-taking"],"metadata":{},"created":"2023-07-04T05:15:19.820068673Z","modified":"2023-07-04T05:24:18.753357325Z","checksum":"697bbcc7e2d2a2efd3f08ab145bdf697116270f2a507e420abbb1fbb42d012b6"},
    {"filename":"5wvnn9jv.md","filenameStem":"5wvnn9jv","path":"5wvnn9jv.md","absPath":"/home/khadd/mynotes/5wvnn9jv.md","title":"Two's Complement","link":"[[5wvnn9jv]]","lead":"Two's complement is how signed integers are represented in binaries. A two's\ncompelemnt number have the most significant bit indicating a negative number.\nThe remaining bits represents the number.","body":"Two's complement is how signed integers are represented in binaries. A two's\ncompelemnt number have the most significant bit indicating a negative number.\nThe remaining bits represents the number.\n\nRange of 8-bit singed int is -128 to 127\n\nThe rule for computing the two's complement form is very simple:\n\n\u003e To get a two's complement form of a negative number, inverse it value bits and\n\u003e adds 1.\n\nFor example, to get two's complement of -128, you get the binary form of 128\n(0b1000 0000):\n\nInverse it:\n\n    0111 1111\n\nAdds 1:\n\n    1000 0000\n\n## Why -1 is 0xff?\n\nBinary of 1 is 0b01\n\nInverse:\n\n    10\n\nAdds 1:\n\n    11\n\n## Why inverse and adds 1?\n\n### Inverse\n\nThe reason is that any negative number -N is actually 0 - N. Let's say N = 3\n\n```\n    0000\n   -0101\n    ----\n    1010\n```\n\n### Adds 1\n\nMaybe because the negative range starts from -1 instead of 0.","snippets":["Two's complement is how signed integers are represented in binaries. A two's\ncompelemnt number have the most significant bit indicating a negative number.\nThe remaining bits represents the number."],"rawContent":"# Two's Complement\n\nTwo's complement is how signed integers are represented in binaries. A two's\ncompelemnt number have the most significant bit indicating a negative number.\nThe remaining bits represents the number.\n\nRange of 8-bit singed int is -128 to 127\n\nThe rule for computing the two's complement form is very simple:\n\n\u003e To get a two's complement form of a negative number, inverse it value bits and\n\u003e adds 1.\n\nFor example, to get two's complement of -128, you get the binary form of 128\n(0b1000 0000):\n\nInverse it:\n\n    0111 1111\n\nAdds 1:\n\n    1000 0000\n\n## Why -1 is 0xff?\n\nBinary of 1 is 0b01\n\nInverse:\n\n    10\n\nAdds 1:\n\n    11\n\n## Why inverse and adds 1?\n\n### Inverse\n\nThe reason is that any negative number -N is actually 0 - N. Let's say N = 3\n\n```\n    0000\n   -0101\n    ----\n    1010\n```\n\n### Adds 1\n\nMaybe because the negative range starts from -1 instead of 0.\n","wordCount":157,"tags":[],"metadata":{},"created":"2024-07-12T06:33:16.015750208Z","modified":"2024-07-12T07:06:54.898555824Z","checksum":"2ea1a216778b4cced1652d30cdfa069bf730e86e52bd66467e3b7c692829e664"},
    {"filename":"jt30dq5c.md","filenameStem":"jt30dq5c","path":"jt30dq5c.md","absPath":"/home/khadd/mynotes/jt30dq5c.md","title":"US Visa","link":"[[jt30dq5c]]","lead":"#project","body":"#project\n\n\n- https://travel.state.gov/content/travel/en/us-visas/tourism-visit/visitor.html\n\nApplication ID: AA00DCCV49\n\n\n# Steps\n\n1. Visa application DS-160\n2. Pay + schedule: [URL](https://www.usvisascheduling.com/)\n3. \n\n# Message after DS-160\nPlease note: The first step in applying for a visa is to electronically submit the DS-160 online application form. The next step is to look at the Internet pages of the region where you want to apply for a visa. Embassy or Consulate Most visa applicants will be scheduled for a visa interview, but some others may be eligible for visa renewal. Embassy or consulate information may include local, personalized guidance on scheduling interviews, submitting visa applications and frequently asked questions.\n\nYou must bring the following with you at all stages of your application:\npassport\nIf you have additional documents that you believe will help with the visa process, please submit them.\n## Instructions\nAt the time of interview, you must submit a confirmation page with a clear, legible barcode. You do not need to submit the application itself at the time of interview. If you are currently unable to connect to your printer, choose to have your confirmation page sent to your email address. You may print or email the application for your own reference.\nIf you have paid the visa application fee receipt and other fees related to the application, you must submit proof of this. There may be other costs associated with the visa application process. Please check if your nationality applies to: Fees for reciprocity (excluding Korea) Other costs to be paid\n\nFor other inquiries or information on how to contact the U.S. consulate, please visit the following website. https://kr.usembassy.gov/visas/ or http://travel.state.gov .\nNOTE: Unless you are exempt from an interview, you will be asked to sign your biometric signature when completing the application. Example) When your fingerprints are taken in front of the consul. Your biometric signature certifies that you have read and understood the nonimmigrant visa application questions and that your answers are true and accurate to the best of your knowledge and belief. You also certify under the penalty of perjury that all statements you make on the application and at the time of the interview are true and accurate to the best of your knowledge and belief.\n\nYou electronically signed your application on the following date: 20-May-2024 02:12:40 (GMT-05:00). Even if someone else has completed the application, you must personally sign the application electronically, unless exempted by regulations. Your electronic signature certifies that you have read and understood the application questions and that your answers are true and accurate to the best of your knowledge and belief. Submitting an application with any false or misleading statements may result in permanent visa denial or denial of entry into the United States. The statements made in this application have not been declared under the penalty of perjury. (28 USC 1746).\nInformation you submit along with statements you make in your application may be used by other government agencies with lawful authority, including for law enforcement and immigration law enforcement purposes. If your fingerprints are collected during the visa application process, your fingerprints may be used to match other fingerprints registered in the Federal Bureau of Investigation's Next Generation Identification Fingerprint System or other systems developed in the future (including civil, criminal, and latent fingerprint storage systems). . The photo you submit with your application may be used to verify employment or for other purposes as required by U.S. law.\n\n\n\n# Additional documents\nYou should bring the following documents to your interview. Original documents are always preferred over photocopies. Do not fax, email or mail any supporting documents to the Embassy\n- Current proof of income, tax payments, property or business ownership, or assets.\n- Your travel itinerary and/or other explanation about your planned trip.\n- A letter from your employer detailing your position, salary, how long you have been employed, any authorized vacation, and the business purpose, if any, of your U.S. trip.\n- Criminal/court records pertaining to any arrest or conviction anywhere, even if you completed your sentence or were later pardoned.\n- \nAdditionally, based on your purpose of travel, you should consider bringing the following:\n\nStudents\nBring your latest school results, transcripts and degrees/diplomas. Also bring evidence of financial support such as monthly bank statements, fixed deposit slips, or other evidence.\n\nWorking adults\nBring an employment letter from your employer and pay slips from the most recent three months.\n\nBusinessmen and company directors\nBring evidence of your position in the company and remuneration.\n\nPrevious visitors to the U.S.\nIf you were previously in the United States, any documents attesting to your immigration or visa status.\n\n\n# Notes on usvisascheduling.com\nNotes and Instructions\nBefore you proceed to the next step ensure that all details including the passport bio data and DS-160 information are correct for all applicants scheduled during this session. Any incorrect data might lead to the cancellation of your appointments and/or purchase of a new visa fee receipt. Visa fees are not refundable nor transferrable.\n-: --------------------------------------\nA: Your DS-160 number must be accurate and the DS-160 must be newly filled out for each application. You cannot use a prior DS-160 application to make a new application. If you provide an incorrect DS-160 number, it may delay your interview.\n-: --------------------------------------\nB: Your local contact number must be a phone number in Korea. If you provide an international contact number, it may delay the delivery of your passport.\n-: --------------------------------------\nC: Students (F and M) visas for new students can be issued up to 365 days in advance of the start date for a course of study.\n-: --------------------------------------\nD: Applicants can drop off visa applications only on your scheduled appointment day. If you drop off your visa applications at one of Ilyang Logis’ offices on a date other than your scheduled appointment date, your application will be returned, and your delivery fees will not be refunded.\n-: --------------------------------------\nE: If you have been refused of any type of visa in the past three months, please select “Previously Refused” visa priority when scheduling your interview. Selecting “Regular” visa priority may result in jeopardizing your visa interview.\n-: --------------------------------------\nF: Non-Koreans seeking a Regular appointment who are in Korea with a valid Residence Card should select “Regular - Korean Passport or Residence Card holders” when scheduling your interview. If you are not a Korean citizen and do not have a valid Residence Card, you must select “Regular - Non-Koreans without a Residence Card.” Failure to select the correct priority may result in jeopardizing your visa interview.\n-: --------------------------------------\nG: You must bring your I-129 petition receipt number and a copy of your Form I-797 to your interview at the Embassy or Consulate in order to verify your petition.","snippets":["#project"],"rawContent":"# US Visa\n#project\n\n\n- https://travel.state.gov/content/travel/en/us-visas/tourism-visit/visitor.html\n\nApplication ID: AA00DCCV49\n\n\n# Steps\n\n1. Visa application DS-160\n2. Pay + schedule: [URL](https://www.usvisascheduling.com/)\n3. \n\n# Message after DS-160\nPlease note: The first step in applying for a visa is to electronically submit the DS-160 online application form. The next step is to look at the Internet pages of the region where you want to apply for a visa. Embassy or Consulate Most visa applicants will be scheduled for a visa interview, but some others may be eligible for visa renewal. Embassy or consulate information may include local, personalized guidance on scheduling interviews, submitting visa applications and frequently asked questions.\n\nYou must bring the following with you at all stages of your application:\npassport\nIf you have additional documents that you believe will help with the visa process, please submit them.\n## Instructions\nAt the time of interview, you must submit a confirmation page with a clear, legible barcode. You do not need to submit the application itself at the time of interview. If you are currently unable to connect to your printer, choose to have your confirmation page sent to your email address. You may print or email the application for your own reference.\nIf you have paid the visa application fee receipt and other fees related to the application, you must submit proof of this. There may be other costs associated with the visa application process. Please check if your nationality applies to: Fees for reciprocity (excluding Korea) Other costs to be paid\n\nFor other inquiries or information on how to contact the U.S. consulate, please visit the following website. https://kr.usembassy.gov/visas/ or http://travel.state.gov .\nNOTE: Unless you are exempt from an interview, you will be asked to sign your biometric signature when completing the application. Example) When your fingerprints are taken in front of the consul. Your biometric signature certifies that you have read and understood the nonimmigrant visa application questions and that your answers are true and accurate to the best of your knowledge and belief. You also certify under the penalty of perjury that all statements you make on the application and at the time of the interview are true and accurate to the best of your knowledge and belief.\n\nYou electronically signed your application on the following date: 20-May-2024 02:12:40 (GMT-05:00). Even if someone else has completed the application, you must personally sign the application electronically, unless exempted by regulations. Your electronic signature certifies that you have read and understood the application questions and that your answers are true and accurate to the best of your knowledge and belief. Submitting an application with any false or misleading statements may result in permanent visa denial or denial of entry into the United States. The statements made in this application have not been declared under the penalty of perjury. (28 USC 1746).\nInformation you submit along with statements you make in your application may be used by other government agencies with lawful authority, including for law enforcement and immigration law enforcement purposes. If your fingerprints are collected during the visa application process, your fingerprints may be used to match other fingerprints registered in the Federal Bureau of Investigation's Next Generation Identification Fingerprint System or other systems developed in the future (including civil, criminal, and latent fingerprint storage systems). . The photo you submit with your application may be used to verify employment or for other purposes as required by U.S. law.\n\n\n\n# Additional documents\nYou should bring the following documents to your interview. Original documents are always preferred over photocopies. Do not fax, email or mail any supporting documents to the Embassy\n- Current proof of income, tax payments, property or business ownership, or assets.\n- Your travel itinerary and/or other explanation about your planned trip.\n- A letter from your employer detailing your position, salary, how long you have been employed, any authorized vacation, and the business purpose, if any, of your U.S. trip.\n- Criminal/court records pertaining to any arrest or conviction anywhere, even if you completed your sentence or were later pardoned.\n- \nAdditionally, based on your purpose of travel, you should consider bringing the following:\n\nStudents\nBring your latest school results, transcripts and degrees/diplomas. Also bring evidence of financial support such as monthly bank statements, fixed deposit slips, or other evidence.\n\nWorking adults\nBring an employment letter from your employer and pay slips from the most recent three months.\n\nBusinessmen and company directors\nBring evidence of your position in the company and remuneration.\n\nPrevious visitors to the U.S.\nIf you were previously in the United States, any documents attesting to your immigration or visa status.\n\n\n# Notes on usvisascheduling.com\nNotes and Instructions\nBefore you proceed to the next step ensure that all details including the passport bio data and DS-160 information are correct for all applicants scheduled during this session. Any incorrect data might lead to the cancellation of your appointments and/or purchase of a new visa fee receipt. Visa fees are not refundable nor transferrable.\n-: --------------------------------------\nA: Your DS-160 number must be accurate and the DS-160 must be newly filled out for each application. You cannot use a prior DS-160 application to make a new application. If you provide an incorrect DS-160 number, it may delay your interview.\n-: --------------------------------------\nB: Your local contact number must be a phone number in Korea. If you provide an international contact number, it may delay the delivery of your passport.\n-: --------------------------------------\nC: Students (F and M) visas for new students can be issued up to 365 days in advance of the start date for a course of study.\n-: --------------------------------------\nD: Applicants can drop off visa applications only on your scheduled appointment day. If you drop off your visa applications at one of Ilyang Logis’ offices on a date other than your scheduled appointment date, your application will be returned, and your delivery fees will not be refunded.\n-: --------------------------------------\nE: If you have been refused of any type of visa in the past three months, please select “Previously Refused” visa priority when scheduling your interview. Selecting “Regular” visa priority may result in jeopardizing your visa interview.\n-: --------------------------------------\nF: Non-Koreans seeking a Regular appointment who are in Korea with a valid Residence Card should select “Regular - Korean Passport or Residence Card holders” when scheduling your interview. If you are not a Korean citizen and do not have a valid Residence Card, you must select “Regular - Non-Koreans without a Residence Card.” Failure to select the correct priority may result in jeopardizing your visa interview.\n-: --------------------------------------\nG: You must bring your I-129 petition receipt number and a copy of your Form I-797 to your interview at the Embassy or Consulate in order to verify your petition.\n","wordCount":1121,"tags":["project"],"metadata":{},"created":"2024-05-22T08:24:03.270754538Z","modified":"2024-05-23T06:27:53.274204857Z","checksum":"0d3ecd0085a5d6ffc7813a05b1b29ab8b523b9e5dd97a08f96512437cbc9d7c9"},
    {"filename":"k57qb7oh.md","filenameStem":"k57qb7oh","path":"k57qb7oh.md","absPath":"/home/khadd/mynotes/k57qb7oh.md","title":"Ubuntu notes","link":"[[k57qb7oh]]","lead":"#linux-user #distro","body":"#linux-user #distro\n\n# Package manager\n\n## Maintaining apt mirror\n\nIt is unnecessary to manually rewrite `/etc/apt/source.list` with the fastest\none. Apt supports selecting from a list of mirrors. Just put this to the top of\nthe `/etc/apt/source.list`:\n\n```bash\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-updates main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-backports main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-security main restricted universe multiverse\n```","snippets":["#linux-user #distro"],"rawContent":"# Ubuntu notes\n\n#linux-user #distro\n\n# Package manager\n\n## Maintaining apt mirror\n\nIt is unnecessary to manually rewrite `/etc/apt/source.list` with the fastest\none. Apt supports selecting from a list of mirrors. Just put this to the top of\nthe `/etc/apt/source.list`:\n\n```bash\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-updates main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-backports main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-security main restricted universe multiverse\n```\n","wordCount":70,"tags":["distro","linux-user"],"metadata":{},"created":"2023-06-16T08:04:25.806849293Z","modified":"2024-06-20T05:23:57.945588431Z","checksum":"37dab9d60df3e40272e33365f80ae82222fc30de51f71c2caab032d422c61fd5"},
    {"filename":"4nobp1na.md","filenameStem":"4nobp1na","path":"4nobp1na.md","absPath":"/home/khadd/mynotes/4nobp1na.md","title":"Understanding the ELF Specification","link":"[[4nobp1na]]","lead":"#ELF","body":"#ELF\n\nIt is a lot to take in lol. Maybe it is easier to get in terms of relationships.\n\n## Sections and headers\n\n```text\n                  ELF Header ─────────────────────────────────────────────┐\n               Program Header Table (PHDR) ─────┐            ◄────────────┤ size, no. of entry,\n               Segments                         │                         │ offset in file\nUsed by linker   Text segmenht     ◄────────────┤                         │\n        ┌────────► .text Section                │  Used by executable     │\n        │        Data segmenht                  │                         │\n        ├────────► .data Section                │                         │\n        ├────────► .rodata Section ◄────────────┘                         │\n        └───── Section Header Table (SHDR)                   ◄────────────┘\n```\n\n## `.rela.plt`, `.rela.dyn`, `.dynstr`, `.dynsym`\n\nCopied from [@federico2015how]\n\n```text\n_dl_runtime_resolve(link_map_obj, reloc_index)\n                                        │\n┌───────────────────────────────────────┘\n│\n│   .rel.plt               .dynsym          .dynstr\n│    ...                     ...              ...\n└► r_offset                st_name ────────► read\\0\n   r_info    ─────┐  ┌───► st_info           ...\n              ┌───┼──┘                  ┌──► printf\\0\n   r_offset   │   │        st_name ─────┘\n   r_info   ──┘   └──────► st_info\n\n```\n\n## Relationships\n\n- Program header table _defines_ segments\n- Segments _contain_ sections\n- Relocation table _is a_ section\n- Dynamic Linker _is a_ (type of) program interpreter\n- Link editor _is_ the linker\n-\n\n## Notes\n\n- Every data useful for linking is in a section, e.g., `.symtab`: symbol table,\n  `rela`\n- Execution does not need to care about linking.\n\n## More references\n\n[lastweek]: http://lastweek.io/notes/dynamic_linking/","snippets":["#ELF"],"rawContent":"# Understanding the ELF Specification\n\n#ELF\n\nIt is a lot to take in lol. Maybe it is easier to get in terms of relationships.\n\n## Sections and headers\n\n```text\n                  ELF Header ─────────────────────────────────────────────┐\n               Program Header Table (PHDR) ─────┐            ◄────────────┤ size, no. of entry,\n               Segments                         │                         │ offset in file\nUsed by linker   Text segmenht     ◄────────────┤                         │\n        ┌────────► .text Section                │  Used by executable     │\n        │        Data segmenht                  │                         │\n        ├────────► .data Section                │                         │\n        ├────────► .rodata Section ◄────────────┘                         │\n        └───── Section Header Table (SHDR)                   ◄────────────┘\n```\n\n## `.rela.plt`, `.rela.dyn`, `.dynstr`, `.dynsym`\n\nCopied from [@federico2015how]\n\n```text\n_dl_runtime_resolve(link_map_obj, reloc_index)\n                                        │\n┌───────────────────────────────────────┘\n│\n│   .rel.plt               .dynsym          .dynstr\n│    ...                     ...              ...\n└► r_offset                st_name ────────► read\\0\n   r_info    ─────┐  ┌───► st_info           ...\n              ┌───┼──┘                  ┌──► printf\\0\n   r_offset   │   │        st_name ─────┘\n   r_info   ──┘   └──────► st_info\n\n```\n\n## Relationships\n\n- Program header table _defines_ segments\n- Segments _contain_ sections\n- Relocation table _is a_ section\n- Dynamic Linker _is a_ (type of) program interpreter\n- Link editor _is_ the linker\n-\n\n## Notes\n\n- Every data useful for linking is in a section, e.g., `.symtab`: symbol table,\n  `rela`\n- Execution does not need to care about linking.\n\n## More references\n\n[lastweek]: http://lastweek.io/notes/dynamic_linking/\n","wordCount":195,"tags":["ELF"],"metadata":{},"created":"2024-06-27T07:54:08.797321443Z","modified":"2024-07-03T03:33:33.697260901Z","checksum":"34d03bdc37a518f623d4bf52e3a38d7dc1b8a090a3bb2d0a4ed2972369cee7b0"},
    {"filename":"wwxm9czw.md","filenameStem":"wwxm9czw","path":"wwxm9czw.md","absPath":"/home/khadd/mynotes/wwxm9czw.md","title":"Unikernel Binary Compatibility","link":"[[wwxm9czw]]","lead":"#unikernel #os #binary","body":"#unikernel #os #binary\n\nUnikernels are build systems for specialized kernels, so it is expected for\nsource code to be available. However, there has been researches and projects\nthat combine the benefits of unikernels (small footprint, fast system calls,\nattack surface reduction [[e7p8xpz4]]) with binary compatibility. Examples\ninclude Unikraft, OSv, HermiTux [@olivier2019binarycompatible], Rump, Lupine\nLinux.\n\nBinary compatibility seems to be the future direction for unikernel deployments,\nas shown by the efforts in Unikraft.\n\nBinary compatibility is provided through two aspects, load time compatibility\nand runtime compatibility [@olivier2019binarycompatible], following the Linux\nABI.\n\n## Load-time compatibility\n\nLoad-time compatibility is provided by having loader that support the Linux\nbinary format (ELF). To support dynamic libraries, Unikernels includes a custom\nloader that redirect calls to libc functions to unikernel calls. Customized libc\nfunctions are commonly used that directly invoke the system call implementation.\n\n## Runtime Compatibility\n\nRuntime compatibility means that the unikernel supports the system call ABI,\ne.g., syscall number is in `rax` register, etc. This can be simply provided\nthrough a custom trap handler.\n\nHowever, the performance of trap handler is worse than a function call, which\nhurts the fast system calls benefit of unikernels. A simple solution is to\nstatically rewrite system call instructions into function calls\n[@olivier2019binarycompatible] [@yasukata2023zpoline].\n\n### Runtime compatibility without performance\n\nA better way is to rely on the ELF loader and library loading? You would link\nELFs unikernel functions. However, it does hurt the generality.\n\nAnother approach is to lazily rewrite syscalls when they are called, similar to\nlazypoline.","snippets":["#unikernel #os #binary"],"rawContent":"# Unikernel Binary Compatibility\n\n#unikernel #os #binary\n\nUnikernels are build systems for specialized kernels, so it is expected for\nsource code to be available. However, there has been researches and projects\nthat combine the benefits of unikernels (small footprint, fast system calls,\nattack surface reduction [[e7p8xpz4]]) with binary compatibility. Examples\ninclude Unikraft, OSv, HermiTux [@olivier2019binarycompatible], Rump, Lupine\nLinux.\n\nBinary compatibility seems to be the future direction for unikernel deployments,\nas shown by the efforts in Unikraft.\n\nBinary compatibility is provided through two aspects, load time compatibility\nand runtime compatibility [@olivier2019binarycompatible], following the Linux\nABI.\n\n## Load-time compatibility\n\nLoad-time compatibility is provided by having loader that support the Linux\nbinary format (ELF). To support dynamic libraries, Unikernels includes a custom\nloader that redirect calls to libc functions to unikernel calls. Customized libc\nfunctions are commonly used that directly invoke the system call implementation.\n\n## Runtime Compatibility\n\nRuntime compatibility means that the unikernel supports the system call ABI,\ne.g., syscall number is in `rax` register, etc. This can be simply provided\nthrough a custom trap handler.\n\nHowever, the performance of trap handler is worse than a function call, which\nhurts the fast system calls benefit of unikernels. A simple solution is to\nstatically rewrite system call instructions into function calls\n[@olivier2019binarycompatible] [@yasukata2023zpoline].\n\n### Runtime compatibility without performance\n\nA better way is to rely on the ELF loader and library loading? You would link\nELFs unikernel functions. However, it does hurt the generality.\n\nAnother approach is to lazily rewrite syscalls when they are called, similar to\nlazypoline.\n","wordCount":254,"tags":["os","unikernel","binary"],"metadata":{},"created":"2024-06-20T06:42:51.659979811Z","modified":"2024-12-02T04:24:03.351098331Z","checksum":"4a3300dbc6f467ba05a8964290c81abb0304bcfe754925d045696f3c03b46440"},
    {"filename":"e7p8xpz4.md","filenameStem":"e7p8xpz4","path":"e7p8xpz4.md","absPath":"/home/khadd/mynotes/e7p8xpz4.md","title":"Unikernel Security","link":"[[e7p8xpz4]]","lead":"#area #unikernel #os #security","body":"#area #unikernel #os #security\n\n[@hindy2020security] provides an overview of security of unikernels, which is\nsummarized here.\n\n## The plus\n\n### Reduced attack curface\n\nOverall, unikernels enables extreme attack surface reduction due to being\nspecialized. This means less gadgets of attacks, and less attack surfaces in\ngeneral.\n\n#### Impact to TCB\n\nFor trusted execution, the goal is to minimize the TCB, which is also align with\nthe philosophy of unikernels.\n\n#### Side-benefits from reduced attack surface\n\nFirst, there is no shell implemented in unikernels, making attacks that aims to\nlaunch a shell infeasible.\n\nSecond, unikernels do not implement system calls, which can be an entry point\nfor attacks (note some unikernels offer syscall interface for binary\ncompatibility [[wwxm9czw]]). Hence, attackers are forced to use control-flow\nhijacking-based attacks to jump to unikernel functions,which can be mitigated\nthrough ASLR/CFI.\n\nThird, since the hardware are interfaces not emulated, attack against emulated\nhardware interface (the Venom attack ?) is mitigated.\n\n### Immutable infrastructure\n\nUnikernel's infrastructures is _immutable_, to rebuild the unikernel app, the\nentire infrastructure (OS, application, libraries) need to be rebuilt (through\nthe application may be exchanged through binary-compatibility [[wwxm9czw]]).\nThis avoid illegal modification, vulnerabilities from out-dated configurations.\n\n### Better isolation\n\nHardware-accelerated virtualization also offers better isolation compared to\ncontainers [@yasukata2023exitless], [[h3manv25]].\n\n## The negative\n\nThe negatives (in security) of unikernels comes from two aspect: due to hardware\nvirtualization, and due to lack of ring separation.\n\n### Virtualized hardware\n\nBecause hardware is virtualized, entrophy suffers. Due to hardware being\nvirtualized, random number generator based on hardware events lacks entropy.\nThis leads to attacks on random number generator.\n\n### Lack of ring separtation\n\nDue to the lack of ring separation, arbitrary execution attacks on application\ncode enable access to kernel space, making privilege escalation unnecessary.\n\n### Compatibility issues\n\nmany security features that are commonly deployed are missing on unikernels\n(maybe due to it being hard to maintain for both applications and kernel code).\nExamples are ASLR, `__FORTIFY_SOURCE`","snippets":["#area #unikernel #os #security"],"rawContent":"# Unikernel Security\n\n#area #unikernel #os #security\n\n[@hindy2020security] provides an overview of security of unikernels, which is\nsummarized here.\n\n## The plus\n\n### Reduced attack curface\n\nOverall, unikernels enables extreme attack surface reduction due to being\nspecialized. This means less gadgets of attacks, and less attack surfaces in\ngeneral.\n\n#### Impact to TCB\n\nFor trusted execution, the goal is to minimize the TCB, which is also align with\nthe philosophy of unikernels.\n\n#### Side-benefits from reduced attack surface\n\nFirst, there is no shell implemented in unikernels, making attacks that aims to\nlaunch a shell infeasible.\n\nSecond, unikernels do not implement system calls, which can be an entry point\nfor attacks (note some unikernels offer syscall interface for binary\ncompatibility [[wwxm9czw]]). Hence, attackers are forced to use control-flow\nhijacking-based attacks to jump to unikernel functions,which can be mitigated\nthrough ASLR/CFI.\n\nThird, since the hardware are interfaces not emulated, attack against emulated\nhardware interface (the Venom attack ?) is mitigated.\n\n### Immutable infrastructure\n\nUnikernel's infrastructures is _immutable_, to rebuild the unikernel app, the\nentire infrastructure (OS, application, libraries) need to be rebuilt (through\nthe application may be exchanged through binary-compatibility [[wwxm9czw]]).\nThis avoid illegal modification, vulnerabilities from out-dated configurations.\n\n### Better isolation\n\nHardware-accelerated virtualization also offers better isolation compared to\ncontainers [@yasukata2023exitless], [[h3manv25]].\n\n## The negative\n\nThe negatives (in security) of unikernels comes from two aspect: due to hardware\nvirtualization, and due to lack of ring separation.\n\n### Virtualized hardware\n\nBecause hardware is virtualized, entrophy suffers. Due to hardware being\nvirtualized, random number generator based on hardware events lacks entropy.\nThis leads to attacks on random number generator.\n\n### Lack of ring separtation\n\nDue to the lack of ring separation, arbitrary execution attacks on application\ncode enable access to kernel space, making privilege escalation unnecessary.\n\n### Compatibility issues\n\nmany security features that are commonly deployed are missing on unikernels\n(maybe due to it being hard to maintain for both applications and kernel code).\nExamples are ASLR, `__FORTIFY_SOURCE`\n","wordCount":325,"tags":["os","unikernel","security","area"],"metadata":{},"created":"2023-05-22T02:06:14.454012603Z","modified":"2024-11-28T12:18:04.780680138Z","checksum":"3d9bdc24f5030db9c4b690f6390972dbff50d8d7d1adfe8048cf7437d797bfca"},
    {"filename":"oh8ubbsc.md","filenameStem":"oh8ubbsc","path":"oh8ubbsc.md","absPath":"/home/khadd/mynotes/oh8ubbsc.md","title":"Unikraft Common bugs","link":"[[oh8ubbsc]]","lead":"- When CR2 shows 0x0003fffffff\n  - Probably stack overflow by some infinite loops. Stack is at 0x4xxxxxxxx and\n    grows down.","body":"- When CR2 shows 0x0003fffffff\n  - Probably stack overflow by some infinite loops. Stack is at 0x4xxxxxxxx and\n    grows down.","snippets":["- When CR2 shows 0x0003fffffff\n  - Probably stack overflow by some infinite loops. Stack is at 0x4xxxxxxxx and\n    grows down."],"rawContent":"# Unikraft Common bugs\n\n- When CR2 shows 0x0003fffffff\n  - Probably stack overflow by some infinite loops. Stack is at 0x4xxxxxxxx and\n    grows down.\n","wordCount":24,"tags":[],"metadata":{},"created":"2024-07-08T09:04:38.810636224Z","modified":"2024-07-08T09:06:03.697272755Z","checksum":"3951d7dfd5aaa14afa36c23e90613cb524ae5637b96d88e399f7582c3304b70a"},
    {"filename":"gkmhn4kd.md","filenameStem":"gkmhn4kd","path":"gkmhn4kd.md","absPath":"/home/khadd/mynotes/gkmhn4kd.md","title":"Unikraft ELF loader notes","link":"[[gkmhn4kd]]","lead":"#project","body":"#project\n\n```log\n\u003cmain.c @  206\u003e helloworld: Load executable (helloworld)...\n\u003celf_load.c @  104\u003e helloworld: ELF machine type: 62\n\u003celf_load.c @  120\u003e helloworld: ELF OS ABI: 0\n\u003celf_load.c @  134\u003e helloworld: ELF object type: 3\n\u003celf_load.c @  177\u003e helloworld: phdr[2]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 1528 B, memsz 1528 B, align: 4096 B\n\u003celf_load.c @  188\u003e helloworld: \\_ segment at pie + 0x0 (len: 0x5f8) from file @ 0x0 (len: 0x5f8)\n\u003celf_load.c @  177\u003e helloworld: phdr[3]: R-X, offset: 0x1000, vaddr: 0x1000, paddr: 0x1000, filesz: 501 B, memsz 501 B, align: 4096 B\n\u003celf_load.c @  188\u003e helloworld: \\_ segment at pie + 0x1000 (len: 0x1f5) from file @ 0x1000 (len: 0x1f5)\n\u003celf_load.c @  177\u003e helloworld: phdr[4]: R--, offset: 0x2000, vaddr: 0x2000, paddr: 0x2000, filesz: 344 B, memsz 344 B, align: 4096 B\n\u003celf_load.c @  188\u003e helloworld: \\_ segment at pie + 0x2000 (len: 0x158) from file @ 0x2000 (len: 0x158)\n\u003celf_load.c @  177\u003e helloworld: phdr[5]: RW-, offset: 0x2db8, vaddr: 0x3db8, paddr: 0x3db8, filesz: 600 B, memsz 608 B, align: 4096 B\n\u003celf_load.c @  188\u003e helloworld: \\_ segment at pie + 0x3db8 (len: 0x260) from file @ 0x2db8 (len: 0x258)\n\u003celf_load.c @  205\u003e helloworld: base: pie + 0x0, len: 0x4018\n\u003celf_load.c @  440\u003e helloworld: Memory mapped 0x0 - 0x5f8 to 0x100000b000 - 0x100000b5f8\n\u003celf_load.c @  462\u003e helloworld: Program/Library memory region: 0x100000b000-0x1000010000\n\u003celf_load.c @  347\u003e helloworld: Zeroing 0x100000b5f8 - 0x100000c000\n\u003celf_load.c @  508\u003e helloworld: Memory mapping 0x1000 - 0x11f5 to 0x100000c000 - 0x100000c1f5\n\u003celf_load.c @  347\u003e helloworld: Zeroing 0x100000c1f5 - 0x100000d000\n\u003celf_load.c @  508\u003e helloworld: Memory mapping 0x2000 - 0x2158 to 0x100000d000 - 0x100000d158\n\u003celf_load.c @  347\u003e helloworld: Zeroing 0x100000d158 - 0x100000e000\n\u003celf_load.c @  508\u003e helloworld: Memory mapping 0x2000 - 0x3dc8 to 0x100000e000 - 0x100000f010\n\u003celf_load.c @  347\u003e helloworld: Zeroing 0x100000f010 - 0x1000010000\n\u003celf_load.c @  779\u003e helloworld: Protecting 0x100000b000 - 0x100000c000: R--\n\u003celf_load.c @  779\u003e helloworld: Protecting 0x100000c000 - 0x100000d000: R-X\n\u003celf_load.c @  779\u003e helloworld: Protecting 0x100000d000 - 0x100000e000: R--\n\u003celf_load.c @  779\u003e helloworld: Protecting 0x100000e000 - 0x1000010000: RW-\n\u003celf_load.c @ 1022\u003e helloworld: Loading program interpreter /lib64/ld-linux-x86-64.so.2...\n\u003celf_load.c @  104\u003e \u003cinterp\u003e: ELF machine type: 62\n\u003celf_load.c @  120\u003e \u003cinterp\u003e: ELF OS ABI: 0\n\u003celf_load.c @  134\u003e \u003cinterp\u003e: ELF object type: 3\n\u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[0]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 4040 B, memsz 4040 B, align: 4096 B\n\u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x0 (len: 0xfc8) from file @ 0x0 (len: 0xfc8)\n\u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[1]: R-X, offset: 0x1000, vaddr: 0x1000, paddr: 0x1000, filesz: 140932 B, memsz 140932 B, align: 4096 B\n\u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x1000 (len: 0x22684) from file @ 0x1000 (len: 0x22684)\n\u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[2]: R--, offset: 0x24000, vaddr: 0x24000, paddr: 0x24000, filesz: 31948 B, memsz 31948 B, align: 4096 B\n\u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x24000 (len: 0x7ccc) from file @ 0x24000 (len: 0x7ccc)\n\u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[3]: RW-, offset: 0x2c520, vaddr: 0x2d520, paddr: 0x2d520, filesz: 6872 B, memsz 7280 B, align: 4096 B\n\u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x2d520 (len: 0x1c70) from file @ 0x2c520 (len: 0x1ad8)\n\u003celf_load.c @  205\u003e \u003cinterp\u003e: base: pie + 0x0, len: 0x2f190\n\u003celf_load.c @  440\u003e \u003cinterp\u003e: Memory mapped 0x0 - 0xfc8 to 0x100003f000 - 0x100003ffc8\n\u003celf_load.c @  462\u003e \u003cinterp\u003e: Program/Library memory region: 0x100003f000-0x100006f000\n\u003celf_load.c @  347\u003e \u003cinterp\u003e: Zeroing 0x100003ffc8 - 0x1000040000\n\u003celf_load.c @  508\u003e \u003cinterp\u003e: Memory mapping 0x1000 - 0x23684 to 0x1000040000 - 0x1000062684\n\u003celf_load.c @  347\u003e \u003cinterp\u003e: Zeroing 0x1000062684 - 0x1000063000\n\u003celf_load.c @  508\u003e \u003cinterp\u003e: Memory mapping 0x24000 - 0x2bccc to 0x1000063000 - 0x100006accc\n\u003celf_load.c @  347\u003e \u003cinterp\u003e: Zeroing 0x100006accc - 0x100006b000\n\u003celf_load.c @  508\u003e \u003cinterp\u003e: Memory mapping 0x2c000 - 0x2e518 to 0x100006c000 - 0x100006dff8\n\u003celf_load.c @  347\u003e \u003cinterp\u003e: Zeroing 0x100006dff8 - 0x100006f000\n\u003celf_load.c @  779\u003e \u003cinterp\u003e: Protecting 0x100003f000 - 0x1000040000: R--\n\u003celf_load.c @  779\u003e \u003cinterp\u003e: Protecting 0x1000040000 - 0x1000063000: R-X\n\u003celf_load.c @  779\u003e \u003cinterp\u003e: Protecting 0x1000063000 - 0x100006b000: R--\n\u003celf_load.c @  779\u003e \u003cinterp\u003e: Protecting 0x100006c000 - 0x100006f000: RW-\n\u003cmain.c @  213\u003e helloworld: ELF program loaded to 0x100000b000-0x1000010000 (20480 B), entry at 0x100000c080\n\u003cmain.c @  231\u003e helloworld: Prepare application thread...\n\u003celf_ctx.c @  114\u003e helloworld: image:          0x100000b000 - 0x1000010000\n\u003celf_ctx.c @  117\u003e helloworld: start:          0x100000b000\n\u003celf_ctx.c @  119\u003e helloworld: entry:          0x100000c080\n\u003celf_ctx.c @  121\u003e helloworld: phdr.off:       0x40\n\u003celf_ctx.c @  123\u003e helloworld: phdr.num:       13\n\u003celf_ctx.c @  125\u003e helloworld: phdr.entsize:   0x38\n\u003celf_ctx.c @  128\u003e helloworld: interp:         0x100003f000 - 0x100006f000\n\u003celf_ctx.c @  132\u003e helloworld: interp.start:   0x100003f000\n\u003celf_ctx.c @  134\u003e helloworld: interp.entry:   0x1000040100\n\u003celf_ctx.c @  211\u003e env[0]=\"PATH=/bin\"\n\u003cmain.c @  240\u003e helloworld: Application stack at 0x400300020 - 0x400320020, pointer: 0x40031fe70\n\u003cmain.c @  246\u003e helloworld: Application entrance at 0x2dc1b0\n```\n\n## Notes\n\n- Distributed files actually contain debug symbols, as shown by\n  `objdump -D nginx`","snippets":["#project"],"rawContent":"# Unikraft ELF loader notes\n\n#project\n\n```log\n\u003cmain.c @  206\u003e helloworld: Load executable (helloworld)...\n\u003celf_load.c @  104\u003e helloworld: ELF machine type: 62\n\u003celf_load.c @  120\u003e helloworld: ELF OS ABI: 0\n\u003celf_load.c @  134\u003e helloworld: ELF object type: 3\n\u003celf_load.c @  177\u003e helloworld: phdr[2]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 1528 B, memsz 1528 B, align: 4096 B\n\u003celf_load.c @  188\u003e helloworld: \\_ segment at pie + 0x0 (len: 0x5f8) from file @ 0x0 (len: 0x5f8)\n\u003celf_load.c @  177\u003e helloworld: phdr[3]: R-X, offset: 0x1000, vaddr: 0x1000, paddr: 0x1000, filesz: 501 B, memsz 501 B, align: 4096 B\n\u003celf_load.c @  188\u003e helloworld: \\_ segment at pie + 0x1000 (len: 0x1f5) from file @ 0x1000 (len: 0x1f5)\n\u003celf_load.c @  177\u003e helloworld: phdr[4]: R--, offset: 0x2000, vaddr: 0x2000, paddr: 0x2000, filesz: 344 B, memsz 344 B, align: 4096 B\n\u003celf_load.c @  188\u003e helloworld: \\_ segment at pie + 0x2000 (len: 0x158) from file @ 0x2000 (len: 0x158)\n\u003celf_load.c @  177\u003e helloworld: phdr[5]: RW-, offset: 0x2db8, vaddr: 0x3db8, paddr: 0x3db8, filesz: 600 B, memsz 608 B, align: 4096 B\n\u003celf_load.c @  188\u003e helloworld: \\_ segment at pie + 0x3db8 (len: 0x260) from file @ 0x2db8 (len: 0x258)\n\u003celf_load.c @  205\u003e helloworld: base: pie + 0x0, len: 0x4018\n\u003celf_load.c @  440\u003e helloworld: Memory mapped 0x0 - 0x5f8 to 0x100000b000 - 0x100000b5f8\n\u003celf_load.c @  462\u003e helloworld: Program/Library memory region: 0x100000b000-0x1000010000\n\u003celf_load.c @  347\u003e helloworld: Zeroing 0x100000b5f8 - 0x100000c000\n\u003celf_load.c @  508\u003e helloworld: Memory mapping 0x1000 - 0x11f5 to 0x100000c000 - 0x100000c1f5\n\u003celf_load.c @  347\u003e helloworld: Zeroing 0x100000c1f5 - 0x100000d000\n\u003celf_load.c @  508\u003e helloworld: Memory mapping 0x2000 - 0x2158 to 0x100000d000 - 0x100000d158\n\u003celf_load.c @  347\u003e helloworld: Zeroing 0x100000d158 - 0x100000e000\n\u003celf_load.c @  508\u003e helloworld: Memory mapping 0x2000 - 0x3dc8 to 0x100000e000 - 0x100000f010\n\u003celf_load.c @  347\u003e helloworld: Zeroing 0x100000f010 - 0x1000010000\n\u003celf_load.c @  779\u003e helloworld: Protecting 0x100000b000 - 0x100000c000: R--\n\u003celf_load.c @  779\u003e helloworld: Protecting 0x100000c000 - 0x100000d000: R-X\n\u003celf_load.c @  779\u003e helloworld: Protecting 0x100000d000 - 0x100000e000: R--\n\u003celf_load.c @  779\u003e helloworld: Protecting 0x100000e000 - 0x1000010000: RW-\n\u003celf_load.c @ 1022\u003e helloworld: Loading program interpreter /lib64/ld-linux-x86-64.so.2...\n\u003celf_load.c @  104\u003e \u003cinterp\u003e: ELF machine type: 62\n\u003celf_load.c @  120\u003e \u003cinterp\u003e: ELF OS ABI: 0\n\u003celf_load.c @  134\u003e \u003cinterp\u003e: ELF object type: 3\n\u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[0]: R--, offset: 0, vaddr: 0, paddr: 0, filesz: 4040 B, memsz 4040 B, align: 4096 B\n\u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x0 (len: 0xfc8) from file @ 0x0 (len: 0xfc8)\n\u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[1]: R-X, offset: 0x1000, vaddr: 0x1000, paddr: 0x1000, filesz: 140932 B, memsz 140932 B, align: 4096 B\n\u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x1000 (len: 0x22684) from file @ 0x1000 (len: 0x22684)\n\u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[2]: R--, offset: 0x24000, vaddr: 0x24000, paddr: 0x24000, filesz: 31948 B, memsz 31948 B, align: 4096 B\n\u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x24000 (len: 0x7ccc) from file @ 0x24000 (len: 0x7ccc)\n\u003celf_load.c @  177\u003e \u003cinterp\u003e: phdr[3]: RW-, offset: 0x2c520, vaddr: 0x2d520, paddr: 0x2d520, filesz: 6872 B, memsz 7280 B, align: 4096 B\n\u003celf_load.c @  188\u003e \u003cinterp\u003e: \\_ segment at pie + 0x2d520 (len: 0x1c70) from file @ 0x2c520 (len: 0x1ad8)\n\u003celf_load.c @  205\u003e \u003cinterp\u003e: base: pie + 0x0, len: 0x2f190\n\u003celf_load.c @  440\u003e \u003cinterp\u003e: Memory mapped 0x0 - 0xfc8 to 0x100003f000 - 0x100003ffc8\n\u003celf_load.c @  462\u003e \u003cinterp\u003e: Program/Library memory region: 0x100003f000-0x100006f000\n\u003celf_load.c @  347\u003e \u003cinterp\u003e: Zeroing 0x100003ffc8 - 0x1000040000\n\u003celf_load.c @  508\u003e \u003cinterp\u003e: Memory mapping 0x1000 - 0x23684 to 0x1000040000 - 0x1000062684\n\u003celf_load.c @  347\u003e \u003cinterp\u003e: Zeroing 0x1000062684 - 0x1000063000\n\u003celf_load.c @  508\u003e \u003cinterp\u003e: Memory mapping 0x24000 - 0x2bccc to 0x1000063000 - 0x100006accc\n\u003celf_load.c @  347\u003e \u003cinterp\u003e: Zeroing 0x100006accc - 0x100006b000\n\u003celf_load.c @  508\u003e \u003cinterp\u003e: Memory mapping 0x2c000 - 0x2e518 to 0x100006c000 - 0x100006dff8\n\u003celf_load.c @  347\u003e \u003cinterp\u003e: Zeroing 0x100006dff8 - 0x100006f000\n\u003celf_load.c @  779\u003e \u003cinterp\u003e: Protecting 0x100003f000 - 0x1000040000: R--\n\u003celf_load.c @  779\u003e \u003cinterp\u003e: Protecting 0x1000040000 - 0x1000063000: R-X\n\u003celf_load.c @  779\u003e \u003cinterp\u003e: Protecting 0x1000063000 - 0x100006b000: R--\n\u003celf_load.c @  779\u003e \u003cinterp\u003e: Protecting 0x100006c000 - 0x100006f000: RW-\n\u003cmain.c @  213\u003e helloworld: ELF program loaded to 0x100000b000-0x1000010000 (20480 B), entry at 0x100000c080\n\u003cmain.c @  231\u003e helloworld: Prepare application thread...\n\u003celf_ctx.c @  114\u003e helloworld: image:          0x100000b000 - 0x1000010000\n\u003celf_ctx.c @  117\u003e helloworld: start:          0x100000b000\n\u003celf_ctx.c @  119\u003e helloworld: entry:          0x100000c080\n\u003celf_ctx.c @  121\u003e helloworld: phdr.off:       0x40\n\u003celf_ctx.c @  123\u003e helloworld: phdr.num:       13\n\u003celf_ctx.c @  125\u003e helloworld: phdr.entsize:   0x38\n\u003celf_ctx.c @  128\u003e helloworld: interp:         0x100003f000 - 0x100006f000\n\u003celf_ctx.c @  132\u003e helloworld: interp.start:   0x100003f000\n\u003celf_ctx.c @  134\u003e helloworld: interp.entry:   0x1000040100\n\u003celf_ctx.c @  211\u003e env[0]=\"PATH=/bin\"\n\u003cmain.c @  240\u003e helloworld: Application stack at 0x400300020 - 0x400320020, pointer: 0x40031fe70\n\u003cmain.c @  246\u003e helloworld: Application entrance at 0x2dc1b0\n```\n\n## Notes\n\n- Distributed files actually contain debug symbols, as shown by\n  `objdump -D nginx`\n","wordCount":777,"tags":["project"],"metadata":{},"created":"2024-06-25T08:20:40.398916425Z","modified":"2024-06-25T10:41:09.466912679Z","checksum":"6b11288bba32bf5dea05b4d7a95208bbe030e15339ea91b139fc86acbcb4fcfb"},
    {"filename":"v7hs7i1d.md","filenameStem":"v7hs7i1d","path":"v7hs7i1d.md","absPath":"/home/khadd/mynotes/v7hs7i1d.md","title":"Unikraft SMP support","link":"[[v7hs7i1d]]","lead":"#unikraft","body":"#unikraft\n\n- [PR 502](https://github.com/unikraft/unikraft/pull/502) discuss how to test\n  SMP support.\n- It seems virtio driver is not SMP-safe","snippets":["#unikraft"],"rawContent":"# Unikraft SMP support\n\n#unikraft\n\n- [PR 502](https://github.com/unikraft/unikraft/pull/502) discuss how to test\n  SMP support.\n- It seems virtio driver is not SMP-safe\n","wordCount":22,"tags":["unikraft"],"metadata":{},"created":"2024-05-30T07:40:28.038320961Z","modified":"2024-06-19T05:27:55.505492217Z","checksum":"4384c4f170cd3d4165b86ff1eea1437f88cbfb755ff8c792496635a0a59ae1b8"},
    {"filename":"fcf5pozg.md","filenameStem":"fcf5pozg","path":"fcf5pozg.md","absPath":"/home/khadd/mynotes/fcf5pozg.md","title":"Unikraft development notes","link":"[[fcf5pozg]]","lead":"#unikraft #unikernel","body":"#unikraft #unikernel\n\n# Development environment\n\nThe kraft tutorials are completely broken (at this moment).\n\nTo set up a functional development, first create a directory structure like\nthis.\n\n```x\n- root\n  - unikraft // The unikraft repo\n  - apps // external application\n    - helloworld\n    - ...\n  - libs // external libraries\n    - lib_test\n    - ...\n```\n\n`unikraft` is cloned from the main repo, and apps can be any applications. There\nmust be an application for testing the unikernel. The helloworld application is\na good starting point for testing.\n\n```bash\ngit clone https://github.com/unikraft/unikraft.git\ncd apps\ngit clone https://github.com/unikraft/app-helloworld.git\n```\n\n# Building applications\n\nFirst, the application needs to be configured. Use\n\n```\nmake menuconfig\n```\n\nand walk through the configuration.\n\nAfter the kernel is configured, just run to build.\n\n```\nmake\n```\n\n## Running\n\n```bash\nqemu-system-x86_64 -enable-kvm -nographic -cpu host -kernel build/helloworld_qemu-x86_64\n\n```\n\n# Coding convention\n\n## Variable definition\n\nUse `const` for constant variable.\n\n## Addresses\n\nPhysical addresses has the type `__paddr_t`. There is also `__vaddr_t`\n\n## Function definition\n\n`static inline` is used for short functions.\n\n## struct definition\n\nstructs are sometimes defined in C files, or header files.\n\n`typedef struct` is not used.\n\n## Private states\n\nModules contains a pointer to their private states.\n\n```c\nstatic struct uk_vas *vmem_active_vas;\n```\n\n# Debugging\n\nrun qemu with the flags `-S -s` on the non-debugging image.\n\nSoftware breakpoints does not work, so hardware breakpoints need to be used with\n`hbreak`.\n\n## Debugging test case\n\nTest case name will be concactenated like this:\n`_uk_testsuite_ukvmem_case_test_basic_vas_layout`\n\n## Printing raw bytes\n\n`uk_hexdumpk` dumps the content of some region to printk.\n\n# Other notes\n\n- [[7gbms9if]]\n- [[xpolyx1l]]\n- [[1k9i1cr3]]\n- [[gel6dwih]]","snippets":["#unikraft #unikernel"],"rawContent":"# Unikraft development notes\n\n#unikraft #unikernel\n\n# Development environment\n\nThe kraft tutorials are completely broken (at this moment).\n\nTo set up a functional development, first create a directory structure like\nthis.\n\n```x\n- root\n  - unikraft // The unikraft repo\n  - apps // external application\n    - helloworld\n    - ...\n  - libs // external libraries\n    - lib_test\n    - ...\n```\n\n`unikraft` is cloned from the main repo, and apps can be any applications. There\nmust be an application for testing the unikernel. The helloworld application is\na good starting point for testing.\n\n```bash\ngit clone https://github.com/unikraft/unikraft.git\ncd apps\ngit clone https://github.com/unikraft/app-helloworld.git\n```\n\n# Building applications\n\nFirst, the application needs to be configured. Use\n\n```\nmake menuconfig\n```\n\nand walk through the configuration.\n\nAfter the kernel is configured, just run to build.\n\n```\nmake\n```\n\n## Running\n\n```bash\nqemu-system-x86_64 -enable-kvm -nographic -cpu host -kernel build/helloworld_qemu-x86_64\n\n```\n\n# Coding convention\n\n## Variable definition\n\nUse `const` for constant variable.\n\n## Addresses\n\nPhysical addresses has the type `__paddr_t`. There is also `__vaddr_t`\n\n## Function definition\n\n`static inline` is used for short functions.\n\n## struct definition\n\nstructs are sometimes defined in C files, or header files.\n\n`typedef struct` is not used.\n\n## Private states\n\nModules contains a pointer to their private states.\n\n```c\nstatic struct uk_vas *vmem_active_vas;\n```\n\n# Debugging\n\nrun qemu with the flags `-S -s` on the non-debugging image.\n\nSoftware breakpoints does not work, so hardware breakpoints need to be used with\n`hbreak`.\n\n## Debugging test case\n\nTest case name will be concactenated like this:\n`_uk_testsuite_ukvmem_case_test_basic_vas_layout`\n\n## Printing raw bytes\n\n`uk_hexdumpk` dumps the content of some region to printk.\n\n# Other notes\n\n- [[7gbms9if]]\n- [[xpolyx1l]]\n- [[1k9i1cr3]]\n- [[gel6dwih]]\n","wordCount":276,"tags":["unikernel","unikraft"],"metadata":{},"created":"2023-06-16T08:04:25.803782694Z","modified":"2024-07-08T09:04:18.170169269Z","checksum":"cca6a9943af66a6ca7c7301e6c51513d8a5ec8713494d5c49f68122cc3c60e13"},
    {"filename":"7gbms9if.md","filenameStem":"7gbms9if","path":"7gbms9if.md","absPath":"/home/khadd/mynotes/7gbms9if.md","title":"Unikraft's heap allocator","link":"[[7gbms9if]]","lead":"#unikraft #os","body":"#unikraft #os\n\n## Flexible allocator backends\n\nUnikraft is designed to support multiple backends. The original paper includes\nup to 5 allocator backends: buddy, TLFS, real-time, tinyalloc, mimalloc and\nOscar. [@lupu2023nephele] says tiny has the best performance among all\n\n## ukalloc\n\nUnikraft enables swapping of different allocator backends through the `ukalloc`\ninterface. `ukalloc` keeps a linked-list pointers to\n`struct uk_alloc* _uk_alloc_head`, that points to the currently registered\nallocator.\n\n## Registration\n\nNew allocators must implement the interface Allocators are registered with\n`uk_alloc_register`, which assign `_uk_alloc_head` to the new allocator.\n\nIn `boot.c`, the allocators are hard-coded as:\n\n```c\n#if CONFIG_LIBUKBOOT_INITBBUDDY\n#include \u003cuk/allocbbuddy.h\u003e\n#define uk_alloc_init uk_allocbbuddy_init\n#elif CONFIG_LIBUKBOOT_INITREGION\n#include \u003cuk/allocregion.h\u003e\n#define uk_alloc_init uk_allocregion_init\n#elif CONFIG_LIBUKBOOT_INITMIMALLOC\n#include \u003cuk/mimalloc.h\u003e\n#define uk_alloc_init uk_mimalloc_init\n#elif CONFIG_LIBUKBOOT_INITTLSF\n#include \u003cuk/tlsf.h\u003e\n#define uk_alloc_init uk_tlsf_init\n#elif CONFIG_LIBUKBOOT_INITTINYALLOC\n#include \u003cuk/tinyalloc.h\u003e\n#define uk_alloc_init uk_tinyalloc_init\n#endif\n```\n\nHence, any allocator that are selected will be set as the heap allocator.\n\nThe `heap_init()` function takes the remaining memory (starting from\n`CONFIG_LIBUKBOOT_HEAP_BASE`), map them as anonymous pages, and adds them to the\nmemory pool of the allocator.\n\nFinally, `ukplat_memallocator_set()` set the current memory allocator\n\n## POSIX malloc\n\n`malloc` definition in `stdlib.h`:\n\n```c\nstatic inline void malloc(size_t size){\n  return uk_malloc(uk_alloc_get_default(), size);\n}\n```\n\nWhere `uk_alloc_get_default()` returns `_uk_alloc_head`.","snippets":["#unikraft #os"],"rawContent":"# Unikraft's heap allocator\n\n#unikraft #os\n\n## Flexible allocator backends\n\nUnikraft is designed to support multiple backends. The original paper includes\nup to 5 allocator backends: buddy, TLFS, real-time, tinyalloc, mimalloc and\nOscar. [@lupu2023nephele] says tiny has the best performance among all\n\n## ukalloc\n\nUnikraft enables swapping of different allocator backends through the `ukalloc`\ninterface. `ukalloc` keeps a linked-list pointers to\n`struct uk_alloc* _uk_alloc_head`, that points to the currently registered\nallocator.\n\n## Registration\n\nNew allocators must implement the interface Allocators are registered with\n`uk_alloc_register`, which assign `_uk_alloc_head` to the new allocator.\n\nIn `boot.c`, the allocators are hard-coded as:\n\n```c\n#if CONFIG_LIBUKBOOT_INITBBUDDY\n#include \u003cuk/allocbbuddy.h\u003e\n#define uk_alloc_init uk_allocbbuddy_init\n#elif CONFIG_LIBUKBOOT_INITREGION\n#include \u003cuk/allocregion.h\u003e\n#define uk_alloc_init uk_allocregion_init\n#elif CONFIG_LIBUKBOOT_INITMIMALLOC\n#include \u003cuk/mimalloc.h\u003e\n#define uk_alloc_init uk_mimalloc_init\n#elif CONFIG_LIBUKBOOT_INITTLSF\n#include \u003cuk/tlsf.h\u003e\n#define uk_alloc_init uk_tlsf_init\n#elif CONFIG_LIBUKBOOT_INITTINYALLOC\n#include \u003cuk/tinyalloc.h\u003e\n#define uk_alloc_init uk_tinyalloc_init\n#endif\n```\n\nHence, any allocator that are selected will be set as the heap allocator.\n\nThe `heap_init()` function takes the remaining memory (starting from\n`CONFIG_LIBUKBOOT_HEAP_BASE`), map them as anonymous pages, and adds them to the\nmemory pool of the allocator.\n\nFinally, `ukplat_memallocator_set()` set the current memory allocator\n\n## POSIX malloc\n\n`malloc` definition in `stdlib.h`:\n\n```c\nstatic inline void malloc(size_t size){\n  return uk_malloc(uk_alloc_get_default(), size);\n}\n```\n\nWhere `uk_alloc_get_default()` returns `_uk_alloc_head`.\n","wordCount":203,"tags":["os","unikraft"],"metadata":{},"created":"2023-07-04T11:22:42.589135038Z","modified":"2024-06-28T07:55:22.042755899Z","checksum":"8b7773b921a2372bacb97232c2dd98984e42c40bd6e2ab7da3541040a5214491"},
    {"filename":"njh7pnzn.md","filenameStem":"njh7pnzn","path":"njh7pnzn.md","absPath":"/home/khadd/mynotes/njh7pnzn.md","title":"Unintended Instructions Problem","link":"[[njh7pnzn]]","lead":"The problem of unintended occur because of variable-length encoding used in x86.\nAny sequence of bytes may result in a valid instruction sequences. Another issue\nis that data inside `.text` section mess up disassembly, since distinguishing\ndata from text is undecidable [@needcite].","body":"The problem of unintended occur because of variable-length encoding used in x86.\nAny sequence of bytes may result in a valid instruction sequences. Another issue\nis that data inside `.text` section mess up disassembly, since distinguishing\ndata from text is undecidable [@needcite].\n\nFor this reason, binary disassembler often require employs assumptions and\nheuristics to make the problem easier.\n\nAssumptions:\n\n- There is no data in between instructions, so that instructions can be decoded\n  by reading from the entry. This requires that you know the starting point for\n  decoding, like function entries. This information may be unavailable for\n  stripped binaries.\n\nHeuristics:\n\n- While disassemblers can use various on heuristics [@pang2021sok], these are\n  not applicable to handwritten assemblies.\n- You can also rely on jump targets to find instruction boundaries, as the jump\n  target should be always aligned to instruction boundary.","snippets":["The problem of unintended occur because of variable-length encoding used in x86.\nAny sequence of bytes may result in a valid instruction sequences. Another issue\nis that data inside `.text` section mess up disassembly, since distinguishing\ndata from text is undecidable [@needcite]."],"rawContent":"# Unintended Instructions Problem\n\nThe problem of unintended occur because of variable-length encoding used in x86.\nAny sequence of bytes may result in a valid instruction sequences. Another issue\nis that data inside `.text` section mess up disassembly, since distinguishing\ndata from text is undecidable [@needcite].\n\nFor this reason, binary disassembler often require employs assumptions and\nheuristics to make the problem easier.\n\nAssumptions:\n\n- There is no data in between instructions, so that instructions can be decoded\n  by reading from the entry. This requires that you know the starting point for\n  decoding, like function entries. This information may be unavailable for\n  stripped binaries.\n\nHeuristics:\n\n- While disassemblers can use various on heuristics [@pang2021sok], these are\n  not applicable to handwritten assemblies.\n- You can also rely on jump targets to find instruction boundaries, as the jump\n  target should be always aligned to instruction boundary.\n","wordCount":143,"tags":[],"metadata":{},"created":"2024-07-22T01:57:04.015221962Z","modified":"2024-07-22T01:59:23.160664268Z","checksum":"eee6955ddb8f2fda6980f092011ee2c08c31f85c0bbb524ac6af91113643b6a4"},
    {"filename":"irmocm7l.md","filenameStem":"irmocm7l","path":"irmocm7l.md","absPath":"/home/khadd/mynotes/irmocm7l.md","title":"Using static to enhance dynamic","link":"[[irmocm7l]]","lead":"Time and time again, this pattern appear.","body":"Time and time again, this pattern appear.\n\n\u003e Using static points-to analysis to reduce overheads of runtime (dynamic) taint\n\u003e tracking.","snippets":["Time and time again, this pattern appear."],"rawContent":"# Using static to enhance dynamic\n\nTime and time again, this pattern appear.\n\n\u003e Using static points-to analysis to reduce overheads of runtime (dynamic) taint\n\u003e tracking.\n","wordCount":27,"tags":[],"metadata":{},"created":"2024-07-28T08:04:46.437396093Z","modified":"2024-07-28T07:41:51.193272729Z","checksum":"f8e5de5c256f88a79d9940f13145690d25cf96127bca652308c071c235bea93d"},
    {"filename":"eqbigndi.md","filenameStem":"eqbigndi","path":"eqbigndi.md","absPath":"/home/khadd/mynotes/eqbigndi.md","title":"Virtual Memory","link":"[[eqbigndi]]","lead":"#os #virtualization","body":"#os #virtualization\n\nVirtual memory is a co-design between the CPU hardware and the OS programming\nmodel. Almost all modern CPUs includes a MMU to support virtual memory.\n\nAs with other OS abstractions [[7t4jlnaq]], virtual memory goal is to eases the\nprogramming efforts [@yan2019translation].\n\n- Virtualizes and abstracts physical memory such that a single physical space\n  can be shared among different processes.\n- Facilitates communication between cores (shared memory mapping), and\n  CPU-device communication (through DMA/MMIO).\n- Enables memory access control between processes (each process use a different\n  page table set up by the OS), and within a single process (RWX permissions).\n\nHowever, there are also performance trade-offs due to address translation\n[[nhovug1d]].","snippets":["#os #virtualization"],"rawContent":"# Virtual Memory\n\n#os #virtualization\n\nVirtual memory is a co-design between the CPU hardware and the OS programming\nmodel. Almost all modern CPUs includes a MMU to support virtual memory.\n\nAs with other OS abstractions [[7t4jlnaq]], virtual memory goal is to eases the\nprogramming efforts [@yan2019translation].\n\n- Virtualizes and abstracts physical memory such that a single physical space\n  can be shared among different processes.\n- Facilitates communication between cores (shared memory mapping), and\n  CPU-device communication (through DMA/MMIO).\n- Enables memory access control between processes (each process use a different\n  page table set up by the OS), and within a single process (RWX permissions).\n\nHowever, there are also performance trade-offs due to address translation\n[[nhovug1d]].\n","wordCount":114,"tags":["os","virtualization"],"metadata":{},"created":"2023-07-22T08:12:54.947881231Z","modified":"2024-12-09T04:15:06.172051626Z","checksum":"811a1d97436af1ee3eaceadbab98fac2a0cf1de38a4179ca95d59adbd43c0771"},
    {"filename":"dlvrfm5i.md","filenameStem":"dlvrfm5i","path":"dlvrfm5i.md","absPath":"/home/khadd/mynotes/dlvrfm5i.md","title":"Virtualizing X in Y","link":"[[dlvrfm5i]]","lead":"#research-pattern","body":"#research-pattern\n\nVirtualizing a certain feature on a system on another system is a common\npattern.\n\n## Virtualizee\n\nA vitualizee has a set of feature that are desirable to implement a different\nsystem. Unfortunately, such a feature is unavailable.\n\n## Virtualizer\n\nThe virtualizer lacks the specific feature that the virtualizee has.\n\nHowever, it has two components.\n\n- It has interposition ability\n- There exist overlapping of feature set.\n-\n\n## Virtualizing condition","snippets":["#research-pattern"],"rawContent":"# Virtualizing X in Y\n\n#research-pattern\n\nVirtualizing a certain feature on a system on another system is a common\npattern.\n\n## Virtualizee\n\nA vitualizee has a set of feature that are desirable to implement a different\nsystem. Unfortunately, such a feature is unavailable.\n\n## Virtualizer\n\nThe virtualizer lacks the specific feature that the virtualizee has.\n\nHowever, it has two components.\n\n- It has interposition ability\n- There exist overlapping of feature set.\n-\n\n## Virtualizing condition\n","wordCount":76,"tags":["research-pattern"],"metadata":{},"created":"2024-07-28T08:04:46.43360859Z","modified":"2024-07-28T07:41:51.193272729Z","checksum":"8f008ccac90247c6b9db59d4d4d7ad1917113cdecd16b949b8ca6354f3247561"},
    {"filename":"9sbjh4gy.md","filenameStem":"9sbjh4gy","path":"9sbjh4gy.md","absPath":"/home/khadd/mynotes/9sbjh4gy.md","title":"Von Neumann Architecture","link":"[[9sbjh4gy]]","lead":"The von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device.","body":"The von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device.\n\nAt each cycle, the CPU fetch an instruction from memory, then execute it. The instruction may perform data read/write from memory, perform operations, or write to input/output devices.\n\nVon Neumann architecture has a bottleneck where instruction fetch and data operations cannot be performed in one cycle due to them using the same bus. Computer caches with separated icache and dcache mitigates this. There are also non-von Neumann architectures that significantly departure from the von Neumann model (to overcome this bottleneck?).","snippets":["The von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device."],"rawContent":"# Von Neumann Architecture\n\nThe von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device.\n\nAt each cycle, the CPU fetch an instruction from memory, then execute it. The instruction may perform data read/write from memory, perform operations, or write to input/output devices.\n\nVon Neumann architecture has a bottleneck where instruction fetch and data operations cannot be performed in one cycle due to them using the same bus. Computer caches with separated icache and dcache mitigates this. There are also non-von Neumann architectures that significantly departure from the von Neumann model (to overcome this bottleneck?).\n\n","wordCount":164,"tags":[],"metadata":{},"created":"2023-05-22T05:10:44.094878652Z","modified":"2023-05-22T06:08:52.376270738Z","checksum":"f0ef069f4eb9e6dbc715b9ca6672f6afb1a51ab59c9647d97f3875cb1da99693"},
    {"filename":"5st7ndhi.md","filenameStem":"5st7ndhi","path":"5st7ndhi.md","absPath":"/home/khadd/mynotes/5st7ndhi.md","title":"Wayland notes","link":"[[5st7ndhi]]","lead":"#distro #wayland","body":"#distro #wayland\n\n# Monitor sleep \nThis is specific to hyprland. To turn off monitor run:\n```bash\nhyprctl dispatch dpms off\n```\nHowever, there have to be a way to turn it back on, so in `hyprland.conf`, add the following to `misc`: \n\n```\nmisc {\n    mouse_move_enables_dpms = true\n    key_press_enables_dpms = true\n}\n```\n\n\n\n# Clipboard management on Wayland\n#wayland #distro\n\nWayland uses a different clipboard management system than X11.  \n\n## SSH clipboard\n\nOn both the remote and local machine, [`waypipe`](https://gitlab.freedesktop.org/mstoeckl/waypipe) and `wl-clipboard` need to be installed. On ubuntu, waypipe is not provided by APT, so it needs to be compiled and installed manually. Follow the instructions on [gitlab](https://gitlab.freedesktop.org/mstoeckl/waypipe.).\n\nAfter `waypipe` is installed, on the local machine, just add the prefix `waypipe` to the call to `ssh`:\n```bash\nwaypipe ssh theserver\n```\n\n## Neovim\nNeovim will automatically detect if `wl-clipboard` (`wl-copy` and `wl-paste`) exists.","snippets":["#distro #wayland"],"rawContent":"# Wayland notes\n#distro #wayland\n\n# Monitor sleep \nThis is specific to hyprland. To turn off monitor run:\n```bash\nhyprctl dispatch dpms off\n```\nHowever, there have to be a way to turn it back on, so in `hyprland.conf`, add the following to `misc`: \n\n```\nmisc {\n    mouse_move_enables_dpms = true\n    key_press_enables_dpms = true\n}\n```\n\n\n\n# Clipboard management on Wayland\n#wayland #distro\n\nWayland uses a different clipboard management system than X11.  \n\n## SSH clipboard\n\nOn both the remote and local machine, [`waypipe`](https://gitlab.freedesktop.org/mstoeckl/waypipe) and `wl-clipboard` need to be installed. On ubuntu, waypipe is not provided by APT, so it needs to be compiled and installed manually. Follow the instructions on [gitlab](https://gitlab.freedesktop.org/mstoeckl/waypipe.).\n\nAfter `waypipe` is installed, on the local machine, just add the prefix `waypipe` to the call to `ssh`:\n```bash\nwaypipe ssh theserver\n```\n\n## Neovim\nNeovim will automatically detect if `wl-clipboard` (`wl-copy` and `wl-paste`) exists.\n\n\n\n","wordCount":145,"tags":["distro","wayland"],"metadata":{},"created":"2023-09-07T04:44:41.836778012Z","modified":"2024-05-20T11:00:29.301946541Z","checksum":"6ab4a174d0912a488df96b7a3aa6bb0df6cb9ba0a0c11443c9a0c845ef958585"},
    {"filename":"q4cvky96.md","filenameStem":"q4cvky96","path":"q4cvky96.md","absPath":"/home/khadd/mynotes/q4cvky96.md","title":"Wide-Area Network (WAN)","link":"[[q4cvky96]]","lead":"Wide-area network technologies connect multiple local area networks together,\nallowing participants from dispersed networks to communicate through long\ndistances.","body":"Wide-area network technologies connect multiple local area networks together,\nallowing participants from dispersed networks to communicate through long\ndistances.\n\nA WAN may be built with a private _leased line_ between the two network, but\nthis approach is very expensive. Modern implementations perform packet switching\nthrough different protocols, like Multi-protocol label switching (MPLS).","snippets":["Wide-area network technologies connect multiple local area networks together,\nallowing participants from dispersed networks to communicate through long\ndistances."],"rawContent":"# Wide-Area Network (WAN)\n\nWide-area network technologies connect multiple local area networks together,\nallowing participants from dispersed networks to communicate through long\ndistances.\n\nA WAN may be built with a private _leased line_ between the two network, but\nthis approach is very expensive. Modern implementations perform packet switching\nthrough different protocols, like Multi-protocol label switching (MPLS).\n","wordCount":56,"tags":[],"metadata":{},"created":"2024-12-18T03:04:09.140538613Z","modified":"2024-12-18T03:28:47.295197503Z","checksum":"f84aeee6a2e42767908c2cc2a945146766ad58a3c9de134f217feb7683230022"},
    {"filename":"m6zbqotq.md","filenameStem":"m6zbqotq","path":"m6zbqotq.md","absPath":"/home/khadd/mynotes/m6zbqotq.md","title":"Writing Ideas","link":"[[m6zbqotq]]","lead":"#project #writing","body":"#project #writing\n\n- [ ] Write about the magical XOR operation\n- [ ] The duality of security: More security is better, but sometime security\n      vulnerabilities enable unseen benefits. For example, hacking community\n      leverages vulnerabilities to bring life to end-of-life devices.","snippets":["#project #writing"],"rawContent":"# Writing Ideas\n\n#project #writing\n\n- [ ] Write about the magical XOR operation\n- [ ] The duality of security: More security is better, but sometime security\n      vulnerabilities enable unseen benefits. For example, hacking community\n      leverages vulnerabilities to bring life to end-of-life devices.\n","wordCount":44,"tags":["project","writing"],"metadata":{},"created":"2024-06-10T09:33:47.547670356Z","modified":"2024-06-10T12:02:02.313711916Z","checksum":"1f4dbab3814445a7de0323a35b3640452fbab8e8080d8562357e75bf3a5f67bc"},
    {"filename":"4ea8wn6r.md","filenameStem":"4ea8wn6r","path":"4ea8wn6r.md","absPath":"/home/khadd/mynotes/4ea8wn6r.md","title":"Zero-copy Communications with Single-ownership","link":"[[4ea8wn6r]]","lead":"Zero-copy data transfer, where a pointer is passed between to subsystems, is\ninherently in conflict with isolation of subsystems. Particularly, the sender\nmay modify data when the receiver is processing it, leading to TOCTOU issues\n([[yef2w9yc]]).","body":"Zero-copy data transfer, where a pointer is passed between to subsystems, is\ninherently in conflict with isolation of subsystems. Particularly, the sender\nmay modify data when the receiver is processing it, leading to TOCTOU issues\n([[yef2w9yc]]).\n\nA language runtime, specifically their _single-ownership_ model (e.g., Rust)\nfundamentally enable safe zero-copy communication. It prevents modification to\nobjects after they are sent to other domains, e.g., after the ownership of\nobjects are transferred.\n\nSeveral systems took advantage of this property to enable zero-copy\ncommunication, starting from the Singularity OS [@hunt2007singularity]. The Rust\nlanguage enforce single-ownership by design and is suitable for system\nprogramming, which has been explored for kernel subsystems isolation\n[@narayanan2020redleaf], packet isolation [[2it4soew]] in a language-based NFV\nruntime [panda2016netbricks].","snippets":["Zero-copy data transfer, where a pointer is passed between to subsystems, is\ninherently in conflict with isolation of subsystems. Particularly, the sender\nmay modify data when the receiver is processing it, leading to TOCTOU issues\n([[yef2w9yc]])."],"rawContent":"# Zero-copy Communications with Single-ownership\n\nZero-copy data transfer, where a pointer is passed between to subsystems, is\ninherently in conflict with isolation of subsystems. Particularly, the sender\nmay modify data when the receiver is processing it, leading to TOCTOU issues\n([[yef2w9yc]]).\n\nA language runtime, specifically their _single-ownership_ model (e.g., Rust)\nfundamentally enable safe zero-copy communication. It prevents modification to\nobjects after they are sent to other domains, e.g., after the ownership of\nobjects are transferred.\n\nSeveral systems took advantage of this property to enable zero-copy\ncommunication, starting from the Singularity OS [@hunt2007singularity]. The Rust\nlanguage enforce single-ownership by design and is suitable for system\nprogramming, which has been explored for kernel subsystems isolation\n[@narayanan2020redleaf], packet isolation [[2it4soew]] in a language-based NFV\nruntime [panda2016netbricks].\n","wordCount":123,"tags":[],"metadata":{},"created":"2024-12-23T04:34:03.9875874Z","modified":"2024-12-23T04:52:36.186587995Z","checksum":"d6dbb380da37a482ad27838d064104d981272066f7bbbbfaee3db98cbc58be44"},
    {"filename":"t11oathy.md","filenameStem":"t11oathy","path":"t11oathy.md","absPath":"/home/khadd/mynotes/t11oathy.md","title":"Zk","link":"[[t11oathy]]","lead":"","body":"","snippets":[],"rawContent":"# Zk\n\n\n","wordCount":2,"tags":[],"metadata":{},"created":"2024-11-09T07:33:07.683673724Z","modified":"2024-11-09T07:11:08.863757311Z","checksum":"044fdbfca1e7a83b16fc17279ab78a414741f8a4442a0365126e865663245c77"},
    {"filename":"hello.md","filenameStem":"hello","path":"presentations/hello-marp/hello.md","absPath":"/home/khadd/mynotes/presentations/hello-marp/hello.md","title":"hello marp","link":"[[presentations/hello-marp/hello]]","lead":"\u003cstyle\u003e\nblockquote {\n    border-top: 0.1em dashed #555;\n    font-size: 60%;\n    margin-top: auto;\n}\n\u003c/style\u003e","body":"\u003cstyle\u003e\nblockquote {\n    border-top: 0.1em dashed #555;\n    font-size: 60%;\n    margin-top: auto;\n}\n\u003c/style\u003e\n\n## test\n\n- a\n- b\n- [1]\n\n\u003e [1] Test testt \\\n\u003e [2] Test testt\n\n---\n\n## Test test\n\n1. c\n2. d\n3. e\n4. f","snippets":["\u003cstyle\u003e\nblockquote {\n    border-top: 0.1em dashed #555;\n    font-size: 60%;\n    margin-top: auto;\n}\n\u003c/style\u003e"],"rawContent":"# hello marp\n\n\u003cstyle\u003e\nblockquote {\n    border-top: 0.1em dashed #555;\n    font-size: 60%;\n    margin-top: auto;\n}\n\u003c/style\u003e\n\n## test\n\n- a\n- b\n- [1]\n\n\u003e [1] Test testt \\\n\u003e [2] Test testt\n\n---\n\n## Test test\n\n1. c\n2. d\n3. e\n4. f\n","wordCount":45,"tags":[],"metadata":{},"created":"2024-09-14T11:08:41.815051086Z","modified":"2024-09-14T10:30:50.47215959Z","checksum":"337a8804a2c813bb9b876a97dc0a2f3d824221cc82fae9c1bbde670fec0116f7"},
    {"filename":"1mhpx5ds.md","filenameStem":"1mhpx5ds","path":"1mhpx5ds.md","absPath":"/home/khadd/mynotes/1mhpx5ds.md","title":"kprobes","link":"[[1mhpx5ds]]","lead":"#linux #os","body":"#linux #os\n\n[kprobes](https://docs.kernel.org/trace/kprobes.html) is a Linux kernel\nsubsystem allows the user to insert breakpoint in almost anywhere within kernel.\nOn encountering such breakpoint, the custom user handler function (a\npre_handler) is called. kprobes then single-step/emulate the instruction and\ncall a post_handler.\n\n## Intercept mechanism\n\n### int3\n\nOn x86, the `int3` instruction for debug breakpoint is used. The opcode for\n`int3`, 0xCC is injected into the desired location, while the original\ninstruction is backed in the `kprobe` structure.\n\nWhen the CPU encounter `int3`, the following handler is invoked.\n\n```c\nint kprobe_int3_handler(struct pt_regs *regs) {\n  kprobe_opcode_t *addr;\n  struct kprobe *p;\n  struct kprobe_ctlblk *kcb;\n\n  if (user_mode(regs))\n    return 0;\n\n  addr = (kprobe_opcode_t *)(regs-\u003eip - sizeof(kprobe_opcode_t));\n  /*\n   * We don't want to be preempted for the entire duration of kprobe\n   * processing. Since int3 and debug trap disables irqs and we clear\n   * IF while singlestepping, it must be no preemptible.\n   */\n\n  kcb = get_kprobe_ctlblk();\n  p = get_kprobe(addr);\n\n  if (p) {\n    if (kprobe_running()) {\n      if (reenter_kprobe(p, regs, kcb))\n        return 1;\n    } else {\n      set_current_kprobe(p, regs, kcb);\n      kcb-\u003ekprobe_status = KPROBE_HIT_ACTIVE;\n\n      /*\n       * If we have no pre-handler or it returned 0, we\n       * continue with normal processing.  If we have a\n       * pre-handler and it returned non-zero, that means\n       * user handler setup registers to exit to another\n       * instruction, we must skip the single stepping.\n       */\n      if (!p-\u003epre_handler || !p-\u003epre_handler(p, regs))\n        setup_singlestep(p, regs, kcb, 0);\n      else\n        reset_current_kprobe();\n      return 1;\n    }\n  } else if (kprobe_is_ss(kcb)) {\n    p = kprobe_running();\n    if ((unsigned long)p-\u003eainsn.insn \u003c regs-\u003eip \u0026\u0026\n        (unsigned long)p-\u003eainsn.insn + MAX_INSN_SIZE \u003e regs-\u003eip) {\n      /* Most provably this is the second int3 for singlestep */\n      resume_singlestep(p, regs, kcb);\n      kprobe_post_process(p, regs, kcb);\n      return 1;\n    }\n  }\n\n  if (*addr != INT3_INSN_OPCODE) {\n    /*\n     * The breakpoint instruction was removed right\n     * after we hit it.  Another cpu has removed\n     * either a probepoint or a debugger breakpoint\n     * at this address.  In either case, no further\n     * handling of this interrupt is appropriate.\n     * Back up over the (now missing) int3 and run\n     * the original instruction.\n     *\n     */\n    regs-\u003eip = (unsigned long)addr;\n    return 1;\n  } /* else: not a kprobe fault; let the kernel handle it */\n\n  return 0;\n}\n```\n\n### jmp-based interception\n\n## Single-stepping\n\nSingle-stepping places in `int3` after the executed instruction buffer, such\nthat the `int3` handler is once again triggered.\n\n```term\nExecution flow    ┌─►kprobe_int3_handler      insn buffer       ┌──► int3 handler\n   inst1          │  RIP = insn buffer    ┌─────► inst4         │    resume_singlestep\n   inst2          │  ret──────────────────┘       int3──────────┘          rip = original_rip + 1\n   inst3          │                                                  ret\n   int3───────────┘                                                   │\n   inst5◄─────────────────────────────────────────────────────────────┘\n\n```\n\n### Notes on emulation vs single stepping\n\nkprobe supports two ways to execute the probed instruction, emulating them vs.\nstepping over.\n\nSingle-stepping is performed by injecting `int3`right after the probed\ninstruction in the insn cache.\n\nControl flow transfer instruction like `jmp` and `call` cannot be\nsingle-stepped, because they transfer control flow somewhere else. Even when\n`int3` is inserted right after a `jmp`, it cannot be called a single-step\nanymore.\n\nFor this reason, control flow transfers _must_ be emulated in kprobes. In deed,\nin the `prepare_emulation` function, most of the emulated instructions are\ncontrol flow transfers.\n\n## Optimizations\n\n### Boosting\n\nThe act of \"boosting\" refers to the part in single stepping, where `int3` can be\nreplaced with a relative `jmp` instruction that transfer control back to the\noriginal instruction.\n\n```term\nExecution flow    ┌─►kprobe_int3_handler      insn buffer\n   inst1          │  RIP = insn buffer    ┌─────► inst4\n   inst2          │  ret──────────────────┘       jmp original_rip +1\n   inst3          │                                         │\n   int3───────────┘                                         │\n   inst5◄───────────────────────────────────────────────────┘\n\n```\n\n```c\n/*\n * Returns non-zero if INSN is boostable.\n * RIP relative instructions are adjusted at copying time in 64 bits mode\n */\nint can_boost(struct insn *insn, void *addr) {\n  kprobe_opcode_t opcode;\n  insn_byte_t prefix;\n  int i;\n\n  if (search_exception_tables((unsigned long)addr))\n    return 0; /* Page fault may occur on this address. */\n\n  /* 2nd-byte opcode */\n  if (insn-\u003eopcode.nbytes == 2)\n    return test_bit(insn-\u003eopcode.bytes[1],\n                    (unsigned long *)twobyte_is_boostable);\n\n  if (insn-\u003eopcode.nbytes != 1)\n    return 0;\n\n  for_each_insn_prefix(insn, i, prefix) {\n    insn_attr_t attr;\n\n    attr = inat_get_opcode_attribute(prefix);\n    /* Can't boost Address-size override prefix and CS override prefix */\n    if (prefix == 0x2e || inat_is_address_size_prefix(attr))\n      return 0;\n  }\n\n  opcode = insn-\u003eopcode.bytes[0];\n\n  switch (opcode) {\n  case 0x62:          /* bound */\n  case 0x70 ... 0x7f: /* Conditional jumps */\n  case 0x9a:          /* Call far */\n  case 0xc0 ... 0xc1: /* Grp2 */\n  case 0xcc ... 0xce: /* software exceptions */\n  case 0xd0 ... 0xd3: /* Grp2 */\n  case 0xd6:          /* (UD) */\n  case 0xd8 ... 0xdf: /* ESC */\n  case 0xe0 ... 0xe3: /* LOOP*, JCXZ */\n  case 0xe8 ... 0xe9: /* near Call, JMP */\n  case 0xeb:          /* Short JMP */\n  case 0xf0 ... 0xf4: /* LOCK/REP, HLT */\n  case 0xf6 ... 0xf7: /* Grp3 */\n  case 0xfe:          /* Grp4 */\n    /* ... are not boostable */\n    return 0;\n  case 0xff: /* Grp5 */\n    /* Only indirect jmp is boostable */\n    return X86_MODRM_REG(insn-\u003emodrm.bytes[0]) == 4;\n  default:\n    return 1;\n  }\n}\n```\n\n### Jump optimization\n\nJump optimization, proposed in this paper [@hiramatsu2010djprobe], replace\n`int3` with a jump instruction. However, since jmp is 5 bytes long, the rewrite\ntarget just be carefully chosen\n\n## Handling instruction boundary\n\n`int3` must be placed at instruction boundary, otherwise it will causes an\nundefined behavior. For instance, when breakpoint `0xCC` is injected into a\n5-byte jmp leads to different instruction sequences, where only int3 is\naccurately decoded when placed at instruction boundary. [[kskzr2l4]].\n\n```asm\n\n0:  e9 c9 ab 00 00          jmp    abce \u003c_main+0xabce\u003e\n\n    v\n0:  cc                      int3\n1:  c9                      leave\n2:  ab                      stos   DWORD PTR es:[edi],eax\n\n       v\n0:  e9 cc ab 00 00          jmp    0xabd1\n\n          v\n0:  e9 c9 cc 00 00          jmp    0xccce\n```\n\nFor this reason, the address to set the breakpoint must align to instruction\nboundary. Kprobes handles this case using kallsyms kernel debug symbols. Before\nthe breakpoint is registered, the `can_probe` function looks for the function\nsymbol to first find the function boundary. It then decodes, starting from the\nfunction boundary, until the probe address (`paddr`) is reached. If the\ninstructions are decoded successfully then probe can be inserted there.\n\n```c\n/* Check if paddr is at an instruction boundary */\nstatic int can_probe(unsigned long paddr) {\n  unsigned long addr, __addr, offset = 0;\n  struct insn insn;\n  kprobe_opcode_t buf[MAX_INSN_SIZE];\n\n  if (!kallsyms_lookup_size_offset(paddr, NULL, \u0026offset))\n    return 0;\n\n  /* Decode instructions */\n  addr = paddr - offset;\n  while (addr \u003c paddr) {\n    int ret;\n\n    /*\n     * Check if the instruction has been modified by another\n     * kprobe, in which case we replace the breakpoint by the\n     * original instruction in our buffer.\n     * Also, jump optimization will change the breakpoint to\n     * relative-jump. Since the relative-jump itself is\n     * normally used, we just go through if there is no kprobe.\n     */\n    __addr = recover_probed_instruction(buf, addr);\n    if (!__addr)\n      return 0;\n\n    ret = insn_decode_kernel(\u0026insn, (void *)__addr);\n    if (ret \u003c 0)\n      return 0;\n\n#ifdef CONFIG_KGDB\n    /*\n     * If there is a dynamically installed kgdb sw breakpoint,\n     * this function should not be probed.\n     */\n    if (insn.opcode.bytes[0] == INT3_INSN_OPCODE \u0026\u0026 kgdb_has_hit_break(addr))\n      return 0;\n#endif\n    addr += insn.length;\n  }\n\n  return (addr == paddr);\n}\n```\n\n## Registering flow\n\n```cxx\n// cxx handles bullshit syntax quite well\n\nregister_kprobe(struct kprobe* p)\n         │                       // !kprobe-\u003esymbol_name\n         ├───► _kprobe_addr(p-\u003eaddr) ────────────► kallsyms_lookup_size_offset() ──► arch_ajust_kprobe_addr()\n         │ // if exist kprobe at the addr\n         ├───► register_aggr_kprobe() // Register aggregated kprobes, e.g., multiple handler function are invoked on the probe\n         │\n         ├───► prepare_kprobe(p) ───► arch_prepare_kprobe(p) // e.g., x86/kernel/kprobes/core.c\n         │                                       ├────► can_probe(p-\u003eaddr) // Check instruction boundary again, by decoding starting\n                                                 │                         // from the function start symbol.\n         │                                       ├────► get_insn_slot() // get a slot from the instruction cache,\n         │                                       │                      // an array of executable page for instructions\n         │                                       └────► arch_copy_kprobe(p)\n         │                                                     │\n         │                                                     ├───► __copy_instruction()\n         │                                                     │              │\n         │                                                     │              ├────► copy_from_kernel_nofault()\n         │                                                     │              │\n         │                                                     │              ├────► insn_decode_kernel(insn, dest) // Decode the instruction\n         │                                                     │              │\n         │                                                     │              └────► insn_rip_relative(insn)\n         │                                                     │                        └─► // Handle displacement a RIP relative the instruction is relocated\n         │                                                     ├──► prepare_emulation(p, \u0026insn) // now the instruction is decoded, check if instruction should be emulated\n         │                                                     │\n         │                                                     ├──► prepare_singlestep() // Prepare the landing site for single stepping\n         │                                                     │          │ │ // If can_boost()\n         │                                                     │          │ └───► synthesize_reljump() // Place relative jump to the end of the buffer\n         │                                                     │          │ // cannot boost\n         │                                                     │          └──────► // Places int3 at the end of the buffer\n         │                                                     │\n         │                                                     └──► text_poke() // Write the newly constructed instructions to instruction cache slot\n         │\n         ├─► arm_kprobe() ────► arch_arm_kprobe() ────► text_poke()\n         │\n         └─► try_to_optimize_kprobe() // jump optimization\n```\n\n### Notes\n\n- Instruction execution cache page should be within 2GB of the kernel image,\n  because of RIP-relative fixing (see `alloc_insn_page`)","snippets":["#linux #os"],"rawContent":"# kprobes\n\n#linux #os\n\n[kprobes](https://docs.kernel.org/trace/kprobes.html) is a Linux kernel\nsubsystem allows the user to insert breakpoint in almost anywhere within kernel.\nOn encountering such breakpoint, the custom user handler function (a\npre_handler) is called. kprobes then single-step/emulate the instruction and\ncall a post_handler.\n\n## Intercept mechanism\n\n### int3\n\nOn x86, the `int3` instruction for debug breakpoint is used. The opcode for\n`int3`, 0xCC is injected into the desired location, while the original\ninstruction is backed in the `kprobe` structure.\n\nWhen the CPU encounter `int3`, the following handler is invoked.\n\n```c\nint kprobe_int3_handler(struct pt_regs *regs) {\n  kprobe_opcode_t *addr;\n  struct kprobe *p;\n  struct kprobe_ctlblk *kcb;\n\n  if (user_mode(regs))\n    return 0;\n\n  addr = (kprobe_opcode_t *)(regs-\u003eip - sizeof(kprobe_opcode_t));\n  /*\n   * We don't want to be preempted for the entire duration of kprobe\n   * processing. Since int3 and debug trap disables irqs and we clear\n   * IF while singlestepping, it must be no preemptible.\n   */\n\n  kcb = get_kprobe_ctlblk();\n  p = get_kprobe(addr);\n\n  if (p) {\n    if (kprobe_running()) {\n      if (reenter_kprobe(p, regs, kcb))\n        return 1;\n    } else {\n      set_current_kprobe(p, regs, kcb);\n      kcb-\u003ekprobe_status = KPROBE_HIT_ACTIVE;\n\n      /*\n       * If we have no pre-handler or it returned 0, we\n       * continue with normal processing.  If we have a\n       * pre-handler and it returned non-zero, that means\n       * user handler setup registers to exit to another\n       * instruction, we must skip the single stepping.\n       */\n      if (!p-\u003epre_handler || !p-\u003epre_handler(p, regs))\n        setup_singlestep(p, regs, kcb, 0);\n      else\n        reset_current_kprobe();\n      return 1;\n    }\n  } else if (kprobe_is_ss(kcb)) {\n    p = kprobe_running();\n    if ((unsigned long)p-\u003eainsn.insn \u003c regs-\u003eip \u0026\u0026\n        (unsigned long)p-\u003eainsn.insn + MAX_INSN_SIZE \u003e regs-\u003eip) {\n      /* Most provably this is the second int3 for singlestep */\n      resume_singlestep(p, regs, kcb);\n      kprobe_post_process(p, regs, kcb);\n      return 1;\n    }\n  }\n\n  if (*addr != INT3_INSN_OPCODE) {\n    /*\n     * The breakpoint instruction was removed right\n     * after we hit it.  Another cpu has removed\n     * either a probepoint or a debugger breakpoint\n     * at this address.  In either case, no further\n     * handling of this interrupt is appropriate.\n     * Back up over the (now missing) int3 and run\n     * the original instruction.\n     *\n     */\n    regs-\u003eip = (unsigned long)addr;\n    return 1;\n  } /* else: not a kprobe fault; let the kernel handle it */\n\n  return 0;\n}\n```\n\n### jmp-based interception\n\n## Single-stepping\n\nSingle-stepping places in `int3` after the executed instruction buffer, such\nthat the `int3` handler is once again triggered.\n\n```term\nExecution flow    ┌─►kprobe_int3_handler      insn buffer       ┌──► int3 handler\n   inst1          │  RIP = insn buffer    ┌─────► inst4         │    resume_singlestep\n   inst2          │  ret──────────────────┘       int3──────────┘          rip = original_rip + 1\n   inst3          │                                                  ret\n   int3───────────┘                                                   │\n   inst5◄─────────────────────────────────────────────────────────────┘\n\n```\n\n### Notes on emulation vs single stepping\n\nkprobe supports two ways to execute the probed instruction, emulating them vs.\nstepping over.\n\nSingle-stepping is performed by injecting `int3`right after the probed\ninstruction in the insn cache.\n\nControl flow transfer instruction like `jmp` and `call` cannot be\nsingle-stepped, because they transfer control flow somewhere else. Even when\n`int3` is inserted right after a `jmp`, it cannot be called a single-step\nanymore.\n\nFor this reason, control flow transfers _must_ be emulated in kprobes. In deed,\nin the `prepare_emulation` function, most of the emulated instructions are\ncontrol flow transfers.\n\n## Optimizations\n\n### Boosting\n\nThe act of \"boosting\" refers to the part in single stepping, where `int3` can be\nreplaced with a relative `jmp` instruction that transfer control back to the\noriginal instruction.\n\n```term\nExecution flow    ┌─►kprobe_int3_handler      insn buffer\n   inst1          │  RIP = insn buffer    ┌─────► inst4\n   inst2          │  ret──────────────────┘       jmp original_rip +1\n   inst3          │                                         │\n   int3───────────┘                                         │\n   inst5◄───────────────────────────────────────────────────┘\n\n```\n\n```c\n/*\n * Returns non-zero if INSN is boostable.\n * RIP relative instructions are adjusted at copying time in 64 bits mode\n */\nint can_boost(struct insn *insn, void *addr) {\n  kprobe_opcode_t opcode;\n  insn_byte_t prefix;\n  int i;\n\n  if (search_exception_tables((unsigned long)addr))\n    return 0; /* Page fault may occur on this address. */\n\n  /* 2nd-byte opcode */\n  if (insn-\u003eopcode.nbytes == 2)\n    return test_bit(insn-\u003eopcode.bytes[1],\n                    (unsigned long *)twobyte_is_boostable);\n\n  if (insn-\u003eopcode.nbytes != 1)\n    return 0;\n\n  for_each_insn_prefix(insn, i, prefix) {\n    insn_attr_t attr;\n\n    attr = inat_get_opcode_attribute(prefix);\n    /* Can't boost Address-size override prefix and CS override prefix */\n    if (prefix == 0x2e || inat_is_address_size_prefix(attr))\n      return 0;\n  }\n\n  opcode = insn-\u003eopcode.bytes[0];\n\n  switch (opcode) {\n  case 0x62:          /* bound */\n  case 0x70 ... 0x7f: /* Conditional jumps */\n  case 0x9a:          /* Call far */\n  case 0xc0 ... 0xc1: /* Grp2 */\n  case 0xcc ... 0xce: /* software exceptions */\n  case 0xd0 ... 0xd3: /* Grp2 */\n  case 0xd6:          /* (UD) */\n  case 0xd8 ... 0xdf: /* ESC */\n  case 0xe0 ... 0xe3: /* LOOP*, JCXZ */\n  case 0xe8 ... 0xe9: /* near Call, JMP */\n  case 0xeb:          /* Short JMP */\n  case 0xf0 ... 0xf4: /* LOCK/REP, HLT */\n  case 0xf6 ... 0xf7: /* Grp3 */\n  case 0xfe:          /* Grp4 */\n    /* ... are not boostable */\n    return 0;\n  case 0xff: /* Grp5 */\n    /* Only indirect jmp is boostable */\n    return X86_MODRM_REG(insn-\u003emodrm.bytes[0]) == 4;\n  default:\n    return 1;\n  }\n}\n```\n\n### Jump optimization\n\nJump optimization, proposed in this paper [@hiramatsu2010djprobe], replace\n`int3` with a jump instruction. However, since jmp is 5 bytes long, the rewrite\ntarget just be carefully chosen\n\n## Handling instruction boundary\n\n`int3` must be placed at instruction boundary, otherwise it will causes an\nundefined behavior. For instance, when breakpoint `0xCC` is injected into a\n5-byte jmp leads to different instruction sequences, where only int3 is\naccurately decoded when placed at instruction boundary. [[kskzr2l4]].\n\n```asm\n\n0:  e9 c9 ab 00 00          jmp    abce \u003c_main+0xabce\u003e\n\n    v\n0:  cc                      int3\n1:  c9                      leave\n2:  ab                      stos   DWORD PTR es:[edi],eax\n\n       v\n0:  e9 cc ab 00 00          jmp    0xabd1\n\n          v\n0:  e9 c9 cc 00 00          jmp    0xccce\n```\n\nFor this reason, the address to set the breakpoint must align to instruction\nboundary. Kprobes handles this case using kallsyms kernel debug symbols. Before\nthe breakpoint is registered, the `can_probe` function looks for the function\nsymbol to first find the function boundary. It then decodes, starting from the\nfunction boundary, until the probe address (`paddr`) is reached. If the\ninstructions are decoded successfully then probe can be inserted there.\n\n```c\n/* Check if paddr is at an instruction boundary */\nstatic int can_probe(unsigned long paddr) {\n  unsigned long addr, __addr, offset = 0;\n  struct insn insn;\n  kprobe_opcode_t buf[MAX_INSN_SIZE];\n\n  if (!kallsyms_lookup_size_offset(paddr, NULL, \u0026offset))\n    return 0;\n\n  /* Decode instructions */\n  addr = paddr - offset;\n  while (addr \u003c paddr) {\n    int ret;\n\n    /*\n     * Check if the instruction has been modified by another\n     * kprobe, in which case we replace the breakpoint by the\n     * original instruction in our buffer.\n     * Also, jump optimization will change the breakpoint to\n     * relative-jump. Since the relative-jump itself is\n     * normally used, we just go through if there is no kprobe.\n     */\n    __addr = recover_probed_instruction(buf, addr);\n    if (!__addr)\n      return 0;\n\n    ret = insn_decode_kernel(\u0026insn, (void *)__addr);\n    if (ret \u003c 0)\n      return 0;\n\n#ifdef CONFIG_KGDB\n    /*\n     * If there is a dynamically installed kgdb sw breakpoint,\n     * this function should not be probed.\n     */\n    if (insn.opcode.bytes[0] == INT3_INSN_OPCODE \u0026\u0026 kgdb_has_hit_break(addr))\n      return 0;\n#endif\n    addr += insn.length;\n  }\n\n  return (addr == paddr);\n}\n```\n\n## Registering flow\n\n```cxx\n// cxx handles bullshit syntax quite well\n\nregister_kprobe(struct kprobe* p)\n         │                       // !kprobe-\u003esymbol_name\n         ├───► _kprobe_addr(p-\u003eaddr) ────────────► kallsyms_lookup_size_offset() ──► arch_ajust_kprobe_addr()\n         │ // if exist kprobe at the addr\n         ├───► register_aggr_kprobe() // Register aggregated kprobes, e.g., multiple handler function are invoked on the probe\n         │\n         ├───► prepare_kprobe(p) ───► arch_prepare_kprobe(p) // e.g., x86/kernel/kprobes/core.c\n         │                                       ├────► can_probe(p-\u003eaddr) // Check instruction boundary again, by decoding starting\n                                                 │                         // from the function start symbol.\n         │                                       ├────► get_insn_slot() // get a slot from the instruction cache,\n         │                                       │                      // an array of executable page for instructions\n         │                                       └────► arch_copy_kprobe(p)\n         │                                                     │\n         │                                                     ├───► __copy_instruction()\n         │                                                     │              │\n         │                                                     │              ├────► copy_from_kernel_nofault()\n         │                                                     │              │\n         │                                                     │              ├────► insn_decode_kernel(insn, dest) // Decode the instruction\n         │                                                     │              │\n         │                                                     │              └────► insn_rip_relative(insn)\n         │                                                     │                        └─► // Handle displacement a RIP relative the instruction is relocated\n         │                                                     ├──► prepare_emulation(p, \u0026insn) // now the instruction is decoded, check if instruction should be emulated\n         │                                                     │\n         │                                                     ├──► prepare_singlestep() // Prepare the landing site for single stepping\n         │                                                     │          │ │ // If can_boost()\n         │                                                     │          │ └───► synthesize_reljump() // Place relative jump to the end of the buffer\n         │                                                     │          │ // cannot boost\n         │                                                     │          └──────► // Places int3 at the end of the buffer\n         │                                                     │\n         │                                                     └──► text_poke() // Write the newly constructed instructions to instruction cache slot\n         │\n         ├─► arm_kprobe() ────► arch_arm_kprobe() ────► text_poke()\n         │\n         └─► try_to_optimize_kprobe() // jump optimization\n```\n\n### Notes\n\n- Instruction execution cache page should be within 2GB of the kernel image,\n  because of RIP-relative fixing (see `alloc_insn_page`)\n","wordCount":1420,"tags":["os","linux"],"metadata":{},"created":"2024-06-19T07:09:32.538278124Z","modified":"2024-07-12T05:37:03.653730548Z","checksum":"46d39da46f1bf4f77e9bc13b8a81c01bfd33473165ccedbda24ba959a8afa14b"},
    {"filename":"o8e5t1ma.md","filenameStem":"o8e5t1ma","path":"o8e5t1ma.md","absPath":"/home/khadd/mynotes/o8e5t1ma.md","title":"overview incognitos","link":"[[o8e5t1ma]]","lead":"```mermaid\ngraph TB\n\tunikernel[\"Unikernel for Obfuscated CVM\"]:::overview\n    \tgoal_transparent[\"Goal:\\nTransparent obfuscation\"]:::overview\n    \tgoal_adaptive[\"Goal:\\nAdaptive Defense\"]:::overview\n    \tfeat_directhw[\"Feature:\\nDirect Hardware Access\"]:::overview\n    \tfeat_smalltcb[\"Feature:\\nSmall TCB\"]:::overview","body":"```mermaid\ngraph TB\n\tunikernel[\"Unikernel for Obfuscated CVM\"]:::overview\n    \tgoal_transparent[\"Goal:\\nTransparent obfuscation\"]:::overview\n    \tgoal_adaptive[\"Goal:\\nAdaptive Defense\"]:::overview\n    \tfeat_directhw[\"Feature:\\nDirect Hardware Access\"]:::overview\n    \tfeat_smalltcb[\"Feature:\\nSmall TCB\"]:::overview\n\n\n\tchal_rate[\"Challenge: \\nRobust and reliable sampling\"]:::overview\n\tchal_untrusted_int[\"Challenge: \\nScheduler that deepends on\\nhypervisor is untrustworthy\"]:::overview\n\n\tmotiv_rates[\"Motivation:\\nEmpirical attack VMEXIT analysis\"]:::overview\n\tmotiv_overheads[\"Motivation:\\nHigh overheads of\\nobfsuscation\"]:::overview\n\n\tobs_adaptive[\"Observation:\\nRate can be scaled without \\nreducing security\"]:::overview\n\tobs_vmexit[\"Observation:\\nVMExit can be sampled\"]:::overview\n\tobs_gpa[\"Observation:\\nAttacker can only observe GPA \\nwhile gvA is hidden\"]:::overview\n\n\tsched_policy[\"Details:\\nHigh-level policy\"]:::scheduling\n\n\n\ttech_sbi[\"Technique:\\nStatic binary instrumentation\"]:::overview\n    \ttech_mmunative[\"Technique:\\nMMU-native obfuscation\\n only reerand GPA while\"]:::overview\n\n\tsol_sampling[\"Solution:\\n Robust and transparent Rate sampling\"]:::scheduling\n\tsol_synctick[\"Solution:\\nSynchronous ticks independent of Hyp\"]:::scheduling\n\tsol_rerand_paging[\"Soluion:\\nRerandomizing page management\"]:::paging\n\n\treq_sampling[\"Requirement:\\nSampling rate sufficiency\"]:::scheduling\n\n\tsched_placement[\"Detail:\\nTick placement strategy\"]:::scheduling\n\tsched_coverage[\"Loop coverage\"]:::scheduling\n\tsched_basicblock[\"Basic block scheme\"]:::scheduling\n\tsched_sbi[\"Details:\\nStatic binary inst\"]:::scheduling\n\tsched_time[\"Instruction as time\"]:::scheduling\n\tsched_scaling[\"Scaling function\"]:::scheduling\n\tsched_window[\"Rolling window\"]:::scheduling\n\tsched_nyquyst[\"Nyquyst theorem\"]:::scheduling\n\tsched_trampoline[\"Trampline design\"]:::scheduling\n\tsched_inst[\"Instruction selection\"]:::scheduling\n\n    \tunikernel--\u003efeat_directhw\n    \tunikernel--\u003efeat_smalltcb\n    \tunikernel--\u003egoal_transparent\n\tunikernel--\u003egoal_adaptive\n\n\tgoal_transparent--\u003etech_sbi\n\tgoal_adaptive--\u003emotiv_rates\n\tgoal_adaptive--\u003emotiv_overheads\n    \tgoal_transparent--\u003etech_mmunative\n\n\tmotiv_overheads--\u003eobs_adaptive\n\n\tobs_vmexit--\u003echal_untrusted_int\n\n\tmotiv_rates--\u003eobs_vmexit\n\tobs_vmexit--\u003echal_rate\n\tchal_rate--\u003esol_sampling\n\n\n\ttech_mmunative--\u003eobs_gpa\n\ttech_sbi--\u003esol_synctick\n\ttech_sbi--\u003esched_sbi\n\n\tfeat_directhw--\u003etech_mmunative\n\tfeat_smalltcb--\u003etech_mmunative\n\n\tsol_sampling--\u003ereq_sampling\n\tsol_sampling--\u003esol_synctick\n\tsol_sampling--\u003esched_policy\n\n\tsched_policy--\u003esched_window\n\tsched_policy--\u003esched_scaling\n\n\tchal_untrusted_int--\u003esol_synctick\n\tsol_synctick--\u003esched_time\n\tsol_synctick--\u003esched_sbi\n\n\tsched_time--\u003esched_sbi\n\tsched_time--\u003esched_window\n\n\tsched_sbi--\u003esched_trampoline\n\tsched_sbi--\u003esched_inst\n\n\n\treq_sampling--\u003esched_nyquyst\n\treq_sampling--\u003esched_placement\n\tsched_placement--\u003esched_sbi\n\tsched_placement--\u003esched_coverage\n\tsched_placement--\u003esched_basicblock\n\n\n\ttech_mmunative--\u003esol_rerand_paging\n\n    \tclassDef overview fill:#f9f\n    \tclassDef scheduling fill:lightblue\n    \tclassDef paging fill:lightgreen\n```","snippets":["```mermaid\ngraph TB\n\tunikernel[\"Unikernel for Obfuscated CVM\"]:::overview\n    \tgoal_transparent[\"Goal:\\nTransparent obfuscation\"]:::overview\n    \tgoal_adaptive[\"Goal:\\nAdaptive Defense\"]:::overview\n    \tfeat_directhw[\"Feature:\\nDirect Hardware Access\"]:::overview\n    \tfeat_smalltcb[\"Feature:\\nSmall TCB\"]:::overview"],"rawContent":"# overview incognitos\n\n```mermaid\ngraph TB\n\tunikernel[\"Unikernel for Obfuscated CVM\"]:::overview\n    \tgoal_transparent[\"Goal:\\nTransparent obfuscation\"]:::overview\n    \tgoal_adaptive[\"Goal:\\nAdaptive Defense\"]:::overview\n    \tfeat_directhw[\"Feature:\\nDirect Hardware Access\"]:::overview\n    \tfeat_smalltcb[\"Feature:\\nSmall TCB\"]:::overview\n\n\n\tchal_rate[\"Challenge: \\nRobust and reliable sampling\"]:::overview\n\tchal_untrusted_int[\"Challenge: \\nScheduler that deepends on\\nhypervisor is untrustworthy\"]:::overview\n\n\tmotiv_rates[\"Motivation:\\nEmpirical attack VMEXIT analysis\"]:::overview\n\tmotiv_overheads[\"Motivation:\\nHigh overheads of\\nobfsuscation\"]:::overview\n\n\tobs_adaptive[\"Observation:\\nRate can be scaled without \\nreducing security\"]:::overview\n\tobs_vmexit[\"Observation:\\nVMExit can be sampled\"]:::overview\n\tobs_gpa[\"Observation:\\nAttacker can only observe GPA \\nwhile gvA is hidden\"]:::overview\n\n\tsched_policy[\"Details:\\nHigh-level policy\"]:::scheduling\n\n\n\ttech_sbi[\"Technique:\\nStatic binary instrumentation\"]:::overview\n    \ttech_mmunative[\"Technique:\\nMMU-native obfuscation\\n only reerand GPA while\"]:::overview\n\n\tsol_sampling[\"Solution:\\n Robust and transparent Rate sampling\"]:::scheduling\n\tsol_synctick[\"Solution:\\nSynchronous ticks independent of Hyp\"]:::scheduling\n\tsol_rerand_paging[\"Soluion:\\nRerandomizing page management\"]:::paging\n\n\treq_sampling[\"Requirement:\\nSampling rate sufficiency\"]:::scheduling\n\n\tsched_placement[\"Detail:\\nTick placement strategy\"]:::scheduling\n\tsched_coverage[\"Loop coverage\"]:::scheduling\n\tsched_basicblock[\"Basic block scheme\"]:::scheduling\n\tsched_sbi[\"Details:\\nStatic binary inst\"]:::scheduling\n\tsched_time[\"Instruction as time\"]:::scheduling\n\tsched_scaling[\"Scaling function\"]:::scheduling\n\tsched_window[\"Rolling window\"]:::scheduling\n\tsched_nyquyst[\"Nyquyst theorem\"]:::scheduling\n\tsched_trampoline[\"Trampline design\"]:::scheduling\n\tsched_inst[\"Instruction selection\"]:::scheduling\n\n    \tunikernel--\u003efeat_directhw\n    \tunikernel--\u003efeat_smalltcb\n    \tunikernel--\u003egoal_transparent\n\tunikernel--\u003egoal_adaptive\n\n\tgoal_transparent--\u003etech_sbi\n\tgoal_adaptive--\u003emotiv_rates\n\tgoal_adaptive--\u003emotiv_overheads\n    \tgoal_transparent--\u003etech_mmunative\n\n\tmotiv_overheads--\u003eobs_adaptive\n\n\tobs_vmexit--\u003echal_untrusted_int\n\n\tmotiv_rates--\u003eobs_vmexit\n\tobs_vmexit--\u003echal_rate\n\tchal_rate--\u003esol_sampling\n\n\n\ttech_mmunative--\u003eobs_gpa\n\ttech_sbi--\u003esol_synctick\n\ttech_sbi--\u003esched_sbi\n\n\tfeat_directhw--\u003etech_mmunative\n\tfeat_smalltcb--\u003etech_mmunative\n\n\tsol_sampling--\u003ereq_sampling\n\tsol_sampling--\u003esol_synctick\n\tsol_sampling--\u003esched_policy\n\n\tsched_policy--\u003esched_window\n\tsched_policy--\u003esched_scaling\n\n\tchal_untrusted_int--\u003esol_synctick\n\tsol_synctick--\u003esched_time\n\tsol_synctick--\u003esched_sbi\n\n\tsched_time--\u003esched_sbi\n\tsched_time--\u003esched_window\n\n\tsched_sbi--\u003esched_trampoline\n\tsched_sbi--\u003esched_inst\n\n\n\treq_sampling--\u003esched_nyquyst\n\treq_sampling--\u003esched_placement\n\tsched_placement--\u003esched_sbi\n\tsched_placement--\u003esched_coverage\n\tsched_placement--\u003esched_basicblock\n\n\n\ttech_mmunative--\u003esol_rerand_paging\n\n    \tclassDef overview fill:#f9f\n    \tclassDef scheduling fill:lightblue\n    \tclassDef paging fill:lightgreen\n```\n","wordCount":156,"tags":[],"metadata":{},"created":"2024-10-30T08:25:15.287963208Z","modified":"2024-10-30T09:23:13.379615813Z","checksum":"840f5bf1bf2440990f747984dc756163a68c4af543f485204e0ecf77b534cc91"},
    {"filename":"hog0h5z8.md","filenameStem":"hog0h5z8","path":"hog0h5z8.md","absPath":"/home/khadd/mynotes/hog0h5z8.md","title":"sel4 Resources","link":"[[hog0h5z8]]","lead":"#sel4 #os #capabilities","body":"#sel4 #os #capabilities\n\n- [L4 microkernels: The lessons from 20 years of research and deployment](https://trustworthy.systems/publications/nictaabstracts/Heiser_Elphinstone_16.abstract): A summary of seL4 in the context of previous research such as EROS, KeykOS.\n- [seL4 Overview and Tutorial](http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf): tutorial slides","snippets":["#sel4 #os #capabilities"],"rawContent":"# sel4 Resources\n#sel4 #os #capabilities\n\n- [L4 microkernels: The lessons from 20 years of research and deployment](https://trustworthy.systems/publications/nictaabstracts/Heiser_Elphinstone_16.abstract): A summary of seL4 in the context of previous research such as EROS, KeykOS.\n- [seL4 Overview and Tutorial](http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf): tutorial slides\n\n","wordCount":39,"tags":["sel4","capabilities","os"],"metadata":{},"created":"2023-05-22T02:06:14.45509701Z","modified":"2023-05-17T05:11:30.05308355Z","checksum":"f34bc12d5fac842170f578aced5310a89266a99f4fc7d2527fdbfc7c7b47f0aa"},
    {"filename":"c1265k4b.md","filenameStem":"c1265k4b","path":"c1265k4b.md","absPath":"/home/khadd/mynotes/c1265k4b.md","title":"tikz notes","link":"[[c1265k4b]]","lead":"#area #tikz #latex","body":"#area #tikz #latex\n\n# Arrow\n## Ankles\nThere are several ways to add ankle to tikz arrows. All of them are non-trivial (like just changing the arrow types in most diagram makers.)\n\n### Relative coordinate\nYou can use relative addressing to address the point between two nodes. However, this require some manual adjustment.\n\n```tikz\n\\begin{document}\n\\begin{tikzpicture}\n\\node(a) at (0,0) {A};\n\\node(b) at (2,2) {B};\n\\draw[-\u003e] (a) -| ++(1,1) |- (b);\n\\end{tikzpicture}\n\\end{document}\n```\n\n### Calculating middle point \nThis requires the `calc` tikz library.\n```tikz\n\\usetikzlibrary{calc}\n\\begin{document}\n\\begin{tikzpicture}\n\\node(a) at (0,0) {A};\n\\node(b) at (2,2) {B};\n\\draw[-\u003e] (a) -| ($(a)!0.5!(b)$) |- (b);\n\\end{tikzpicture}\n\\end{document}\n```","snippets":["#area #tikz #latex"],"rawContent":"# tikz notes\n#area #tikz #latex\n\n# Arrow\n## Ankles\nThere are several ways to add ankle to tikz arrows. All of them are non-trivial (like just changing the arrow types in most diagram makers.)\n\n### Relative coordinate\nYou can use relative addressing to address the point between two nodes. However, this require some manual adjustment.\n\n```tikz\n\\begin{document}\n\\begin{tikzpicture}\n\\node(a) at (0,0) {A};\n\\node(b) at (2,2) {B};\n\\draw[-\u003e] (a) -| ++(1,1) |- (b);\n\\end{tikzpicture}\n\\end{document}\n```\n\n### Calculating middle point \nThis requires the `calc` tikz library.\n```tikz\n\\usetikzlibrary{calc}\n\\begin{document}\n\\begin{tikzpicture}\n\\node(a) at (0,0) {A};\n\\node(b) at (2,2) {B};\n\\draw[-\u003e] (a) -| ($(a)!0.5!(b)$) |- (b);\n\\end{tikzpicture}\n\\end{document}\n```\n\n\n\n","wordCount":107,"tags":["area","tikz","latex"],"metadata":{},"created":"2024-05-22T08:24:03.23914394Z","modified":"2024-05-22T08:23:40.663275058Z","checksum":"a924252058843892bac45ee13d3ba99e5b53b4ed67e4088fb388097e963f804f"},
    {"filename":"o53nse4p.md","filenameStem":"o53nse4p","path":"o53nse4p.md","absPath":"/home/khadd/mynotes/o53nse4p.md","title":"vSGX: Virtualizing SGX Enclaves on AMD SEV","link":"[[o53nse4p]]","lead":"#literature #sgx #tee #sev #virtualization","body":"#literature #sgx #tee #sev #virtualization\n\n# Main arguments\n\n## Benefits of virtualizing SGX on AMD\n\n- Binary compatiblity: unmodified applications be ran on AMD SEV machines, while\n  having comparable security guarantees.\n- Finer-grain trust: SGX model only places the trust in the small userspace\n  enclave, and does not trust the OS and the untrusted part of the process. In\n  ths paper, they _trust the OS in the VM that run the enclave (EVM)_, but do\n  not trust the untrusted part of the enclave program.\n\n## SGX can be virtualized on AMD SEV","snippets":["#literature #sgx #tee #sev #virtualization"],"rawContent":"# vSGX: Virtualizing SGX Enclaves on AMD SEV\n\n#literature #sgx #tee #sev #virtualization\n\n# Main arguments\n\n## Benefits of virtualizing SGX on AMD\n\n- Binary compatiblity: unmodified applications be ran on AMD SEV machines, while\n  having comparable security guarantees.\n- Finer-grain trust: SGX model only places the trust in the small userspace\n  enclave, and does not trust the OS and the untrusted part of the process. In\n  ths paper, they _trust the OS in the VM that run the enclave (EVM)_, but do\n  not trust the untrusted part of the enclave program.\n\n## SGX can be virtualized on AMD SEV\n","wordCount":100,"tags":["literature","sgx","tee","sev","virtualization"],"metadata":{},"created":"2024-05-22T08:24:03.291962798Z","modified":"2024-07-28T07:41:51.196606077Z","checksum":"bedcd9bf828245c9b0dd4ea6d329e0c35fac8ab9698b06fde97686a45da2e266"},
    {"filename":"d22taxo6.md","filenameStem":"d22taxo6","path":"d22taxo6.md","absPath":"/home/khadd/mynotes/d22taxo6.md","title":"x86 prefixes","link":"[[d22taxo6]]","lead":"#instruction-encoding #intel","body":"#instruction-encoding #intel\n\n\n\n\nPrefixes  are divided into 4 groups\n\n| Prefix                 | Group |\n|------------------------|-------|\n| F0, F2, F3             | Grp 1 |\n| 2E, 36, 3E, 26, 64, 67 | Grp 2 |\n| 66                     | Grp 3 |\n| 67                     | Grp 4 |\n\n\n\n```\nprefix\n▲  ┌► two-byte opcode prefix\n│  │  ┌─────────────►(Move Unaligned Packed Single-Precision Floating-Point Values)\n│  │  │\n│  │  │\n-- 0f 10             MOVUPS \txmm \txmm/m128\n\nGrp 3                (Move Unaligned Packed Double-Precision Floating-Point Values)\n▲\n│\n66 0f 11             MOVUPD   xmm   xmm/m128\n\nGrp 1 with REPNE/REPNZ encoded                (Move Unaligned Packed Single-Precision Floating-Point Values)\n▲\n│\nF2 0f 11                                      MOVSD    xmm   xmm/m64\n\nGrp 1 REPE/REPZ encoded                       (Move or Merge Scalar Single-Precision Floating-Point Value)\n▲\n│\nF3 0f 11                                      MOVSS    xmm   xmm/m32\n\n```","snippets":["#instruction-encoding #intel"],"rawContent":"# x86 prefixes\n#instruction-encoding #intel\n\n\n\n\nPrefixes  are divided into 4 groups\n\n| Prefix                 | Group |\n|------------------------|-------|\n| F0, F2, F3             | Grp 1 |\n| 2E, 36, 3E, 26, 64, 67 | Grp 2 |\n| 66                     | Grp 3 |\n| 67                     | Grp 4 |\n\n\n\n```\nprefix\n▲  ┌► two-byte opcode prefix\n│  │  ┌─────────────►(Move Unaligned Packed Single-Precision Floating-Point Values)\n│  │  │\n│  │  │\n-- 0f 10             MOVUPS \txmm \txmm/m128\n\nGrp 3                (Move Unaligned Packed Double-Precision Floating-Point Values)\n▲\n│\n66 0f 11             MOVUPD   xmm   xmm/m128\n\nGrp 1 with REPNE/REPNZ encoded                (Move Unaligned Packed Single-Precision Floating-Point Values)\n▲\n│\nF2 0f 11                                      MOVSD    xmm   xmm/m64\n\nGrp 1 REPE/REPZ encoded                       (Move or Merge Scalar Single-Precision Floating-Point Value)\n▲\n│\nF3 0f 11                                      MOVSS    xmm   xmm/m32\n\n```\n\n\n","wordCount":130,"tags":["intel","instruction-encoding"],"metadata":{},"created":"2023-07-29T03:13:23.64852312Z","modified":"2023-08-09T06:04:56.500519354Z","checksum":"7c24b41b7556c95f781ffbcde34e1d3d8140105f5c36356eb38641ad3f7e1856"}
  ],
  "links": [
    {"title":"dyx2t4oz","href":"dyx2t4oz","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Using frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.","snippetStart":242,"snippetEnd":367,"sourceId":23,"sourcePath":"cemsxh4n.md","targetId":24,"targetPath":"dyx2t4oz.md"},
    {"title":"zz3cedu0","href":"zz3cedu0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Using frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.","snippetStart":242,"snippetEnd":367,"sourceId":23,"sourcePath":"cemsxh4n.md","targetId":215,"targetPath":"zz3cedu0.md"},
    {"title":"b740rhio","href":"b740rhio","type":"wiki-link","isExternal":false,"rels":[],"snippet":"It is also important to remember the [[b740rhio]], so spend more time on the\nbeginning and the end of the section.","snippetStart":284,"snippetEnd":398,"sourceId":43,"sourcePath":"k0wjwjhg.md","targetId":44,"targetPath":"b740rhio.md"},
    {"title":"2a7l7odo","href":"2a7l7odo","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[@gu2020harmonizing] (see [[2a7l7odo]]) performed a study of the source of\noverheads of such IPC. SQLite3 is run on Zircon and seL4 microkernels. It is\nfound that total IPC time is 79% the time on Zircon and 44% of the time on seL4\n(with KPTI).","snippetStart":677,"snippetEnd":921,"sourceId":47,"sourcePath":"i2blyo37.md","targetId":219,"targetPath":"2a7l7odo.md"},
    {"title":"iwu6p0mt","href":"iwu6p0mt","type":"wiki-link","isExternal":false,"rels":[],"snippet":"PARA hashtags ([[iwu6p0mt]]).","snippetStart":22,"snippetEnd":51,"sourceId":51,"sourcePath":"index.md","targetId":293,"targetPath":"iwu6p0mt.md"},
    {"title":"s16ct1rj","href":"s16ct1rj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Containers and virtual machines ([[s16ct1rj]]) are two main isolation primitives\nwhen it come to cloud isolation.","snippetStart":83,"snippetEnd":196,"sourceId":53,"sourcePath":"h3manv25.md","targetId":100,"targetPath":"s16ct1rj.md"},
    {"title":"qti6u06p","href":"qti6u06p","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Removing state spill forces the caller to memory to allocate the context used\nfor cross-compartment interaction. In a sense, it also improves the security of\nthe per-compartment interface. See 1 and 4 in [[qti6u06p]].","snippetStart":2007,"snippetEnd":2224,"sourceId":68,"sourcePath":"2j6s9zpm.md","targetId":95,"targetPath":"qti6u06p.md"},
    {"title":"jfm8ud28","href":"jfm8ud28","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[@boos2020theseus] (see [[jfm8ud28]]): An operating system design that aim to\n  minimize state spill.","snippetStart":2228,"snippetEnd":2329,"sourceId":68,"sourcePath":"2j6s9zpm.md","targetId":226,"targetPath":"jfm8ud28.md"},
    {"title":"douswvq0","href":"douswvq0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[douswvq0]]","snippetStart":31,"snippetEnd":43,"sourceId":70,"sourcePath":"2dw6pwrd.md","targetId":242,"targetPath":"douswvq0.md"},
    {"title":"k60yjf6q","href":"k60yjf6q","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[k60yjf6q]]","snippetStart":1272,"snippetEnd":1284,"sourceId":71,"sourcePath":"7t4jlnaq.md","targetId":99,"targetPath":"k60yjf6q.md"},
    {"title":"a0g41kid","href":"a0g41kid","type":"wiki-link","isExternal":false,"rels":[],"snippet":"From the top-down view of the user, the OS provides abstraction over complex\ninteractions with the hardware. It turns an impossible task (write applications\nthat interacts with the hardware directly) in to two manageable tasks: (1)\ndesign and implement the abstraction, and (2) use the abstraction to do useful\nworks. Two most fundamental abstractions provided by most OSes are _files_ and\n_processes_. Files and file-related system calls abstract away the communication\nand management of data stored on the disk. Process is a unit of execution that\nenable multitasking (1.1, [@tanenbaum2015modern]) [[a0g41kid]].","snippetStart":130,"snippetEnd":743,"sourceId":71,"sourcePath":"7t4jlnaq.md","targetId":110,"targetPath":"a0g41kid.md"},
    {"title":"dyx2t4oz","href":"dyx2t4oz","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[dyx2t4oz]]","snippetStart":438,"snippetEnd":450,"sourceId":72,"sourcePath":"a6uh87al.md","targetId":24,"targetPath":"dyx2t4oz.md"},
    {"title":"zz3cedu0","href":"zz3cedu0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[zz3cedu0]]","snippetStart":453,"snippetEnd":465,"sourceId":72,"sourcePath":"a6uh87al.md","targetId":215,"targetPath":"zz3cedu0.md"},
    {"title":"gbkc1fhy","href":"gbkc1fhy","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Another use case is to enforce valid data flow between program points to prevent\ndata-only attacks [[gbkc1fhy]]. For instance, defenses such as DFI and WIT use\ndependence analysis to find all valid writer to a variable.","snippetStart":376,"snippetEnd":595,"sourceId":74,"sourcePath":"dgdvhu1e.md","targetId":105,"targetPath":"gbkc1fhy.md"},
    {"title":"4zdjxws6","href":"4zdjxws6","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[@lu2023practical] ([[4zdjxws6]]) notes several limitations with such an\napproach:","snippetStart":1066,"snippetEnd":1148,"sourceId":74,"sourcePath":"dgdvhu1e.md","targetId":221,"targetPath":"4zdjxws6.md"},
    {"title":"h3manv25","href":"h3manv25","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Hardware-accelerated virtualization also offers better isolation compared to\ncontainers [@yasukata2023exitless], [[h3manv25]].","snippetStart":1462,"snippetEnd":1588,"sourceId":75,"sourcePath":"e7p8xpz4.md","targetId":53,"targetPath":"h3manv25.md"},
    {"title":"wwxm9czw","href":"wwxm9czw","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Second, unikernels do not implement system calls, which can be an entry point\nfor attacks (note some unikernels offer syscall interface for binary\ncompatibility [[wwxm9czw]]). Hence, attackers are forced to use control-flow\nhijacking-based attacks to jump to unikernel functions,which can be mitigated\nthrough ASLR/CFI.","snippetStart":640,"snippetEnd":959,"sourceId":75,"sourcePath":"e7p8xpz4.md","targetId":268,"targetPath":"wwxm9czw.md"},
    {"title":"wwxm9czw","href":"wwxm9czw","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Unikernel's infrastructures is _immutable_, to rebuild the unikernel app, the\nentire infrastructure (OS, application, libraries) need to be rebuilt (through\nthe application may be exchanged through binary-compatibility [[wwxm9czw]]).\nThis avoid illegal modification, vulnerabilities from out-dated configurations.","snippetStart":1125,"snippetEnd":1438,"sourceId":75,"sourcePath":"e7p8xpz4.md","targetId":268,"targetPath":"wwxm9czw.md"},
    {"title":"y9wu5ut7","href":"y9wu5ut7","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Maybe the first one to coin the term confused deputy [[y9wu5ut7]] in his paper\n[@hardy1988confused].","snippetStart":185,"snippetEnd":285,"sourceId":79,"sourcePath":"j19hdkto.md","targetId":211,"targetPath":"y9wu5ut7.md"},
    {"title":"2j6s9zpm","href":"2j6s9zpm","type":"wiki-link","isExternal":false,"rels":[],"snippet":"State spills hinders flexibility in systems similarly by creating implicit\n  dependencies [[2j6s9zpm]].","snippetStart":1172,"snippetEnd":1275,"sourceId":92,"sourcePath":"c4icaua4.md","targetId":68,"targetPath":"2j6s9zpm.md"},
    {"title":"y9wu5ut7","href":"y9wu5ut7","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Strict hierarchical system leads to increasingly privileged system components,\n  and therefore leads to a component that have the \"most privileged\" only\n  because it manages other subsystems. This leads to confused deputy problems\n  ([[y9wu5ut7]]) in those components.","snippetStart":760,"snippetEnd":1028,"sourceId":92,"sourcePath":"c4icaua4.md","targetId":211,"targetPath":"y9wu5ut7.md"},
    {"title":"4vysjbn9","href":"4vysjbn9","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[4vysjbn9]].","snippetStart":1293,"snippetEnd":1306,"sourceId":92,"sourcePath":"c4icaua4.md","targetId":401,"targetPath":"4vysjbn9.md"},
    {"title":"khi9ihj9","href":"khi9ihj9","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Capabilities [[khi9ihj9]] systems naturally remove hierarchies by centralizing\naccess control decision to a reference monitor.","snippetStart":1030,"snippetEnd":1156,"sourceId":92,"sourcePath":"c4icaua4.md","targetId":403,"targetPath":"khi9ihj9.md"},
    {"title":"8113ygxd","href":"8113ygxd","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[8113ygxd]]","snippetStart":1278,"snippetEnd":1290,"sourceId":92,"sourcePath":"c4icaua4.md","targetId":413,"targetPath":"8113ygxd.md"},
    {"title":"7t4jlnaq","href":"7t4jlnaq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[7t4jlnaq]]","snippetStart":1619,"snippetEnd":1631,"sourceId":99,"sourcePath":"k60yjf6q.md","targetId":71,"targetPath":"7t4jlnaq.md"},
    {"title":"a0g41kid","href":"a0g41kid","type":"wiki-link","isExternal":false,"rels":[],"snippet":"OS provides threads and processes [[a0g41kid]] abstractions to conveniently\nmanage multiple concurrent tasks.","snippetStart":931,"snippetEnd":1040,"sourceId":99,"sourcePath":"k60yjf6q.md","targetId":110,"targetPath":"a0g41kid.md"},
    {"title":"d3nt6uix","href":"d3nt6uix","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Interposition give the virtualized system the illusion of hardware access. The\nhypervisor can interpose hardware interrupts, page faults, VM enter and exit,\nand handle them in software (handling them in the actual hardware would affect\nthe entire system). This give the illusion to virtual machine have actual access\nto those hardware resources. See [[d3nt6uix]].","snippetStart":983,"snippetEnd":1346,"sourceId":100,"sourcePath":"s16ct1rj.md","targetId":101,"targetPath":"d3nt6uix.md"},
    {"title":"s16ct1rj#interposition","href":"s16ct1rj#interposition","type":"wiki-link","isExternal":false,"rels":[],"snippet":"It performs interposition ([[s16ct1rj#interposition]]) on a certain\n_interesting_ instructions to _emulate_ then, hence _trap-and-emulate_. Those\ninteresting instruction can be:","snippetStart":125,"snippetEnd":302,"sourceId":101,"sourcePath":"d3nt6uix.md","targetId":100,"targetPath":"s16ct1rj.md"},
    {"title":"amyz6o6h","href":"amyz6o6h","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[amyz6o6h]]","snippetStart":182,"snippetEnd":194,"sourceId":109,"sourcePath":"8v4evysc.md","targetId":366,"targetPath":"amyz6o6h.md"},
    {"title":"msjmb62t","href":"msjmb62t","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[msjmb62t]]","snippetStart":167,"snippetEnd":179,"sourceId":109,"sourcePath":"8v4evysc.md","targetId":367,"targetPath":"msjmb62t.md"},
    {"title":"s16ct1rj","href":"s16ct1rj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[s16ct1rj]]","snippetStart":5247,"snippetEnd":5259,"sourceId":111,"sourcePath":"c7cva598.md","targetId":100,"targetPath":"s16ct1rj.md"},
    {"title":"d3nt6uix","href":"d3nt6uix","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[d3nt6uix]]","snippetStart":5232,"snippetEnd":5244,"sourceId":111,"sourcePath":"c7cva598.md","targetId":101,"targetPath":"d3nt6uix.md"},
    {"title":"zmt276jl","href":"zmt276jl","type":"wiki-link","isExternal":false,"rels":[],"snippet":"See [[zmt276jl]].","snippetStart":5194,"snippetEnd":5211,"sourceId":111,"sourcePath":"c7cva598.md","targetId":213,"targetPath":"zmt276jl.md"},
    {"title":"taztx2mo","href":"taztx2mo","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[taztx2mo]]","snippetStart":1294,"snippetEnd":1306,"sourceId":119,"sourcePath":"jcoxpgnk.md","targetId":203,"targetPath":"taztx2mo.md"},
    {"title":"1yhmh234","href":"1yhmh234","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Controlled-channel attacks [[1yhmh234]]","snippetStart":144,"snippetEnd":183,"sourceId":120,"sourcePath":"l3lzsza3.md","targetId":106,"targetPath":"1yhmh234.md"},
    {"title":"013pr50f","href":"013pr50f","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Purity (e.g., always returns same value for the same input, have no side effect) (possibly related to [[013pr50f]])","snippetStart":1719,"snippetEnd":1834,"sourceId":124,"sourcePath":"2hnk4l00.md","targetId":126,"targetPath":"013pr50f.md"},
    {"title":"zzq5zy5v","href":"zzq5zy5v","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[zzq5zy5v]]","snippetStart":3343,"snippetEnd":3355,"sourceId":124,"sourcePath":"2hnk4l00.md","targetId":216,"targetPath":"zzq5zy5v.md"},
    {"title":"1k9i1cr3","href":"1k9i1cr3","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[1k9i1cr3]]","snippetStart":1925,"snippetEnd":1937,"sourceId":129,"sourcePath":"fcf5pozg.md","targetId":146,"targetPath":"1k9i1cr3.md"},
    {"title":"xpolyx1l","href":"xpolyx1l","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[xpolyx1l]]","snippetStart":1910,"snippetEnd":1922,"sourceId":129,"sourcePath":"fcf5pozg.md","targetId":148,"targetPath":"xpolyx1l.md"},
    {"title":"7gbms9if","href":"7gbms9if","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[7gbms9if]]","snippetStart":1895,"snippetEnd":1907,"sourceId":129,"sourcePath":"fcf5pozg.md","targetId":156,"targetPath":"7gbms9if.md"},
    {"title":"gel6dwih","href":"gel6dwih","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[gel6dwih]]","snippetStart":1940,"snippetEnd":1952,"sourceId":129,"sourcePath":"fcf5pozg.md","targetId":225,"targetPath":"gel6dwih.md"},
    {"title":"dx7vz8d5","href":"dx7vz8d5","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Most of these defenses uses Intel TSX [[dx7vz8d5]], due to its ability to\nsupress page faults. For more details, see [[fvom56lw]].","snippetStart":796,"snippetEnd":926,"sourceId":132,"sourcePath":"5kzr3hwx.md","targetId":135,"targetPath":"dx7vz8d5.md"},
    {"title":"fvom56lw","href":"fvom56lw","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Most of these defenses uses Intel TSX [[dx7vz8d5]], due to its ability to\nsupress page faults. For more details, see [[fvom56lw]].","snippetStart":796,"snippetEnd":926,"sourceId":132,"sourcePath":"5kzr3hwx.md","targetId":136,"targetPath":"fvom56lw.md"},
    {"title":"n9bxzpge","href":"n9bxzpge","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The first line of defense is obfuscated execution ([[n9bxzpge]]), which\nguarantees that code and data accesses of a program looks the same, given a\nsensitive input. They usually have high overheads and are considered\nimpractical.","snippetStart":310,"snippetEnd":539,"sourceId":132,"sourcePath":"5kzr3hwx.md","targetId":138,"targetPath":"n9bxzpge.md"},
    {"title":"7t4jlnaq","href":"7t4jlnaq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"An OS requires isolation between different processes [[7t4jlnaq]]. Traditional\nOSes achieve this through the page table that virtualize each process's memory\nview [[eqbigndi]].","snippetStart":511,"snippetEnd":687,"sourceId":133,"sourcePath":"8igqoq32.md","targetId":71,"targetPath":"7t4jlnaq.md"},
    {"title":"e7p8xpz4","href":"e7p8xpz4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"See [[e7p8xpz4]].","snippetStart":385,"snippetEnd":402,"sourceId":133,"sourcePath":"8igqoq32.md","targetId":75,"targetPath":"e7p8xpz4.md"},
    {"title":"eqbigndi","href":"eqbigndi","type":"wiki-link","isExternal":false,"rels":[],"snippet":"An OS requires isolation between different processes [[7t4jlnaq]]. Traditional\nOSes achieve this through the page table that virtualize each process's memory\nview [[eqbigndi]].","snippetStart":511,"snippetEnd":687,"sourceId":133,"sourcePath":"8igqoq32.md","targetId":173,"targetPath":"eqbigndi.md"},
    {"title":"dx7vz8d5","href":"dx7vz8d5","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Transactional memory can be supported by the ISA, e.g., Intel TSX [[dx7vz8d5]],\nthat improve performance and make it easier to develop.","snippetStart":887,"snippetEnd":1022,"sourceId":134,"sourcePath":"cosmdjej.md","targetId":135,"targetPath":"dx7vz8d5.md"},
    {"title":"cosmdjej","href":"cosmdjej","type":"wiki-link","isExternal":false,"rels":[],"snippet":"TSX simplifies concurrent programming with ISA support for transactional memory\n([[cosmdjej]]). It introduce two modes of execution, hardware lock elision\n(HLE), which","snippetStart":69,"snippetEnd":236,"sourceId":135,"sourcePath":"dx7vz8d5.md","targetId":134,"targetPath":"cosmdjej.md"},
    {"title":"fvom56lw","href":"fvom56lw","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Since page faults are suppressed by TSX, the OS cannot know whether page faults\noccurs or not. This property has been used by defenses against control-channel\nattacks that use the page table on SGX [@shih2017tsgx]. The enclave can stop\nexecution, when ever it encounters a page fault. See [[fvom56lw]].","snippetStart":1722,"snippetEnd":2024,"sourceId":135,"sourcePath":"dx7vz8d5.md","targetId":136,"targetPath":"fvom56lw.md"},
    {"title":"5kzr3hwx","href":"5kzr3hwx","type":"wiki-link","isExternal":false,"rels":[],"snippet":"For more context, see [[5kzr3hwx]].","snippetStart":64,"snippetEnd":99,"sourceId":136,"sourcePath":"fvom56lw.md","targetId":132,"targetPath":"5kzr3hwx.md"},
    {"title":"5kzr3hwx","href":"5kzr3hwx","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This type of protection commonly has very high overheads, due to the threat\nmodel being too strict (attackers with perfect observation of program counter\nand memory accesses). However, in practice, the observable side channels are\nusually more coarse-grained, at cache-line or page-fault-level. For instance, in\nSGX, attacker side-channels usually need page-fault-level trace before\nperforming more fine-grained cache side-channel attacks. Hence, been works that\nonly target page-fault-level leakage ([[5kzr3hwx]]), for more practical\nprotection.","snippetStart":185,"snippetEnd":731,"sourceId":138,"sourcePath":"n9bxzpge.md","targetId":132,"targetPath":"5kzr3hwx.md"},
    {"title":"d3nt6uix","href":"d3nt6uix","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Virtualization hardware enables two-stage translation process from gVA to gPA, and from gPA to hPA through the nested page table (NPT) ([[d3nt6uix]]). This is the same in SEV. Although there is no official documentation, many paper indicate that hypervisor cannot intercept guest page faults (gPF) and look for faulting address.","snippetStart":120,"snippetEnd":448,"sourceId":142,"sourcePath":"qq4qcbos.md","targetId":101,"targetPath":"d3nt6uix.md"},
    {"title":"1k9i1cr3","href":"1k9i1cr3","type":"wiki-link","isExternal":false,"rels":[],"snippet":"See [[1k9i1cr3]] for more about Unikraft's interrupt handling.","snippetStart":2761,"snippetEnd":2823,"sourceId":148,"sourcePath":"xpolyx1l.md","targetId":146,"targetPath":"1k9i1cr3.md"},
    {"title":"cn9u3d79","href":"cn9u3d79","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The function initializes the kernel's page table. On Linux, there is also the\nsame function, but the process is a bit different ([[cn9u3d79]]).","snippetStart":1492,"snippetEnd":1635,"sourceId":148,"sourcePath":"xpolyx1l.md","targetId":159,"targetPath":"cn9u3d79.md"},
    {"title":"cn9u3d79","href":"cn9u3d79","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[cn9u3d79]]","snippetStart":3582,"snippetEnd":3594,"sourceId":148,"sourcePath":"xpolyx1l.md","targetId":159,"targetPath":"cn9u3d79.md"},
    {"title":"b63h10sx","href":"b63h10sx","type":"wiki-link","isExternal":false,"rels":[],"snippet":"However, there are tricks to achieve this, by defining each type as a separated\nstruct [[b63h10sx]].","snippetStart":353,"snippetEnd":453,"sourceId":164,"sourcePath":"mt8zp6w4.md","targetId":277,"targetPath":"b63h10sx.md"},
    {"title":"lfyjdfv4","href":"lfyjdfv4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[lfyjdfv4]]","snippetStart":46,"snippetEnd":58,"sourceId":165,"sourcePath":"mwf41frv.md","targetId":161,"targetPath":"lfyjdfv4.md"},
    {"title":"7t4jlnaq","href":"7t4jlnaq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"As with other OS abstractions [[7t4jlnaq]], virtual memory goal is to eases the\nprogramming efforts [@yan2019translation].","snippetStart":190,"snippetEnd":312,"sourceId":173,"sourcePath":"eqbigndi.md","targetId":71,"targetPath":"7t4jlnaq.md"},
    {"title":"nhovug1d","href":"nhovug1d","type":"wiki-link","isExternal":false,"rels":[],"snippet":"However, there are also performance trade-offs due to address translation\n[[nhovug1d]].","snippetStart":713,"snippetEnd":800,"sourceId":173,"sourcePath":"eqbigndi.md","targetId":383,"targetPath":"nhovug1d.md"},
    {"title":"l56og3zt","href":"l56og3zt","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Some research work for the C language requires the programmer's annotations\n[@gudka2015clean]. Essentially, adding program annotation is no different from\ncreating new C syntaxes on the flight. With C rich macro system, some common\nprogramming patterns may be defined in C, e.g., [[l56og3zt]].","snippetStart":87,"snippetEnd":380,"sourceId":184,"sourcePath":"2w43507r.md","targetId":163,"targetPath":"l56og3zt.md"},
    {"title":"xxn0pki0","href":"xxn0pki0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[xxn0pki0]]","snippetStart":19,"snippetEnd":31,"sourceId":186,"sourcePath":"awlfkl73.md","targetId":185,"targetPath":"xxn0pki0.md"},
    {"title":"nobagcn6","href":"nobagcn6","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[nobagcn6]]","snippetStart":79,"snippetEnd":91,"sourceId":199,"sourcePath":"s5ss13en.md","targetId":139,"targetPath":"nobagcn6.md"},
    {"title":"llhmwuim","href":"llhmwuim","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[llhmwuim]]","snippetStart":64,"snippetEnd":76,"sourceId":199,"sourcePath":"s5ss13en.md","targetId":195,"targetPath":"llhmwuim.md"},
    {"title":"1yhmh234","href":"1yhmh234","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[1yhmh234]]","snippetStart":3976,"snippetEnd":3988,"sourceId":203,"sourcePath":"taztx2mo.md","targetId":106,"targetPath":"1yhmh234.md"},
    {"title":"fvom56lw","href":"fvom56lw","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[fvom56lw]]","snippetStart":3961,"snippetEnd":3973,"sourceId":203,"sourcePath":"taztx2mo.md","targetId":136,"targetPath":"fvom56lw.md"},
    {"title":"yef2w9yc","href":"yef2w9yc","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Interface vulnerabilities is a manifestation of confused deputy problem, where\ndifferent mutually distrusting entities interacts with each other through\nexposed interfaces [@lefeuvre2023assessing]. More: [[yef2w9yc]].","snippetStart":1618,"snippetEnd":1835,"sourceId":211,"sourcePath":"y9wu5ut7.md","targetId":368,"targetPath":"yef2w9yc.md"},
    {"title":"khi9ihj9","href":"khi9ihj9","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The confused deputy problem requires rethinking about access control, and leads\nto development of capabilities-based access control models, where access through\nresources are given to each user through _capabilities_ [[khi9ihj9]].","snippetStart":307,"snippetEnd":537,"sourceId":211,"sourcePath":"y9wu5ut7.md","targetId":403,"targetPath":"khi9ihj9.md"},
    {"title":"7isqcppd","href":"7isqcppd","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[7isqcppd]]","snippetStart":311,"snippetEnd":323,"sourceId":214,"sourcePath":"zy68i5ym.md","targetId":147,"targetPath":"7isqcppd.md"},
    {"title":"cemsxh4n","href":"cemsxh4n","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This idea helps to discover the context of a Zettelkasten note. More\n            importantly, helps writing notes easier [[cemsxh4n]]","snippetStart":1719,"snippetEnd":1852,"sourceId":215,"sourcePath":"zz3cedu0.md","targetId":23,"targetPath":"cemsxh4n.md"},
    {"title":"dyx2t4oz","href":"dyx2t4oz","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[This](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/)\n       introduces another technique called the _knowledge flower_ [[dyx2t4oz]]\n       that is more open for interpretation.","snippetStart":1939,"snippetEnd":2150,"sourceId":215,"sourcePath":"zz3cedu0.md","targetId":24,"targetPath":"dyx2t4oz.md"},
    {"title":"k57qb7oh","href":"k57qb7oh","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[k57qb7oh]]","snippetStart":40,"snippetEnd":52,"sourceId":218,"sourcePath":"0igotm4i.md","targetId":130,"targetPath":"k57qb7oh.md"},
    {"title":"i2blyo37#Overhead analysis","href":"i2blyo37#Overhead analysis","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The paper argues that the cost of IPC in microkernels are too high, and proposed\nusing MPK-based domains to reduce the number of context switches during IPCs.\nThe paper provides a motivation study by profiling the overheads of IPC in\ncommon microkernels (see [[i2blyo37#Overhead analysis]]).","snippetStart":187,"snippetEnd":478,"sourceId":219,"sourcePath":"2a7l7odo.md","targetId":47,"targetPath":"i2blyo37.md"},
    {"title":"1yhmh234","href":"1yhmh234","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The paper's main argument against the previous work is that a _practical_\nsolution for the control channels for SGX must be backward compatible with\nexisting x86 software, and also the OS. Hence, solutions that employ two\nseparate page tables, such as [@aga2019invisipage], and [@costan2016sanctum] are\nnot practical as they require changes to even the host OS. On the other hand,\nother software-only defenses (at the time of the paper, there are @shih2017tsgx,\nand [@oleksenko2018varys]) restrict the usability as forbid demand paging, have\nhuge overheads, and are also susceptible to non-page-fault attacks that use the\ndirty bits [[1yhmh234]].","snippetStart":141,"snippetEnd":787,"sourceId":220,"sourcePath":"36d79g1n.md","targetId":106,"targetPath":"1yhmh234.md"},
    {"title":"taztx2mo","href":"taztx2mo","type":"wiki-link","isExternal":false,"rels":[],"snippet":"While introducing hardware changes, the work aims to do it in the least\nintrusive manner. It tries to _change only the same path that SGX's mechanisms\nchange in x86 architectures_. This includes (1) SGX-specific checks that are\nperformed after PTE checks during enclave mode, and (2) AEX page fault procedure\n([[taztx2mo]]).","snippetStart":824,"snippetEnd":1148,"sourceId":220,"sourcePath":"36d79g1n.md","targetId":203,"targetPath":"taztx2mo.md"},
    {"title":"dgdvhu1e","href":"dgdvhu1e","type":"wiki-link","isExternal":false,"rels":[],"snippet":"See [[dgdvhu1e]]","snippetStart":341,"snippetEnd":357,"sourceId":221,"sourcePath":"4zdjxws6.md","targetId":74,"targetPath":"dgdvhu1e.md"},
    {"title":"2j6s9zpm","href":"2j6s9zpm","type":"wiki-link","isExternal":false,"rels":[],"snippet":"State spill harms availability and evolvability of system software (see\n[[2j6s9zpm]]).","snippetStart":138,"snippetEnd":224,"sourceId":226,"sourcePath":"jfm8ud28.md","targetId":68,"targetPath":"2j6s9zpm.md"},
    {"title":"qq4qcbos","href":"qq4qcbos","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Pattern matching stage uses the nested page fault side-channel [[qq4qcbos]] to\ndetermine which pages are being accessed when the VM serves the SSH packet. The\nhypervisor first sends an SSH packet to the VM, then clears the present bits in\nthe NPT PTEs. It collects the sequences of page fault accesses to build a\n_signature_ of the page accessed from the time of receiving the request, to the\ntime right before sending the packet. It then uses this signature to determine\nthe page containing the `sk_buff` structure that contains the packet.","snippetStart":1321,"snippetEnd":1862,"sourceId":231,"sourcePath":"ncfh611p.md","targetId":142,"targetPath":"qq4qcbos.md"},
    {"title":"zmt276jl","href":"zmt276jl","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The target of the attack is an SSH service running inside a cVM. While the ssh\npackets are encrypted, due to unprotected I/O [[zmt276jl]], the hypervisor can\nobserve and modify the TCP and IP headers.","snippetStart":613,"snippetEnd":813,"sourceId":231,"sourcePath":"ncfh611p.md","targetId":213,"targetPath":"zmt276jl.md"},
    {"title":"wex0mob4","href":"wex0mob4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"PosMap: The $PosMap$ itself is stored in another ORAM ($ORAM_{PosMap}$), where each block contains the translation for $X$ contiguous addresses. $ORAM_{PosMap}$ now only requires its $PosMap$ to map $N/X$ addresses. This can repeat multiple times (i.e., recursion happens). See [[wex0mob4]].","snippetStart":717,"snippetEnd":1008,"sourceId":237,"sourcePath":"xogiuia9.md","targetId":236,"targetPath":"wex0mob4.md"},
    {"title":"c4icaua4","href":"c4icaua4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Hierarchical layering limits flexibility: See [[c4icaua4]].","snippetStart":132,"snippetEnd":191,"sourceId":238,"sourcePath":"zecj938z.md","targetId":92,"targetPath":"c4icaua4.md"},
    {"title":"h3manv25","href":"h3manv25","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Containers and Virtual machines both have disadvantages for implementing\nisolation and sharing. See [[h3manv25]].","snippetStart":350,"snippetEnd":463,"sourceId":239,"sourcePath":"zw0lj520.md","targetId":53,"targetPath":"h3manv25.md"},
    {"title":"dpg049d1","href":"dpg049d1","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[dpg049d1]]","snippetStart":36,"snippetEnd":48,"sourceId":243,"sourcePath":"u1qgpjhe.md","targetId":244,"targetPath":"dpg049d1.md"},
    {"title":"baoqhski","href":"baoqhski","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[baoqhski]]","snippetStart":51,"snippetEnd":63,"sourceId":243,"sourcePath":"u1qgpjhe.md","targetId":264,"targetPath":"baoqhski.md"},
    {"title":"rlcg39bj","href":"rlcg39bj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[rlcg39bj]]","snippetStart":76,"snippetEnd":88,"sourceId":243,"sourcePath":"u1qgpjhe.md","targetId":274,"targetPath":"rlcg39bj.md"},
    {"title":"8bxl41ng","href":"8bxl41ng","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Ideally, TEE should be provided access to hardware-enforced time [[8bxl41ng]].\nHowever, SGX lacks this feature (or it is removed). Still, timing is useful in\nsome tasks, like detecting whether enclave exits happened.","snippetStart":63,"snippetEnd":279,"sourceId":253,"sourcePath":"iwfcxxfi.md","targetId":250,"targetPath":"8bxl41ng.md"},
    {"title":"1mhpx5ds","href":"1mhpx5ds","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Kprobe [[1mhpx5ds]] offer similar functionalities.","snippetStart":2706,"snippetEnd":2756,"sourceId":264,"sourcePath":"baoqhski.md","targetId":265,"targetPath":"1mhpx5ds.md"},
    {"title":"kskzr2l4","href":"kskzr2l4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"`int3` must be placed at instruction boundary, otherwise it will causes an\nundefined behavior. For instance, when breakpoint `0xCC` is injected into a\n5-byte jmp leads to different instruction sequences, where only int3 is\naccurately decoded when placed at instruction boundary. [[kskzr2l4]].","snippetStart":6881,"snippetEnd":7173,"sourceId":265,"sourcePath":"1mhpx5ds.md","targetId":271,"targetPath":"kskzr2l4.md"},
    {"title":"e7p8xpz4","href":"e7p8xpz4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Unikernels are build systems for specialized kernels, so it is expected for\nsource code to be available. However, there has been researches and projects\nthat combine the benefits of unikernels (small footprint, fast system calls,\nattack surface reduction [[e7p8xpz4]]) with binary compatibility. Examples\ninclude Unikraft, OSv, HermiTux [@olivier2019binarycompatible], Rump, Lupine\nLinux.","snippetStart":58,"snippetEnd":446,"sourceId":268,"sourcePath":"wwxm9czw.md","targetId":75,"targetPath":"e7p8xpz4.md"},
    {"title":"n43kyyfh","href":"n43kyyfh","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Binary rewriting is hard [[n43kyyfh]]","snippetStart":225,"snippetEnd":262,"sourceId":271,"sourcePath":"kskzr2l4.md","targetId":302,"targetPath":"n43kyyfh.md"},
    {"title":"fps6sygk","href":"fps6sygk","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Disassembly is hard [[fps6sygk]]","snippetStart":265,"snippetEnd":297,"sourceId":271,"sourcePath":"kskzr2l4.md","targetId":303,"targetPath":"fps6sygk.md"},
    {"title":"kskzr2l4","href":"kskzr2l4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Linear scan may be confused by _gaps_ in the program, e.g., paddings for\nalignment, [@zhang2013control], which it may incorrectly treat as instructions\n(e.g., unintended instruction problem [[kskzr2l4]]).","snippetStart":403,"snippetEnd":607,"sourceId":283,"sourcePath":"hxoovt97.md","targetId":271,"targetPath":"kskzr2l4.md"},
    {"title":"kskzr2l4","href":"kskzr2l4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Caveats includes how to accurately determine indirect jump targets, and\nnon-explicit control flow transfers like interrupts [[kskzr2l4]].","snippetStart":879,"snippetEnd":1016,"sourceId":283,"sourcePath":"hxoovt97.md","targetId":271,"targetPath":"kskzr2l4.md"},
    {"title":"c4icaua4","href":"c4icaua4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Similar to operating systems, where hierarchical layering limits flexibility\n[[c4icaua4]], these notes lack flexibility. That is, new ideas are harder to\nemerge.","snippetStart":414,"snippetEnd":575,"sourceId":295,"sourcePath":"nx37h6lu.md","targetId":92,"targetPath":"c4icaua4.md"},
    {"title":"kfs6h55d","href":"kfs6h55d","type":"wiki-link","isExternal":false,"rels":[],"snippet":"and [[kfs6h55d]]","snippetStart":220,"snippetEnd":236,"sourceId":296,"sourcePath":"24t7ope8.md","targetId":297,"targetPath":"kfs6h55d.md"},
    {"title":"itd1o3ic","href":"itd1o3ic","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Because [[itd1o3ic]]","snippetStart":197,"snippetEnd":217,"sourceId":296,"sourcePath":"24t7ope8.md","targetId":298,"targetPath":"itd1o3ic.md"},
    {"title":"kfs6h55d","href":"kfs6h55d","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Second, it probably follows some principles/patterns that has been applied\nbefore [[kfs6h55d]].","snippetStart":596,"snippetEnd":691,"sourceId":298,"sourcePath":"itd1o3ic.md","targetId":297,"targetPath":"kfs6h55d.md"},
    {"title":"itd1o3ic","href":"itd1o3ic","type":"wiki-link","isExternal":false,"rels":[],"snippet":"However, as the comparison target is only its immediate predecessor in the scope\nof Rust, the paper has clear advantages over these works and is considered (at\nleast by the reviewers [[itd1o3ic]]).","snippetStart":726,"snippetEnd":923,"sourceId":299,"sourcePath":"qypdxa5v.md","targetId":298,"targetPath":"itd1o3ic.md"},
    {"title":"4yeegysq","href":"4yeegysq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Now, if the replaced instruction happens to be frequent target of control flow,\nthe amount of traps will destroy any performance gain from punning, so this\napproach need some kind of control flow recovery [@duck2020binary] that has its\nown limitations [[4yeegysq]]","snippetStart":1575,"snippetEnd":1839,"sourceId":301,"sourcePath":"jejw1spb.md","targetId":305,"targetPath":"4yeegysq.md"},
    {"title":"1mhpx5ds","href":"1mhpx5ds","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Rewriting that _poke_ / probe the binary code with other code does not change\nthe address layout, so is safe with PC-relative code. For example, Kprobes\n[[1mhpx5ds]] insert `int3` and `jmp` insertion to probe parts of the kernel.","snippetStart":1094,"snippetEnd":1323,"sourceId":302,"sourcePath":"n43kyyfh.md","targetId":265,"targetPath":"1mhpx5ds.md"},
    {"title":"jejw1spb","href":"jejw1spb","type":"wiki-link","isExternal":false,"rels":[],"snippet":"**Overheads**: `int3` probes are slow, so `jmp` are much more desired.\n   However, `jmp` are 5-bytes, which may overwrite more instructions if the\n   probe target is smaller than 5. Instruction punning [[jejw1spb]] is a\n   technique to maximize the `jmp` probes.","snippetStart":1721,"snippetEnd":1983,"sourceId":302,"sourcePath":"n43kyyfh.md","targetId":301,"targetPath":"jejw1spb.md"},
    {"title":"fps6sygk","href":"fps6sygk","type":"wiki-link","isExternal":false,"rels":[],"snippet":"You may modify the binary layout for more flexible rewriting policies. However,\nnow you must also perform control-flow recovery, to cope with the changes in the\naddress space. This is a difficult problem in binary analysis [[fps6sygk]].","snippetStart":758,"snippetEnd":994,"sourceId":302,"sourcePath":"n43kyyfh.md","targetId":303,"targetPath":"fps6sygk.md"},
    {"title":"4yeegysq","href":"4yeegysq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Many techniques avoid this by leveraging probes-based binary rewriting\n[[4yeegysq]].","snippetStart":996,"snippetEnd":1080,"sourceId":302,"sourcePath":"n43kyyfh.md","targetId":305,"targetPath":"4yeegysq.md"},
    {"title":"hxoovt97","href":"hxoovt97","type":"wiki-link","isExternal":false,"rels":[],"snippet":"More on disassembly techniques [[hxoovt97]].","snippetStart":23,"snippetEnd":67,"sourceId":303,"sourcePath":"fps6sygk.md","targetId":283,"targetPath":"hxoovt97.md"},
    {"title":"4yeegysq","href":"4yeegysq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"It needs to reliably recover control flow for any useful rewriting/reassembly.\nNote that some form of rewriting does not need this [[4yeegysq]].","snippetStart":89,"snippetEnd":233,"sourceId":303,"sourcePath":"fps6sygk.md","targetId":305,"targetPath":"4yeegysq.md"},
    {"title":"njh7pnzn","href":"njh7pnzn","type":"wiki-link","isExternal":false,"rels":[],"snippet":"It is hard because of the unintended instruction problem [[njh7pnzn]].","snippetStart":235,"snippetEnd":305,"sourceId":303,"sourcePath":"fps6sygk.md","targetId":308,"targetPath":"njh7pnzn.md"},
    {"title":"jejw1spb","href":"jejw1spb","type":"wiki-link","isExternal":false,"rels":[],"snippet":"A class of binary rewriting techniques focus on not using control-flow (sub\nfunction) recovery techniques for more robustness\n[@chamith2017instruction,@duck2020binary]. To this end, probe-based techniques,\nespecially instruction punning [[jejw1spb]] does not requires fine-grained\ncontrol-flow recovery since they do not modify the binary layout.","snippetStart":358,"snippetEnd":704,"sourceId":305,"sourcePath":"4yeegysq.md","targetId":301,"targetPath":"jejw1spb.md"},
    {"title":"n43kyyfh","href":"n43kyyfh","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Many rewriting approaches requires control-flow recovery to that they can\nrelocate RIP-relative code [[n43kyyfh]] to different locations. However, these\napproaches are not robust and require heuristics and assumptions. However,\ncontrol-flow recovery is generally undecidable [[fps6sygk]].","snippetStart":68,"snippetEnd":356,"sourceId":305,"sourcePath":"4yeegysq.md","targetId":302,"targetPath":"n43kyyfh.md"},
    {"title":"fps6sygk","href":"fps6sygk","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Many rewriting approaches requires control-flow recovery to that they can\nrelocate RIP-relative code [[n43kyyfh]] to different locations. However, these\napproaches are not robust and require heuristics and assumptions. However,\ncontrol-flow recovery is generally undecidable [[fps6sygk]].","snippetStart":68,"snippetEnd":356,"sourceId":305,"sourcePath":"4yeegysq.md","targetId":303,"targetPath":"fps6sygk.md"},
    {"title":"fps6sygk","href":"fps6sygk","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Disassembly is an error-prone process due to the challenges in disassembly\n[[fps6sygk]]. Disassembly tools often make the assumptions about the\ndisassembled binary to make the process easier. These assumptions include:","snippetStart":33,"snippetEnd":251,"sourceId":306,"sourcePath":"u6datkss.md","targetId":303,"targetPath":"fps6sygk.md"},
    {"title":"4yeegysq","href":"4yeegysq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"One approach is to not rey on recovered control flow at all [[4yeegysq]].","snippetStart":726,"snippetEnd":799,"sourceId":306,"sourcePath":"u6datkss.md","targetId":305,"targetPath":"4yeegysq.md"},
    {"title":"zmxk4kdo","href":"zmxk4kdo","type":"wiki-link","isExternal":false,"rels":[],"snippet":"A1: Simple solution includees treating every possbile offsets as potential\n  instruction bounrary [[zmxk4kdo]].","snippetStart":604,"snippetEnd":715,"sourceId":306,"sourcePath":"u6datkss.md","targetId":307,"targetPath":"zmxk4kdo.md"},
    {"title":"njh7pnzn","href":"njh7pnzn","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Most disassembly tool that use linear scan from the entries cannot handle data\nin between code, due to the problem of unintended instruction [[njh7pnzn]].","snippetStart":59,"snippetEnd":213,"sourceId":307,"sourcePath":"zmxk4kdo.md","targetId":308,"targetPath":"njh7pnzn.md"},
    {"title":"26npf1xb","href":"26npf1xb","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Given these premise, a recent trend is to introduce extensible interfaces to the\nOS dynamic loader/linker [@castes2023dynamic,@ren2022dynamic]. iFed\n[@castes2023dynamic] adds a pass-based framework based on glibc loader\n([[26npf1xb]]) to implement transformations on the library. Spindl\n[@castes2023dynamic] reimagine the OS dynamic linker with facilities to\nimplement extensions.","snippetStart":1126,"snippetEnd":1506,"sourceId":311,"sourcePath":"xnhumnfb.md","targetId":290,"targetPath":"26npf1xb.md"},
    {"title":"kfs6h55d","href":"kfs6h55d","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[kfs6h55d]]","snippetStart":112,"snippetEnd":124,"sourceId":319,"sourcePath":"2f8urcvf.md","targetId":297,"targetPath":"kfs6h55d.md"},
    {"title":"dlvrfm5i","href":"dlvrfm5i","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[dlvrfm5i]]","snippetStart":126,"snippetEnd":138,"sourceId":319,"sourcePath":"2f8urcvf.md","targetId":320,"targetPath":"dlvrfm5i.md"},
    {"title":"j111e16c","href":"j111e16c","type":"wiki-link","isExternal":false,"rels":[],"snippet":"If all does not work, we may exclude certain function as a last resort. You may\nget function size by the `nm` command [[j111e16c]].","snippetStart":49,"snippetEnd":180,"sourceId":329,"sourcePath":"azyquhm6.md","targetId":330,"targetPath":"j111e16c.md"},
    {"title":"fswawlk9","href":"fswawlk9","type":"wiki-link","isExternal":false,"rels":[],"snippet":"If you just want to link with custom libraries, you can use `LD_LIBRARY_PATH`\n[[fswawlk9]]","snippetStart":407,"snippetEnd":497,"sourceId":331,"sourcePath":"q8xx4lfz.md","targetId":332,"targetPath":"fswawlk9.md"},
    {"title":"q8xx4lfz","href":"q8xx4lfz","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This will not work for binaries that need root access. For these you may use\nchroot [[q8xx4lfz]].","snippetStart":821,"snippetEnd":918,"sourceId":332,"sourcePath":"fswawlk9.md","targetId":331,"targetPath":"q8xx4lfz.md"},
    {"title":"ya2sfv7q","href":"ya2sfv7q","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The manifestation of this imbalance is the integrity attacks on SEV [[ya2sfv7q]]\nthat can compromise confidentiality.","snippetStart":618,"snippetEnd":735,"sourceId":358,"sourcePath":"gl6uzrqm.md","targetId":393,"targetPath":"ya2sfv7q.md"},
    {"title":"7r5okim8","href":"7r5okim8","type":"wiki-link","isExternal":false,"rels":[],"snippet":"For the selection of compartmentalization subjects (a part of defining\ncompartmentalization policy [[7r5okim8]]), the strategies can be broadly\nclassified into three types, _data-centric_ and _code-centric_ and _hybrid_\n[@lefeuvre2024sok].","snippetStart":77,"snippetEnd":316,"sourceId":359,"sourcePath":"x9zetwej.md","targetId":412,"targetPath":"7r5okim8.md"},
    {"title":"8qvweuj8","href":"8qvweuj8","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[8qvweuj8]]","snippetStart":1519,"snippetEnd":1531,"sourceId":362,"sourcePath":"3eot91og.md","targetId":364,"targetPath":"8qvweuj8.md"},
    {"title":"yef2w9yc","href":"yef2w9yc","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Even with IOMMU isolation, devices can still attack the kernel through malicious\npackets (more of an interface attack [[yef2w9yc]]). This is more concerning for\nbluetooth and USB devices that are easily pluggable. Another approach for\nsecurity to install packet filters to check for malformed packets\n[@tian2019lbm].","snippetStart":1575,"snippetEnd":1891,"sourceId":362,"sourcePath":"3eot91og.md","targetId":368,"targetPath":"yef2w9yc.md"},
    {"title":"hxm4jt6e","href":"hxm4jt6e","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The IOMMU and related hardware allows the hypervisor to isolate device's DMA\naccesses [[hxm4jt6e]].","snippetStart":1305,"snippetEnd":1404,"sourceId":362,"sourcePath":"3eot91og.md","targetId":394,"targetPath":"hxm4jt6e.md"},
    {"title":"hxm4jt6e","href":"hxm4jt6e","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[hxm4jt6e]]","snippetStart":1534,"snippetEnd":1546,"sourceId":362,"sourcePath":"3eot91og.md","targetId":394,"targetPath":"hxm4jt6e.md"},
    {"title":"jj89s7vj","href":"jj89s7vj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Since the host cannot directly access the private memory of the CVM, bounce\nbuffers located in shared memory [[jj89s7vj]] must be maintained by the _guest_.\nTo send any packets to the hardware, the guest must copy the data from its\nprivate memory into the bounce buffer, and the host must maps the bounce buffer\ninto the device (NIC) for it to perform DMA. The reversed direction is the\nsimilar. This contributes 19.45% of CPU cycles [@li2023bifrost]","snippetStart":347,"snippetEnd":797,"sourceId":363,"sourcePath":"68nms906.md","targetId":365,"targetPath":"jj89s7vj.md"},
    {"title":"eczmc02q","href":"eczmc02q","type":"wiki-link","isExternal":false,"rels":[],"snippet":"VMExits is known to be more expensive on CVMs compared to normal VMs\n[[eczmc02q]], since it have to encrypt VM states and perform security checks.\nAsynchronous interrupt posting mechansisms supported by hardware kind of make\nthis less of an issue [@li2023bifrost].","snippetStart":1113,"snippetEnd":1377,"sourceId":363,"sourcePath":"68nms906.md","targetId":374,"targetPath":"eczmc02q.md"},
    {"title":"471vf8vr","href":"471vf8vr","type":"wiki-link","isExternal":false,"rels":[],"snippet":"More: [[471vf8vr]].","snippetStart":1637,"snippetEnd":1656,"sourceId":363,"sourcePath":"68nms906.md","targetId":375,"targetPath":"471vf8vr.md"},
    {"title":"hxm4jt6e","href":"hxm4jt6e","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Access control prevent subjects that use the shared CPU to access shared memory.\nHardware DMA accesses also have a kind of access control through the IOMMU\n[[hxm4jt6e]] [@feng2024siopmp] [@sang2024portal].","snippetStart":215,"snippetEnd":420,"sourceId":364,"sourcePath":"8qvweuj8.md","targetId":394,"targetPath":"hxm4jt6e.md"},
    {"title":"3eot91og","href":"3eot91og","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Certain devices are commonly considered untrusted, e.g., USB. in the case of\nvirtualization, devices may also be configured to perform illegal actions by the\nVM [[3eot91og]].","snippetStart":657,"snippetEnd":831,"sourceId":365,"sourcePath":"jj89s7vj.md","targetId":362,"targetPath":"3eot91og.md"},
    {"title":"3eot91og","href":"3eot91og","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Bounce buffering create redundant memory copies that reduce I/O performance.\nThis contributes to overheads in confidetial I/O [[68nms906]] and also\nvirtualized I/O [[3eot91og]].","snippetStart":1371,"snippetEnd":1548,"sourceId":365,"sourcePath":"jj89s7vj.md","targetId":362,"targetPath":"3eot91og.md"},
    {"title":"68nms906","href":"68nms906","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Bounce buffering create redundant memory copies that reduce I/O performance.\nThis contributes to overheads in confidetial I/O [[68nms906]] and also\nvirtualized I/O [[3eot91og]].","snippetStart":1371,"snippetEnd":1548,"sourceId":365,"sourcePath":"jj89s7vj.md","targetId":363,"targetPath":"68nms906.md"},
    {"title":"hxm4jt6e","href":"hxm4jt6e","type":"wiki-link","isExternal":false,"rels":[],"snippet":"While IOMMU [[hxm4jt6e]] is useful in containing untrusted memory, it is\npage-granular ([@markuze2016true]), so the shared page with the device might\ncontain other kernel memory.","snippetStart":833,"snippetEnd":1011,"sourceId":365,"sourcePath":"jj89s7vj.md","targetId":394,"targetPath":"hxm4jt6e.md"},
    {"title":"8v4evysc","href":"8v4evysc","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This may be implemented (roughly) in a ZK system by hoarding quotes torelated to\nrelavant concepts [[8v4evysc]].","snippetStart":729,"snippetEnd":841,"sourceId":366,"sourcePath":"amyz6o6h.md","targetId":109,"targetPath":"8v4evysc.md"},
    {"title":"msjmb62t","href":"msjmb62t","type":"wiki-link","isExternal":false,"rels":[],"snippet":"It's impressive to see people pulling out relavant quotations of things they\nread that are insightful [[msjmb62t]]. In order to achieve this, a system for\nquotation tracking and management should be in place.","snippetStart":52,"snippetEnd":260,"sourceId":366,"sourcePath":"amyz6o6h.md","targetId":367,"targetPath":"msjmb62t.md"},
    {"title":"lqni89fq","href":"lqni89fq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Commonplace notebook [[lqni89fq]] categorize quotes based on categories\n   (commonplaces).","snippetStart":637,"snippetEnd":727,"sourceId":366,"sourcePath":"amyz6o6h.md","targetId":373,"targetPath":"lqni89fq.md"},
    {"title":"qti6u06p","href":"qti6u06p","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Thus, considerations must be made in designing interfaces for security\n[[qti6u06p]].","snippetStart":626,"snippetEnd":710,"sourceId":368,"sourcePath":"yef2w9yc.md","targetId":95,"targetPath":"qti6u06p.md"},
    {"title":"y9wu5ut7","href":"y9wu5ut7","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Communications between isolated components leads to the problem of _interface\nsecurity_, where the interface between the components should not compromise the\nenforced isolation between them. Interface vulnerabilities is a manifestation of\nthe confused deputy problem [@lefeuvre2023assessing] [[y9wu5ut7]].","snippetStart":319,"snippetEnd":624,"sourceId":368,"sourcePath":"yef2w9yc.md","targetId":211,"targetPath":"y9wu5ut7.md"},
    {"title":"qctx04tc","href":"qctx04tc","type":"wiki-link","isExternal":false,"rels":[],"snippet":"DPDK (Data Plane Development Kit) [[qctx04tc]] and `io_uring` are both\ntechniques to improve I/O performance in Linux by reducing the amount of context\nswitches. `io_uring` implements new syscalls for asynchronous I/O in the kernel.","snippetStart":30,"snippetEnd":262,"sourceId":369,"sourcePath":"bkdcd5nv.md","targetId":370,"targetPath":"qctx04tc.md"},
    {"title":"qctx04tc","href":"qctx04tc","type":"wiki-link","isExternal":false,"rels":[],"snippet":"DPDK sacrifies safety, requiring it to trust other users of the devices, or\nexpecting some safe multiplexor [@hedayati2019hodor]. ([[qctx04tc]])","snippetStart":617,"snippetEnd":761,"sourceId":369,"sourcePath":"bkdcd5nv.md","targetId":370,"targetPath":"qctx04tc.md"},
    {"title":"amyz6o6h","href":"amyz6o6h","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Most of what you want to log in the commonplace note are quotations [[amyz6o6h]]","snippetStart":180,"snippetEnd":260,"sourceId":373,"sourcePath":"lqni89fq.md","targetId":366,"targetPath":"amyz6o6h.md"},
    {"title":"68nms906","href":"68nms906","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The cost of switching generally 5x more (10,170 vs. 1800 for SGX\n[@thalheim2021rktio], 7,476 vs. 1,643 for CVMs [@li2023bifrost]). The overheads\ncontributes a lot to the costs of confidential I/O [[68nms906]].","snippetStart":660,"snippetEnd":869,"sourceId":374,"sourcePath":"eczmc02q.md","targetId":363,"targetPath":"68nms906.md"},
    {"title":"qctx04tc","href":"qctx04tc","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Direct I/O ([[qctx04tc]]) and unikernels remove kernel crossing costs.","snippetStart":1049,"snippetEnd":1119,"sourceId":375,"sourcePath":"471vf8vr.md","targetId":370,"targetPath":"qctx04tc.md"},
    {"title":"llh2ly47","href":"llh2ly47","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Scheduling costs is removed with a run-to-completion model [[llh2ly47]], where\n  a thread perform all packet processing steps until it completes\n  [@belay2014ix].","snippetStart":1122,"snippetEnd":1284,"sourceId":375,"sourcePath":"471vf8vr.md","targetId":376,"targetPath":"llh2ly47.md"},
    {"title":"eqbigndi","href":"eqbigndi","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Virtual memory abstraction [[eqbigndi]] enable easy programming model through\nMMU support and address translation.","snippetStart":69,"snippetEnd":183,"sourceId":383,"sourcePath":"nhovug1d.md","targetId":173,"targetPath":"eqbigndi.md"},
    {"title":"qctx04tc","href":"qctx04tc","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Direct I/O [[qctx04tc]] removes the data plane from the OS, leaving it solely in\ncharge of the control plane.","snippetStart":1348,"snippetEnd":1457,"sourceId":392,"sourcePath":"l6tidpzy.md","targetId":370,"targetPath":"qctx04tc.md"},
    {"title":"471vf8vr","href":"471vf8vr","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Traditionally, the OS performs a mixes between control and data plane, by\nproviding packet processing infrastructures in the kernel, and providing\nabstractions to the userspace. However, this split model results in overheads\n[[471vf8vr]].","snippetStart":1108,"snippetEnd":1346,"sourceId":392,"sourcePath":"l6tidpzy.md","targetId":375,"targetPath":"471vf8vr.md"},
    {"title":"3eot91og","href":"3eot91og","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This is in response to threats of malicious DMA from devices [[3eot91og]].","snippetStart":161,"snippetEnd":235,"sourceId":394,"sourcePath":"hxm4jt6e.md","targetId":362,"targetPath":"3eot91og.md"},
    {"title":"jj89s7vj","href":"jj89s7vj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This mechanism is refered to as **bounce buffering** [[jj89s7vj]] by Linux\ndevelopers and some modern papers.","snippetStart":662,"snippetEnd":771,"sourceId":394,"sourcePath":"hxm4jt6e.md","targetId":365,"targetPath":"jj89s7vj.md"},
    {"title":"jj89s7vj","href":"jj89s7vj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"SWIOTLB is kind of an emulation of hardware IOMMU [1]. In certain scenarios,\nlike confidential computing [[jj89s7vj]], DMA cannot be performed directly onto\nthe target memory buffer. SWIOTLB is an allocator that allocate memory that\nconform to the restriction for DMA (e.g., unencrypted memory). The CPU copy data\nto this bounce buffer, then data from the bounce buffer is DMA-ed by the device.","snippetStart":1727,"snippetEnd":2121,"sourceId":394,"sourcePath":"hxm4jt6e.md","targetId":365,"targetPath":"jj89s7vj.md"},
    {"title":"asuoudgb","href":"asuoudgb","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[asuoudgb]]","snippetStart":785,"snippetEnd":797,"sourceId":394,"sourcePath":"hxm4jt6e.md","targetId":395,"targetPath":"asuoudgb.md"},
    {"title":"hxm4jt6e","href":"hxm4jt6e","type":"wiki-link","isExternal":false,"rels":[],"snippet":"API interaction with IOMMU [[hxm4jt6e]]:","snippetStart":298,"snippetEnd":338,"sourceId":395,"sourcePath":"asuoudgb.md","targetId":394,"targetPath":"hxm4jt6e.md"},
    {"title":"c4icaua4","href":"c4icaua4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Capability-based security [[c4icaua4]]","snippetStart":81,"snippetEnd":119,"sourceId":401,"sourcePath":"4vysjbn9.md","targetId":92,"targetPath":"c4icaua4.md"},
    {"title":"y9wu5ut7","href":"y9wu5ut7","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[y9wu5ut7]]","snippetStart":127,"snippetEnd":139,"sourceId":402,"sourcePath":"kp9kr1qi.md","targetId":211,"targetPath":"y9wu5ut7.md"},
    {"title":"j19hdkto","href":"j19hdkto","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes\n  of capabilities by [[j19hdkto]] himself.","snippetStart":570,"snippetEnd":690,"sourceId":403,"sourcePath":"khi9ihj9.md","targetId":79,"targetPath":"j19hdkto.md"},
    {"title":"c4icaua4","href":"c4icaua4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Flexibility of systems policies [[c4icaua4]] through separation of mechanism\n  and policies [[8113ygxd]]. That is, the reference monitor only needs to\n  validate the references using simple mechanisms. The policies themselves are\n  embedded in the capabilities.","snippetStart":115,"snippetEnd":376,"sourceId":403,"sourcePath":"khi9ihj9.md","targetId":92,"targetPath":"c4icaua4.md"},
    {"title":"y9wu5ut7","href":"y9wu5ut7","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Avoid the problem of confused deputy [[y9wu5ut7]]. In a capability system, all\n  subjects must be explicitly given the access rights, so that there is no\n  _ambient authorities_.","snippetStart":379,"snippetEnd":557,"sourceId":403,"sourcePath":"khi9ihj9.md","targetId":211,"targetPath":"y9wu5ut7.md"},
    {"title":"y0z8fhtd","href":"y0z8fhtd","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[y0z8fhtd]]","snippetStart":863,"snippetEnd":875,"sourceId":403,"sourcePath":"khi9ihj9.md","targetId":404,"targetPath":"y0z8fhtd.md"},
    {"title":"8113ygxd","href":"8113ygxd","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Flexibility of systems policies [[c4icaua4]] through separation of mechanism\n  and policies [[8113ygxd]]. That is, the reference monitor only needs to\n  validate the references using simple mechanisms. The policies themselves are\n  embedded in the capabilities.","snippetStart":115,"snippetEnd":376,"sourceId":403,"sourcePath":"khi9ihj9.md","targetId":413,"targetPath":"8113ygxd.md"},
    {"title":"sn99wrm0","href":"sn99wrm0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"There must be a security monitor that serves **capability invocations**. Usually\nin OSes capabilities are given as an opaque handle that are index to a\nkernel-maintained capability table [@steinberg2010nova,@klein2009sel4]\n([[sn99wrm0]]), which cannot be used directly, but must be _invoked_ through the\nprivileged software through system calls.","snippetStart":1508,"snippetEnd":1853,"sourceId":404,"sourcePath":"y0z8fhtd.md","targetId":425,"targetPath":"sn99wrm0.md"},
    {"title":"471vf8vr","href":"471vf8vr","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Packets should be processed from start to finish by the same stack, e.g.,\n   [[llh2ly47]], to reduce bottle necks with scheduling, kernel crossing\n   [[471vf8vr]]","snippetStart":327,"snippetEnd":489,"sourceId":410,"sourcePath":"2i45v7qf.md","targetId":375,"targetPath":"471vf8vr.md"},
    {"title":"llh2ly47","href":"llh2ly47","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Packets should be processed from start to finish by the same stack, e.g.,\n   [[llh2ly47]], to reduce bottle necks with scheduling, kernel crossing\n   [[471vf8vr]]","snippetStart":327,"snippetEnd":489,"sourceId":410,"sourcePath":"2i45v7qf.md","targetId":376,"targetPath":"llh2ly47.md"},
    {"title":"vbeb82fs","href":"vbeb82fs","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Packet from the same flow [[vbeb82fs]] must be processed together, e.g,.,\n   aranged in the smame ring buffer. This avoid complexities with out-of-order\n   packet reordering and also the need for looking for packets all over the\n   places ([[vtn586yc]]).","snippetStart":69,"snippetEnd":323,"sourceId":410,"sourcePath":"2i45v7qf.md","targetId":417,"targetPath":"vbeb82fs.md"},
    {"title":"vtn586yc","href":"vtn586yc","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Packet from the same flow [[vbeb82fs]] must be processed together, e.g,.,\n   aranged in the smame ring buffer. This avoid complexities with out-of-order\n   packet reordering and also the need for looking for packets all over the\n   places ([[vtn586yc]]).","snippetStart":69,"snippetEnd":323,"sourceId":410,"sourcePath":"2i45v7qf.md","targetId":419,"targetPath":"vtn586yc.md"},
    {"title":"x9zetwej","href":"x9zetwej","type":"wiki-link","isExternal":false,"rels":[],"snippet":"**Policy definition methods (PDM)**. How to determine what is the policy to\n  enforce. This reflect the methodology for selecting the subject and resources\n  (e.g., see [[x9zetwej]]) for isolation, which may be performed manually or\n  automatically.","snippetStart":485,"snippetEnd":734,"sourceId":412,"sourcePath":"7r5okim8.md","targetId":359,"targetPath":"x9zetwej.md"},
    {"title":"c4icaua4","href":"c4icaua4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The principle is mostly discussed in the context of computer security, where a\nseparation of mechanism and policy would greatly improve flexibility and\nsecurity of the system [[c4icaua4]].","snippetStart":269,"snippetEnd":457,"sourceId":413,"sourcePath":"8113ygxd.md","targetId":92,"targetPath":"c4icaua4.md"},
    {"title":"khi9ihj9","href":"khi9ihj9","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Capability systems [[khi9ihj9]] fundamentally implements separation of mechanism\nand policy, which is why it is used in many microkernels [[sn99wrm0]] designs.","snippetStart":863,"snippetEnd":1022,"sourceId":413,"sourcePath":"8113ygxd.md","targetId":403,"targetPath":"khi9ihj9.md"},
    {"title":"y0z8fhtd","href":"y0z8fhtd","type":"wiki-link","isExternal":false,"rels":[],"snippet":"In the system, the main TCB (kernel) implements the _mechanism_ layer that\nenforces properties of the capabilities, like capability storage, invocation,\ndelegation, [[y0z8fhtd]].","snippetStart":1024,"snippetEnd":1202,"sourceId":413,"sourcePath":"8113ygxd.md","targetId":404,"targetPath":"y0z8fhtd.md"},
    {"title":"sn99wrm0","href":"sn99wrm0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This is one of the principles behind microkernels [[sn99wrm0]]. More\nparticularly, in microkernel, the principle is instantiated as the _law of\nminimality_:","snippetStart":476,"snippetEnd":632,"sourceId":413,"sourcePath":"8113ygxd.md","targetId":425,"targetPath":"sn99wrm0.md"},
    {"title":"sn99wrm0","href":"sn99wrm0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Capability systems [[khi9ihj9]] fundamentally implements separation of mechanism\nand policy, which is why it is used in many microkernels [[sn99wrm0]] designs.","snippetStart":863,"snippetEnd":1022,"sourceId":413,"sourcePath":"8113ygxd.md","targetId":425,"targetPath":"sn99wrm0.md"},
    {"title":"2i45v7qf","href":"2i45v7qf","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Identifying flows useful in scaling network processing. For example, hardware\nNICs provides multiple Tx, Rx rings, and enforces each rings to contain packets\nof certain flow [@turtles] [[2i45v7qf]]. Some NICs determine the rings is based\non the hashing of certain fields packet headers (also called Recieved Side\nScalling (RSS)).","snippetStart":551,"snippetEnd":880,"sourceId":417,"sourcePath":"vbeb82fs.md","targetId":410,"targetPath":"2i45v7qf.md"},
    {"title":"i2blyo37","href":"i2blyo37","type":"wiki-link","isExternal":false,"rels":[],"snippet":"On IPC-heavy system like microkenrels, the choice matters a lot. An IPC in the\nmicrokernel require a synchronous system call to switch to the microkernel,\nwhere the microkernel can schedule the target service [[i2blyo37]].","snippetStart":502,"snippetEnd":724,"sourceId":418,"sourcePath":"vjmpqh7z.md","targetId":47,"targetPath":"i2blyo37.md"},
    {"title":"i2blyo37","href":"i2blyo37","type":"wiki-link","isExternal":false,"rels":[],"snippet":"However, the costs of synchronous IPC becomes a bottleneck in modern computing\nwith emphasis multiprocessing, which motivates modern optimization techniques\n[[i2blyo37]].","snippetStart":820,"snippetEnd":990,"sourceId":418,"sourcePath":"vjmpqh7z.md","targetId":47,"targetPath":"i2blyo37.md"},
    {"title":"2i45v7qf","href":"2i45v7qf","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[2i45v7qf]] Following the rule, a networking interface is scalable if its\noperations does not commute. Network processing on packets of the same flow\n[[vbeb82fs]] (e.g., same IP) are commute, so they can be implemented scalably if\neach interface process a packet from start to finish [@belay2014ix]. NICs also\ntry to follow this [@turtles] to avoid collecting packets and reordering across\nring buffers. More: [[2i45v7qf]].","snippetStart":1632,"snippetEnd":2056,"sourceId":419,"sourcePath":"vtn586yc.md","targetId":410,"targetPath":"2i45v7qf.md"},
    {"title":"2i45v7qf","href":"2i45v7qf","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[2i45v7qf]] Following the rule, a networking interface is scalable if its\noperations does not commute. Network processing on packets of the same flow\n[[vbeb82fs]] (e.g., same IP) are commute, so they can be implemented scalably if\neach interface process a packet from start to finish [@belay2014ix]. NICs also\ntry to follow this [@turtles] to avoid collecting packets and reordering across\nring buffers. More: [[2i45v7qf]].","snippetStart":1632,"snippetEnd":2056,"sourceId":419,"sourcePath":"vtn586yc.md","targetId":410,"targetPath":"2i45v7qf.md"},
    {"title":"vbeb82fs","href":"vbeb82fs","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[2i45v7qf]] Following the rule, a networking interface is scalable if its\noperations does not commute. Network processing on packets of the same flow\n[[vbeb82fs]] (e.g., same IP) are commute, so they can be implemented scalably if\neach interface process a packet from start to finish [@belay2014ix]. NICs also\ntry to follow this [@turtles] to avoid collecting packets and reordering across\nring buffers. More: [[2i45v7qf]].","snippetStart":1632,"snippetEnd":2056,"sourceId":419,"sourcePath":"vtn586yc.md","targetId":417,"targetPath":"vbeb82fs.md"},
    {"title":"7t4jlnaq","href":"7t4jlnaq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The three fundamental pieces of a microkernel are **address spaces** (memory\nmanagement), **scheduling** (time-share management), **inter-process**\ncommunication (IPC) (first conceptualized in [@liedtke1995microkernel]). Looking\nback at the goals of operating systems [[7t4jlnaq]], these are the minimum\nabstraction to achieve them.","snippetStart":225,"snippetEnd":557,"sourceId":425,"sourcePath":"sn99wrm0.md","targetId":71,"targetPath":"7t4jlnaq.md"},
    {"title":"8113ygxd","href":"8113ygxd","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The microkernel is a minimized OS layer that only implement the minimal\n_mechanisms_ [[8113ygxd]] for safe multiplexing and interactions, while letting\nthe _policies_ being implemented in the userspace.","snippetStart":21,"snippetEnd":223,"sourceId":425,"sourcePath":"sn99wrm0.md","targetId":413,"targetPath":"8113ygxd.md"},
    {"title":"khi9ihj9","href":"khi9ihj9","type":"wiki-link","isExternal":false,"rels":[],"snippet":"When designing interfaces from the ground up for safety, capabilities\n[[khi9ihj9]] is a good choice.","snippetStart":41,"snippetEnd":141,"sourceId":426,"sourcePath":"idff94ne.md","targetId":403,"targetPath":"khi9ihj9.md"},
    {"title":"y0z8fhtd","href":"y0z8fhtd","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The object handles are then given to the subjects (threads, processes,\ncompartments). There must be a security monitor that validate the **capability\ninvocations** to check for permissions and also allowing access to the resource.\nFor more on implementation: [[y0z8fhtd]].","snippetStart":2273,"snippetEnd":2545,"sourceId":426,"sourcePath":"idff94ne.md","targetId":404,"targetPath":"y0z8fhtd.md"},
    {"title":"sn99wrm0","href":"sn99wrm0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"For example, microkernels [[sn99wrm0]] goals is to provide a safe time-sharing\n\u003e environment. They encapsulate types of objects for scheduling (time resource),\n\u003e virtual address space (memory resource) and IPC (communication). Providing an\n\u003e IPC abstraction allow highly composable systems and also allow flexible\n\u003e policies. E.g., the right to perform IPC may be passed from processes to\n\u003e another.","snippetStart":1210,"snippetEnd":1609,"sourceId":426,"sourcePath":"idff94ne.md","targetId":425,"targetPath":"sn99wrm0.md"},
    {"title":"szlwwqsj","href":"szlwwqsj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Hardware are commonly located the lowest in the stack (L2, before physical\nlayer), but sometimes they provide features that belong to higher levels (L3,\nnetworking). Moreover, for flexibility, many hardware functionalities are\nimplemented in software as a dedicated service, i.e., [[szlwwqsj]]","snippetStart":30,"snippetEnd":323,"sourceId":429,"sourcePath":"27le2qfj.md","targetId":430,"targetPath":"szlwwqsj.md"},
    {"title":"q4cvky96","href":"q4cvky96","type":"wiki-link","isExternal":false,"rels":[],"snippet":"**Flexible network architecture implementations** (e.g., firewall, load\n  balancers, WAN [[q4cvky96]], ... ). This allows faster development and also\n  deployment.","snippetStart":477,"snippetEnd":640,"sourceId":430,"sourcePath":"szlwwqsj.md","targetId":431,"targetPath":"q4cvky96.md"},
    {"title":"ijh22i54","href":"ijh22i54","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This naturally leads to a service model where third party services provide\nnetworking functionalities like firewall, load balancer, VPN, to enterprises as\ncloud services [[ijh22i54]].","snippetStart":972,"snippetEnd":1155,"sourceId":430,"sourcePath":"szlwwqsj.md","targetId":432,"targetPath":"ijh22i54.md"},
    {"title":"szlwwqsj","href":"szlwwqsj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Network-as-a-Service (NaaS) is a cloud service model where network services are\nprovided to customers that replace traditional networking devices. These\nservices are usually implemented with NFV [[szlwwqsj]].","snippetStart":59,"snippetEnd":267,"sourceId":432,"sourcePath":"ijh22i54.md","targetId":430,"targetPath":"szlwwqsj.md"},
    {"title":"oktf2gql","href":"oktf2gql","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This service model leads to a conflict of security interests between the parties\n[[oktf2gql]], which motived development of TEE-protected NF services\n[@poddar2018safebricks,@duan2019lightbox].","snippetStart":269,"snippetEnd":461,"sourceId":432,"sourcePath":"ijh22i54.md","targetId":433,"targetPath":"oktf2gql.md"},
    {"title":"ijh22i54","href":"ijh22i54","type":"wiki-link","isExternal":false,"rels":[],"snippet":"send their data to be processed by an external services and receive the\n  results. Examples of this can be seen in can be AI prediction services, LLM\n  chatbots, NaaS [[ijh22i54]]","snippetStart":237,"snippetEnd":416,"sourceId":433,"sourcePath":"oktf2gql.md","targetId":432,"targetPath":"ijh22i54.md"},
    {"title":"szlwwqsj","href":"szlwwqsj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"NetBrick [@panda2016netbricks] discussed the property _packet isolation_ in the\ncontext of network functions (NF) [[szlwwqsj]]. Ideally you would want to only\npass the pointer to the packet between the NFs to avoid copying. However, this\nlead to a NF can modify the NF after it has been sent.","snippetStart":20,"snippetEnd":312,"sourceId":441,"sourcePath":"2it4soew.md","targetId":430,"targetPath":"szlwwqsj.md"},
    {"title":"4ea8wn6r","href":"4ea8wn6r","type":"wiki-link","isExternal":false,"rels":[],"snippet":"In NetBrick, the property is enforced through Rust ownership model [[4ea8wn6r]],\nwhere after the packet's is sent by the NF, Rust prevents further modifications\nto it. RedLeaf [@narayanan2020redleaf] enforces similar property for zero-copy\ndata transfer.","snippetStart":314,"snippetEnd":568,"sourceId":441,"sourcePath":"2it4soew.md","targetId":442,"targetPath":"4ea8wn6r.md"},
    {"title":"yef2w9yc","href":"yef2w9yc","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Zero-copy data transfer, where a pointer is passed between to subsystems, is\ninherently in conflict with isolation of subsystems. Particularly, the sender\nmay modify data when the receiver is processing it, leading to TOCTOU issues\n([[yef2w9yc]]).","snippetStart":50,"snippetEnd":297,"sourceId":442,"sourcePath":"4ea8wn6r.md","targetId":368,"targetPath":"yef2w9yc.md"},
    {"title":"2it4soew","href":"2it4soew","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Several systems took advantage of this property to enable zero-copy\ncommunication, starting from the Singularity OS [@hunt2007singularity]. The Rust\nlanguage enforce single-ownership by design and is suitable for system\nprogramming, which has been explored for kernel subsystems isolation\n[@narayanan2020redleaf], packet isolation [[2it4soew]] in a language-based NFV\nruntime [panda2016netbricks].","snippetStart":556,"snippetEnd":953,"sourceId":442,"sourcePath":"4ea8wn6r.md","targetId":441,"targetPath":"2it4soew.md"},
    {"title":"sn99wrm0","href":"sn99wrm0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This concept is different from microkernels [[sn99wrm0]] in that there is almost\nno abstractions in exokernels. However, implementation of the secure binding\nmechanisms is very dependent on the type of resource. It is unclear if the\napproach results in a smaller TCB compared to microkernels. E.g., a network\nfilter is required in the kernel for multiplexing of networking.","snippetStart":1047,"snippetEnd":1420,"sourceId":443,"sourcePath":"07bi6une.md","targetId":425,"targetPath":"sn99wrm0.md"}
  ]
}
