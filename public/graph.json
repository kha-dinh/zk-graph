{
  "notes": [
    {"filename":"index.md","filenameStem":"index","path":"index.md","absPath":"/Users/khadd/mynotes/index.md","title":"","link":"[[index]]","lead":"","body":"","snippets":[],"rawContent":"","wordCount":0,"tags":[],"metadata":{},"created":"2023-08-09T13:49:43.469048083Z","modified":"2023-08-09T13:49:43.469048083Z","checksum":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"},
    {"filename":"README.md","filenameStem":"README","path":"styles/write-good/README.md","absPath":"/Users/khadd/mynotes/styles/write-good/README.md","title":"","link":"[[styles/write-good/README]]","lead":"Based on [write-good](https://github.com/btford/write-good).","body":"Based on [write-good](https://github.com/btford/write-good).\n\n\u003e Naive linter for English prose for developers who can't write good and wanna learn to do other stuff good too.\n\n```\nThe MIT License (MIT)\n\nCopyright (c) 2014 Brian Ford\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n```","snippets":["Based on [write-good](https://github.com/btford/write-good)."],"rawContent":"Based on [write-good](https://github.com/btford/write-good).\n\n\u003e Naive linter for English prose for developers who can't write good and wanna learn to do other stuff good too.\n\n```\nThe MIT License (MIT)\n\nCopyright (c) 2014 Brian Ford\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n```\n","wordCount":197,"tags":[],"metadata":{},"created":"2023-08-09T13:49:43.477928028Z","modified":"2023-08-09T13:49:43.477972653Z","checksum":"8826e2193035d98c38a7ef1560f1677ce7e9c305e2de48d469276e877b2d42f7"},
    {"filename":"2023-05-26.md","filenameStem":"2023-05-26","path":"daily/2023-05-26.md","absPath":"/Users/khadd/mynotes/daily/2023-05-26.md","title":"2023-05-26","link":"[[daily/2023-05-26]]","lead":"#daily","body":"#daily\n\nAssigned to MIA inference IITP project. Basically it tries to perform MIA on driver licenses dataset. \n\nVirtIO daemon security?","snippets":["#daily"],"rawContent":"# 2023-05-26\n#daily\n\nAssigned to MIA inference IITP project. Basically it tries to perform MIA on driver licenses dataset. \n\nVirtIO daemon security?\n\n","wordCount":22,"tags":["daily"],"metadata":{},"created":"2023-08-09T13:49:43.462456728Z","modified":"2023-08-09T13:49:43.462495561Z","checksum":"124e5ccb7f871396234f918fc9eca661ec0c1330880741e08f2ac67294c2a5ad"},
    {"filename":"2023-06-16.md","filenameStem":"2023-06-16","path":"daily/2023-06-16.md","absPath":"/Users/khadd/mynotes/daily/2023-06-16.md","title":"2023-06-16","link":"[[daily/2023-06-16]]","lead":"#daily","body":"#daily\n\n- [ ] Learn about nested page fault attacks on SEV\n\n\n\nThere may be benefits from combining self-paging VMs with obfuscated execution / page fault protection.","snippets":["#daily"],"rawContent":"# 2023-06-16\n#daily\n\n- [ ] Learn about nested page fault attacks on SEV\n\n\n\nThere may be benefits from combining self-paging VMs with obfuscated execution / page fault protection.\n","wordCount":29,"tags":["daily"],"metadata":{},"created":"2023-08-09T13:49:43.462526062Z","modified":"2023-08-09T13:49:43.46256302Z","checksum":"702b109d7f444b06f455059ef35f12633fbd280f3f0966253e9a361bdfa5cd1d"},
    {"filename":"2023-06-19.md","filenameStem":"2023-06-19","path":"daily/2023-06-19.md","absPath":"/Users/khadd/mynotes/daily/2023-06-19.md","title":"2023-06-19","link":"[[daily/2023-06-19]]","lead":"#daily","body":"#daily\n\n\n- [ ] Does SEV guarantee the mapping of huge pages?\n- [x] Check on CLG","snippets":["#daily"],"rawContent":"# 2023-06-19\n#daily\n\n\n- [ ] Does SEV guarantee the mapping of huge pages?\n- [x] Check on CLG  \n\n\n","wordCount":19,"tags":["daily"],"metadata":{},"created":"2023-08-09T13:49:43.462587853Z","modified":"2023-08-09T13:49:43.462620103Z","checksum":"c08e4de8e92bb7044da2c9bb82acc9611086249ab8b3ed86df891ba9aaee6037"},
    {"filename":"2023-07-06.md","filenameStem":"2023-07-06","path":"daily/2023-07-06.md","absPath":"/Users/khadd/mynotes/daily/2023-07-06.md","title":"2023-07-06","link":"[[daily/2023-07-06]]","lead":"#daily","body":"#daily\n\nHi, I don't know where to ask this question so I'm gonna put it here. I'm trying to override the page fault handler for the heap memory region. For that, I created a new type of vma using `ukvmem` and replaced the `uk_vma_map_anon` with my vma type in `heap_init`. The problem is I want to access the previous PTE in my custom page fault handler, but it is cleared in `pg_page_mapx`, when the flag `PAGE_FLAG_KEEP_PTES` is not passed.","snippets":["#daily"],"rawContent":"# 2023-07-06\n#daily\n\nHi, I don't know where to ask this question so I'm gonna put it here. I'm trying to override the page fault handler for the heap memory region. For that, I created a new type of vma using `ukvmem` and replaced the `uk_vma_map_anon` with my vma type in `heap_init`. The problem is I want to access the previous PTE in my custom page fault handler, but it is cleared in `pg_page_mapx`, when the flag `PAGE_FLAG_KEEP_PTES` is not passed.\n\n\n","wordCount":81,"tags":["daily"],"metadata":{},"created":"2023-08-09T13:49:43.462646187Z","modified":"2023-08-09T13:49:43.462685895Z","checksum":"14717acaf5dd0cb351708e9d7ca56da2f70a7907a38a6928ec8307bcb3865e7e"},
    {"filename":"2023-07-09.md","filenameStem":"2023-07-09","path":"daily/2023-07-09.md","absPath":"/Users/khadd/mynotes/daily/2023-07-09.md","title":"2023-07-09","link":"[[daily/2023-07-09]]","lead":"#daily","body":"#daily\n\nI don't know where to put this question so I'm gonna put it here. I am trying to make a page fault handler that serves physical memory from a pre-allocated physical memory region. To do that, I allocate memory at boot time using `pt-\u003efa-\u003efalloc()` and store the physical address. I then extended `ukvmem` to introduce a custom VMA type to register my page fault handler. E.g.,\n\n```c\nstatic int vma_op_custom_fault(__unused struct uk_vma *vma,\n                                     struct uk_vm_fault *fault)\n{\n  __paddr_t paddr = get_allocated_paddr();\n  /* initialize memory  */\n\tfault-\u003epaddr = paddr;\n  return 0;\n}\n```\n\nHowever, for some reason, memory write does not go through, and I got junk data when reading from the mapped address.\nHere is a simple test case:\n```c\n\tva = __VADDR_ANY;\n\tuk_vma_map_custom(vas, \u0026va, 0x10000, PROT_RW, UK_VMA_MAP_UNINITIALIZED,\n\t\t\t NULL);\n\tmemset((void *)va, 0xAB, 0x100);\n\tmemset((void *)va + 0x100, 0xCD, 0x100);\n\tuk_hexdumpk(KLVL_INFO, (void *)va, 0x1000,\n\t\t    UK_HXDF_COMPRESS | UK_HXDF_ADDR, UK_HXDF_GRPQWORD);\n```\nHere is the console output. The first `memset` would create the `20 07` pattern in memory. \n```\n[    0.304939] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07\n[    0.322053] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.326263] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.344048] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```\n\nStrangely enough, when I compile the test file with `isr` flag, or use `memset_isr`, the problem does not happen.\n\n```\n[    0.305990] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab\n[    0.323425] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.327827] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.345547] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```","snippets":["#daily"],"rawContent":"# 2023-07-09\n#daily\n\nI don't know where to put this question so I'm gonna put it here. I am trying to make a page fault handler that serves physical memory from a pre-allocated physical memory region. To do that, I allocate memory at boot time using `pt-\u003efa-\u003efalloc()` and store the physical address. I then extended `ukvmem` to introduce a custom VMA type to register my page fault handler. E.g.,\n\n```c\nstatic int vma_op_custom_fault(__unused struct uk_vma *vma,\n                                     struct uk_vm_fault *fault)\n{\n  __paddr_t paddr = get_allocated_paddr();\n  /* initialize memory  */\n\tfault-\u003epaddr = paddr;\n  return 0;\n}\n```\n\nHowever, for some reason, memory write does not go through, and I got junk data when reading from the mapped address.\nHere is a simple test case:\n```c\n\tva = __VADDR_ANY;\n\tuk_vma_map_custom(vas, \u0026va, 0x10000, PROT_RW, UK_VMA_MAP_UNINITIALIZED,\n\t\t\t NULL);\n\tmemset((void *)va, 0xAB, 0x100);\n\tmemset((void *)va + 0x100, 0xCD, 0x100);\n\tuk_hexdumpk(KLVL_INFO, (void *)va, 0x1000,\n\t\t    UK_HXDF_COMPRESS | UK_HXDF_ADDR, UK_HXDF_GRPQWORD);\n```\nHere is the console output. The first `memset` would create the `20 07` pattern in memory. \n```\n[    0.304939] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07\n[    0.322053] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.326263] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.344048] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```\n\nStrangely enough, when I compile the test file with `isr` flag, or use `memset_isr`, the problem does not happen.\n\n```\n[    0.305990] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab\n[    0.323425] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.327827] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.345547] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```\n\n","wordCount":390,"tags":["daily"],"metadata":{},"created":"2023-08-09T13:49:43.462710896Z","modified":"2023-08-09T13:49:43.462758604Z","checksum":"862851b9864f06f782badd0dda8cebfdd8cd73aea794fe85a38c24d772833f9e"},
    {"filename":"2023-07-12.md","filenameStem":"2023-07-12","path":"daily/2023-07-12.md","absPath":"/Users/khadd/mynotes/daily/2023-07-12.md","title":"2023-07-12","link":"[[daily/2023-07-12]]","lead":"#daily","body":"#daily\n\n\n\n\n# Message to unikraft\n\nRegarding page table isolation. I plan to first implement the features we discussed earlier, randomization and page table unmapping/sealing.\n\nRandomization\n- Currently the page table's virtual addresses are direct-mapped by `pgarch_pt_map` and `pgarch_pt_unmap`. We probably only need to provide an alternative implementation that map to a random address.\n- To support this, we may use a secondary direct-mapped area address that is randomized at boot time.\n- Another approach is to use the heap memory space to map the page table addresses. The addresses are naturally randomized by the heap allocator. \n\nPage-table unmapping/sealing\n- We need to keep track of the virtual addresses of the page table, then unmap them when the page table update is finished, then re-map them on page faults or page table updates.\n- I guess we can insert a hook in `pg_pt_alloc` used to allocate the page table to collect the page table virtual addresses in a list. We can then insert the code to unmap/remap these pages where the page table is accessed.\n  - I see only 4 main entry points of the page table: `pg_page_mapx`, `pg_page_split`, `pg_page_setattr`, and `pg_page_unmmap`.\n- How are the direct-mapped pages mapped? I don't see the direct-mapped pages being mapped in the source.","snippets":["#daily"],"rawContent":"# 2023-07-12\n#daily\n\n\n\n\n# Message to unikraft\n\nRegarding page table isolation. I plan to first implement the features we discussed earlier, randomization and page table unmapping/sealing.\n\nRandomization\n- Currently the page table's virtual addresses are direct-mapped by `pgarch_pt_map` and `pgarch_pt_unmap`. We probably only need to provide an alternative implementation that map to a random address.\n- To support this, we may use a secondary direct-mapped area address that is randomized at boot time.\n- Another approach is to use the heap memory space to map the page table addresses. The addresses are naturally randomized by the heap allocator. \n\nPage-table unmapping/sealing\n- We need to keep track of the virtual addresses of the page table, then unmap them when the page table update is finished, then re-map them on page faults or page table updates.\n- I guess we can insert a hook in `pg_pt_alloc` used to allocate the page table to collect the page table virtual addresses in a list. We can then insert the code to unmap/remap these pages where the page table is accessed.\n  - I see only 4 main entry points of the page table: `pg_page_mapx`, `pg_page_split`, `pg_page_setattr`, and `pg_page_unmmap`.\n- How are the direct-mapped pages mapped? I don't see the direct-mapped pages being mapped in the source.\n\n\n","wordCount":211,"tags":["daily"],"metadata":{},"created":"2023-08-09T13:49:43.462783437Z","modified":"2023-08-09T13:49:43.462828604Z","checksum":"e32cdc1c1311c8b33f7f9bd7db0ea6b6c88960aeb7243a06c4bf99cc4c436fb4"},
    {"filename":"2023-07-25.md","filenameStem":"2023-07-25","path":"daily/2023-07-25.md","absPath":"/Users/khadd/mynotes/daily/2023-07-25.md","title":"2023-07-25","link":"[[daily/2023-07-25]]","lead":"#daily","body":"#daily\n\n\n# Typst\n= Introduction\n\n==== Unsafe rust is not that dangerous compared to FFI \nRust has two main sources of unsafety: the code inside `unsafe` and the foreign function interface (FFI). However, unsafe code is well-contained and is used sparingly. Moreover, previous research proposed static analysis that can detect memory safety bugs triggered by `unsafe`. On the other hand, the FFI is written in unsafe languages and can easily trigger memory bugs. A bug in FFI can compromise the security guarantees of Rust. Hence, we argue that FFI is more harmful to Rust.\n\n==== Limitation of previous work\nPrevious proposals proposed systems that automatically separate memory used by safe rust and unsafe components. \n\n\n==== Our system\nIn response to the limitation of the previous wo","snippets":["#daily"],"rawContent":"# 2023-07-25\n#daily\n\n\n# Typst\n= Introduction\n\n==== Unsafe rust is not that dangerous compared to FFI \nRust has two main sources of unsafety: the code inside `unsafe` and the foreign function interface (FFI). However, unsafe code is well-contained and is used sparingly. Moreover, previous research proposed static analysis that can detect memory safety bugs triggered by `unsafe`. On the other hand, the FFI is written in unsafe languages and can easily trigger memory bugs. A bug in FFI can compromise the security guarantees of Rust. Hence, we argue that FFI is more harmful to Rust.\n\n==== Limitation of previous work\nPrevious proposals proposed systems that automatically separate memory used by safe rust and unsafe components. \n\n\n==== Our system\nIn response to the limitation of the previous wo\n\n\n","wordCount":128,"tags":["daily"],"metadata":{},"created":"2023-08-09T13:49:43.462853063Z","modified":"2023-08-09T13:49:43.462895979Z","checksum":"7a6fd23c5ce0d9eee134ae6bf9bb91574a5aa36e5988499904c53d7716c426d1"},
    {"filename":"2023-07-26.md","filenameStem":"2023-07-26","path":"daily/2023-07-26.md","absPath":"/Users/khadd/mynotes/daily/2023-07-26.md","title":"2023-07-26","link":"[[daily/2023-07-26]]","lead":"#daily","body":"#daily\n\nThis figure is awesome (in [shared_mem_handling.h](https://github.com/ReMon-MVEE/ReMon/blob/master/MVEE/Inc/arch/amd64/shared_mem/shared_mem_handling.h))\n```c\n    /* +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     * | _ | _ | _ _ _ | _ | _ | _ | _ _ | _ _ _ _ | _ _ | _ _ | _ | _ | _ _ _ | _ _ | _ | _ | _ _ _ _ | _ |\n     * +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     *  \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         \\\n     *   \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         +-\u003e REX present\n     *    \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   +-\u003e REX prefixes [WRXB]\n     *     \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   +-\u003e prefix group 1 present\n     *      \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     +-\u003e prefix group 2 present\n     *       \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       +-\u003e prefix group 1\n     *        \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   +-\u003e prefix group 2\n     *         \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   +-\u003e prefix group 3\n     *          \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     +-\u003e prefix group 4\n     *           \\   \\   \\       \\   \\   \\   \\     \\         \\     +-\u003e VEX size\n     *            \\   \\   \\       \\   \\   \\   \\     \\         +-\u003e VEX.L\n     *             \\   \\   \\       \\   \\   \\   \\     +-\u003e VEX.vvvv\n     *              \\   \\   \\       \\   \\   \\   +-\u003e VEX.mmmmm\n     *               \\   \\   \\       \\   \\   +-\u003e EVEX.R'\n     *                \\   \\   \\       \\   +-\u003e EVEX.X\n     *                 \\   \\   \\       +-\u003e EVEX.V'\n     *                  \\   \\   +-\u003e EVEX.aaa\n     *                   \\   +-\u003e EVEX.z\n     *                    +-\u003e EVEX.b\n     *                    \n     *                    */\n```","snippets":["#daily"],"rawContent":"# 2023-07-26\n#daily\n\nThis figure is awesome (in [shared_mem_handling.h](https://github.com/ReMon-MVEE/ReMon/blob/master/MVEE/Inc/arch/amd64/shared_mem/shared_mem_handling.h))\n```c\n    /* +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     * | _ | _ | _ _ _ | _ | _ | _ | _ _ | _ _ _ _ | _ _ | _ _ | _ | _ | _ _ _ | _ _ | _ | _ | _ _ _ _ | _ |\n     * +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     *  \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         \\\n     *   \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         +-\u003e REX present\n     *    \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   +-\u003e REX prefixes [WRXB]\n     *     \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   +-\u003e prefix group 1 present\n     *      \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     +-\u003e prefix group 2 present\n     *       \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       +-\u003e prefix group 1\n     *        \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   +-\u003e prefix group 2\n     *         \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   +-\u003e prefix group 3\n     *          \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     +-\u003e prefix group 4\n     *           \\   \\   \\       \\   \\   \\   \\     \\         \\     +-\u003e VEX size\n     *            \\   \\   \\       \\   \\   \\   \\     \\         +-\u003e VEX.L\n     *             \\   \\   \\       \\   \\   \\   \\     +-\u003e VEX.vvvv\n     *              \\   \\   \\       \\   \\   \\   +-\u003e VEX.mmmmm\n     *               \\   \\   \\       \\   \\   +-\u003e EVEX.R'\n     *                \\   \\   \\       \\   +-\u003e EVEX.X\n     *                 \\   \\   \\       +-\u003e EVEX.V'\n     *                  \\   \\   +-\u003e EVEX.aaa\n     *                   \\   +-\u003e EVEX.z\n     *                    +-\u003e EVEX.b\n     *                    \n     *                    */\n```\n\n\n","wordCount":314,"tags":["daily"],"metadata":{},"created":"2023-08-09T13:49:43.462922063Z","modified":"2023-08-09T13:49:43.462963313Z","checksum":"321e0803b887e255f3cd1e32fa742fb0c7520b7fdcd1bb4c18d7a66d25fb7c59"},
    {"filename":"2023-07-28.md","filenameStem":"2023-07-28","path":"daily/2023-07-28.md","absPath":"/Users/khadd/mynotes/daily/2023-07-28.md","title":"2023-07-28","link":"[[daily/2023-07-28]]","lead":"#daily","body":"#daily","snippets":["#daily"],"rawContent":"# 2023-07-28\n#daily\n\n\n\n\n","wordCount":3,"tags":["daily"],"metadata":{},"created":"2023-08-09T13:49:43.463048105Z","modified":"2023-08-09T13:49:43.463087063Z","checksum":"2a4ecfb7a2a71b3b558a5f3aac8e69478dc2ecbc39510046076bc65807fa018c"},
    {"filename":"k0wjwjhg.md","filenameStem":"k0wjwjhg","path":"k0wjwjhg.md","absPath":"/Users/khadd/mynotes/k0wjwjhg.md","title":"A paper/book should be read in multiple passes","link":"[[k0wjwjhg]]","lead":"#reading #learning #zettelkasten","body":"#reading #learning #zettelkasten\n\nAn article/paper/book should be read in multiple passes for the best extraction of information.\nThe point of reading in many passes is to maximize the time efficiency when reading.   \n\n\n## The three passes\n[keshav] suggested that reading can be divided into three passes, that cover from high-level ideas to low-level details.\n### Inspectional reading\nThe first pass should establish the context around the article.\n[keshav] suggested that 5-10% of the time should be spent on this.\n\nThis step may have the following goals:\n- *Establishing context*: What is the background of this paper? What is the previous work, and what comes after this?\n- *Relavancy*: How is this related to your research? \n- *Importance*: Is this worth reading? If not then it is a waste of time to read the article.\n- *Usefulness*: What information do you want to extract from this paper? \n- *The main arguments*: that are the arguments of the paper/article? This helps establish the mental model before going into more detailed reading.\n\nIn this step, it is also important to remember the  [[b740rhio|hourglass structure of information]], so spend more time on the beginning and the end of the section.\n\n\n### Detailed reading\nWhile doing the detailed reading, we should pay attention to the main arguments of the paper. For instance, what argument/idea is this particular paragraph/sentence supporting? Is it a convincing argument? What other ideas does it contradict?\n\n### Synthesis\n\n\n## Reference\n[keshav]: https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf","snippets":["#reading #learning #zettelkasten"],"rawContent":"# A paper/book should be read in multiple passes\n#reading #learning #zettelkasten\n\nAn article/paper/book should be read in multiple passes for the best extraction of information.\nThe point of reading in many passes is to maximize the time efficiency when reading.   \n\n\n## The three passes\n[keshav] suggested that reading can be divided into three passes, that cover from high-level ideas to low-level details.\n### Inspectional reading\nThe first pass should establish the context around the article.\n[keshav] suggested that 5-10% of the time should be spent on this.\n\nThis step may have the following goals:\n- *Establishing context*: What is the background of this paper? What is the previous work, and what comes after this?\n- *Relavancy*: How is this related to your research? \n- *Importance*: Is this worth reading? If not then it is a waste of time to read the article.\n- *Usefulness*: What information do you want to extract from this paper? \n- *The main arguments*: that are the arguments of the paper/article? This helps establish the mental model before going into more detailed reading.\n\nIn this step, it is also important to remember the  [[b740rhio|hourglass structure of information]], so spend more time on the beginning and the end of the section.\n\n\n### Detailed reading\nWhile doing the detailed reading, we should pay attention to the main arguments of the paper. For instance, what argument/idea is this particular paragraph/sentence supporting? Is it a convincing argument? What other ideas does it contradict?\n\n### Synthesis\n\n\n## Reference\n[keshav]: https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf\n","wordCount":250,"tags":["zettelkasten","reading","learning"],"metadata":{},"created":"2023-08-09T13:49:43.469294458Z","modified":"2023-08-09T13:49:43.469341542Z","checksum":"c402720275f0fb1831d9b5e64ad2e4eeb64acf8e00427a2f4195be91f391cefa"},
    {"filename":"c7cva598.md","filenameStem":"c7cva598","path":"c7cva598.md","absPath":"/Users/khadd/mynotes/c7cva598.md","title":"AMD Secure Encrypted Virtualization (SEV)","link":"[[c7cva598]]","lead":"#sev #virtualization #tee #amd","body":"#sev #virtualization #tee #amd\n\nAMD's Secure Encrypted Virtualization (SEV) enables TEEs at the granularity of virtual machines. \n\n# Memory encryption\nThe CPU employs a secure processor (SP) that transparently encrypts/decrypt data when they are written into the memory pages of the encrypted VMs.\n\nEncryption is performed with a per-cVM key maintained by the CPU,c called the VM encryption key (VEK). It is indexed by the ASID of the VM.\n\nA flag called the c-bit (bit 47) indicates whether a page should be encrypted or not. The c-bit is stored in *both* the host PTEs and the guest PTEs. Its effect is determined from the combination of the two c-bit in gPT and NPT.\n\n|             | host c-bit               |                          |\n|-------------|--------------------------|--------------------------|\n| guest c-bit | 0                        | 1                        |\n|-------------|--------------------------|--------------------------|\n| 0           | not encrypted            | encrypted with host key  |\n| 1           | encrypted with guest key | encrypted with guest key |\n\n\n\n# SEV-ES\nThe original design of SEV does not encrypt the VM states upon VM exit. This leads to attacks that can extract information from the VM based on the register state.\n\nSEV-Encrypted State (ES) solve this issue by also encrypting the VM states upon VMEXIT. It splits the virtual machine control block (VMCB) into two areas, a control area and a save area (VMSA). The VMSA is encrypted with the VEK upon VMEXIT.\n\n## Automatic and non-automatic exits.\nNow, every exit from the guest into the hypervisor (`VMEXIT`) is categorized into Automatic Exit (AE) and Non-automatic Exit (NAE). \n\nAE consists of basically all interrupts that are trigger by the hypervisor. Since these interrupt does not require knowledge of VM register state, all of VM registers will be encrypted and stored into the VMSA.\n\nNAE are the remaining exits, i.e., faults triggered by the VM. Faults can be triggered by the hardware exception such as page fault, or executing a privilege instruction (e.g., write into CR3). \nIn this case, the guest might want to share some register states with the hypervisor.\n\nHence, a `VC` exception (VMM Communication Exception) is generated by the CPU, with the cauuse of exception. The VM then invoke the handler to handle the fault. The handler can copy the selected VM registers into a  shared page, called the  Guest Hypervisor Communication Block (GHCB), which is non-encrypted. It then triggers an AE with a call to  `VMGEXIT`, so that the host can serve the fault.\n\n# SEV-SNP\n## Mapping integrity protection\nSEV-Secure Nested Paging (SNP) adds integrity protection to SEV, that protect the encrypted pages from replaying (replaced with an old page), being mapped to two regions, and being remapped.\n\nIt uses an Reseve Page Mapping (RMP), which is a table maintained by the hardware to keep the mapping metatada for each physical pages.\nAll memory write accesses look up the RMP to verify the mapping correctness.\n\nEven with the RMP mapping protection, a malicious VMM could still tammper with the permission flags in the page table entries @qin2023protecting. For instance, a malicious hypervisor can overwrite the present bit in the NPT, that indicate wheter the page is inside memory. When the VM access the page, a nested page fault will be trigger.\n\n\n## VMPL\nSEV-SNP also includes the Virtual Machine Privilege Level (VMPL) security mechanism. It adds privilege levels within the encrypted VM.\n\n\nHecate @ge2022hecate uses this feature to implement an in-VM hypervisor that handle the VM-VMM interactions for an unmodified, un-enlighteneda OS. \nIt put the hypervisor in VMPL layer 0, and the guest VM in VMPL level 4, then have the VMM forwards all faults into the in-VM VMM for handling.\n\n# I/O operations in SEV\nSee [[zmt276jl]].\n\n# Related notes\n- [[d3nt6uix]]\n- [[s16ct1rj]]","snippets":["#sev #virtualization #tee #amd"],"rawContent":"# AMD Secure Encrypted Virtualization (SEV)\n#sev #virtualization #tee #amd\n\nAMD's Secure Encrypted Virtualization (SEV) enables TEEs at the granularity of virtual machines. \n\n# Memory encryption\nThe CPU employs a secure processor (SP) that transparently encrypts/decrypt data when they are written into the memory pages of the encrypted VMs.\n\nEncryption is performed with a per-cVM key maintained by the CPU,c called the VM encryption key (VEK). It is indexed by the ASID of the VM.\n\nA flag called the c-bit (bit 47) indicates whether a page should be encrypted or not. The c-bit is stored in *both* the host PTEs and the guest PTEs. Its effect is determined from the combination of the two c-bit in gPT and NPT.\n\n|             | host c-bit               |                          |\n|-------------|--------------------------|--------------------------|\n| guest c-bit | 0                        | 1                        |\n|-------------|--------------------------|--------------------------|\n| 0           | not encrypted            | encrypted with host key  |\n| 1           | encrypted with guest key | encrypted with guest key |\n\n\n\n# SEV-ES\nThe original design of SEV does not encrypt the VM states upon VM exit. This leads to attacks that can extract information from the VM based on the register state.\n\nSEV-Encrypted State (ES) solve this issue by also encrypting the VM states upon VMEXIT. It splits the virtual machine control block (VMCB) into two areas, a control area and a save area (VMSA). The VMSA is encrypted with the VEK upon VMEXIT.\n\n## Automatic and non-automatic exits.\nNow, every exit from the guest into the hypervisor (`VMEXIT`) is categorized into Automatic Exit (AE) and Non-automatic Exit (NAE). \n\nAE consists of basically all interrupts that are trigger by the hypervisor. Since these interrupt does not require knowledge of VM register state, all of VM registers will be encrypted and stored into the VMSA.\n\nNAE are the remaining exits, i.e., faults triggered by the VM. Faults can be triggered by the hardware exception such as page fault, or executing a privilege instruction (e.g., write into CR3). \nIn this case, the guest might want to share some register states with the hypervisor.\n\nHence, a `VC` exception (VMM Communication Exception) is generated by the CPU, with the cauuse of exception. The VM then invoke the handler to handle the fault. The handler can copy the selected VM registers into a  shared page, called the  Guest Hypervisor Communication Block (GHCB), which is non-encrypted. It then triggers an AE with a call to  `VMGEXIT`, so that the host can serve the fault.\n\n# SEV-SNP\n## Mapping integrity protection\nSEV-Secure Nested Paging (SNP) adds integrity protection to SEV, that protect the encrypted pages from replaying (replaced with an old page), being mapped to two regions, and being remapped.\n\nIt uses an Reseve Page Mapping (RMP), which is a table maintained by the hardware to keep the mapping metatada for each physical pages.\nAll memory write accesses look up the RMP to verify the mapping correctness.\n\nEven with the RMP mapping protection, a malicious VMM could still tammper with the permission flags in the page table entries @qin2023protecting. For instance, a malicious hypervisor can overwrite the present bit in the NPT, that indicate wheter the page is inside memory. When the VM access the page, a nested page fault will be trigger.\n\n\n## VMPL\nSEV-SNP also includes the Virtual Machine Privilege Level (VMPL) security mechanism. It adds privilege levels within the encrypted VM.\n\n\nHecate @ge2022hecate uses this feature to implement an in-VM hypervisor that handle the VM-VMM interactions for an unmodified, un-enlighteneda OS. \nIt put the hypervisor in VMPL layer 0, and the guest VM in VMPL level 4, then have the VMM forwards all faults into the in-VM VMM for handling.\n\n# I/O operations in SEV\nSee [[zmt276jl]].\n\n# Related notes\n- [[d3nt6uix]]\n- [[s16ct1rj]]\n","wordCount":619,"tags":["tee","sev","virtualization","amd"],"metadata":{},"created":"2023-08-09T13:49:43.461767226Z","modified":"2023-08-09T13:49:43.461833601Z","checksum":"caa5400c4a912eb1827b604a80a305573e03c782d1aa04e0e691bbd4c527fdb2"},
    {"filename":"2xsjor1o.md","filenameStem":"2xsjor1o","path":"2xsjor1o.md","absPath":"/Users/khadd/mynotes/2xsjor1o.md","title":"Accessing user memory from Kernel","link":"[[2xsjor1o]]","lead":"#linux","body":"#linux\n\nLinux provides `__user` annotation to mark userspace pointers. *Transfer functions* such as `copy_from_user` can only operate on those pointers. User pointers are always compared against userspace address space to avoid kernel pointers. An example of `get_user`:\n``` assembly\n.text\nENTRY(__get_user_1)\n    mov PER_CPU_VAR(current_task), %_ASM_DX\n    cmp TASK_addr_limit(%_ASM_DX),%_ASM_AX\n    jae bad_get_user\n    ASM_STAC\n1:  movzbl (%_ASM_AX),%edx\n    xor %eax,%eax\n    ASM_CLAC\n    ret\nENDPROC(__get_user_1)\n\nbad_get_user:\n    xor %edx,%edx\n    mov $(-EFAULT),%_ASM_AX\n    ASM_CLAC\n    ret\nEND(bad_get_user)\n\n_ASM_EXTABLE(1b,bad_get_user)\n```\n\nThe first two instructions check the pointer against the process descriptor to make sure it's not pointer from usersapce. Then it disable SMAP (ASM_STAC) and access userspace memory (at 1: block)","snippets":["#linux"],"rawContent":"# Accessing user memory from Kernel\n#linux\n\nLinux provides `__user` annotation to mark userspace pointers. *Transfer functions* such as `copy_from_user` can only operate on those pointers. User pointers are always compared against userspace address space to avoid kernel pointers. An example of `get_user`:\n``` assembly\n.text\nENTRY(__get_user_1)\n    mov PER_CPU_VAR(current_task), %_ASM_DX\n    cmp TASK_addr_limit(%_ASM_DX),%_ASM_AX\n    jae bad_get_user\n    ASM_STAC\n1:  movzbl (%_ASM_AX),%edx\n    xor %eax,%eax\n    ASM_CLAC\n    ret\nENDPROC(__get_user_1)\n\nbad_get_user:\n    xor %edx,%edx\n    mov $(-EFAULT),%_ASM_AX\n    ASM_CLAC\n    ret\nEND(bad_get_user)\n\n_ASM_EXTABLE(1b,bad_get_user)\n```\n\nThe first two instructions check the pointer against the process descriptor to make sure it's not pointer from usersapce. Then it disable SMAP (ASM_STAC) and access userspace memory (at 1: block)\n\n\n","wordCount":104,"tags":["linux"],"metadata":{},"created":"2023-08-09T13:49:43.460351471Z","modified":"2023-08-09T13:49:43.460398555Z","checksum":"1ad3d4da984f85d73f04005f77941bd93e1d80a1842d87f790b9283e72b0c152"},
    {"filename":"lfyjdfv4.md","filenameStem":"lfyjdfv4","path":"lfyjdfv4.md","absPath":"/Users/khadd/mynotes/lfyjdfv4.md","title":"Bit manipulation tricks","link":"[[lfyjdfv4]]","lead":"#programming #kernel #c #cxx","body":"#programming #kernel #c #cxx\n\n\n\n# Creating a mask with all N bit set\n```c\n#define mask(N) (1UL \u003c\u003c N) - 1\n```\nFor example, if N = 3, then the first shift will create ` 1000`. When subtracted by 1 bit, the result will be `111`\n\n# Checking if the Nth bit is set in a word\n\n```c\n#define check(word, N) (word \u0026 (1UL \u003c\u003c N))\n```\n# Clearing the Nth bit\n```c\n#define clear(word, N) (word \u0026 ~(1UL \u003c\u003c N))\n```\n# Check if a number is power of 2 \nThe key property is that if the number is the power of 2, it only has m bit set in the leftmost bit.\n```c\n#define is_power_of_2(n) ((n \u0026 (n - 1)) == 0)\n```","snippets":["#programming #kernel #c #cxx"],"rawContent":"# Bit manipulation tricks\n#programming #kernel #c #cxx\n\n\n\n# Creating a mask with all N bit set\n```c\n#define mask(N) (1UL \u003c\u003c N) - 1\n```\nFor example, if N = 3, then the first shift will create ` 1000`. When subtracted by 1 bit, the result will be `111`\n\n# Checking if the Nth bit is set in a word\n\n```c\n#define check(word, N) (word \u0026 (1UL \u003c\u003c N))\n```\n# Clearing the Nth bit\n```c\n#define clear(word, N) (word \u0026 ~(1UL \u003c\u003c N))\n```\n# Check if a number is power of 2 \nThe key property is that if the number is the power of 2, it only has m bit set in the leftmost bit.\n```c\n#define is_power_of_2(n) ((n \u0026 (n - 1)) == 0)\n```\n","wordCount":129,"tags":["programming","kernel","c","cxx"],"metadata":{},"created":"2023-08-09T13:49:43.469671251Z","modified":"2023-08-09T13:49:43.469719626Z","checksum":"4313c218c0b7504db9c206d496b2311930104e9d3632f7ac9e88f49247d3d54c"},
    {"filename":"1rqx4xia.md","filenameStem":"1rqx4xia","path":"1rqx4xia.md","absPath":"/Users/khadd/mynotes/1rqx4xia.md","title":"Bits in page table entries","link":"[[1rqx4xia]]","lead":"#os #architecture","body":"#os #architecture\n\n\n# Present flag\nThe *present* flag indicates that there exists a backing physical frame for this page table entry. If the present bit is not set, a page fault will be triggered.\n\n\n# Access and dirty flags\nOn x86, bit 5 is the *accessed* flag, and bit 6 is the *dirty* flag.\n\nThe _accessed_ flag is set when a page is accessed by the CPU during address translation. The *dirty* flag is set when a page is written by the CPU. \n\nAfter being set, these flags need to be cleared by the software.\n\nThe dirty bit indicates that page must be written to the disk before the frame can be reused for other pages. Else, the page content is unchanged, so it is safe to reuse the page [standford-paging].\n\n# References\n- @2023intel\n- [standford-paging](https://web.stanford.edu/~ouster/cgi-bin/cs140-winter16/lecture.php?topic=paging)","snippets":["#os #architecture"],"rawContent":"# Bits in page table entries\n#os #architecture\n\n\n# Present flag\nThe *present* flag indicates that there exists a backing physical frame for this page table entry. If the present bit is not set, a page fault will be triggered.\n\n\n# Access and dirty flags\nOn x86, bit 5 is the *accessed* flag, and bit 6 is the *dirty* flag.\n\nThe _accessed_ flag is set when a page is accessed by the CPU during address translation. The *dirty* flag is set when a page is written by the CPU. \n\nAfter being set, these flags need to be cleared by the software.\n\nThe dirty bit indicates that page must be written to the disk before the frame can be reused for other pages. Else, the page content is unchanged, so it is safe to reuse the page [standford-paging].\n\n# References\n- @2023intel\n- [standford-paging](https://web.stanford.edu/~ouster/cgi-bin/cs140-winter16/lecture.php?topic=paging)\n","wordCount":143,"tags":["os","architecture"],"metadata":{},"created":"2023-08-09T13:49:43.459966637Z","modified":"2023-08-09T13:49:43.460009845Z","checksum":"d72e515f4683595e686ffd79b9de17de60fc9da1ecde62ce05d9883bbaaaa04d"},
    {"filename":"mwf41frv.md","filenameStem":"mwf41frv","path":"mwf41frv.md","absPath":"/Users/khadd/mynotes/mwf41frv.md","title":"C programming notes","link":"[[mwf41frv]]","lead":"#programming #c #cxx","body":"#programming #c #cxx\n\n- [[lfyjdfv4]]","snippets":["#programming #c #cxx"],"rawContent":"# C programming notes\n#programming #c #cxx\n\n- [[lfyjdfv4]]\n\n\n","wordCount":9,"tags":["programming","c","cxx"],"metadata":{},"created":"2024-05-19T06:14:25.466257007Z","modified":"2024-05-19T06:14:25.466630294Z","checksum":"86db599502391877a0b4a39849b1e6be03ebc69b624a877d5e3fc2583940870f"},
    {"filename":"zw0lj520.md","filenameStem":"zw0lj520","path":"literature/zw0lj520.md","absPath":"/Users/khadd/mynotes/literature/zw0lj520.md","title":"CAP-VMs: Capability-Based Isolation and Sharing in the Cloud","link":"[[literature/zw0lj520]]","lead":"#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]","body":"#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]\n\n## One sentence summary\nThe paper built a container-like isolation abstraction on top of CHERI architecture for efficient sharing on and isolation.\n\n## Context\n### Containers vs. Virtual machines\nContainers and Virtual machines both have disadvantages for implementing isolation and sharing. See [[h3manv25]]. \n\n### Capabilities\nCheri capabilities enable in-process compartmentalization with the hybrid capability model.\n\n### Contributions\nThis paper proposed the best of both world with CHERI capabilities: *cVM*, new VM-like abstraction for cloud isolation with efficient, single-address space sharing.\n- Communication between cVMs bypass the OS with new in-process capabilities abstractions for trusted safe ipc.\n- Compatible with existing applications with the *hybrid* capability model. Only a subset of libC, the library OS, and the intravisor need to be capability-aware.\n- No namespace isolation is required, since the isolation boundary is in-process through capabilities. The OS is only needed for I/O, synchronization, execution context (similar to a VM).\n\n## System overview\nThe system introduces 2 layers of isolation. A *library OS* provides namespace isolation for and provides OS primitives for the cVMs. An *intravisor* manage cVMs instances, enable cross-communication and other primitives.\n\nThe program interacts with the libOS through the syscall interface provided by the musl libc. LibOS interact with intravisor through hostcall interface. Both interfaces are capability-ware.\n\n## APIs\nA set of APIs is provided to manage cVM and facilitate their communications.\n\nCP_FILE-based interfaces enable file-like access to other cVM memory through capability invocation.\nA cVM registers shared memory to be shared across other cVMs with a key. Other cVMs read and write into the CP-FILE obtained with the same key.\n\nCP_CALL-based interfaces allows for capability-based registration and invocation of external functions.\n\n## Capability management\nThe system revoke CAP_STORE from capabilities, preventing them from being stored into memory outside of the intra.","snippets":["#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]"],"rawContent":"# CAP-VMs: Capability-Based Isolation and Sharing in the Cloud \n#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]\n\n## One sentence summary\nThe paper built a container-like isolation abstraction on top of CHERI architecture for efficient sharing on and isolation.\n\n## Context\n### Containers vs. Virtual machines\nContainers and Virtual machines both have disadvantages for implementing isolation and sharing. See [[h3manv25]]. \n\n### Capabilities\nCheri capabilities enable in-process compartmentalization with the hybrid capability model.\n\n### Contributions\nThis paper proposed the best of both world with CHERI capabilities: *cVM*, new VM-like abstraction for cloud isolation with efficient, single-address space sharing.\n- Communication between cVMs bypass the OS with new in-process capabilities abstractions for trusted safe ipc.\n- Compatible with existing applications with the *hybrid* capability model. Only a subset of libC, the library OS, and the intravisor need to be capability-aware.\n- No namespace isolation is required, since the isolation boundary is in-process through capabilities. The OS is only needed for I/O, synchronization, execution context (similar to a VM).\n\n## System overview\nThe system introduces 2 layers of isolation. A *library OS* provides namespace isolation for and provides OS primitives for the cVMs. An *intravisor* manage cVMs instances, enable cross-communication and other primitives.\n\nThe program interacts with the libOS through the syscall interface provided by the musl libc. LibOS interact with intravisor through hostcall interface. Both interfaces are capability-ware.\n\n## APIs\nA set of APIs is provided to manage cVM and facilitate their communications.\n\nCP_FILE-based interfaces enable file-like access to other cVM memory through capability invocation.\nA cVM registers shared memory to be shared across other cVMs with a key. Other cVMs read and write into the CP-FILE obtained with the same key.\n\nCP_CALL-based interfaces allows for capability-based registration and invocation of external functions.\n\n## Capability management\nThe system revoke CAP_STORE from capabilities, preventing them from being stored into memory outside of the intra.\n\n","wordCount":312,"tags":["os","capabilities","vm","container","ipc","literature","cheri","libos"],"metadata":{},"created":"2023-08-09T13:49:43.470603963Z","modified":"2023-08-09T13:49:43.470660588Z","checksum":"01a044e0390963119a730dacc7e174bd51f825a0dc26477d8dc8d9ea09fd18be"},
    {"filename":"icjubure.md","filenameStem":"icjubure","path":"icjubure.md","absPath":"/Users/khadd/mynotes/icjubure.md","title":"Capabilities resources","link":"[[icjubure]]","lead":"- [Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes of capabilities by [[j19hdkto|Norman Hardy]] himself","body":"- [Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes of capabilities by [[j19hdkto|Norman Hardy]] himself","snippets":["- [Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes of capabilities by [[j19hdkto|Norman Hardy]] himself"],"rawContent":"# Capabilities resources\n\n- [Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes of capabilities by [[j19hdkto|Norman Hardy]] himself\n\n\n","wordCount":16,"tags":[],"metadata":{},"created":"2023-08-09T13:49:43.468552248Z","modified":"2023-08-09T13:49:43.468590498Z","checksum":"e4175df3f803f26504b342cf7a11b48ce48ab89eac869b81b8baba45f7f962be"},
    {"filename":"douswvq0.md","filenameStem":"douswvq0","path":"fleeting/douswvq0.md","absPath":"/Users/khadd/mynotes/fleeting/douswvq0.md","title":"Compartment-aware hardening","link":"[[fleeting/douswvq0]]","lead":"#fleeting #idea","body":"#fleeting #idea\n \n\n# Background\nSoftware defenses such as DFI/CPI/CFI see the program at one unit.\n\nEfforts in compartmentalization brings the boundary to within the program. \n\n\n# Main arguments\nExisting software hardening techniques are not compartment-aware, so they miss classes of attacks on compartment interfaces.\n\nMaking them compartment-aware requires some static / runtime analysis at the boundary.\n\n\n# Compartment-aware CFI\nCFI type matching + compartment-aware narrowing for cross-compartment indirect calls\ne.g., A site can only call type B from compartment X.\n\n# Compartment-aware DFI\nAssuming data isolation between domains.\nDFI only for cross-domain objects.\n- Use static analysis to determine subset of sensitive objects.\n- We enforce DFI on them.\n\nThis has sanitizing effect, remove CIV.","snippets":["#fleeting #idea"],"rawContent":"# Compartment-aware hardening\n#fleeting #idea\n \n\n# Background\nSoftware defenses such as DFI/CPI/CFI see the program at one unit.\n\nEfforts in compartmentalization brings the boundary to within the program. \n\n\n# Main arguments\nExisting software hardening techniques are not compartment-aware, so they miss classes of attacks on compartment interfaces.\n\nMaking them compartment-aware requires some static / runtime analysis at the boundary.\n\n\n# Compartment-aware CFI\nCFI type matching + compartment-aware narrowing for cross-compartment indirect calls\ne.g., A site can only call type B from compartment X.\n\n# Compartment-aware DFI\nAssuming data isolation between domains.\nDFI only for cross-domain objects.\n- Use static analysis to determine subset of sensitive objects.\n- We enforce DFI on them.\n\nThis has sanitizing effect, remove CIV.\n\n\n\n\n\n\n\n\n\n\n\n\n","wordCount":118,"tags":["fleeting","idea"],"metadata":{},"created":"2023-08-09T13:49:43.467924037Z","modified":"2023-08-09T13:49:43.467970287Z","checksum":"06d48b7b6ff77b495bbc567181a1c7c9dc18cb64107de5dd989c6d98c4bbf5e2"},
    {"filename":"pc1fa30d.md","filenameStem":"pc1fa30d","path":"pc1fa30d.md","absPath":"/Users/khadd/mynotes/pc1fa30d.md","title":"Concepts of an Operating System","link":"[[pc1fa30d]]","lead":"","body":"","snippets":[],"rawContent":"# Concepts of an Operating System\n\n\n","wordCount":6,"tags":[],"metadata":{},"created":"2023-08-09T13:49:43.471372132Z","modified":"2023-08-09T13:49:43.47140359Z","checksum":"6c2c4935bd31a4f174099abdfe2c80525dfc3a73f8d463122cf2ef6d7efd48d8"},
    {"filename":"y9wu5ut7.md","filenameStem":"y9wu5ut7","path":"y9wu5ut7.md","absPath":"/Users/khadd/mynotes/y9wu5ut7.md","title":"Confused deputy","link":"[[y9wu5ut7]]","lead":"#capabilities #compartmentalization","body":"#capabilities #compartmentalization\n\nConfused deputy happens when a high-privilege system is tricked into perform a certain action on behalf of a lower privilege system.\n\n## An example\nThe example  used in the original paper [@hardy1988confused] is a compiler program. A user invoke the compiler with the name of the input file to compile a program, and also an output file to receive statistics.\nThe compiler is given the authority to write into its home directory. Let's say there is another file in the home directory of the compiler that contains the billing information. A malicious user of the compiler can invoke it to trick the compiler into writing into the billing file, since it is within the authority of the compiler.\n\nIn a sense, confused deputy happens due to the *ambient authority*. In the compiler case, the compiler user obtains more authority than needed (access to the whole home directory) to perform it job (read input, write output). \n\nTo solve this problem, a naive solution would be to switch the authority of the compiler (through some system call) to that of the invoker. However, such a system would lead to complexity when there is a high amount of authorities, and also hard to generalize [@hardy1988confused]. \n\n## Interface vulnerabilities\nInterface vulnerabilities is a manifestation of confused deputy problem, where different mutually distrusting entities interacts with each other through exposed interfaces [@lefeuvre2022assessing]. For instance, a malicious process can exploit the system call interface to tricking the kernel into corrupting itself. Interface vulnerabilites is also there at other boundaries, such as libraries, in-process compartments [@lefeuvre2022assessing].","snippets":["#capabilities #compartmentalization"],"rawContent":"# Confused deputy\n#capabilities #compartmentalization\n\nConfused deputy happens when a high-privilege system is tricked into perform a certain action on behalf of a lower privilege system.\n\n## An example\nThe example  used in the original paper [@hardy1988confused] is a compiler program. A user invoke the compiler with the name of the input file to compile a program, and also an output file to receive statistics.\nThe compiler is given the authority to write into its home directory. Let's say there is another file in the home directory of the compiler that contains the billing information. A malicious user of the compiler can invoke it to trick the compiler into writing into the billing file, since it is within the authority of the compiler.\n\nIn a sense, confused deputy happens due to the *ambient authority*. In the compiler case, the compiler user obtains more authority than needed (access to the whole home directory) to perform it job (read input, write output). \n\nTo solve this problem, a naive solution would be to switch the authority of the compiler (through some system call) to that of the invoker. However, such a system would lead to complexity when there is a high amount of authorities, and also hard to generalize [@hardy1988confused]. \n\n## Interface vulnerabilities\nInterface vulnerabilities is a manifestation of confused deputy problem, where different mutually distrusting entities interacts with each other through exposed interfaces [@lefeuvre2022assessing]. For instance, a malicious process can exploit the system call interface to tricking the kernel into corrupting itself. Interface vulnerabilites is also there at other boundaries, such as libraries, in-process compartments [@lefeuvre2022assessing].\n\n","wordCount":264,"tags":["capabilities","compartmentalization"],"metadata":{},"created":"2023-08-09T13:49:43.478549155Z","modified":"2024-05-19T05:59:38.560436427Z","checksum":"257f7dca5c435cd7883263799e46aff8ecaff39d75976f3d8a69f1589294bdcb"},
    {"filename":"h3manv25.md","filenameStem":"h3manv25","path":"h3manv25.md","absPath":"/Users/khadd/mynotes/h3manv25.md","title":"Containers vs. Virtual machines","link":"[[h3manv25]]","lead":"#vm #container #cloud #ipc #os #virtualization","body":"#vm #container #cloud #ipc #os #virtualization\n\nContainers and virtual machines ([[s16ct1rj]]) are two main isolation primitives when it come to cloud isolation.\n\nVirtual machines provides strong isolation between application components and a small TCB a small hypervisor need to be trusted. \nHowever, data sharing between VMs is challenging and commonly have high overheads (see [@yasukata2023exitless]).\n\nOn the other hand, containers allows application components to share the underlying OS. This enable richer IPC mechanisms for better data sharing. This comes at the cost of larger TCB: a shared OS have to implement namespace isolation and complex IPC primitives [@sartakov2022capvms]. \n\nStill, sharing is coarse-grained in both of the case, since the IPC interfaces are designed at page granularity. \nSharing is also expensive. VMFUNC-based sharing in VMs have expensive cost of VMEEXIT, which exit-less mechanisms tries to achieve [@yasukata2023exitless].","snippets":["#vm #container #cloud #ipc #os #virtualization"],"rawContent":"# Containers vs. Virtual machines\n#vm #container #cloud #ipc #os #virtualization\n\nContainers and virtual machines ([[s16ct1rj]]) are two main isolation primitives when it come to cloud isolation.\n\nVirtual machines provides strong isolation between application components and a small TCB a small hypervisor need to be trusted. \nHowever, data sharing between VMs is challenging and commonly have high overheads (see [@yasukata2023exitless]).\n\nOn the other hand, containers allows application components to share the underlying OS. This enable richer IPC mechanisms for better data sharing. This comes at the cost of larger TCB: a shared OS have to implement namespace isolation and complex IPC primitives [@sartakov2022capvms]. \n\nStill, sharing is coarse-grained in both of the case, since the IPC interfaces are designed at page granularity. \nSharing is also expensive. VMFUNC-based sharing in VMs have expensive cost of VMEEXIT, which exit-less mechanisms tries to achieve [@yasukata2023exitless].  \n\n\n\n\n\n\n","wordCount":141,"tags":["os","virtualization","vm","container","cloud","ipc"],"metadata":{},"created":"2023-08-09T13:49:43.468262955Z","modified":"2023-08-09T13:49:43.468310705Z","checksum":"fbca22c2e2781ec8e5c39520ee9fb9183c0eb3f916b11e35b36879691cdcbf2e"},
    {"filename":"c6cpkdl9.md","filenameStem":"c6cpkdl9","path":"c6cpkdl9.md","absPath":"/Users/khadd/mynotes/c6cpkdl9.md","title":"Context-sensitive heap modeling","link":"[[c6cpkdl9]]","lead":"#analysis #points-to-analysis","body":"#analysis #points-to-analysis\n\nPoints-to analysis often requre heap modeling, which is essentially tracking which functions can allocate pointers. Commonly, you would hard-code the allocation function name (e.g., `malloc`), and assume that the function returns a heap object.\n\nHowever, things get compilated when allocator wrappers are used.\nThis is troublesome for automated analysis in certain cases. Consider the following code. Something like this is commonly seen in C libraries.\n```c \nkey_t* key_alloc(){\n  return malloc(sizeof(key_t));\n}\nvoid fee(){\n  void* buf = malloc(512);\n  unsafe_access(buf);\n}\nvoid foo(){ \n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\nIn Rust, there are also similar cases. `Box\u003cT\u003e` abstracts away the malloc call.\n\nLet say we want to replace all object touched by `unsafe_access` with a different allocator. Points-to analysis is needed for this case. For `fee`, it is straightforward, since the analysis can immediately find the allocation function. However, for `foo`, there is a complication. If we perform a *context-insensitive* points-to analysis on on the key access, the result will contains *all* pointers that are allocated using `key_alloc()`.\n\nHence, a *context-sensitve* analysis is needed for modeling the heap in this case.\n\nThere are two methods to achieve context sensitivity. The first is to just use a *context-senstive* analysis, which is very expensive.\n\nThe second is to perform cloning to introduce context senstivity. In the above example, cloning key_alloc into `unsafe_key_alloc` and `key_alloc_safe` , and replace the key_alloc call would differentiate the heap context between foo and bar. \n```c\nvoid foo(){ \n  key_t* key = key_alloc_unsafe();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc_safe();\n  safe_access(key);\n}\n```\n\nAnother challenge here is to identify which *depth* to clone. \n```c\nkey_t* special_key_alloc(){\n  key_t *key = key_alloc();\n  key-\u003etype = SPECIAL;\n  return key;\n}\nvoid fez(){\n  key_t  *key = special_key_alloc();\n  unsafe_access(key);\n}\nvoid fiz(){\n  key_t  *key = special_key_alloc();\n  safe_access(key);\n}\nvoid foo(){ \n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\nIn the above example, we need to clone the contexts for all 4 functions.","snippets":["#analysis #points-to-analysis"],"rawContent":"# Context-sensitive heap modeling\n#analysis #points-to-analysis\n\nPoints-to analysis often requre heap modeling, which is essentially tracking which functions can allocate pointers. Commonly, you would hard-code the allocation function name (e.g., `malloc`), and assume that the function returns a heap object.\n\nHowever, things get compilated when allocator wrappers are used.\nThis is troublesome for automated analysis in certain cases. Consider the following code. Something like this is commonly seen in C libraries.\n```c \nkey_t* key_alloc(){\n  return malloc(sizeof(key_t));\n}\nvoid fee(){\n  void* buf = malloc(512);\n  unsafe_access(buf);\n}\nvoid foo(){ \n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\nIn Rust, there are also similar cases. `Box\u003cT\u003e` abstracts away the malloc call.\n\nLet say we want to replace all object touched by `unsafe_access` with a different allocator. Points-to analysis is needed for this case. For `fee`, it is straightforward, since the analysis can immediately find the allocation function. However, for `foo`, there is a complication. If we perform a *context-insensitive* points-to analysis on on the key access, the result will contains *all* pointers that are allocated using `key_alloc()`.\n\nHence, a *context-sensitve* analysis is needed for modeling the heap in this case.\n\nThere are two methods to achieve context sensitivity. The first is to just use a *context-senstive* analysis, which is very expensive.\n\nThe second is to perform cloning to introduce context senstivity. In the above example, cloning key_alloc into `unsafe_key_alloc` and `key_alloc_safe` , and replace the key_alloc call would differentiate the heap context between foo and bar. \n```c\nvoid foo(){ \n  key_t* key = key_alloc_unsafe();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc_safe();\n  safe_access(key);\n}\n```\n\nAnother challenge here is to identify which *depth* to clone. \n```c\nkey_t* special_key_alloc(){\n  key_t *key = key_alloc();\n  key-\u003etype = SPECIAL;\n  return key;\n}\nvoid fez(){\n  key_t  *key = special_key_alloc();\n  unsafe_access(key);\n}\nvoid fiz(){\n  key_t  *key = special_key_alloc();\n  safe_access(key);\n}\nvoid foo(){ \n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\nIn the above example, we need to clone the contexts for all 4 functions.\n","wordCount":338,"tags":["analysis","points-to-analysis"],"metadata":{},"created":"2023-08-09T13:49:43.46165835Z","modified":"2023-08-09T13:49:43.461736351Z","checksum":"9c6969a0223cb582b4d078348c0c6663731e13c0d41ec555c30eeeccf7f9f6e2"},
    {"filename":"1yhmh234.md","filenameStem":"1yhmh234","path":"1yhmh234.md","absPath":"/Users/khadd/mynotes/1yhmh234.md","title":"Controlled-channel Attacks","link":"[[1yhmh234]]","lead":"#attack #tee #sgx","body":"#attack #tee #sgx\n\nControlled-channel attack refers to attacks launched by the higher-privilege system against the lower privilege one. The confidential lower-privilege system (SGX, VM) lacks capabilities (e.g., paging, file access), and need to request the higher-privilege system (OS, hypervisor) for resources. The higher-privilege can use this *controlled-channel* to monitor the lower-privilege one. This scenario happen especially in confidential execution environment, where the protected program do not trust the underlying infrastructure, or cloud service provider (CSP).","snippets":["#attack #tee #sgx"],"rawContent":"# Controlled-channel Attacks\n#attack #tee #sgx\n\nControlled-channel attack refers to attacks launched by the higher-privilege system against the lower privilege one. The confidential lower-privilege system (SGX, VM) lacks capabilities (e.g., paging, file access), and need to request the higher-privilege system (OS, hypervisor) for resources. The higher-privilege can use this *controlled-channel* to monitor the lower-privilege one. This scenario happen especially in confidential execution environment, where the protected program do not trust the underlying infrastructure, or cloud service provider (CSP).\n","wordCount":78,"tags":["attack","tee","sgx"],"metadata":{},"created":"2023-08-09T13:49:43.460034137Z","modified":"2023-08-09T13:49:43.460077387Z","checksum":"46270c37878db91d5bd3db827a24df78ba8f9875a6964911afd7d266905e216a"},
    {"filename":"qq4qcbos.md","filenameStem":"qq4qcbos","path":"qq4qcbos.md","absPath":"/Users/khadd/mynotes/qq4qcbos.md","title":"Controlled-channel attacks against SEV","link":"[[qq4qcbos]]","lead":"#controlled-channel #side-channel #sev #tee","body":"#controlled-channel #side-channel #sev #tee\n\n# Nested page fault side-channels\nVirtualization hardware enables two-stage translation process from gVA to gPA, and from gPA to hPA through the nested page table (NPT) ([[d3nt6uix]]). This is the same in SEV. Although there is no official documentation, many paper indicate that hypervisor cannot intercept guest page faults (gPF) and look for faulting address.\n\nPage fault attacks in SEV is similar to the controlled-channel attacks on SGX @xu2015controlledchannel. \nThe hypervisor can unset the present bit (`P` bit) in the NPT for particular physical pages, such that nested page fault (NPF) will be generated when the page is accessed by the VM, which the hypervisor can capture and analyze.\n\n# IO events\nSome applications requiring I/O events can leak certain behaviors of the program. For instance, @morbitzer2019extracting, @li2019exploiting use network packets to determine the start/end of a TLS connection, and disk I/O to determine disk encryption operation.\n\n\n# Related notes\n- @li2019exploiting: [[literature/ncfh611p]]","snippets":["#controlled-channel #side-channel #sev #tee"],"rawContent":"# Controlled-channel attacks against SEV\n#controlled-channel #side-channel #sev #tee\n\n# Nested page fault side-channels\nVirtualization hardware enables two-stage translation process from gVA to gPA, and from gPA to hPA through the nested page table (NPT) ([[d3nt6uix]]). This is the same in SEV. Although there is no official documentation, many paper indicate that hypervisor cannot intercept guest page faults (gPF) and look for faulting address.\n\nPage fault attacks in SEV is similar to the controlled-channel attacks on SGX @xu2015controlledchannel. \nThe hypervisor can unset the present bit (`P` bit) in the NPT for particular physical pages, such that nested page fault (NPF) will be generated when the page is accessed by the VM, which the hypervisor can capture and analyze.\n\n# IO events\nSome applications requiring I/O events can leak certain behaviors of the program. For instance, @morbitzer2019extracting, @li2019exploiting use network packets to determine the start/end of a TLS connection, and disk I/O to determine disk encryption operation.\n\n\n# Related notes\n- @li2019exploiting: [[literature/ncfh611p]]\n","wordCount":162,"tags":["tee","side-channel","controlled-channel","sev"],"metadata":{},"created":"2023-08-09T13:49:43.471699508Z","modified":"2023-08-09T13:49:43.471761299Z","checksum":"e3d7b4385bb89907a20faf04b9ffb37bf87bb5b6db63a8ed5f544fc66d2654a7"},
    {"filename":"i2blyo37.md","filenameStem":"i2blyo37","path":"i2blyo37.md","absPath":"/Users/khadd/mynotes/i2blyo37.md","title":"Cost of IPC in microkernels","link":"[[i2blyo37]]","lead":"#microkernel #sel4 #ipc #kpti #os","body":"#microkernel #sel4 #ipc #kpti #os\n\nIn microkernels such as sel4, kernel code is kept to the minimum, and most of the system services such as file system, and networking are moved into the userspace as a *system server*. Applications that use those services need to invoke them through *IPCs*.\nSince those services are in the userspace in different address spaces, an IPC would consist of:\n1. Privilege switch to from application the kernel\n2. Process switch to the callee process\n3. Privilege switch to the callee  \n2. Process switch back to the caller  process\n4. Privilege switch from kernel to the caller\n\n## Overhead analysis\n[@gu2020armonizing] (see [[literature/2a7l7odo]]) performed a study of the source of overheads of such IPC. SQLite3 is run on Zircon and seL4 microkernels. It is found that total IPC time is 79% [of](2024-05-19_of.md) the time on Zircon and 44% of the time on seL4 (with KPTI).\n\nThe overheads of each component are also studied in the following table. \n\n|   Parts  | w/o KPTI    | w/ KPTI    |\n| ---------------- | --------------- | --------------- |\n| Privilege switch    | 158    | 690    |\n|  Process switch    | 295    | included above    |\n| Others   | 277   | 320   |\n| Total   | 730   | 1010   |\n\n*Privilege switch* is the overhead of a syscall instruction.\n*Process switch* is mostly changing the page table by writing into the CR3 register (about 270 cycles). With KPTI enabled, an additional page table switch needs to be added to every user-to-kernel privilege switch, which adds another layer of overheads. \nAdditionally, there are also other types of overheads such as permission checks, and capabilities checks.","snippets":["#microkernel #sel4 #ipc #kpti #os"],"rawContent":"# Cost of IPC in microkernels\n#microkernel #sel4 #ipc #kpti #os\n\nIn microkernels such as sel4, kernel code is kept to the minimum, and most of the system services such as file system, and networking are moved into the userspace as a *system server*. Applications that use those services need to invoke them through *IPCs*.\nSince those services are in the userspace in different address spaces, an IPC would consist of:\n1. Privilege switch to from application the kernel\n2. Process switch to the callee process\n3. Privilege switch to the callee  \n2. Process switch back to the caller  process\n4. Privilege switch from kernel to the caller\n\n## Overhead analysis\n[@gu2020armonizing] (see [[literature/2a7l7odo]]) performed a study of the source of overheads of such IPC. SQLite3 is run on Zircon and seL4 microkernels. It is found that total IPC time is 79% [of](2024-05-19_of.md) the time on Zircon and 44% of the time on seL4 (with KPTI).\n\nThe overheads of each component are also studied in the following table. \n\n|   Parts  | w/o KPTI    | w/ KPTI    |\n| ---------------- | --------------- | --------------- |\n| Privilege switch    | 158    | 690    |\n|  Process switch    | 295    | included above    |\n| Others   | 277   | 320   |\n| Total   | 730   | 1010   |\n\n*Privilege switch* is the overhead of a syscall instruction.\n*Process switch* is mostly changing the page table by writing into the CR3 register (about 270 cycles). With KPTI enabled, an additional page table switch needs to be added to every user-to-kernel privilege switch, which adds another layer of overheads. \nAdditionally, there are also other types of overheads such as permission checks, and capabilities checks.\n\n","wordCount":279,"tags":["os","microkernel","ipc","sel4","kpti"],"metadata":{},"created":"2023-08-09T13:49:43.468481331Z","modified":"2024-05-19T05:59:42.733278117Z","checksum":"be172d84a9e5422450e4ecb3f702fe0e2bf0de24a5b36f20a642bdf9b4dfee53"},
    {"filename":"v2qcb4lm.md","filenameStem":"v2qcb4lm","path":"v2qcb4lm.md","absPath":"/Users/khadd/mynotes/v2qcb4lm.md","title":"Cryptographic Capabilities for efficient Microkernel Access Control","link":"[[v2qcb4lm]]","lead":"#project","body":"#project\n\n## Introduction\n### Microkernel is efficient and secure\n\n### Main overheads in Microkernels is IPC \n\n### Capability management and permission checks is one of the main overheads\n\n### Cryptographic capabilities eliminates the need for capability management\n\n\n## References\n\n[@sartakov2022capvms]\n@gu2020harmonizing","snippets":["#project"],"rawContent":"# Cryptographic Capabilities for efficient Microkernel Access Control\n#project\n\n## Introduction\n### Microkernel is efficient and secure\n\n### Main overheads in Microkernels is IPC \n\n### Capability management and permission checks is one of the main overheads\n\n### Cryptographic capabilities eliminates the need for capability management\n\n\n## References\n\n[@sartakov2022capvms]\n@gu2020harmonizing\n","wordCount":49,"tags":["project"],"metadata":{},"created":"2023-08-09T13:49:43.471637882Z","modified":"2023-08-09T13:49:43.471674883Z","checksum":"6845fb5f5812719bd39d49dce6016b996b3c7e47abd1b99979e2d5f74bc4f5e1"},
    {"filename":"zzq5zy5v.md","filenameStem":"zzq5zy5v","path":"zzq5zy5v.md","absPath":"/Users/khadd/mynotes/zzq5zy5v.md","title":"Detecting bugs in Rust","link":"[[zzq5zy5v]]","lead":"#rust","body":"#rust\n\n\n# Rudra\nRudra @bae2021rudra analyzes Rust HIR and MIR to have a *generic type-aware* analysis.\nGeneric type-awareness is necessary, because a certain bugs only happen for the implementation of specific types.\n\n```rust\nfn double_drop\u003cT\u003e (mut val: T){\n  unsafe {ptr::drop_in_place(\u0026mut val);}\n  drop(val);\n}\ndouble_drop(123); // no violation since drop on integer is no-op\ndouble_drop(vec![1, 2, 3]); // double-free happens\n```\n\nMore specifically, Rudra consider a generic function having bugs, if any of the instantiation has a safety bug.\n\n## Unsafe Dataflow Checker\nThis checker simply find if their exists a dataflow from the start of lifetime bypass to a suspicious function call. The hope is to find dataflwo from unsafe into functions that might `panic`, or functions that might implicitly requires some higher-order invariants (but not upholded by the unsafe caller).\n\nIt is suprising that this simple heuristic helps finds a lot of bugs. On the other hand, it has very high false positive rate (53.3% precision on highest precision). \nMoreover, this kind of heuristic is coarse-grained, it does not try to identify the *root cause* of the bug, but instead finds pattern that commonly have bugs,and rely on the programmer instead instead to filter out the bugs.\n\n\nThere are two heuristics used by this checker,  to determine the lifetime bypass locations, and to determine suspicious function calls.\n\n### Suspicious function calls\nThis check marks all *unresolvable generic function call* as suspicious. Unresolvable functions are functions that their definitions cannot be found without precise type parameters. \nAn example was:\n```rust\nfn foo\u003cT\u003e(reader: T)\n  where T: Reader {\n  reader::read();\n}\n\n```\n\nIn this case, to know the definition of `read()`, the type of `reader` must be known, but it is available at runtime. On the other hand, `Vec\u003cT\u003e::push()` has implementation of `push()` implemeted for all possible type `T`.\n\nThe author finds that those unresolable function are where programmers usually make mistake, since they have to *speculate* about the function behaviors.\n\n\n\n\n\n### Lifetime bypass locations\nThere are six classes of lifetime bypasses:\n- Unintialized value (created by extending `Vec` with `Vec::set_len()`)\n- Duplicating lifetime (e.g., `mem::read()`)\n- Overwriting memory (e.g., `mem::write`)\n- Copying values (e.g., buffer copy) (this has the effect of duplicating and overwriting)\n- Transmuting a type and its lifetime\n- Converting a pointer to a reference\n\nRudra uses three precision settings:\n- High precision only detect uninitialized values (e.g., `Vec::set_len()`)\n- Medium precision setting additionally find lifetime bypass using `read()`, `write()`, `copy()`.\n- Low precision setting find all `transmute()`a and raw pointer casting.","snippets":["#rust"],"rawContent":"# Detecting bugs in Rust\n#rust\n\n\n# Rudra\nRudra @bae2021rudra analyzes Rust HIR and MIR to have a *generic type-aware* analysis.\nGeneric type-awareness is necessary, because a certain bugs only happen for the implementation of specific types.\n\n```rust\nfn double_drop\u003cT\u003e (mut val: T){\n  unsafe {ptr::drop_in_place(\u0026mut val);}\n  drop(val);\n}\ndouble_drop(123); // no violation since drop on integer is no-op\ndouble_drop(vec![1, 2, 3]); // double-free happens\n```\n\nMore specifically, Rudra consider a generic function having bugs, if any of the instantiation has a safety bug.\n\n## Unsafe Dataflow Checker\nThis checker simply find if their exists a dataflow from the start of lifetime bypass to a suspicious function call. The hope is to find dataflwo from unsafe into functions that might `panic`, or functions that might implicitly requires some higher-order invariants (but not upholded by the unsafe caller).\n\nIt is suprising that this simple heuristic helps finds a lot of bugs. On the other hand, it has very high false positive rate (53.3% precision on highest precision). \nMoreover, this kind of heuristic is coarse-grained, it does not try to identify the *root cause* of the bug, but instead finds pattern that commonly have bugs,and rely on the programmer instead instead to filter out the bugs.\n\n\nThere are two heuristics used by this checker,  to determine the lifetime bypass locations, and to determine suspicious function calls.\n\n### Suspicious function calls\nThis check marks all *unresolvable generic function call* as suspicious. Unresolvable functions are functions that their definitions cannot be found without precise type parameters. \nAn example was:\n```rust\nfn foo\u003cT\u003e(reader: T)\n  where T: Reader {\n  reader::read();\n}\n\n```\n\nIn this case, to know the definition of `read()`, the type of `reader` must be known, but it is available at runtime. On the other hand, `Vec\u003cT\u003e::push()` has implementation of `push()` implemeted for all possible type `T`.\n\nThe author finds that those unresolable function are where programmers usually make mistake, since they have to *speculate* about the function behaviors.\n\n\n\n\n\n### Lifetime bypass locations\nThere are six classes of lifetime bypasses:\n- Unintialized value (created by extending `Vec` with `Vec::set_len()`)\n- Duplicating lifetime (e.g., `mem::read()`)\n- Overwriting memory (e.g., `mem::write`)\n- Copying values (e.g., buffer copy) (this has the effect of duplicating and overwriting)\n- Transmuting a type and its lifetime\n- Converting a pointer to a reference\n\nRudra uses three precision settings:\n- High precision only detect uninitialized values (e.g., `Vec::set_len()`)\n- Medium precision setting additionally find lifetime bypass using `read()`, `write()`, `copy()`.\n- Low precision setting find all `transmute()`a and raw pointer casting.\n","wordCount":419,"tags":["rust"],"metadata":{},"created":"2023-08-09T13:49:43.478861239Z","modified":"2023-08-09T13:49:43.478911489Z","checksum":"73cc8eb98a7406f0beea9e1dc18a6ff639f41d1e9f3c7555f7111514832e6da5"},
    {"filename":"f25v3txq.md","filenameStem":"f25v3txq","path":"f25v3txq.md","absPath":"/Users/khadd/mynotes/f25v3txq.md","title":"Do only what only you can do","link":"[[f25v3txq]]","lead":"#quote","body":"#quote\n\nThe advice is given by Dijkstra when asked how to select a research topic.","snippets":["#quote"],"rawContent":"# Do only what only you can do\n#quote\n\nThe advice is given by Dijkstra when asked how to select a research topic. \n\n\n","wordCount":23,"tags":["quote"],"metadata":{},"created":"2024-05-19T06:08:00.353386427Z","modified":"2024-05-19T06:08:00.353621597Z","checksum":"400065023950310586de7452956e32af03f77e069d682739c9db016d29be856e"},
    {"filename":"9zudb41g.md","filenameStem":"9zudb41g","path":"9zudb41g.md","absPath":"/Users/khadd/mynotes/9zudb41g.md","title":"Emulating x86 push and pop on ARM","link":"[[9zudb41g]]","lead":"#assembly #arm","body":"#assembly #arm\n\nAlthough there is no push and pop instructions, Arm support addressing modes that can both update and address memory. This can be used to implement stack push and pop\nMore concretely, post-indexing is used for push, and pre-indexing is used for pop\n\nPre-indexing update the address register *before* the store, which is essentialy the same as x86 push instruction that decrease the stack pointer, then store the value\n``` asm\nstr x1, [sp, -#16]!\n```\n\nPre-index addressing update the address register after the store. \n``` asm\nldr x1, [sp] #16\n```\n\nSource: [Addressing Lab](https://www.cs.uregina.ca/Links/class-info/301/ARM-addressing/lecture.html)","snippets":["#assembly #arm"],"rawContent":"# Emulating x86 push and pop on ARM\n#assembly #arm\n\nAlthough there is no push and pop instructions, Arm support addressing modes that can both update and address memory. This can be used to implement stack push and pop\nMore concretely, post-indexing is used for push, and pre-indexing is used for pop\n\nPre-indexing update the address register *before* the store, which is essentialy the same as x86 push instruction that decrease the stack pointer, then store the value\n``` asm\nstr x1, [sp, -#16]!\n```\n\nPre-index addressing update the address register after the store. \n``` asm\nldr x1, [sp] #16\n```\n\nSource: [Addressing Lab](https://www.cs.uregina.ca/Links/class-info/301/ARM-addressing/lecture.html)\n\n\n","wordCount":104,"tags":["assembly","arm"],"metadata":{},"created":"2023-08-09T13:49:43.461055432Z","modified":"2023-08-09T13:49:43.461105099Z","checksum":"91a6b4a805f8745061324a66dca4cc9a579675d644d25602edb6b50766d72e11"},
    {"filename":"mt8zp6w4.md","filenameStem":"mt8zp6w4","path":"mt8zp6w4.md","absPath":"/Users/khadd/mynotes/mt8zp6w4.md","title":"Enforcing strict type checks in C","link":"[[mt8zp6w4]]","lead":"#c #cxx #programming","body":"#c #cxx #programming\n\n\n\n\n*Strict typedef*, or *Strong typedef*, enable strict checking of the aliased type. This is sometimes useful when you want to differentiate same underlying type, but different classes. For instance, different type of index all have the same int type.\nC and C++ does not support this at the language level.\n\nHowever, there is a trick to achieve this, by defining each type as a separated struct. \n\n```c\ntypedef struct {\n  int id; \n} int_type_a_t;\n\ntypedef struct {\n  int id; \n} int_type_a_t;\n```\n\nIn c++, there is the boost library `BOOST_STRONG_TYPEDEF`, which enable the strong typedef checking.\n\n# Reference\n- [enforce-strong-type-checking-in-c-type-strictness-for-typedefs](https://stackoverflow.com/questions/376452/enforce-strong-type-checking-in-c-type-strictness-for-typedefs)","snippets":["#c #cxx #programming"],"rawContent":"# Enforcing strict type checks in C\n#c #cxx #programming\n\n\n\n\n*Strict typedef*, or *Strong typedef*, enable strict checking of the aliased type. This is sometimes useful when you want to differentiate same underlying type, but different classes. For instance, different type of index all have the same int type.\nC and C++ does not support this at the language level.\n\nHowever, there is a trick to achieve this, by defining each type as a separated struct. \n\n```c\ntypedef struct {\n  int id; \n} int_type_a_t;\n\ntypedef struct {\n  int id; \n} int_type_a_t;\n```\n\nIn c++, there is the boost library `BOOST_STRONG_TYPEDEF`, which enable the strong typedef checking.\n\n# Reference\n- [enforce-strong-type-checking-in-c-type-strictness-for-typedefs](https://stackoverflow.com/questions/376452/enforce-strong-type-checking-in-c-type-strictness-for-typedefs)\n\n\n\n","wordCount":110,"tags":["programming","c","cxx"],"metadata":{},"created":"2023-08-09T13:49:43.470819005Z","modified":"2023-08-09T13:49:43.470858755Z","checksum":"1f165c6a30b5d7615f079104a7b82d2a64ac6024eb23736fcc3cdacdda4e7e0b"},
    {"filename":"d27hs51i.md","filenameStem":"d27hs51i","path":"d27hs51i.md","absPath":"/Users/khadd/mynotes/d27hs51i.md","title":"EuroSys 2023","link":"[[d27hs51i]]","lead":"#conference","body":"#conference\n\nServerless\n- Groundhog: Efficient Request Isolation in FaaS\n- Unikernel Linux (UKL)","snippets":["#conference"],"rawContent":"# EuroSys 2023\n#conference\n\nServerless\n- Groundhog: Efficient Request Isolation in FaaS\n- Unikernel Linux (UKL)\n\n\n","wordCount":16,"tags":["conference"],"metadata":{},"created":"2023-08-09T13:49:43.462255561Z","modified":"2023-08-09T13:49:43.462303436Z","checksum":"a026e2fad79f4a4470d6bf0a276488c35d52e9014961a812132de70a2c569f5f"},
    {"filename":"jcoxpgnk.md","filenameStem":"jcoxpgnk","path":"jcoxpgnk.md","absPath":"/Users/khadd/mynotes/jcoxpgnk.md","title":"Exitless system calls for SGX","link":"[[jcoxpgnk]]","lead":"#sgx #tee #system-call #performance #rpc","body":"#sgx #tee #system-call #performance #rpc\n\nTo perform system calls in SGX, the enclave must perform enclave exit and enter through `EEXIT`, `EENTER`. It is found that these two instructions have heavy overheads of about 3,300 and 3,800 cycles @orenbach2017eleos. This is much higher than the overheads of a normal system call, about 250 cycles.\n\nAnother cost of SGX is due to page fault, since in an enclave exit also need to be triggered.\n\n# Elos\n## RPC for system calls\n@orenbach2017eleos proposed using RPC instead to serve system calls on an enclave. The system employs a separated thread in the untrusted part of the application to serve system call. Ocalls in SGX for serving system call is then replaced with RPC to the system call-serving threads. \n\nMoreover, the system uses Intel Cache Allocation Technology (CAT) to allocate only 25% of the cache to the worker thread, while keeping 75% cache. This avoids LLC pollution.\n\n@orenbach2020autarky, @orenbach2019cosmix also adapts this.\n\n## User-managed virtual memory \nElos also includes a fine-grained page management system to avoid enclave exit on page faults. The idea is to cache the commonly used pages in the untrusted memory, and serve from it first, instead of relying on the OS.","snippets":["#sgx #tee #system-call #performance #rpc"],"rawContent":"# Exitless system calls for SGX\n#sgx #tee #system-call #performance #rpc\n\nTo perform system calls in SGX, the enclave must perform enclave exit and enter through `EEXIT`, `EENTER`. It is found that these two instructions have heavy overheads of about 3,300 and 3,800 cycles @orenbach2017eleos. This is much higher than the overheads of a normal system call, about 250 cycles.\n\nAnother cost of SGX is due to page fault, since in an enclave exit also need to be triggered.\n\n# Elos\n## RPC for system calls\n@orenbach2017eleos proposed using RPC instead to serve system calls on an enclave. The system employs a separated thread in the untrusted part of the application to serve system call. Ocalls in SGX for serving system call is then replaced with RPC to the system call-serving threads. \n\nMoreover, the system uses Intel Cache Allocation Technology (CAT) to allocate only 25% of the cache to the worker thread, while keeping 75% cache. This avoids LLC pollution.\n\n@orenbach2020autarky, @orenbach2019cosmix also adapts this.\n\n## User-managed virtual memory \nElos also includes a fine-grained page management system to avoid enclave exit on page faults. The idea is to cache the commonly used pages in the untrusted memory, and serve from it first, instead of relying on the OS.\n\n","wordCount":208,"tags":["tee","sgx","system-call","performance","rpc"],"metadata":{},"created":"2023-08-09T13:49:43.469163125Z","modified":"2023-08-09T13:49:43.469209583Z","checksum":"0ee0ee2b2dfb63857dc1d676f2786d229d897880d370ceacd89fc1e4dcadc55e"},
    {"filename":"ncfh611p.md","filenameStem":"ncfh611p","path":"literature/ncfh611p.md","absPath":"/Users/khadd/mynotes/literature/ncfh611p.md","title":"Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization","link":"[[literature/ncfh611p]]","lead":"#literature #side-channel #sev\n@li2019exploiting","body":"#literature #side-channel #sev\n@li2019exploiting\n\n\n# Summary\nThe paper proposes an attack method that exploits the unprotected I/O operations in AMD SEV. Here, *unprotected* means that the I/O operations (MMIO and DMA) must be performed on unencrypted memory that is visible by the hypervisor. The paper shows that by replacing ciphertext blocks in the VM memory, the hypervisor can create trick the VM into encrypting and decrypting arbitrary data, hence encryption/decryption oracles.\n\n\n# Attack overview\n## Encryption oracle\nThe target of the attack is an SSH service running inside a cVM. While the ssh packets are encrypted, due to unprotected I/O [[zmt276jl]], the hypervisor can observe and modify the TCP and IP headers.\n\nBriefly, the attack finds the *encrypted* page that contains the packet to be sent over the I/O channel. It then replaces the encrypted header (16B) with another encrypted block of data, right before the packet is copied into the unencrypted I/O memory observable by the hypervisor. Using this method, a decryption oracle is built that allows the decryption of any memory block.\n\nThe attack is performed in three steps: pattern matching, ciphertext replacement, and packet recovery.\n\n### Pattern matching\nPattern matching stage uses the nested page fault side-channel [[qq4qcbos]] to determine which pages are being accessed when the VM serves the SSH packet. The hypervisor first sends an SSH packet to the VM, then clears the present bits in the NPT PTEs.\nIt collects the sequences of page fault accesses to build a _signature_ of the page accessed from the time of receiving the request, to the time right before sending the packet. It then uses this signature to determine the page containing the `sk_buff` structure that contains the packet.\n\n### Ciphertext replacement\nCiphertext replacement replaces the ciphertext inside the header of the SSH packet and recovers the plaintext result. Since SEV's memory encryption applies a teak function based on the physical address, steps need to be done to recover plaintext:\nAssuming the ciphertext $c$ is copied from the address $P_c$. Plaintext must be obtained by:\n\n$m = d \\oplus  T(hPA((P_{priv}+16))/16*16) \\oplus T(P_c)$ \n\nWhere $d$ is the decrypted text of $c$, T is the tweak function. Essentially, this negates the effect of the teak of the current address and applies the teak of the target location.\n\n### Plaintext recovery\nThe original plaintext must be recovered so that the attack is stealthy. Since the attack only modifies the header of the SSH packet, which is public, it only needs to predict the content of the current header (replaced by the attack). Here, the ID of the packet is increased by 1 after each response, so it adds that to the response's header.\n\n\n# Mitigation\nThe attack in this paper is mitigated by SEV-SNP since the hypervisor cannot write into encrypted memory anymore.\n\nSince SNP did not exist at the time, the paper also suggests other mitigations. One of them is to make the VM encrypts the *entire* packets, and use a trusted proxy server to decrypt the packets, before forwarding them to the client.","snippets":["#literature #side-channel #sev\n@li2019exploiting"],"rawContent":"# Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization\n#literature #side-channel #sev\n@li2019exploiting\n\n\n# Summary\nThe paper proposes an attack method that exploits the unprotected I/O operations in AMD SEV. Here, *unprotected* means that the I/O operations (MMIO and DMA) must be performed on unencrypted memory that is visible by the hypervisor. The paper shows that by replacing ciphertext blocks in the VM memory, the hypervisor can create trick the VM into encrypting and decrypting arbitrary data, hence encryption/decryption oracles.\n\n\n# Attack overview\n## Encryption oracle\nThe target of the attack is an SSH service running inside a cVM. While the ssh packets are encrypted, due to unprotected I/O [[zmt276jl]], the hypervisor can observe and modify the TCP and IP headers.\n\nBriefly, the attack finds the *encrypted* page that contains the packet to be sent over the I/O channel. It then replaces the encrypted header (16B) with another encrypted block of data, right before the packet is copied into the unencrypted I/O memory observable by the hypervisor. Using this method, a decryption oracle is built that allows the decryption of any memory block.\n\nThe attack is performed in three steps: pattern matching, ciphertext replacement, and packet recovery.\n\n### Pattern matching\nPattern matching stage uses the nested page fault side-channel [[qq4qcbos]] to determine which pages are being accessed when the VM serves the SSH packet. The hypervisor first sends an SSH packet to the VM, then clears the present bits in the NPT PTEs.\nIt collects the sequences of page fault accesses to build a _signature_ of the page accessed from the time of receiving the request, to the time right before sending the packet. It then uses this signature to determine the page containing the `sk_buff` structure that contains the packet.\n\n### Ciphertext replacement\nCiphertext replacement replaces the ciphertext inside the header of the SSH packet and recovers the plaintext result. Since SEV's memory encryption applies a teak function based on the physical address, steps need to be done to recover plaintext:\nAssuming the ciphertext $c$ is copied from the address $P_c$. Plaintext must be obtained by:\n\n$m = d \\oplus  T(hPA((P_{priv}+16))/16*16) \\oplus T(P_c)$ \n\nWhere $d$ is the decrypted text of $c$, T is the tweak function. Essentially, this negates the effect of the teak of the current address and applies the teak of the target location.\n\n### Plaintext recovery\nThe original plaintext must be recovered so that the attack is stealthy. Since the attack only modifies the header of the SSH packet, which is public, it only needs to predict the content of the current header (replaced by the attack). Here, the ID of the packet is increased by 1 after each response, so it adds that to the response's header.\n\n\n# Mitigation\nThe attack in this paper is mitigated by SEV-SNP since the hypervisor cannot write into encrypted memory anymore.\n\nSince SNP did not exist at the time, the paper also suggests other mitigations. One of them is to make the VM encrypts the *entire* packets, and use a trusted proxy server to decrypt the packets, before forwarding them to the client.\n","wordCount":515,"tags":["side-channel","sev","literature"],"metadata":{},"created":"2023-08-09T13:49:43.47026792Z","modified":"2023-08-09T13:49:43.470321962Z","checksum":"c4fe4d78fb051afdaf047f2e46dceccd2a7d4f374db46f764f6a08e2ef9761fc"},
    {"filename":"a6uh87al.md","filenameStem":"a6uh87al","path":"a6uh87al.md","absPath":"/Users/khadd/mynotes/a6uh87al.md","title":"Extending on an idea","link":"[[a6uh87al]]","lead":"#writing","body":"#writing\n\nSometimes it is hard to *determine what to write* for a particular idea. Using *frameworks* would helps in such cases. \n\nGenerally, following prompts helps: \n- Answering What, why, how\n- Give an example\n- What is this idea similar to\n- What contradicts this idea\n\nKeep in mind:\n- Why is this an important issue\n- Why reader has to know about this\n\n\n\n\nOther note taking frameworks might helps, such as: \n- [[dyx2t4oz]]\n- [[zz3cedu0]]","snippets":["#writing"],"rawContent":"# Extending on an idea\n#writing\n\nSometimes it is hard to *determine what to write* for a particular idea. Using *frameworks* would helps in such cases. \n\nGenerally, following prompts helps: \n- Answering What, why, how\n- Give an example\n- What is this idea similar to\n- What contradicts this idea\n\nKeep in mind:\n- Why is this an important issue\n- Why reader has to know about this\n\n\n\n\nOther note taking frameworks might helps, such as: \n- [[dyx2t4oz]]\n- [[zz3cedu0]]\n\n\n","wordCount":81,"tags":["writing"],"metadata":{},"created":"2023-08-09T13:49:43.461200641Z","modified":"2023-08-09T13:49:43.461249516Z","checksum":"7e51df8c7dabc81cf1bd782e69245187c898bf067f8079d8dfc18b4dc2a08764"},
    {"filename":"mqnreqwk.md","filenameStem":"mqnreqwk","path":"mqnreqwk.md","absPath":"/Users/khadd/mynotes/mqnreqwk.md","title":"Failure in ORAM","link":"[[mqnreqwk]]","lead":"#oblivious","body":"#oblivious \n\nIn most ORAM algorithms, there is a chance of failure.\n\nThe design of ORAM tries to avoid this using some techniques.\n\n# Eviction strategy\n## Reversed path eviction\nIn the eviction phase (Path ORAM and Ring ORAM), blocks are pushed to the tree in the reversed order, starting from the leaves, and ending at the root. The reason for intuition is that blocks at higher levels are more likely to intersect with another path.\nFor example, in a tree with 3 levels, nodes on the last level (leaf nodes) correspond to only one path. node on the second level can be evicted on 2 paths (1 can be evicted on paths 0 and 1). Nodes on the first level can be evicted on any path.\n\n```\n              0\n          1       2\n      3       4       5\n---------------------------\npath: 0       1       2\n```\n\n## Background Eviction\n@ren2013design proposed a *background eviction* strategy. This happens when the free slots in the stash becomes smaller than $Height*BucketSize$, i.e., the minimum free blocks required in an ORAM access.\n\ndummy access is performed on random a path that read blocks into the stash, and opportunistically place blocks back into the tree. At worst, if the path is already filled, or no blocks can be evicted from the stash, the path is simply written back to the tree.\n\nAn advantage of this is that the background eviction access pattern is identical to an ORAM access, so attackers cannot know when background eviction happens.\n\n\n@renconstants also have a *early reshuffling* strategy.","snippets":["#oblivious"],"rawContent":"# Failure in ORAM\n#oblivious \n\nIn most ORAM algorithms, there is a chance of failure.\n\nThe design of ORAM tries to avoid this using some techniques.\n\n# Eviction strategy\n## Reversed path eviction\nIn the eviction phase (Path ORAM and Ring ORAM), blocks are pushed to the tree in the reversed order, starting from the leaves, and ending at the root. The reason for intuition is that blocks at higher levels are more likely to intersect with another path.\nFor example, in a tree with 3 levels, nodes on the last level (leaf nodes) correspond to only one path. node on the second level can be evicted on 2 paths (1 can be evicted on paths 0 and 1). Nodes on the first level can be evicted on any path.\n\n```\n              0\n          1       2\n      3       4       5\n---------------------------\npath: 0       1       2\n```\n\n## Background Eviction\n@ren2013design proposed a *background eviction* strategy. This happens when the free slots in the stash becomes smaller than $Height*BucketSize$, i.e., the minimum free blocks required in an ORAM access.\n\ndummy access is performed on random a path that read blocks into the stash, and opportunistically place blocks back into the tree. At worst, if the path is already filled, or no blocks can be evicted from the stash, the path is simply written back to the tree.\n\nAn advantage of this is that the background eviction access pattern is identical to an ORAM access, so attackers cannot know when background eviction happens.\n\n\n@renconstants also have a *early reshuffling* strategy.\n","wordCount":255,"tags":["oblivious"],"metadata":{},"created":"2023-08-09T13:49:43.47074988Z","modified":"2023-08-09T13:49:43.470797338Z","checksum":"28d0298120d3c8b5513665533e65153775d95ba143163873d4a031b1c7680677"},
    {"filename":"b8dhhxft.md","filenameStem":"b8dhhxft","path":"fleeting/b8dhhxft.md","absPath":"/Users/khadd/mynotes/fleeting/b8dhhxft.md","title":"Flat vs. hierarchical notes","link":"[[fleeting/b8dhhxft]]","lead":"#fleeting","body":"#fleeting\n\n# Flat notes\nFlat notes make use of hashtag and linking for navigation\n\n## Arguments for flat notes\nFlat notes make every notes equally important.\n\nFlat notes is easier for linking.\n\nEasy to maintain. You can create a a grouping of concepts by just inserting a new hashtag.\n\n## Argument agaisnt\nHashtags can be cluttering.\n\nThis is related to a good hashtag system.\n\n# Hierarchical notes\nHierarchical notes group notes using folders/directories. It is great when you use a file system to maintain your zettel.\n\nHierarchical notes is good when the content within the directory is \n(1) well-maintained, \n(2) well-separated: though, this kind of go against the linking your thinking ideologies. \n(3) you need multiple \n\n## Argument for hierarchical notes\nVisually separated in the file system.\n\nEasy to move around. Though, you rarely need to move your notes.\n\nSupport multiple layers of grouping.\n\n```\n- Group A\n  - Note a.1  \n  - Note a.2\n  - Group A.1\n    - note A.1.1 \n- Group B\n  - Note b.1\n```\n\n## Arguments against\nYour conceptual grouping of notes might change over time.\n\nLinking requires an extra indirection (`\\[\\[directory/note\\]\\]`). This might be dependent on the note manager you are using.\n\n\n\n# Conclusion\n\nIf you are sure the grouping of notes is permanent, and you want to clearly and visually separate those notes from the rest, using a directory is fine. For instance, generally Zettlekasten gurus recommends you to separate fleeting, literature, and permanent notes.\n\nFor notes where their grouping might change overtime, it is best to use flat notes plus hashtags.","snippets":["#fleeting"],"rawContent":"# Flat vs. hierarchical notes\n#fleeting\n\n# Flat notes\nFlat notes make use of hashtag and linking for navigation\n\n## Arguments for flat notes\nFlat notes make every notes equally important.\n\nFlat notes is easier for linking.\n\nEasy to maintain. You can create a a grouping of concepts by just inserting a new hashtag.\n\n## Argument agaisnt\nHashtags can be cluttering.\n\nThis is related to a good hashtag system.\n\n# Hierarchical notes\nHierarchical notes group notes using folders/directories. It is great when you use a file system to maintain your zettel.\n\nHierarchical notes is good when the content within the directory is \n(1) well-maintained, \n(2) well-separated: though, this kind of go against the linking your thinking ideologies. \n(3) you need multiple \n\n## Argument for hierarchical notes\nVisually separated in the file system.\n\nEasy to move around. Though, you rarely need to move your notes.\n\nSupport multiple layers of grouping.\n\n```\n- Group A\n  - Note a.1  \n  - Note a.2\n  - Group A.1\n    - note A.1.1 \n- Group B\n  - Note b.1\n```\n\n## Arguments against\nYour conceptual grouping of notes might change over time.\n\nLinking requires an extra indirection (`\\[\\[directory/note\\]\\]`). This might be dependent on the note manager you are using.\n\n\n\n# Conclusion\n\nIf you are sure the grouping of notes is permanent, and you want to clearly and visually separate those notes from the rest, using a directory is fine. For instance, generally Zettlekasten gurus recommends you to separate fleeting, literature, and permanent notes.\n\nFor notes where their grouping might change overtime, it is best to use flat notes plus hashtags. \n\n\n","wordCount":262,"tags":["fleeting"],"metadata":{},"created":"2023-08-09T13:49:43.467852912Z","modified":"2023-08-09T13:49:43.467900621Z","checksum":"1fe224eda1d1b71c80dbdd67ed9111497e5f5120d18e3e6f7770d72d4ef9343b"},
    {"filename":"nitymocd.md","filenameStem":"nitymocd","path":"nitymocd.md","absPath":"/Users/khadd/mynotes/nitymocd.md","title":"Force function inline in LLVM","link":"[[nitymocd]]","lead":"#llvm","body":"#llvm\n\nThe problem: I'm trying to instrument the program's load and store instruction with wrapper that modify the pointer in the value. Since there are a lot of load/store, and the wrapper is short, I expect inlining would leads to better performance.\n\nI tried to force inline with the function attribute `__attribute__((__always_inline__))` but it did not work. LLVM would not listen.\n\nLuckily `Lib/Transform/Utils/Cloning.h` provide a function call `InlineFunction(CallInst, ...)` when invoked it would try to inline the call instruction. \n\nHence I used two step to inline every calls. The first step instrument the function call normally, but store the inserted LLVM's CallInst in an array. After instrumentation is done, I loop through the array to invoke `InlineFunction` on them.","snippets":["#llvm"],"rawContent":"# Force function inline in LLVM\n#llvm\n\nThe problem: I'm trying to instrument the program's load and store instruction with wrapper that modify the pointer in the value. Since there are a lot of load/store, and the wrapper is short, I expect inlining would leads to better performance.\n\nI tried to force inline with the function attribute `__attribute__((__always_inline__))` but it did not work. LLVM would not listen.\n\nLuckily `Lib/Transform/Utils/Cloning.h` provide a function call `InlineFunction(CallInst, ...)` when invoked it would try to inline the call instruction. \n\nHence I used two step to inline every calls. The first step instrument the function call normally, but store the inserted LLVM's CallInst in an array. After instrumentation is done, I loop through the array to invoke `InlineFunction` on them.\n\n\n\n","wordCount":125,"tags":["llvm"],"metadata":{},"created":"2023-08-09T13:49:43.470999256Z","modified":"2023-08-09T13:49:43.471036214Z","checksum":"d2166fbac553e21b365cdba8b07d34c6efd0baa64bfe8bd7daa00105f3f858e6"},
    {"filename":"l56og3zt.md","filenameStem":"l56og3zt","path":"l56og3zt.md","absPath":"/Users/khadd/mynotes/l56og3zt.md","title":"Foreach pattern in C macro","link":"[[l56og3zt]]","lead":"You can define a foreach macro like this. Useful when iterating over custom structures. \n```c","body":"You can define a foreach macro like this. Useful when iterating over custom structures. \n```c\n\n#define FOREACH(var)\\\n  for (var = 0; var \u003c PREDEFINED_LEN; var++)\n\n#define FOREACH(var, len)\\\n  for (var = 0; var \u003c len; var++)\n\n#define FOREACH_TYPE_T(ptr)\\\n  for (ptr = begin(); ptr != end(); ptr = get_next_ptr(ptr))\n```","snippets":["You can define a foreach macro like this. Useful when iterating over custom structures. \n```c"],"rawContent":"# Foreach pattern in C macro\n\n\n\nYou can define a foreach macro like this. Useful when iterating over custom structures. \n```c\n\n#define FOREACH(var)\\\n  for (var = 0; var \u003c PREDEFINED_LEN; var++)\n\n#define FOREACH(var, len)\\\n  for (var = 0; var \u003c len; var++)\n\n#define FOREACH_TYPE_T(ptr)\\\n  for (ptr = begin(); ptr != end(); ptr = get_next_ptr(ptr))\n```\n","wordCount":55,"tags":[],"metadata":{},"created":"2023-08-09T13:49:43.469613418Z","modified":"2023-08-09T13:49:43.469649626Z","checksum":"d16bf8147c1cf446c69a10a0537ff88d74fdb37e08607b4419a22993f634ec67"},
    {"filename":"zecj938z.md","filenameStem":"zecj938z","path":"literature/zecj938z.md","absPath":"/Users/khadd/mynotes/literature/zecj938z.md","title":"HYDRA:The Kernel of a Multiprocessor Operating System","link":"[[literature/zecj938z]]","lead":"#literature #os #capabilities\n@wulf1974hydra","body":"#literature #os #capabilities\n@wulf1974hydra\n\n\n\n## Noteworthy arguments\n### Hierarchical layering limits flexibility: See [[c4icaua4]].\nHowever, maintaining order in a non-hierarchical manner is challenging in traditional systems. HYDRA's capability model enable flexibility by rejecting hierarchical structuring. In HYDRA, a *template* define the security checking mechanism of a procedure, and allows a procedure to *derive* higher capabilities from the argument capabilities (belong to the caller). This way, a callee function might have greater capabilities than the caller, but the caller have no way of obtaining those capabilities by itself. This enable invocation of procedures in any orders, as long as the callee adhere to the rules defined by the system designer.\n\nAs a downside, such a system must have the support from the kernel. HYDRA uses a kernel-assisted CALL mechanism. The kernel checks for the parameter capabilities with the according to the security requirements. It then derives new capabilities and place it in the callee's environment. Finally, the kernel transfer the control to the callee function.\n\n### Protection (mechanism) should be separated from security (policy)\nThe paper argue that the protection mechanism does not necessary grant security. Take password for example, the password checking mechanism does not guarantee that the user will use a strong enough password.\n\nHence, HYDRA aims to provides primitives (mechanisms) to implements the policy (security), but not to provide  the security by itself.","snippets":["#literature #os #capabilities\n@wulf1974hydra"],"rawContent":"# HYDRA:The Kernel of a Multiprocessor Operating System\n#literature #os #capabilities\n@wulf1974hydra\n\n\n\n## Noteworthy arguments\n### Hierarchical layering limits flexibility: See [[c4icaua4]].\nHowever, maintaining order in a non-hierarchical manner is challenging in traditional systems. HYDRA's capability model enable flexibility by rejecting hierarchical structuring. In HYDRA, a *template* define the security checking mechanism of a procedure, and allows a procedure to *derive* higher capabilities from the argument capabilities (belong to the caller). This way, a callee function might have greater capabilities than the caller, but the caller have no way of obtaining those capabilities by itself. This enable invocation of procedures in any orders, as long as the callee adhere to the rules defined by the system designer.\n\nAs a downside, such a system must have the support from the kernel. HYDRA uses a kernel-assisted CALL mechanism. The kernel checks for the parameter capabilities with the according to the security requirements. It then derives new capabilities and place it in the callee's environment. Finally, the kernel transfer the control to the callee function.\n\n### Protection (mechanism) should be separated from security (policy)\nThe paper argue that the protection mechanism does not necessary grant security. Take password for example, the password checking mechanism does not guarantee that the user will use a strong enough password.\n\nHence, HYDRA aims to provides primitives (mechanisms) to implements the policy (security), but not to provide  the security by itself.\n","wordCount":233,"tags":["os","capabilities","literature"],"metadata":{},"created":"2023-08-09T13:49:43.470548546Z","modified":"2023-08-09T13:49:43.470582004Z","checksum":"ef8d49672048a3a1fffb41b086f8d21d4f2cc910b21f2024b789e977377c3b9e"},
    {"filename":"2a7l7odo.md","filenameStem":"2a7l7odo","path":"literature/2a7l7odo.md","absPath":"/Users/khadd/mynotes/literature/2a7l7odo.md","title":"Harmonizing Performance and Isolation in Microkernels with Efficient Intra-kernel Isolation and Communication","link":"[[literature/2a7l7odo]]","lead":"#literature #mpk #microkernel #sel4 #os\n[@gu2020harmonizing]","body":"#literature #mpk #microkernel #sel4 #os\n[@gu2020harmonizing]\n\n## Context\nThe paper argues that the cost of IPC in microkernels are too high, and proposed using MPK-based domains to reduce the number of context switches during IPCs.\nThe paper provides a motivation study by profiling the overheads of IPC in common microkernels (see [[i2blyo37#Overhead analysis]]).\n\n### Background\nPrevious systems use MPK for single address-space isolation.\n\nPrevious state-of-the-art [@mi2019skybridge] enables fast IPC by retrofitting VMFUNC., but still have high overheads due to Page table switching\n\n### Contributions\nThe proposed system tackles three main challenges in the context of microkernels that previous work did not solve. \n- The first is to prevent illegal IPC calls, since intel MPK does not check for permission before executing code. This is solved by secure IPC gates for the specific connections between two specific servers (a *system server* is an application that provides system-level services) in the trusted domain (core kernel). \n- Second is the limited number of domains. The paper designs a *server migration* technique that allows a server to be migrated between userspace (same as normal microkernel) and kernel space.\n- Third, due to the server executing in the privileged space, the system needs to prevent it from executing privileged instructions.","snippets":["#literature #mpk #microkernel #sel4 #os\n[@gu2020harmonizing]"],"rawContent":"# Harmonizing Performance and Isolation in Microkernels with Efficient Intra-kernel Isolation and Communication\n#literature #mpk #microkernel #sel4 #os\n[@gu2020harmonizing]\n\n## Context\nThe paper argues that the cost of IPC in microkernels are too high, and proposed using MPK-based domains to reduce the number of context switches during IPCs.\nThe paper provides a motivation study by profiling the overheads of IPC in common microkernels (see [[i2blyo37#Overhead analysis]]).\n\n### Background\nPrevious systems use MPK for single address-space isolation.\n\nPrevious state-of-the-art [@mi2019skybridge] enables fast IPC by retrofitting VMFUNC., but still have high overheads due to Page table switching\n\n### Contributions\nThe proposed system tackles three main challenges in the context of microkernels that previous work did not solve. \n- The first is to prevent illegal IPC calls, since intel MPK does not check for permission before executing code. This is solved by secure IPC gates for the specific connections between two specific servers (a *system server* is an application that provides system-level services) in the trusted domain (core kernel). \n- Second is the limited number of domains. The paper designs a *server migration* technique that allows a server to be migrated between userspace (same as normal microkernel) and kernel space.\n- Third, due to the server executing in the privileged space, the system needs to prevent it from executing privileged instructions. \n","wordCount":218,"tags":["os","microkernel","sel4","literature","mpk"],"metadata":{},"created":"2023-08-09T13:49:43.469777335Z","modified":"2023-08-09T13:49:43.469827918Z","checksum":"4732db3c6999f83832e45188b2b1f85489a2dbbfc668c561ef73ab38606a134b"},
    {"filename":"c4icaua4.md","filenameStem":"c4icaua4","path":"c4icaua4.md","absPath":"/Users/khadd/mynotes/c4icaua4.md","title":"Hierarchical layering limits flexibility","link":"[[c4icaua4]]","lead":"#capabilities #os","body":"#capabilities #os\n\nMany systems uses the strict hierarchical layering for resource allocation. In those systems, the rule enforced by the kernel is that \n(1) a process can only allocate resources that it own to its children, \n(2) can only start/stop/remove its own childrens, and \n(3) A process's resources must be returned to its parent when it terminates.\nThis can be seen in modern UNIX system.\n\nHowever, [@wulf1974hydra] found that hierarchical layering of a system limits its flexibility. For example, while resource allocation might contains hierarchical layering, as shown above,  the *control* (e.g., starting/stopping subprocesses) need not to have the same hierarchical. \n\nAlso, a strict hierarchical system leads to increasingly privileged system components, and therefore leads to a component that have the \"most privileged\" only because of it place in the system. This leads to confused deputy problems ([[y9wu5ut7]]) in those components.","snippets":["#capabilities #os"],"rawContent":"# Hierarchical layering limits flexibility\n#capabilities #os\n\nMany systems uses the strict hierarchical layering for resource allocation. In those systems, the rule enforced by the kernel is that \n(1) a process can only allocate resources that it own to its children, \n(2) can only start/stop/remove its own childrens, and \n(3) A process's resources must be returned to its parent when it terminates.\nThis can be seen in modern UNIX system.\n\nHowever, [@wulf1974hydra] found that hierarchical layering of a system limits its flexibility. For example, while resource allocation might contains hierarchical layering, as shown above,  the *control* (e.g., starting/stopping subprocesses) need not to have the same hierarchical. \n\nAlso, a strict hierarchical system leads to increasingly privileged system components, and therefore leads to a component that have the \"most privileged\" only because of it place in the system. This leads to confused deputy problems ([[y9wu5ut7]]) in those components.\n\n\n\n","wordCount":146,"tags":["os","capabilities"],"metadata":{},"created":"2023-08-09T13:49:43.461565058Z","modified":"2023-08-09T13:49:43.461632892Z","checksum":"00f6434fbe55887338b0a871b830f6fb7ea5a0bdbfad0363dd672ab06d456422"},
    {"filename":"b740rhio.md","filenameStem":"b740rhio","path":"b740rhio.md","absPath":"/Users/khadd/mynotes/b740rhio.md","title":"Hourglass structure of information","link":"[[b740rhio]]","lead":"#reading #learning","body":"#reading #learning\n\nIn articles, information is usually structured in an hourglass structure ([keshav]).\nIt is usually high-level information at the beginning and the end, and more specific information in the middle.\nUsually, the importance of information also follows this structure.\n\nHence, during reading, more time should be spent on the begining and the end of the whole chapter, the sections, or even each paragraph.\n\n# References\n[keshav]: https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf","snippets":["#reading #learning"],"rawContent":"# Hourglass structure of information\n#reading #learning\n\nIn articles, information is usually structured in an hourglass structure ([keshav]).\nIt is usually high-level information at the beginning and the end, and more specific information in the middle.\nUsually, the importance of information also follows this structure.\n\nHence, during reading, more time should be spent on the begining and the end of the whole chapter, the sections, or even each paragraph.\n\n# References\n[keshav]: https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf\n","wordCount":73,"tags":["reading","learning"],"metadata":{},"created":"2023-08-09T13:49:43.46149035Z","modified":"2023-08-09T13:49:43.461534475Z","checksum":"6f1aabe29b5cb961c89bd8bee93c75a287731b140d685ee83a1dcaee9d25fd5d"},
    {"filename":"8v4evysc.md","filenameStem":"8v4evysc","path":"8v4evysc.md","absPath":"/Users/khadd/mynotes/8v4evysc.md","title":"How I handle quotes","link":"[[8v4evysc]]","lead":"#quote #note-taking #zettelkasten","body":"#quote #note-taking #zettelkasten\n\nFirst, the title of the note contains the quote itself. This will make the entire quote a first-class content.\n\nSecond, a `#quote` tag is attached to the note. This allows for better indexing. \n\nThird, the note contains description of the note. For instance, who is it from, in what context.\n\nFinally, other notes create link to the quote in the appropriate context. Since the title is the quote it self, it can be searched easily.\n\nThe only thing left is to maintain authors of quotes. There are two approaches, linking to the (may empty) note about author, or use hash tag, both of which have trade-off. Linking force you to create a note on the author, which may not be populated. using hashtags kind of clutter you tags. Searching using hashtags may not be ideal (I might change my mind later).","snippets":["#quote #note-taking #zettelkasten"],"rawContent":"# How I handle quotes\n#quote #note-taking #zettelkasten\n\nFirst, the title of the note contains the quote itself. This will make the entire quote a first-class content.\n\nSecond, a `#quote` tag is attached to the note. This allows for better indexing. \n\nThird, the note contains description of the note. For instance, who is it from, in what context.\n\nFinally, other notes create link to the quote in the appropriate context. Since the title is the quote it self, it can be searched easily.\n\nThe only thing left is to maintain authors of quotes. There are two approaches, linking to the (may empty) note about author, or use hash tag, both of which have trade-off. Linking force you to create a note on the author, which may not be populated. using hashtags kind of clutter you tags. Searching using hashtags may not be ideal (I might change my mind later). \n","wordCount":149,"tags":["quote","note-taking","zettelkasten"],"metadata":{},"created":"2023-08-09T13:49:43.460919057Z","modified":"2023-08-09T13:49:43.460963765Z","checksum":"7195f7120eeafa98eae782370a14a02bee0305778b5e4e6b46049c7be5af69fe"},
    {"filename":"7isqcppd.md","filenameStem":"7isqcppd","path":"7isqcppd.md","absPath":"/Users/khadd/mynotes/7isqcppd.md","title":"How to Speak","link":"[[7isqcppd]]","lead":"# Slides\n- The less text, the better. Cut out headers, footer, unneccessary visual cluttering (e.g., bullet points).\n- Figures should be simple.","body":"# Slides\n- The less text, the better. Cut out headers, footer, unneccessary visual cluttering (e.g., bullet points).\n- Figures should be simple.\n\n# Crimes\n- Hands in pocket\n- Pointers to the slide\n\n\n\n# References\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s)","snippets":["# Slides\n- The less text, the better. Cut out headers, footer, unneccessary visual cluttering (e.g., bullet points).\n- Figures should be simple."],"rawContent":"# How to Speak\n\n\n\n\n\n# Slides\n- The less text, the better. Cut out headers, footer, unneccessary visual cluttering (e.g., bullet points).\n- Figures should be simple.\n\n# Crimes\n- Hands in pocket\n- Pointers to the slide\n\n\n\n# References\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s)\n\n","wordCount":42,"tags":[],"metadata":{},"created":"2023-08-09T13:49:43.460712931Z","modified":"2023-08-09T13:49:43.460752223Z","checksum":"bf5388ea49df707b3eb47c03fde840dd75bb21c59014fadd0f5ac6c859c642fe"},
    {"filename":"gmp22r4e.md","filenameStem":"gmp22r4e","path":"gmp22r4e.md","absPath":"/Users/khadd/mynotes/gmp22r4e.md","title":"How to do research","link":"[[gmp22r4e]]","lead":"#resource","body":"#resource\n\n# References\n- [How to look for ideas in Computer Science Research](https://medium.com/digital-diplomacy/how-to-look-for-ideas-in-computer-science-research-7a3fa6f4696f)","snippets":["#resource"],"rawContent":"# How to do research\n#resource\n\n# References\n- [How to look for ideas in Computer Science Research](https://medium.com/digital-diplomacy/how-to-look-for-ideas-in-computer-science-research-7a3fa6f4696f)\n","wordCount":18,"tags":["resource"],"metadata":{},"created":"2023-08-09T13:49:43.468138038Z","modified":"2024-05-19T06:16:25.293619819Z","checksum":"29acb67c6fdb418b4825847d95a6d639985e62fce7d900af801826574c5fd332"},
    {"filename":"zy68i5ym.md","filenameStem":"zy68i5ym","path":"zy68i5ym.md","absPath":"/Users/khadd/mynotes/zy68i5ym.md","title":"How to explain an idea","link":"[[zy68i5ym]]","lead":"# Heuristics\n[How-to-Speak] describes two heuristics.\n1. *Cycling*: If something is important, it is worth revisiting at least *3* times. This is because people's attention is short.\n2. *Build a fence*: Clearly differentiate the idea and other may-similar ideas.","body":"# Heuristics\n[How-to-Speak] describes two heuristics.\n1. *Cycling*: If something is important, it is worth revisiting at least *3* times. This is because people's attention is short.\n2. *Build a fence*: Clearly differentiate the idea and other may-similar ideas. \n\n\n# How to get your work recognized\n[How-to-Speak] mentioned 5 pillars:\n1. Symbol: A symbol helps \n2. Slogan\n3. Supprise\n4. Salient\n5. Story\n\n[[7isqcppd]]\n\n# References\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s)","snippets":["# Heuristics\n[How-to-Speak] describes two heuristics.\n1. *Cycling*: If something is important, it is worth revisiting at least *3* times. This is because people's attention is short.\n2. *Build a fence*: Clearly differentiate the idea and other may-similar ideas."],"rawContent":"# How to explain an idea\n\n# Heuristics\n[How-to-Speak] describes two heuristics.\n1. *Cycling*: If something is important, it is worth revisiting at least *3* times. This is because people's attention is short.\n2. *Build a fence*: Clearly differentiate the idea and other may-similar ideas. \n\n\n# How to get your work recognized\n[How-to-Speak] mentioned 5 pillars:\n1. Symbol: A symbol helps \n2. Slogan\n3. Supprise\n4. Salient\n5. Story\n\n[[7isqcppd]]\n\n# References\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s) \n\n\n","wordCount":74,"tags":[],"metadata":{},"created":"2023-08-09T13:49:43.478730989Z","modified":"2023-08-09T13:49:43.47877128Z","checksum":"097b000c645a46d74cbb09806a242c74fdb8916c9ecb7488adb05db7995e4f60"},
    {"filename":"cemsxh4n.md","filenameStem":"cemsxh4n","path":"cemsxh4n.md","absPath":"/Users/khadd/mynotes/cemsxh4n.md","title":"How to write a note","link":"[[cemsxh4n]]","lead":"#zettelkasten #note-taking","body":"#zettelkasten #note-taking\n\n#todo: Need more research \n\nThe note content should have three main parts:\n- The idea \n- The observation\n- The conclusion\nThis is which is also similar to how academic papers are structured.\n\nUsing frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.","snippets":["#zettelkasten #note-taking"],"rawContent":"# How to write a note\n#zettelkasten #note-taking\n\n#todo: Need more research \n\nThe note content should have three main parts:\n- The idea \n- The observation\n- The conclusion\nThis is which is also similar to how academic papers are structured.\n\nUsing frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.\n","wordCount":58,"tags":["note-taking","zettelkasten","todo:"],"metadata":{},"created":"2023-08-09T13:49:43.461861226Z","modified":"2023-08-09T13:49:43.46191281Z","checksum":"fb21dbe626763343fe640738e06778e42719a3dd4f747c3865f65081e369afeb"},
    {"filename":"d3nt6uix.md","filenameStem":"d3nt6uix","path":"d3nt6uix.md","absPath":"/Users/khadd/mynotes/d3nt6uix.md","title":"Hypervisor (VMM)","link":"[[d3nt6uix]]","lead":"#virtualization","body":"#virtualization\n\nA hypervisor, also known as virtual machine monitor (VMM) manage virtual machines. \n\nIt performs interposition ([[s16ct1rj#interposition]]) on a certain *interesting* instructions to *emulate* then, hence *trap-and-emulate*. Those interesting instruction can be:\n- Access to hardware devices\n- Special instructions (e.g., CPUID)\n- Access to important and dangerous registers that have global effect \n\nHypervisor works by exploiting modern hardware supports that allows trapping of those important instructions.\n\n## Launching VM\nProcessor state of the VM is stored in a Virtual Machine Control structure/block (VMCS/VMCB) (see [VMCS](https://shhoya.github.io/hv_vmcsdata.html)). VMCS is a complex structure containing informations related to a VM's state. A pointer to the current VMCS is stored in a dedicated register, loaded with `VMPTRLD` instruction ([VMPTR](https://www.felixcloutier.com/x86/vmptrld.)).\n\nThe hypervisor is required to setup the VMCS correctly with necessary information.\n\nThe `VMLAUNCH\\VMRESUME` instruction is then used to lanch the VM based on the current VMCS.\n\n## Memory management\n### Legacy\nPreviously, all access to physical memory in the Guest need to be interposed and emulated, which causes a lot of overheads. Address translation and paging need to be perform twice.\n\n### Shadow Page Table\nTo avoid this, Shadow page table (SPT) is a per-VM page table used by the hypervisor to translate guest virtual memory to host physical memory. \nIt maintain a copy of the guest page table in a *shadow* page table, and mirror every page table update from the guest. \n\nThis shadow page table is pointed to by CR3, and contains the actual mapping.\n\nUpon a guest page fault (aka, shadow page fault):\n- The hypervisor trap it, then forward it to the guest for it to update its page table since there is no entry yet.\n- The guest update its page table (which will not be used by hardware translation). This may trigger a real page fault if guest page table is set at Read-only. Here the hypervisor can intercept and update the shadow page table.\n- The guest then access the memory. Since the mapping is now contained in the shadow page table, it can access it. \n\nNote that this process bypass the two-time address translation.\n\nStill, this is expensive when there is a lot of paging in the guest VM, since every page fault in the guest is forwarded to the host.\n\nNowaday it is still used in nested virtualization.\n\n### EPT/NPT\nExtended page table (EPT), aka Nested page table (NPT), is a hardware extension implementing second-level address translation (SLAT). \nEach VM will have an additional extended page table translate from guest physical address (gPAddr) into host physical address (hPAddr).\nThis extended page table is stored in the VMCS. \nIn virtualization mode, the MMU now walk the guest VM page table first to translate gVAddr to gPAddr. Then the MMU, without stopping, translate the second page table in the host. Hence, host page table is *nested* within the guest page table to translate (gPAddr-\u003ehVAddr-\u003ehPAddr). \nIf there is a page fault, the host OS simply update the nested table with the mapping.\nThis allows more efficient translation.\n\nWith the technology, when there is on guest's page fault, there is no exit to the hypervisor; the CPU automatically wals both page table.\n\nFor more implementation details of the feature, see [bhyve](https://people.freebsd.org/~neel/bhyve/bhyve_nested_paging.pdf)'s implementation.\n\n# More resources\n- [High-level introduction to the Low-Level virtualization](http://haifux.org/lectures/312/High-Level%20Introduction%20to%20the%20Low-Level%20of%20Virtualization.pdf)\n- Intel manual?","snippets":["#virtualization"],"rawContent":"# Hypervisor (VMM)\n#virtualization\n\nA hypervisor, also known as virtual machine monitor (VMM) manage virtual machines. \n\nIt performs interposition ([[s16ct1rj#interposition]]) on a certain *interesting* instructions to *emulate* then, hence *trap-and-emulate*. Those interesting instruction can be:\n- Access to hardware devices\n- Special instructions (e.g., CPUID)\n- Access to important and dangerous registers that have global effect \n\nHypervisor works by exploiting modern hardware supports that allows trapping of those important instructions.\n\n## Launching VM\nProcessor state of the VM is stored in a Virtual Machine Control structure/block (VMCS/VMCB) (see [VMCS](https://shhoya.github.io/hv_vmcsdata.html)). VMCS is a complex structure containing informations related to a VM's state. A pointer to the current VMCS is stored in a dedicated register, loaded with `VMPTRLD` instruction ([VMPTR](https://www.felixcloutier.com/x86/vmptrld.)).\n\nThe hypervisor is required to setup the VMCS correctly with necessary information.\n\nThe `VMLAUNCH\\VMRESUME` instruction is then used to lanch the VM based on the current VMCS.\n\n## Memory management\n### Legacy\nPreviously, all access to physical memory in the Guest need to be interposed and emulated, which causes a lot of overheads. Address translation and paging need to be perform twice.\n\n### Shadow Page Table\nTo avoid this, Shadow page table (SPT) is a per-VM page table used by the hypervisor to translate guest virtual memory to host physical memory. \nIt maintain a copy of the guest page table in a *shadow* page table, and mirror every page table update from the guest. \n\nThis shadow page table is pointed to by CR3, and contains the actual mapping.\n\nUpon a guest page fault (aka, shadow page fault):\n- The hypervisor trap it, then forward it to the guest for it to update its page table since there is no entry yet.\n- The guest update its page table (which will not be used by hardware translation). This may trigger a real page fault if guest page table is set at Read-only. Here the hypervisor can intercept and update the shadow page table.\n- The guest then access the memory. Since the mapping is now contained in the shadow page table, it can access it. \n\nNote that this process bypass the two-time address translation.\n\nStill, this is expensive when there is a lot of paging in the guest VM, since every page fault in the guest is forwarded to the host.\n\nNowaday it is still used in nested virtualization.\n\n### EPT/NPT\nExtended page table (EPT), aka Nested page table (NPT), is a hardware extension implementing second-level address translation (SLAT). \nEach VM will have an additional extended page table translate from guest physical address (gPAddr) into host physical address (hPAddr).\nThis extended page table is stored in the VMCS. \nIn virtualization mode, the MMU now walk the guest VM page table first to translate gVAddr to gPAddr. Then the MMU, without stopping, translate the second page table in the host. Hence, host page table is *nested* within the guest page table to translate (gPAddr-\u003ehVAddr-\u003ehPAddr). \nIf there is a page fault, the host OS simply update the nested table with the mapping.\nThis allows more efficient translation.\n\nWith the technology, when there is on guest's page fault, there is no exit to the hypervisor; the CPU automatically wals both page table.\n\nFor more implementation details of the feature, see [bhyve](https://people.freebsd.org/~neel/bhyve/bhyve_nested_paging.pdf)'s implementation.\n\n# More resources\n- [High-level introduction to the Low-Level virtualization](http://haifux.org/lectures/312/High-Level%20Introduction%20to%20the%20Low-Level%20of%20Virtualization.pdf)\n- Intel manual?\n","wordCount":549,"tags":["virtualization"],"metadata":{},"created":"2023-08-09T13:49:43.462327061Z","modified":"2023-08-09T13:49:43.462393145Z","checksum":"f06a3e57df55fbc12d032b585df60bed56ea674bf49f28efaebfcbb52e9e84f6"},
    {"filename":"zmt276jl.md","filenameStem":"zmt276jl","path":"zmt276jl.md","absPath":"/Users/khadd/mynotes/zmt276jl.md","title":"I/O operations in AMD SEV","link":"[[zmt276jl]]","lead":"#sev #io #tee","body":"#sev #io #tee\n\nSEV VMs interacts with virtualized hardware through QEMU. More particularly, QEMU-KVM on the host side will serve I/O requests of the VM.\n\nSupported common I/O operations are PIO, MMIO, DMA.\n\n# DMA\nThe IOMMU maps DMA-capable I/O buses of hardware devices to the physical memory. Because the IOMMU only supports memory encryption with ASID=0 (host ID), DMA operations must be done on pages that are shared between VM and host. Those pages are called the Software  I/O Translation Look-aside Buffer SWIOTLB.\n\nOn a read DMA request from the guest VM, QEMU-KVM instructs the IOMMU to perform DMA transfer from device into the SWIOTLB (e.g., swapping pages from the disk). The guest VM then copy the pages inside SWIOTLB into its own memory.\n\nOn a write DMA request, the guest need to copy its data into the SWIOTLB first. QEMU-KVM then commands the IOMMU to transfer those pages to the devices.\n\n# Security\nBecause I/O is unencrypted, the cVM needs to encrypt the I/O data using the software. If I/O is not corrupted, the hypervisor can corrupt contents (e.g., binary) loaded from the disk into memory. @li2019exploiting shows an example where a malicious hypervisor patches the `sshd` binaries to bypass the authentication.\n\nHowever, certain types of data cannot be encrypted. For instance, packets for DHF key exchange are not encrypted. \n\n@li2019exploiting took a closer look at I/O operations that must not be encrypted:\n- In network I/O, the header of IP or TCP cannot be encrypted. Hence, the attacker can forge the header.\n- In display I/O (e.g., VNC), QEMU-KVM redirects the VGA display from the guest to the VNC protocol.\n- Disk I/O can be encrypted with a secret key provisioned by the cVM owner. However, the key is stored in memory and can be extracted using the encryption oracle described in the paper.\n\n\n# Related notes\n- @li2019exploiting: [[literature/ncfh611p]]","snippets":["#sev #io #tee"],"rawContent":"# I/O operations in AMD SEV\n#sev #io #tee\n\nSEV VMs interacts with virtualized hardware through QEMU. More particularly, QEMU-KVM on the host side will serve I/O requests of the VM.\n\nSupported common I/O operations are PIO, MMIO, DMA.\n\n# DMA\nThe IOMMU maps DMA-capable I/O buses of hardware devices to the physical memory. Because the IOMMU only supports memory encryption with ASID=0 (host ID), DMA operations must be done on pages that are shared between VM and host. Those pages are called the Software  I/O Translation Look-aside Buffer SWIOTLB.\n\nOn a read DMA request from the guest VM, QEMU-KVM instructs the IOMMU to perform DMA transfer from device into the SWIOTLB (e.g., swapping pages from the disk). The guest VM then copy the pages inside SWIOTLB into its own memory.\n\nOn a write DMA request, the guest need to copy its data into the SWIOTLB first. QEMU-KVM then commands the IOMMU to transfer those pages to the devices.\n\n# Security\nBecause I/O is unencrypted, the cVM needs to encrypt the I/O data using the software. If I/O is not corrupted, the hypervisor can corrupt contents (e.g., binary) loaded from the disk into memory. @li2019exploiting shows an example where a malicious hypervisor patches the `sshd` binaries to bypass the authentication.\n\nHowever, certain types of data cannot be encrypted. For instance, packets for DHF key exchange are not encrypted. \n\n@li2019exploiting took a closer look at I/O operations that must not be encrypted:\n- In network I/O, the header of IP or TCP cannot be encrypted. Hence, the attacker can forge the header.\n- In display I/O (e.g., VNC), QEMU-KVM redirects the VGA display from the guest to the VNC protocol.\n- Disk I/O can be encrypted with a secret key provisioned by the cVM owner. However, the key is stored in memory and can be extracted using the encryption oracle described in the paper.\n\n\n# Related notes\n- @li2019exploiting: [[literature/ncfh611p]]\n","wordCount":319,"tags":["tee","sev","io"],"metadata":{},"created":"2023-08-09T13:49:43.478671655Z","modified":"2023-08-09T13:49:43.478710822Z","checksum":"7fad94d993edb39ad13ae0386de03b028bb46afe01ab672f934e6441992aac94"},
    {"filename":"zz3cedu0.md","filenameStem":"zz3cedu0","path":"zz3cedu0.md","absPath":"/Users/khadd/mynotes/zz3cedu0.md","title":"Idea Compass","link":"[[zz3cedu0]]","lead":"#zettelkasten #note-taking","body":"#zettelkasten #note-taking\n\nIdea Compass is a thinking tool that helps define how to think about a particular idea. In particular, it is described in [Compass of Zettelkasten Thinking](https://feeei.substack.com/i/48707291/the-compass-of-zettelkasten-thinking) as follows:\n\n\u003e\n1.  take one idea (X) and put it in the centre\n2. imagine the four compass directions. each direction helps give definition to the idea in different ways.\n  - NORTH: *“Where does X come from?”* what are its origin? what group/category does X belong to? what exists an order of magnitude higher? zoom out. what gave birth to X? what causes X\n  - WEST: *“What is similar to X?”* what other disciplines could X already exist in? what other disciplines could benefit from X? what are other ways to say/do X?\n  - SOUTH: *“Where can X lead to?”* what does X contribute to? what group/category could X be the headline of? what exists an order of magnitude lower? zoom in. what does X nurture?\n  - EAST: *“What competes with X?”* what is the opposite of X? what is X missing? its disadvantage? what could supercharge X?\n3. The Zettelkasten structure created around the idea could look something like this:\n  - NORTH\n    - The Idea\n      - SOUTH\n      - EAST\n      - WEST\n\n\nTakes the idea of the *idea compass* itself for example. We can start from the NORTH:\n- NORTH: *\"Where does X come from?\"* \n  - This idea comes from the lack of clear instructions for using the zettelkasten [[ae6fatms]] method. For instance, what should an idea contain? How do you connect it with other ideas?\n  - Hence, the author introduces a framework for finding the *context* of an idea.\n  - SOUTH: *What can X leads to?*\n    - This idea helps to discover the context of a Zettelkasten note. More importantly, helps writing notes easier [[cemsxh4n]]\n  - EAST: *“What competes with X?”*\n  - WEST: *“What is similar to _X?”_ [This](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) introduces another technique called the *knowledge flower* [[dyx2t4oz]] that is more open for interpretation.","snippets":["#zettelkasten #note-taking"],"rawContent":"# Idea Compass\n#zettelkasten #note-taking\n\nIdea Compass is a thinking tool that helps define how to think about a particular idea. In particular, it is described in [Compass of Zettelkasten Thinking](https://feeei.substack.com/i/48707291/the-compass-of-zettelkasten-thinking) as follows:\n\n\u003e\n1.  take one idea (X) and put it in the centre\n2. imagine the four compass directions. each direction helps give definition to the idea in different ways.\n  - NORTH: *“Where does X come from?”* what are its origin? what group/category does X belong to? what exists an order of magnitude higher? zoom out. what gave birth to X? what causes X\n  - WEST: *“What is similar to X?”* what other disciplines could X already exist in? what other disciplines could benefit from X? what are other ways to say/do X?\n  - SOUTH: *“Where can X lead to?”* what does X contribute to? what group/category could X be the headline of? what exists an order of magnitude lower? zoom in. what does X nurture?\n  - EAST: *“What competes with X?”* what is the opposite of X? what is X missing? its disadvantage? what could supercharge X?\n3. The Zettelkasten structure created around the idea could look something like this:\n  - NORTH\n    - The Idea\n      - SOUTH\n      - EAST\n      - WEST\n\n\nTakes the idea of the *idea compass* itself for example. We can start from the NORTH:\n- NORTH: *\"Where does X come from?\"* \n  - This idea comes from the lack of clear instructions for using the zettelkasten [[ae6fatms]] method. For instance, what should an idea contain? How do you connect it with other ideas?\n  - Hence, the author introduces a framework for finding the *context* of an idea.\n  - SOUTH: *What can X leads to?*\n    - This idea helps to discover the context of a Zettelkasten note. More importantly, helps writing notes easier [[cemsxh4n]]\n  - EAST: *“What competes with X?”*\n  - WEST: *“What is similar to _X?”_ [This](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) introduces another technique called the *knowledge flower* [[dyx2t4oz]] that is more open for interpretation.\n","wordCount":326,"tags":["note-taking","zettelkasten"],"metadata":{},"created":"2023-08-09T13:49:43.478793114Z","modified":"2023-08-09T13:49:43.478841572Z","checksum":"3f1da98e11e3b412cb56702b44b4a44bd1f160989ee3b447d24269a428d19d37"},
    {"filename":"u55zie42.md","filenameStem":"u55zie42","path":"literature/u55zie42.md","absPath":"/Users/khadd/mynotes/literature/u55zie42.md","title":"InkTag: Secure Applications on an Untrusted Operating System","link":"[[literature/u55zie42]]","lead":"#literature #hypervisor","body":"#literature #hypervisor\n\n# Background\nAt the time of this paper, SGX that have the same functionality but without hypervisor have yet to exist.\n\nPrevious system on protection against untrusted OS, OverShadow [@chen2008overshadow] only focus on isolation of memory (code and data) from the OS. This papers provides methods for verifying OS behaviors, allowing the protected program to use OS services securely.\n\n\n\n\n\n\n\n![hologram](../images/hologram.png)\n\n\n\n\n\n\n\n# Main arguments\n## Verifying OS behaviors with the hypervisors is more simple than reimplementing OS services inside the hypervisor\n- OS services often have simple specifications.\n- Only implementing verification in the kernel reduces the TCB of hypervisor.\n- The introduced technique called *paraverification* to verify the unstrusted OS. Essentially, the OS is changed to cooperate with the hypervisor for verifiable OS services (e.g., page management). \n\n## Untrusted OS verification leads to security\n- This directly address the Iago Attack [[ns7lcn8t]] where the untrusted OS feeds incorrect values to trusted application.\n- InkTag enable crash consistency\n- InkTag is able to secure files with defined access control policies. \n\n# Control flow\nThe High assurance programs (HAPs) and the operating system interacts through a *untrusted trampoline*. The application first invoke the hypervisor to request system call. The hypervisor switch the control to an untrusted trampoline that actually invoke the system call. \n\nThis allows the untrusted OS to schedule among the untrusted trampolines and other contexts.\n\nNOTE: Not quite understand.\n\n# Memory isolation\nInkTag provides two layers of memory isolation: kernel to High assurance programs (HAPs), and between the HAPs.\nMemory isolation are provided by EPT virtualization plus paraverfication.\nThis isolation is maintained from the file system up to the memory pages.\n\nThe *object* abstraction represents files. Each object is given a unique ID (*OID*).\nAn objects consists of *secure pages (S-pages)* that contains metadata about the owner object and the offset within the object (*\u003cOID, offset\u003e*), and also the *hash* of the data (for verification).\n\n## Two EPTs\nTwo EPTs are used for trusted context (HAPs) and untrusted context (kernel / normal apps). The trusted EPT maps the plaintext S-page physical frames. The untrusted EPT maps the other frames.  \n- When OS / untrusted applications access a mapped S-pages in trusted EPT (not mapped in untrusted), the hypervisor unmap it in trusted EPT, take the hash, encrypt the page, then map it to untrusted EPT.\n- When HAP access the frame, hypervisor decrypt the page, verify the hash, map it to trusted EPT, unmap it from untrusted EPT. \n\n## Isolation between HAPs\nThe hypervisor manage page table updates for HAPs, to enforce access control policies of objects. For normal pages, the OS can map without intervention.","snippets":["#literature #hypervisor"],"rawContent":"# InkTag: Secure Applications on an Untrusted Operating System\n#literature #hypervisor\n\n# Background\nAt the time of this paper, SGX that have the same functionality but without hypervisor have yet to exist.\n\nPrevious system on protection against untrusted OS, OverShadow [@chen2008overshadow] only focus on isolation of memory (code and data) from the OS. This papers provides methods for verifying OS behaviors, allowing the protected program to use OS services securely.\n\n\n\n\n\n\n\n![hologram](../images/hologram.png)\n\n\n\n\n\n\n\n# Main arguments\n## Verifying OS behaviors with the hypervisors is more simple than reimplementing OS services inside the hypervisor\n- OS services often have simple specifications.\n- Only implementing verification in the kernel reduces the TCB of hypervisor.\n- The introduced technique called *paraverification* to verify the unstrusted OS. Essentially, the OS is changed to cooperate with the hypervisor for verifiable OS services (e.g., page management). \n\n## Untrusted OS verification leads to security\n- This directly address the Iago Attack [[ns7lcn8t]] where the untrusted OS feeds incorrect values to trusted application.\n- InkTag enable crash consistency\n- InkTag is able to secure files with defined access control policies. \n\n# Control flow\nThe High assurance programs (HAPs) and the operating system interacts through a *untrusted trampoline*. The application first invoke the hypervisor to request system call. The hypervisor switch the control to an untrusted trampoline that actually invoke the system call. \n\nThis allows the untrusted OS to schedule among the untrusted trampolines and other contexts.\n\nNOTE: Not quite understand.\n\n# Memory isolation\nInkTag provides two layers of memory isolation: kernel to High assurance programs (HAPs), and between the HAPs.\nMemory isolation are provided by EPT virtualization plus paraverfication.\nThis isolation is maintained from the file system up to the memory pages.\n\nThe *object* abstraction represents files. Each object is given a unique ID (*OID*).\nAn objects consists of *secure pages (S-pages)* that contains metadata about the owner object and the offset within the object (*\u003cOID, offset\u003e*), and also the *hash* of the data (for verification).\n\n## Two EPTs\nTwo EPTs are used for trusted context (HAPs) and untrusted context (kernel / normal apps). The trusted EPT maps the plaintext S-page physical frames. The untrusted EPT maps the other frames.  \n- When OS / untrusted applications access a mapped S-pages in trusted EPT (not mapped in untrusted), the hypervisor unmap it in trusted EPT, take the hash, encrypt the page, then map it to untrusted EPT.\n- When HAP access the frame, hypervisor decrypt the page, verify the hash, map it to trusted EPT, unmap it from untrusted EPT. \n\n## Isolation between HAPs\nThe hypervisor manage page table updates for HAPs, to enforce access control policies of objects. For normal pages, the OS can map without intervention. \n","wordCount":447,"tags":["literature","hypervisor"],"metadata":{},"created":"2023-08-09T13:49:43.47040717Z","modified":"2023-08-09T13:49:43.470456462Z","checksum":"e6009e3f5d75b04eb6ec20c35e7b3da786c76e19521cd47d43d8868bd3aa3d67"},
    {"filename":"nxznwhum.md","filenameStem":"nxznwhum","path":"nxznwhum.md","absPath":"/Users/khadd/mynotes/nxznwhum.md","title":"Instrumenting function prologue and epilogue with LLVM","link":"[[nxznwhum]]","lead":"#llvm #ir","body":"#llvm #ir\n\nInstrumenting functions' prologue and epilogue is not as straight forward as it seem.\n\nTo instrument every function's prologue: \n```c\n   auto FirstI = \u0026*F.getEntryBlock().begin();\n   IRBuilder\u003c\u003e ProIRB(FirstI);\n   CallInst *Prologue = ProIRB.CreateCall(CapacPrologue);\n\n   DILocation *Loc =\n       DILocation::get(F.getParent()-\u003egetContext(), 0, 0,\n       F.getSubprogram());\n  Prologue-\u003esetDebugLoc(Loc);\n```\nNote that The debug location is needed because of this error:\n\u003e inlinable function call in a function with debug info must have a !dbg location\n\nThe epilogue must cover all exit points of the function. This can be done by scanning for return instructions in the basic blocks. \n```c\n\n   // Collect possible exit points\n   std::vector\u003cBasicBlock *\u003e ReturningBlocks;\n   for (BasicBlock \u0026I : F)\n     if (isa\u003cReturnInst\u003e(I.getTerminator()))\n       ReturningBlocks.push_back(\u0026I);\n\n   // Insert epilogue to all blocks\n   if (ReturningBlocks.size() != 0) {\n     for (BasicBlock *BB : ReturningBlocks) {\n       IRBuilder\u003c\u003e EpiIRB(BB-\u003egetTerminator());\n       CallInst *Epi = EpiIRB.CreateCall(CapacEpilogue);\n       Epi-\u003esetDebugLoc(EpiIRB.getCurrentDebugLocation());\n     }\n   }\n```","snippets":["#llvm #ir"],"rawContent":"# Instrumenting function prologue and epilogue with LLVM\n#llvm #ir\n\nInstrumenting functions' prologue and epilogue is not as straight forward as it seem.\n\nTo instrument every function's prologue: \n```c\n   auto FirstI = \u0026*F.getEntryBlock().begin();\n   IRBuilder\u003c\u003e ProIRB(FirstI);\n   CallInst *Prologue = ProIRB.CreateCall(CapacPrologue);\n\n   DILocation *Loc =\n       DILocation::get(F.getParent()-\u003egetContext(), 0, 0,\n       F.getSubprogram());\n  Prologue-\u003esetDebugLoc(Loc);\n```\nNote that The debug location is needed because of this error:\n\u003e inlinable function call in a function with debug info must have a !dbg location\n\nThe epilogue must cover all exit points of the function. This can be done by scanning for return instructions in the basic blocks. \n```c\n\n   // Collect possible exit points\n   std::vector\u003cBasicBlock *\u003e ReturningBlocks;\n   for (BasicBlock \u0026I : F)\n     if (isa\u003cReturnInst\u003e(I.getTerminator()))\n       ReturningBlocks.push_back(\u0026I);\n\n   // Insert epilogue to all blocks\n   if (ReturningBlocks.size() != 0) {\n     for (BasicBlock *BB : ReturningBlocks) {\n       IRBuilder\u003c\u003e EpiIRB(BB-\u003egetTerminator());\n       CallInst *Epi = EpiIRB.CreateCall(CapacEpilogue);\n       Epi-\u003esetDebugLoc(EpiIRB.getCurrentDebugLocation());\n     }\n   }\n```\n","wordCount":141,"tags":["llvm","ir"],"metadata":{},"created":"2023-08-09T13:49:43.471172464Z","modified":"2023-08-09T13:49:43.471211673Z","checksum":"49da2fae570697d814f22a567c57d17972b27c206c42f1e17c0a1cd9079d5041"},
    {"filename":"dx7vz8d5.md","filenameStem":"dx7vz8d5","path":"dx7vz8d5.md","absPath":"/Users/khadd/mynotes/dx7vz8d5.md","title":"Intel Transactional Synchronization Extensions (TSX)","link":"[[dx7vz8d5]]","lead":"#intel #tsx","body":"#intel #tsx\n\n\nTSX simplifies concurrent programming with transactional memory ([[cosmdjej]]).\n\nIt introduce two modes of execution, hardware lock elision (HLE), which \n\n# Restricted Transactional Memory (RTM)\nRTM adds 4 instructions: `XBEGIN`, `XEND`, `XABORT` and `XTEST`\n\nA thread can initiate transaction with the `XBEGIN` instruction, and terminate with `XEND`. \n\n```c\nif ((status = _xbegin()) == XBEGIN_STARTED)\n  // Perform transaction\n  // ...\n  // commit to memory\n  _xend();\nelse {\n  // handle transaction error\n}\n```\n\nIn the above example, a transaction begin by calling `_xbegin()`. If it can happen, the code inside the `if` block is executed. During the execution, if conflicts or exceptions occur, the transaction is rolled back to `_xbegin()`, and the program execute the `else` block, which handle the error.\n\n\nTSX uses the L1 cache as the intermediate buffer for transaction. Hence, the existing cache coherence protocols can be used to detect conflicts (e.g., memory is modified by two transactions) without introducing new hardware logics. \n\n## Faults during transactions\nA transaction is also aborted when an interrupt occur. For synchronous exceptions (e.g., page faults), TSX *supress* the transaction and does not deliver it to the OS. \nFor asynchronous exceptions (e.g., timer/IO interrupts), the exception is delivered to the OS *after* the transaction is rolled back and aborted, since blocking it would interfere with OS scheduling.\n\n\nHowever, TSX does not allows the program know which type of exception happened. Hence, page fault, divided-by-zero, conflicts, ..., are treated equally.\n\nSince page faults are supressed, the OS cannot know whether page faults occurs or not. This property has been exploited by defenses against control-channel attacks on SGX @shih2017tsgx. The enclave can stop execution, when ever it encounter a page fault. See [[fvom56lw]].","snippets":["#intel #tsx"],"rawContent":"# Intel Transactional Synchronization Extensions (TSX)\n#intel #tsx\n\n\nTSX simplifies concurrent programming with transactional memory ([[cosmdjej]]).\n\nIt introduce two modes of execution, hardware lock elision (HLE), which \n\n# Restricted Transactional Memory (RTM)\nRTM adds 4 instructions: `XBEGIN`, `XEND`, `XABORT` and `XTEST`\n\nA thread can initiate transaction with the `XBEGIN` instruction, and terminate with `XEND`. \n\n```c\nif ((status = _xbegin()) == XBEGIN_STARTED)\n  // Perform transaction\n  // ...\n  // commit to memory\n  _xend();\nelse {\n  // handle transaction error\n}\n```\n\nIn the above example, a transaction begin by calling `_xbegin()`. If it can happen, the code inside the `if` block is executed. During the execution, if conflicts or exceptions occur, the transaction is rolled back to `_xbegin()`, and the program execute the `else` block, which handle the error.\n\n\nTSX uses the L1 cache as the intermediate buffer for transaction. Hence, the existing cache coherence protocols can be used to detect conflicts (e.g., memory is modified by two transactions) without introducing new hardware logics. \n\n## Faults during transactions\nA transaction is also aborted when an interrupt occur. For synchronous exceptions (e.g., page faults), TSX *supress* the transaction and does not deliver it to the OS. \nFor asynchronous exceptions (e.g., timer/IO interrupts), the exception is delivered to the OS *after* the transaction is rolled back and aborted, since blocking it would interfere with OS scheduling.\n\n\nHowever, TSX does not allows the program know which type of exception happened. Hence, page fault, divided-by-zero, conflicts, ..., are treated equally.\n\nSince page faults are supressed, the OS cannot know whether page faults occurs or not. This property has been exploited by defenses against control-channel attacks on SGX @shih2017tsgx. The enclave can stop execution, when ever it encounter a page fault. See [[fvom56lw]].\n\n\n","wordCount":286,"tags":["intel","tsx"],"metadata":{},"created":"2023-08-09T13:49:43.463194647Z","modified":"2023-08-09T13:49:43.463258231Z","checksum":"f1972f01e76d179abcdf34b5d33621def2003a3c90159cf46023a8255b8f14f0"},
    {"filename":"qti6u06p.md","filenameStem":"qti6u06p","path":"qti6u06p.md","absPath":"/Users/khadd/mynotes/qti6u06p.md","title":"Interface design for distrust","link":"[[qti6u06p]]","lead":"#compartmentalization","body":"#compartmentalization\n\n[@lefeuvre2022assessing] proposed 8 guidelines for designing safe interface that helps reduce the interface vulnerabilities.\n\n## 1. Clearly segregate resources\nThis means that each component must be responsible for allocating and freeing their own resources. In other words, they should *not* expose a malloc-like interface to other compartments. Doing so, attackers from a compartment can exploit the allocator (e.g., heap feng shui), or trigger arbitrary use-after-free (if the allocated data is used at both side).\n\n## 2. Always copy cross boundary objects\nIn other words, never let two compartments concurrently modify data. Doing so leads to TOCTOU issues, and the need of cross-compartment synchronization.\n\n\n## 3. Simplifying API-crossing objects\nAPIs should not contains private states of the compartment, since they can easily corrupted.\n\nMoreover, private states are very hard to check for correctness, especially pointer data.\n\nMaintaining immutability of those state is also a hard problem.\n\n\n## 4. Trusted-components allocates\nThe trusted component must allocates memory. \n\nThis guideline is to avoid validating may-corrupted data from other components. \nEspecially, for strings, since the trusted component allocate, it knows the size of the buffer, so checking NULL-termination is not needed. \n\nIt is not sure if it is applicable to other data except from String. A more generalized version is that the trusted component must allocate memory where the size is unknown.\n\n## 5. Trusted interface functions must be thread-safe\nThis is to avoid temporal attacks.\n\n## 6. Ordering requirements \nInterface must enforce ordering requirements if possible.\n\n\n## 7. No sharing of unintialized data\nThis is to avoid leaking of private data in uninitalized memory. \n\n## 8. Check for CIV ASAP\nSafety checks should be performed as soon as the untrusted data is received. This is because it is very hard to ensure the safety once the data is propagated throughout the program, which leads to duplicated checks. \n\nMoreover, it prevent untrusted data from flowing to other compartments.","snippets":["#compartmentalization"],"rawContent":"# Interface design for distrust \n#compartmentalization\n\n[@lefeuvre2022assessing] proposed 8 guidelines for designing safe interface that helps reduce the interface vulnerabilities.\n\n## 1. Clearly segregate resources\nThis means that each component must be responsible for allocating and freeing their own resources. In other words, they should *not* expose a malloc-like interface to other compartments. Doing so, attackers from a compartment can exploit the allocator (e.g., heap feng shui), or trigger arbitrary use-after-free (if the allocated data is used at both side).\n\n## 2. Always copy cross boundary objects\nIn other words, never let two compartments concurrently modify data. Doing so leads to TOCTOU issues, and the need of cross-compartment synchronization.\n\n\n## 3. Simplifying API-crossing objects\nAPIs should not contains private states of the compartment, since they can easily corrupted.\n\nMoreover, private states are very hard to check for correctness, especially pointer data.\n\nMaintaining immutability of those state is also a hard problem.\n\n\n## 4. Trusted-components allocates\nThe trusted component must allocates memory. \n\nThis guideline is to avoid validating may-corrupted data from other components. \nEspecially, for strings, since the trusted component allocate, it knows the size of the buffer, so checking NULL-termination is not needed. \n\nIt is not sure if it is applicable to other data except from String. A more generalized version is that the trusted component must allocate memory where the size is unknown.\n\n## 5. Trusted interface functions must be thread-safe\nThis is to avoid temporal attacks.\n\n## 6. Ordering requirements \nInterface must enforce ordering requirements if possible.\n\n\n## 7. No sharing of unintialized data\nThis is to avoid leaking of private data in uninitalized memory. \n\n## 8. Check for CIV ASAP\nSafety checks should be performed as soon as the untrusted data is received. This is because it is very hard to ensure the safety once the data is propagated throughout the program, which leads to duplicated checks. \n\nMoreover, it prevent untrusted data from flowing to other compartments.\n","wordCount":320,"tags":["compartmentalization"],"metadata":{},"created":"2023-08-09T13:49:43.471783133Z","modified":"2023-08-09T13:49:43.47183255Z","checksum":"61a12eaecb53b1d9ef90113594861015d20ebce30a7600afe95a6c81fb978cbf"},
    {"filename":"1k9i1cr3.md","filenameStem":"1k9i1cr3","path":"1k9i1cr3.md","absPath":"/Users/khadd/mynotes/1k9i1cr3.md","title":"Interrupt handling in Unikraft (x86)","link":"[[1k9i1cr3]]","lead":"#unikraft","body":"#unikraft\n\nOn x86, `lidt %0` loads the IDT address into IDT register ([osdev]).\n\n`traps_table_init` initialize the traps vector table, a.k.a the IDT ([osdev]). It writes into the `cpu_idt` table, with the corresponding trap index.\n\nThe function pointer to the handler in IDT is set to a stub, named `asm_trap_{trapname}` (defined by the macro `ASM_TRAP_SYM`). E.g., `asm_trap_page_fault`.\n\nThe stubs are defined in `cpu_vectors_x86_64.S`. Its implementation call the function with the name `do_{trapname}`. Declarations of these `do_*` functions can be found in `plat/x86/traps.c`. \n\nThe following macro create implementations for the trap that actually call a `_raise_event_{event}` function. \n```c\n#define DECLARE_TRAP(name, str, event)\t\t\t\t\t\\\nvoid do_##name(struct __regs *regs)\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tint rc;\t\t\t\t\t\t\t\t\\\n\trc = _raise_event_##event(TRAP_##name, regs, 0);\t\t\\\n\tif (unlikely(rc \u003c 0))\t\t\t\t\t\t\\\n\t\tuk_pr_crit(\"trap handler returned error: %d\\n\", rc);\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (!rc)\t\t\t\t\t\t\t\\\n\t\tdo_unhandled_trap(TRAP_##name, str, regs, 0);\t\t\\\n}\n```\n\n```c\nDECLARE_TRAP   (debug,           \"debug\",                UKARCH_TRAP_DEBUG)\nDECLARE_TRAP_EC(int3,            \"int3\",                 UKARCH_TRAP_DEBUG)\n```\n\n# References\n- [osdev]: https://wiki.osdev.org/Interrupt_Descriptor_Table","snippets":["#unikraft"],"rawContent":"# Interrupt handling in Unikraft (x86)\n#unikraft\n\nOn x86, `lidt %0` loads the IDT address into IDT register ([osdev]).\n\n`traps_table_init` initialize the traps vector table, a.k.a the IDT ([osdev]). It writes into the `cpu_idt` table, with the corresponding trap index.\n\nThe function pointer to the handler in IDT is set to a stub, named `asm_trap_{trapname}` (defined by the macro `ASM_TRAP_SYM`). E.g., `asm_trap_page_fault`.\n\nThe stubs are defined in `cpu_vectors_x86_64.S`. Its implementation call the function with the name `do_{trapname}`. Declarations of these `do_*` functions can be found in `plat/x86/traps.c`. \n\nThe following macro create implementations for the trap that actually call a `_raise_event_{event}` function. \n```c\n#define DECLARE_TRAP(name, str, event)\t\t\t\t\t\\\nvoid do_##name(struct __regs *regs)\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tint rc;\t\t\t\t\t\t\t\t\\\n\trc = _raise_event_##event(TRAP_##name, regs, 0);\t\t\\\n\tif (unlikely(rc \u003c 0))\t\t\t\t\t\t\\\n\t\tuk_pr_crit(\"trap handler returned error: %d\\n\", rc);\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (!rc)\t\t\t\t\t\t\t\\\n\t\tdo_unhandled_trap(TRAP_##name, str, regs, 0);\t\t\\\n}\n```\n\n```c\nDECLARE_TRAP   (debug,           \"debug\",                UKARCH_TRAP_DEBUG)\nDECLARE_TRAP_EC(int3,            \"int3\",                 UKARCH_TRAP_DEBUG)\n```\n\n# References\n- [osdev]: https://wiki.osdev.org/Interrupt_Descriptor_Table\n\n\n","wordCount":160,"tags":["unikraft"],"metadata":{},"created":"2023-08-09T13:49:43.459889553Z","modified":"2023-08-09T13:49:43.459941137Z","checksum":"ea8688774e71d0c1751ff07a052aad70b415ed1f47467b14bcff22e1ad83da92"},
    {"filename":"2hnk4l00.md","filenameStem":"2hnk4l00","path":"2hnk4l00.md","absPath":"/Users/khadd/mynotes/2hnk4l00.md","title":"Invariants in Rust","link":"[[2hnk4l00]]","lead":"#rust","body":"#rust\n\nRalf Jung described two types of *invariants* in Rust in [this post](https://www.ralfj.de/blog/2018/08/22/two-kinds-of-invariants.html), *safety* and *validity*.\n\n# Safety invariant\nEssentially, *safety invariants* are the invariants of a particualr types, that must be upholded, such that that *no matter what safe code does, it must not cause undefine behaviors*.\n\nOne example of this for any primitive type `T`, the invariant is that the object having the type must be initialized (accesing unintialized data is an undefined behavior). Another example is that reference types must be aligned, non-null, and points to an allocated memory that have no other pointer accesses.\n\n\n## Custom/higher-order safety invariants\nThere can also be *custom* safety invariants -- *higher-order* invariants that are not maintained by the compiler, but must be maintained by the unsafe code @bae2021rudra. For example, *Vec*, defined as \n```rust\npub struct Vec\u003cT\u003e {\n    ptr: Unique\u003cT\u003e, // pointing to the heap-allocated backing store holding all the data\n    cap: usize, // number of elements that fit the backing store\n    len: usize, // number of elements that are actually initialized in the backing store\n}\n```\n, must uphold that `ptr` must points to valid memory size of `cap*sizeof(T)`, . The difference between invariants of Vec and other primitive types is that it is defined by the owner, and that the implementer of the type and the unsafe users must uphold them.\n\nMore specifically, for those types, the Rust compiler only guarantee the corectnesses of the signature. Some higher-order invariants can related to (see @bae2021rudra): \n1. Logical consistency (e.g., respecting total ordering)\n2. Purity (e.g., always returns same value for the same input, have no side effect) (possibly related to [[013pr50f]])\n3. Semantic restrictions (e.g., only write to the arguments because it may contains unintialized memory)\nNOTE: It seems that the first and second types of higher-order invariants cannot trigger undefined behaviors by themself. It is not sure we should consider them safety invariants, even. [There has been discussion among Rust community about this](https://users.rust-lang.org/t/should-i-use-unsafe-merely-to-encourage-users-to-maintain-invariants/27856/4). The conclusion was that they should *not* be unsafe invariants.\n\n### Invariant boundaries of unsafe\nThe unsafe code writter to make sure that they are correct *only at the boundaries* with safe code.\nThis boundary highly depends on the unsafe user. Generally, if an *unsafe* block is well-contained, the safety invariants should be upholded *at the end* of the unsafe scope.\nOn the other hand, for some libraries that use unsafe, but provide safe wrapper for safe code to use, the safety\n\n---\n\n# Validity invariants\nThe other type of invariant is the validity invariant. Validity invariants are the invariants that must be maintained between Rust and the compiler, so that the optimization can be performed safely. For instance, `Option\u003cbool\u003e` can be stored in 1 byte of memory, because it can only have three possible values (`true`, `false` and `None`).\n\n\nDifferent from safety invariant that the unsafe code must uphold only at the boundaries with safe code, validity invariants are the invariants unsafe must *always* uphold.\n\n\n# Related notes\n[[zzq5zy5v]]","snippets":["#rust"],"rawContent":"# Invariants in Rust\n#rust\n\nRalf Jung described two types of *invariants* in Rust in [this post](https://www.ralfj.de/blog/2018/08/22/two-kinds-of-invariants.html), *safety* and *validity*.\n\n# Safety invariant\nEssentially, *safety invariants* are the invariants of a particualr types, that must be upholded, such that that *no matter what safe code does, it must not cause undefine behaviors*.\n\nOne example of this for any primitive type `T`, the invariant is that the object having the type must be initialized (accesing unintialized data is an undefined behavior). Another example is that reference types must be aligned, non-null, and points to an allocated memory that have no other pointer accesses.\n\n\n## Custom/higher-order safety invariants\nThere can also be *custom* safety invariants -- *higher-order* invariants that are not maintained by the compiler, but must be maintained by the unsafe code @bae2021rudra. For example, *Vec*, defined as \n```rust\npub struct Vec\u003cT\u003e {\n    ptr: Unique\u003cT\u003e, // pointing to the heap-allocated backing store holding all the data\n    cap: usize, // number of elements that fit the backing store\n    len: usize, // number of elements that are actually initialized in the backing store\n}\n```\n, must uphold that `ptr` must points to valid memory size of `cap*sizeof(T)`, . The difference between invariants of Vec and other primitive types is that it is defined by the owner, and that the implementer of the type and the unsafe users must uphold them.\n\nMore specifically, for those types, the Rust compiler only guarantee the corectnesses of the signature. Some higher-order invariants can related to (see @bae2021rudra): \n1. Logical consistency (e.g., respecting total ordering)\n2. Purity (e.g., always returns same value for the same input, have no side effect) (possibly related to [[013pr50f]])\n3. Semantic restrictions (e.g., only write to the arguments because it may contains unintialized memory)\nNOTE: It seems that the first and second types of higher-order invariants cannot trigger undefined behaviors by themself. It is not sure we should consider them safety invariants, even. [There has been discussion among Rust community about this](https://users.rust-lang.org/t/should-i-use-unsafe-merely-to-encourage-users-to-maintain-invariants/27856/4). The conclusion was that they should *not* be unsafe invariants.\n\n### Invariant boundaries of unsafe\nThe unsafe code writter to make sure that they are correct *only at the boundaries* with safe code.\nThis boundary highly depends on the unsafe user. Generally, if an *unsafe* block is well-contained, the safety invariants should be upholded *at the end* of the unsafe scope.\nOn the other hand, for some libraries that use unsafe, but provide safe wrapper for safe code to use, the safety\n\n---\n\n# Validity invariants\nThe other type of invariant is the validity invariant. Validity invariants are the invariants that must be maintained between Rust and the compiler, so that the optimization can be performed safely. For instance, `Option\u003cbool\u003e` can be stored in 1 byte of memory, because it can only have three possible values (`true`, `false` and `None`).\n\n\nDifferent from safety invariant that the unsafe code must uphold only at the boundaries with safe code, validity invariants are the invariants unsafe must *always* uphold.\n\n\n# Related notes\n[[zzq5zy5v]]\n","wordCount":500,"tags":["rust"],"metadata":{},"created":"2023-08-09T13:49:43.460163512Z","modified":"2023-08-09T13:49:43.460231013Z","checksum":"1468dd3e35c1a379f0ed798005a56db9710f6f4909d272d1c34e3ce2731f8114"},
    {"filename":"w0weqamx.md","filenameStem":"w0weqamx","path":"literature/w0weqamx.md","absPath":"/Users/khadd/mynotes/literature/w0weqamx.md","title":"InvisiPage: Oblivious Demand Paging for Secure Enclaves","link":"[[literature/w0weqamx]]","lead":"#literature\n@aga2019invisipage","body":"#literature\n@aga2019invisipage\n\n# Summary\nTwo page tables are assumed: one to map EPC pages, and the other is to map normal pages. The EPC page table is safely stored within the EPC, an only the enclave can maintain it. Moreover, page faults are handled to the in-enclave page fault handler, so that the faulting address is not learnt by the OS.\n\nBased on  this, InvisiPage then support the oblivious *demand paging* for the EPC pages.  It supports the spilling of EPC pages into non-EPC memory, and uses ORAM to decide which pages to spill. \n\nIt adapt ORAM primitives for paging, and introduce hardware optimizations to reduce the overheads of ORAM.\n\n\n# Oblivious page management\nThe goal is to allows the OS to control how many pages that an are allocated to an enclave, but not which virtual address that are mapped.\n\nFirst, it maintain two page tables, one to map the EPC pages, the other is for normal use. This approach already exists in @costan2016sanctum. However, the new thing is that it allows the OS to swap EPC pages into non-EPC memory *obliviously.\n\nTo do this, the enclave and the OS has to collaborate for memory management.\n## Collaborative memory management\n### Spilling EPC page to non-EPC\nThe OS provides interface to spill a list of provided virtual addresses to non-EPC memory (`opam_access(o-vpn[])`)\n\nThe ORAM tree is maintained by the OS in a separated tree data structure. This tree is indexed by the oblivious page number (`o-vpn`), which is essentially the block ID in the ORAM tree. \n\nOn receiving the `opam_access()` request, the OS has to keep the requested pages *memory-resident*. The enclave runtime then spills/fetchs the EPC pages according the the ORAM algorithm. \n\nOn a spill, data from EPC pages are copied into non-EPC pages. For fetches, data from non-EPC pages are copied into EPC pages.\nFor this step, there is one optimization introduced: only one page is copied from thea non-EPC into EPC memory. The rest of the non-EPC pages are reshuffle within the non-EPC memory.\nTo the OS, it only seems like a path is accessed. It cannot tell which page is actually copied into the EPC. \n\n\nThe page table is retrofitted to store position map information.\n\n\n### Freeing an EPC page\nTo free a EPC page, the OS request a free request to the enclave, but the actual page that get freed is schosen by the enclave.","snippets":["#literature\n@aga2019invisipage"],"rawContent":"# InvisiPage: Oblivious Demand Paging for Secure Enclaves\n#literature\n@aga2019invisipage\n\n# Summary\nTwo page tables are assumed: one to map EPC pages, and the other is to map normal pages. The EPC page table is safely stored within the EPC, an only the enclave can maintain it. Moreover, page faults are handled to the in-enclave page fault handler, so that the faulting address is not learnt by the OS.\n\nBased on  this, InvisiPage then support the oblivious *demand paging* for the EPC pages.  It supports the spilling of EPC pages into non-EPC memory, and uses ORAM to decide which pages to spill. \n\nIt adapt ORAM primitives for paging, and introduce hardware optimizations to reduce the overheads of ORAM.\n\n\n# Oblivious page management\nThe goal is to allows the OS to control how many pages that an are allocated to an enclave, but not which virtual address that are mapped.\n\nFirst, it maintain two page tables, one to map the EPC pages, the other is for normal use. This approach already exists in @costan2016sanctum. However, the new thing is that it allows the OS to swap EPC pages into non-EPC memory *obliviously.\n\nTo do this, the enclave and the OS has to collaborate for memory management.\n## Collaborative memory management\n### Spilling EPC page to non-EPC\nThe OS provides interface to spill a list of provided virtual addresses to non-EPC memory (`opam_access(o-vpn[])`)\n\nThe ORAM tree is maintained by the OS in a separated tree data structure. This tree is indexed by the oblivious page number (`o-vpn`), which is essentially the block ID in the ORAM tree. \n\nOn receiving the `opam_access()` request, the OS has to keep the requested pages *memory-resident*. The enclave runtime then spills/fetchs the EPC pages according the the ORAM algorithm. \n\nOn a spill, data from EPC pages are copied into non-EPC pages. For fetches, data from non-EPC pages are copied into EPC pages.\nFor this step, there is one optimization introduced: only one page is copied from thea non-EPC into EPC memory. The rest of the non-EPC pages are reshuffle within the non-EPC memory.\nTo the OS, it only seems like a path is accessed. It cannot tell which page is actually copied into the EPC. \n\n\nThe page table is retrofitted to store position map information.\n\n\n### Freeing an EPC page\nTo free a EPC page, the OS request a free request to the enclave, but the actual page that get freed is schosen by the enclave.\n","wordCount":409,"tags":["literature"],"metadata":{},"created":"2023-08-09T13:49:43.470478629Z","modified":"2023-08-09T13:49:43.470525087Z","checksum":"0abe6d913b15ab3079722783221bd6243aa7bff4759ab97c1e9988940992f4d2"},
    {"filename":"d8hi0u6t.md","filenameStem":"d8hi0u6t","path":"literature/d8hi0u6t.md","absPath":"/Users/khadd/mynotes/literature/d8hi0u6t.md","title":"Klotski: Efficient Obfuscated Execution against Controlled-Channel Attacks","link":"[[literature/d8hi0u6t]]","lead":"#literature #controlled-channel #oblivious #sgx \n@zhang2020klotski","body":"#literature #controlled-channel #oblivious #sgx \n@zhang2020klotski\n\n\n\n\n\n# Noteworthy Arguments\n## Positioning\n- Previous solutions for controlled-channel protection are either (0) incomplete against attacks, (2) have incomplete protection for code and data, and (3) has high overheads.\n- Incompleteness against attack:\n    - TXS-based solutions @shih2017tsgx, , that tries to detect interrupts of enclaves, but there has been attacks that can trigger without enclave exit.\n\n -Incomplete protection for code and data\n  - Some only protect data accesses @sasy2018zerotrace @drsgx\n  - Other only protect code access @zizagger, and can be defeated fine-grained attack\n\n- High overheads\n  - @shinde2016preventing places sensitive code and data inside one page, but has high overheads (4000x)\n vim.lsp.diagnostic.show_line_diagnostics() - Obfuscuro @ahmad2019obfuscuro only support small code and data size (8KB).\n\n\n- #todo Subpage-level code and data randomization\n\n\n\n\n# Oblivious memory subsystem scheme\n## Memory subsystem\nKlotski's memory subsystem consists of three levels (akin to the actual memory subsystem). The first is the code and data caches, that has reconfigurable sizes, called the *vCache*. The second level is the ORAM *stashes* for code and data. The final layer is the *ORAM tree*.\n\nThe stash and the tree are parts of an ORAM scheme.\n\nMemory from the higher level is evicted into the lower level, with some policies.\n\nThe main reason for *vCache* is to trade-off security for some performance. This is the main difference with Obfuscuro @ahmad2019obfuscuro vCache can be configure to be larger than the page size.\n- ❓Why do you need three levels, why not just configure the stash size then?\n  - ORAM algorithms requires the stash to be certain sizes, or else it will not work (e.g., the path does not fit into the stash).\n  - The stash in untrusted memory, an can span several pages. \n\nIs there a scheme for storing data into untrusted storage, like in @sasy2018zerotrace?\n- This paper assume all memory is within the enclave, and there is no spilling into untrusted storage.\n\n\n## Memory access hierarchy\n\n### Logical addresses\nLogical addresses are the address that the instructions use (i.e., virtual addresses).\n\nKlotski use 32-bit addresses in their implementation, maybe to limit the number of entries in the software PT?\n\n### Logical address translation\nThe program is instrumented to *translate* the logical address on every operations into *real address*, which is an address inside the execution cache.\n\nLogical addresses are translated using a software page table using same method as real page table. The following function translates logical address into page table index:\n\n``` cpp\nsize_t getRealAddress(size_t logicAddr){\n    size_t index = logicAddr\u003e\u003eSHADOWPAGEWIDE;\n    //if the page does not exist in cache,swap the page in\n    if(!pagetable[index]){\n        struct OramPool * oramPool;\n        size_t blockIndex;\n        if(isBigObject(index)){\n            LOGIC_INDEX_TO_BLOCK_INDEX_FOR_BIG(index,blockIndex)\n            oramPool = \u0026DataPool_bigData;\n        }else{\n            LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)\n            oramPool = \u0026DataPool_smallData;\n        }\n        handleObliviousPageExchangeData(index,blockIndex,oramPool);\n    }\n    return pagetable[index]+logicAddr;\n}\n```\nThe address itself also seems to contain the block ID. `LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)` gets the correct block ID from the position map index.\n\nIn this translation function, if page is not in the page table, then it is not in the cache, so address translation happen. This is not what is described in the paper: a PTE also contains the path ID. Maybe this function is only used for static data...\n\nThe real translation function seems to be `dereference_data()`.\n\n### ORAM access\nOn a page miss, ORAM access is triggered to fetch block into the vCache. \nFirst, the ORAM block (2KB *minipage*) is fetched in to the *stash*, and the position map is updated. The block is then moved to the vCache, and a block inside vCache is swapped out.  \n#### Stash\u003c-\u003eORAM\nRing ORAM evict the blocks after $k$ accesses. On eviction, blocks inside the stash is flushed into the ORAM tree.\n\n#### vCache\u003c-\u003eStash\nThe minipage is then swapped into the vCache, where a block is *randomly* evicted from the vCache to make space.\n\nThe paper argue that *LRU* cache eviction may leak information.\n\nThere is also a reconfigurable re-randomization of the vCache: the user can configure such that the vCache is flushed after $n$ accesses. \n\n\n\n\n## Address translation\nKlotski uses a scheme to *translate* logical address to the actual address inside vCache, in the same way a MMU translate physical to virtual address.\n\n\n```c\n// virtual addr use in Klotski-instrumented program\nloadImm R1, logicalAddr\ncall vPTE_lookup(R1)\n// use pointer\nload R2, R1 \n...\n\nv_addr vPTE_lookup(v_addr logicalAddr){\n    vPTE_t vPTE = position_map_scan(logicalAddr);\n    if (vPTE.cached)\n        return vPTE.addr;\n    else\n        // slow path\n       if (vPTE.in_stash) \n           vPTE = stash_fetch(vPTE.oramIndex);\n       else\n           vPTE = oram_read(vPTE.oramIndex);\n       return vPTE.addr;\n}\n```\n## Operations\n### vCache and Stash\n\n- `LoadCache` reads the target minipage\n- \n\n### Address translation\n\n# Compiler \u0026 runtime\nCompiler changes all memory instructions, call, return, into calls into the runtime functions. \nImplementation: [Here](https://github.com/nczhang88pan/KlotskiSGX/tree/master/klotski/llvmProgram/llvm/lib/Transforms/Instrumentation/Klotski)\nMaybe the compiler transformation would looks like this:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n\n---\n%1 = call mmu_load(%arg1)\n%2 = add %1, 100\ncall mmu_call(\u0026foo)\ncall mmu_store(%2, %1)\n```\n\nThe compiler also split code and data into blocks of 2KB, which is also the ORAM block size. The code is compiled as relocatable code, so that it can be relocated to any virtual addresses.\n- ❓ Why do you need relocatable code here?\n- ❓ What is effiective virtual address, why does it change at runtime?\n\nThe runtime functions acts as a memory subsystem: given a virtual address, it look up \n\n\n# ORAM Accesses\nThe paper uses Ring ORAM for its ORAM algorithm. However, there are several noteworthy extensions. Because the memory used for posmap (virtual page  table) and stash is in untrusted memory, attackers can find out which stash slot and posmap entry is accessed.\n\n## ORead\nAn `ORead` operation is introduced to lineary scan over all data that must be touched to remain oblivious, similar to a `cmov`. The data is stored into a 256-bit  ymm registers. 1 register is reserved for reading unused data, and the remainings is used to store the required data.\n\nNOTE: it is not exactly similar to `CMOV`, you only need to actually touch the data in `ORead`, but not write it back.\n\n---\n\nThe `ReadPath` operation that read from ORAM path into stash uses this to bring data into the stash without revealing the actual bucket/block that is accessed.\n\nFor example, consider fetching of a path in traditional Ring ORAM. On each bucket along the path, a block is fetched, but discarded. On the block that contain non-dummy data, it is actually read into the stash. With visibility over stash and tree, the attacker can see that there is a read from the tree, following by a write into the stash. This means that the block that is just read contains the requested data.\n\nBy fetching all data into YMM registers, and delay the write back to the stash to the last moment, this can be hidden.\n\n---\n\n`LoadCache` that load an entry from stash into cache also needs this (for same reason above). It must scan over all stash entries, and only copy the one needed into the vCache.\n\n## WriteStash\nThe WriteStash operation, that write into the stash, is also made oblivious. There are two potential leakage, when the attacker learns about the stash access:\n1. If data is written into a slot, it means that the slot is empty, so it must have been evicted recently.\n2. If data is written into a stash slot twice (without being read), it can be infered that the slot contained dummy blocks. ❓ Is there actually dummy blocks in the stash?\n\nTo solve this, every (1) block must only be written once (before being reshuffled), and (2) a write to a slot must not reveal the last block being evicted\nKlotski solve this by keeping a pointer to slot that is last written, and increment the pointer to the next slot at every write. When the pointer move to the last empty blocks, the stash is reshuffled.\n\n```\n      Spare stash ptr\n            |\n            v\n| 2 | 5 | 3 | \u003cempty\u003e | 4 | \u003cempty\u003e | \n```\n\nAfter write:\n```\n                      v \n| 2 | 5 | 3 | *6* | 4 | \u003c empty \u003e | \n```\n\nPointer moved to the last empty block, so reshuffle:\n```\n                           v\n| 2 | \u003cevited\u003e | \u003cevicted\u003e | 6 | 4 | *1* | \n```\n\nReshuffling moves actual blocks to the begining and update the spare stash ptr.\n```\n                v\n| 6 | 1 | 4 | 2 | \u003cempty\u003e | \u003cempty\u003e | \n```","snippets":["#literature #controlled-channel #oblivious #sgx \n@zhang2020klotski"],"rawContent":"# Klotski: Efficient Obfuscated Execution against Controlled-Channel Attacks \n#literature #controlled-channel #oblivious #sgx \n@zhang2020klotski\n\n\n\n\n\n# Noteworthy Arguments\n## Positioning\n- Previous solutions for controlled-channel protection are either (0) incomplete against attacks, (2) have incomplete protection for code and data, and (3) has high overheads.\n- Incompleteness against attack:\n    - TXS-based solutions @shih2017tsgx, , that tries to detect interrupts of enclaves, but there has been attacks that can trigger without enclave exit.\n\n -Incomplete protection for code and data\n  - Some only protect data accesses @sasy2018zerotrace @drsgx\n  - Other only protect code access @zizagger, and can be defeated fine-grained attack\n\n- High overheads\n  - @shinde2016preventing places sensitive code and data inside one page, but has high overheads (4000x)\n vim.lsp.diagnostic.show_line_diagnostics() - Obfuscuro @ahmad2019obfuscuro only support small code and data size (8KB).\n\n\n- #todo Subpage-level code and data randomization\n\n\n\n\n# Oblivious memory subsystem scheme\n## Memory subsystem\nKlotski's memory subsystem consists of three levels (akin to the actual memory subsystem). The first is the code and data caches, that has reconfigurable sizes, called the *vCache*. The second level is the ORAM *stashes* for code and data. The final layer is the *ORAM tree*.\n\nThe stash and the tree are parts of an ORAM scheme.\n\nMemory from the higher level is evicted into the lower level, with some policies.\n\nThe main reason for *vCache* is to trade-off security for some performance. This is the main difference with Obfuscuro @ahmad2019obfuscuro vCache can be configure to be larger than the page size.\n- ❓Why do you need three levels, why not just configure the stash size then?\n  - ORAM algorithms requires the stash to be certain sizes, or else it will not work (e.g., the path does not fit into the stash).\n  - The stash in untrusted memory, an can span several pages. \n\nIs there a scheme for storing data into untrusted storage, like in @sasy2018zerotrace?\n- This paper assume all memory is within the enclave, and there is no spilling into untrusted storage.\n\n\n## Memory access hierarchy\n\n### Logical addresses\nLogical addresses are the address that the instructions use (i.e., virtual addresses).\n\nKlotski use 32-bit addresses in their implementation, maybe to limit the number of entries in the software PT?\n\n### Logical address translation\nThe program is instrumented to *translate* the logical address on every operations into *real address*, which is an address inside the execution cache.\n\nLogical addresses are translated using a software page table using same method as real page table. The following function translates logical address into page table index:\n\n``` cpp\nsize_t getRealAddress(size_t logicAddr){\n    size_t index = logicAddr\u003e\u003eSHADOWPAGEWIDE;\n    //if the page does not exist in cache,swap the page in\n    if(!pagetable[index]){\n        struct OramPool * oramPool;\n        size_t blockIndex;\n        if(isBigObject(index)){\n            LOGIC_INDEX_TO_BLOCK_INDEX_FOR_BIG(index,blockIndex)\n            oramPool = \u0026DataPool_bigData;\n        }else{\n            LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)\n            oramPool = \u0026DataPool_smallData;\n        }\n        handleObliviousPageExchangeData(index,blockIndex,oramPool);\n    }\n    return pagetable[index]+logicAddr;\n}\n```\nThe address itself also seems to contain the block ID. `LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)` gets the correct block ID from the position map index.\n\nIn this translation function, if page is not in the page table, then it is not in the cache, so address translation happen. This is not what is described in the paper: a PTE also contains the path ID. Maybe this function is only used for static data...\n\nThe real translation function seems to be `dereference_data()`.\n\n### ORAM access\nOn a page miss, ORAM access is triggered to fetch block into the vCache. \nFirst, the ORAM block (2KB *minipage*) is fetched in to the *stash*, and the position map is updated. The block is then moved to the vCache, and a block inside vCache is swapped out.  \n#### Stash\u003c-\u003eORAM\nRing ORAM evict the blocks after $k$ accesses. On eviction, blocks inside the stash is flushed into the ORAM tree.\n\n#### vCache\u003c-\u003eStash\nThe minipage is then swapped into the vCache, where a block is *randomly* evicted from the vCache to make space.\n\nThe paper argue that *LRU* cache eviction may leak information.\n\nThere is also a reconfigurable re-randomization of the vCache: the user can configure such that the vCache is flushed after $n$ accesses. \n\n\n\n\n## Address translation\nKlotski uses a scheme to *translate* logical address to the actual address inside vCache, in the same way a MMU translate physical to virtual address.\n\n\n```c\n// virtual addr use in Klotski-instrumented program\nloadImm R1, logicalAddr\ncall vPTE_lookup(R1)\n// use pointer\nload R2, R1 \n...\n\nv_addr vPTE_lookup(v_addr logicalAddr){\n    vPTE_t vPTE = position_map_scan(logicalAddr);\n    if (vPTE.cached)\n        return vPTE.addr;\n    else\n        // slow path\n       if (vPTE.in_stash) \n           vPTE = stash_fetch(vPTE.oramIndex);\n       else\n           vPTE = oram_read(vPTE.oramIndex);\n       return vPTE.addr;\n}\n```\n## Operations\n### vCache and Stash\n\n- `LoadCache` reads the target minipage\n- \n\n### Address translation\n\n# Compiler \u0026 runtime\nCompiler changes all memory instructions, call, return, into calls into the runtime functions. \nImplementation: [Here](https://github.com/nczhang88pan/KlotskiSGX/tree/master/klotski/llvmProgram/llvm/lib/Transforms/Instrumentation/Klotski)\nMaybe the compiler transformation would looks like this:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n\n---\n%1 = call mmu_load(%arg1)\n%2 = add %1, 100\ncall mmu_call(\u0026foo)\ncall mmu_store(%2, %1)\n```\n\nThe compiler also split code and data into blocks of 2KB, which is also the ORAM block size. The code is compiled as relocatable code, so that it can be relocated to any virtual addresses.\n- ❓ Why do you need relocatable code here?\n- ❓ What is effiective virtual address, why does it change at runtime?\n\nThe runtime functions acts as a memory subsystem: given a virtual address, it look up \n\n\n# ORAM Accesses\nThe paper uses Ring ORAM for its ORAM algorithm. However, there are several noteworthy extensions. Because the memory used for posmap (virtual page  table) and stash is in untrusted memory, attackers can find out which stash slot and posmap entry is accessed.\n\n## ORead\nAn `ORead` operation is introduced to lineary scan over all data that must be touched to remain oblivious, similar to a `cmov`. The data is stored into a 256-bit  ymm registers. 1 register is reserved for reading unused data, and the remainings is used to store the required data.\n\nNOTE: it is not exactly similar to `CMOV`, you only need to actually touch the data in `ORead`, but not write it back.\n\n---\n\nThe `ReadPath` operation that read from ORAM path into stash uses this to bring data into the stash without revealing the actual bucket/block that is accessed.\n\nFor example, consider fetching of a path in traditional Ring ORAM. On each bucket along the path, a block is fetched, but discarded. On the block that contain non-dummy data, it is actually read into the stash. With visibility over stash and tree, the attacker can see that there is a read from the tree, following by a write into the stash. This means that the block that is just read contains the requested data.\n\nBy fetching all data into YMM registers, and delay the write back to the stash to the last moment, this can be hidden.\n\n---\n\n`LoadCache` that load an entry from stash into cache also needs this (for same reason above). It must scan over all stash entries, and only copy the one needed into the vCache.\n\n## WriteStash\nThe WriteStash operation, that write into the stash, is also made oblivious. There are two potential leakage, when the attacker learns about the stash access:\n1. If data is written into a slot, it means that the slot is empty, so it must have been evicted recently.\n2. If data is written into a stash slot twice (without being read), it can be infered that the slot contained dummy blocks. ❓ Is there actually dummy blocks in the stash?\n\nTo solve this, every (1) block must only be written once (before being reshuffled), and (2) a write to a slot must not reveal the last block being evicted\nKlotski solve this by keeping a pointer to slot that is last written, and increment the pointer to the next slot at every write. When the pointer move to the last empty blocks, the stash is reshuffled.\n\n```\n      Spare stash ptr\n            |\n            v\n| 2 | 5 | 3 | \u003cempty\u003e | 4 | \u003cempty\u003e | \n```\n\nAfter write:\n```\n                      v \n| 2 | 5 | 3 | *6* | 4 | \u003c empty \u003e | \n```\n\nPointer moved to the last empty block, so reshuffle:\n```\n                           v\n| 2 | \u003cevited\u003e | \u003cevicted\u003e | 6 | 4 | *1* | \n```\n\nReshuffling moves actual blocks to the begining and update the spare stash ptr.\n```\n                v\n| 6 | 1 | 4 | 2 | \u003cempty\u003e | \u003cempty\u003e | \n```\n\n","wordCount":1410,"tags":["sgx","controlled-channel","literature","oblivious","todo"],"metadata":{},"created":"2023-08-09T13:49:43.469948585Z","modified":"2023-08-09T13:49:43.470030336Z","checksum":"65e58d7a79627c7d29a32945fbd407aeeac8e4027ce509ec14d8272ae0e5520c"},
    {"filename":"dyx2t4oz.md","filenameStem":"dyx2t4oz","path":"dyx2t4oz.md","absPath":"/Users/khadd/mynotes/dyx2t4oz.md","title":"Knowledge flower","link":"[[dyx2t4oz]]","lead":"#zettelkasten #note-taking","body":"#zettelkasten #note-taking\n\n[This blog post](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) proposes a framework to think about [[ae6fatms|Zettlekasten]] notes.\n\n\n1. Choose an idea and place it in the center.\n2. Think of each leaf as an aspect of the thought that is needed to fully develop it. The thought blossoms like a flower.\n  - Truth: Are there arguments for its truth? Is there empirical evidence for its truth? Is it free of self-contradiction?\n  - Relevance: To whom is the thought important? To whom is it not?\n  - Usefulness: What problem can be solved by the thought? Can it become a tool?\n  - Beauty: How does the thought promote harmony and elegance?\n  - Simplicity: How can you make the thought simpler and easier to understand? Can the thought be used to simplify something else?","snippets":["#zettelkasten #note-taking"],"rawContent":"# Knowledge flower\n#zettelkasten #note-taking\n\n[This blog post](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) proposes a framework to think about [[ae6fatms|Zettlekasten]] notes.\n\n\n1. Choose an idea and place it in the center.\n2. Think of each leaf as an aspect of the thought that is needed to fully develop it. The thought blossoms like a flower.\n  - Truth: Are there arguments for its truth? Is there empirical evidence for its truth? Is it free of self-contradiction?\n  - Relevance: To whom is the thought important? To whom is it not?\n  - Usefulness: What problem can be solved by the thought? Can it become a tool?\n  - Beauty: How does the thought promote harmony and elegance?\n  - Simplicity: How can you make the thought simpler and easier to understand? Can the thought be used to simplify something else?\n","wordCount":130,"tags":["note-taking","zettelkasten"],"metadata":{},"created":"2023-08-09T13:49:43.463285939Z","modified":"2023-08-09T13:49:43.463338023Z","checksum":"ec8dacb8b511db2809c15b84fe8f191a2d8088fb2eaf208006354fca4b460062"},
    {"filename":"vne1zoi3.md","filenameStem":"vne1zoi3","path":"vne1zoi3.md","absPath":"/Users/khadd/mynotes/vne1zoi3.md","title":"LLVM register data flow graph","link":"[[vne1zoi3]]","lead":"#llvm #analysis #backend","body":"#llvm #analysis #backend\n\nLLVM provides a Register Data Flow Graph that contains the flow of registers between instructions. [LLVM: include/llvm/CodeGen/RDFGraph.h Source File](https://llvm.org/doxygen/RDFGraph_8h_source.html). Probably useful for some backend analysis tasks.\n\nThe graph is a collection of **Nodes**, where each node can be either a **code node** or a **reference node**.\n- A **code node** is a collection of other nodes. E.g., A **basic block** code node contains **instruction** code nodes, and instruction code node contains **Reference nodes**\n- **Reference node** describe the register reference. It can either be a **DefNode** or a **UseNode**\n\t- DefNode defines the register\n\t- UseNode uses the register\n\nDefNode contains:\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node\n- First reached use: the first node that use this definition.\n\t- To traverse other register uses, we can use the slibing of the UseNode\n- First reached definition: First node after this that redefine the register\nUseNode contains :\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node","snippets":["#llvm #analysis #backend"],"rawContent":"# LLVM register data flow graph\n#llvm #analysis #backend\n\nLLVM provides a Register Data Flow Graph that contains the flow of registers between instructions. [LLVM: include/llvm/CodeGen/RDFGraph.h Source File](https://llvm.org/doxygen/RDFGraph_8h_source.html). Probably useful for some backend analysis tasks.\n\nThe graph is a collection of **Nodes**, where each node can be either a **code node** or a **reference node**.\n- A **code node** is a collection of other nodes. E.g., A **basic block** code node contains **instruction** code nodes, and instruction code node contains **Reference nodes**\n- **Reference node** describe the register reference. It can either be a **DefNode** or a **UseNode**\n\t- DefNode defines the register\n\t- UseNode uses the register\n\nDefNode contains:\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node\n- First reached use: the first node that use this definition.\n\t- To traverse other register uses, we can use the slibing of the UseNode\n- First reached definition: First node after this that redefine the register\nUseNode contains :\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node\n","wordCount":188,"tags":["llvm","analysis","backend"],"metadata":{},"created":"2023-08-09T13:49:43.478406738Z","modified":"2023-08-09T13:49:43.478450613Z","checksum":"af0b3286f985e081fd9ae6dbb902dbb6dde92658a53acc459e6f4f4b4b80acc3"},
    {"filename":"dgdvhu1e.md","filenameStem":"dgdvhu1e","path":"dgdvhu1e.md","absPath":"/Users/khadd/mynotes/dgdvhu1e.md","title":"Limitations of Data-flow-based Dependence analysis","link":"[[dgdvhu1e]]","lead":"#analysis #compartmentalization #data-flow-analysis","body":"#analysis #compartmentalization #data-flow-analysis\n\nProgram compartmentalization techniques such as [@liu2017ptrsplit] often relies on dependence analysis to determine the data flow between code locations, then separate the program based code dependency. Commonly it is done by first identify all *control dependencies* of instructions, which form a reachable control-flow graph. Then, on the reachable control-flow graph, data-flow analysis is performed to find data dependencies.\n\n[@lu2023practical] ([[literature/4zdjxws6]]) notes several limitations with such an approach:\n\nFirst, control dependencies does not reflect all data dependencies.\n- System calls and interrupt handlers is invoked at arbitrary time, and don't have a control-flow edge on the CFG. \n- Two control-independent functions can still pass data through global variables or shared memory.\n[](2023-05-26_.md)\nSecond, data-flow analysis requires points-to analysis.\n- Points-to analysis is expensive can cannot scale to large programs.\n- Points-to analysis produces a large amount of false positive on large programs.","snippets":["#analysis #compartmentalization #data-flow-analysis"],"rawContent":"# Limitations of Data-flow-based Dependence analysis\n#analysis #compartmentalization #data-flow-analysis\n\nProgram compartmentalization techniques such as [@liu2017ptrsplit] often relies on dependence analysis to determine the data flow between code locations, then separate the program based code dependency. Commonly it is done by first identify all *control dependencies* of instructions, which form a reachable control-flow graph. Then, on the reachable control-flow graph, data-flow analysis is performed to find data dependencies.\n\n[@lu2023practical] ([[literature/4zdjxws6]]) notes several limitations with such an approach:\n\nFirst, control dependencies does not reflect all data dependencies.\n- System calls and interrupt handlers is invoked at arbitrary time, and don't have a control-flow edge on the CFG. \n- Two control-independent functions can still pass data through global variables or shared memory.\n[](2023-05-26_.md)\nSecond, data-flow analysis requires points-to analysis.\n- Points-to analysis is expensive can cannot scale to large programs.\n- Points-to analysis produces a large amount of false positive on large programs.\n\n\n\n\n","wordCount":150,"tags":["analysis","compartmentalization","data-flow-analysis"],"metadata":{},"created":"2023-08-09T13:49:43.46311498Z","modified":"2023-08-09T13:49:43.463166564Z","checksum":"2d5f5e201c3677af41a6149311cca066905def6d78ebaa1987631de037cbec76"},
    {"filename":"3ciove99.md","filenameStem":"3ciove99","path":"3ciove99.md","absPath":"/Users/khadd/mynotes/3ciove99.md","title":"Link-time Optimization in LLVM","link":"[[3ciove99]]","lead":"#lto  #llvm","body":"#lto  #llvm\n\nTo enable LTO:\n1. Register the pass so that it happen during LTO (`EP_FullLinkTimeOptimizaitonLast` or `Early`).\n2. Enable `-flto` flag at compile-time, load the pass in Clang, change linker to lld (not sure about gold linker). \n  e.g., `clang -flto -fuse-ld=lld -Wl,-mllvm=-load=pass.so`\n\nNote:\n- `-flegacy-pass-manager` must be passed  when the pass is registrated with legacy APIs","snippets":["#lto  #llvm"],"rawContent":"# Link-time Optimization in LLVM\n#lto  #llvm\n\nTo enable LTO:\n1. Register the pass so that it happen during LTO (`EP_FullLinkTimeOptimizaitonLast` or `Early`).\n2. Enable `-flto` flag at compile-time, load the pass in Clang, change linker to lld (not sure about gold linker). \n  e.g., `clang -flto -fuse-ld=lld -Wl,-mllvm=-load=pass.so`\n\nNote:\n- `-flegacy-pass-manager` must be passed  when the pass is registrated with legacy APIs\n\n\n","wordCount":62,"tags":["lto","llvm"],"metadata":{},"created":"2023-08-09T13:49:43.460423263Z","modified":"2023-08-09T13:49:43.46046743Z","checksum":"1f65028fb5685908d784b73c1ba4f36b4c421234c3dd0b20f8f38b9697ce8f8e"},
    {"filename":"nobagcn6.md","filenameStem":"nobagcn6","path":"nobagcn6.md","absPath":"/Users/khadd/mynotes/nobagcn6.md","title":"Linux Support for SEV-SNP","link":"[[nobagcn6]]","lead":"#linux #sev","body":"#linux #sev\n\n\n# Guest\nThe documentation for the guest support is found here [here](https://www.kernel.org/doc/Documentation/virt/coco/sev-guest.rst)\n# Kernel\nThe patch for hypervisor support is found [here](https://lwn.net/Articles/923844/)","snippets":["#linux #sev"],"rawContent":"# Linux Support for SEV-SNP\n#linux #sev\n\n\n# Guest\nThe documentation for the guest support is found here [here](https://www.kernel.org/doc/Documentation/virt/coco/sev-guest.rst)\n# Kernel\nThe patch for hypervisor support is found [here](https://lwn.net/Articles/923844/) \n\n\n","wordCount":29,"tags":["linux","sev"],"metadata":{},"created":"2023-08-09T13:49:43.471058964Z","modified":"2023-08-09T13:49:43.471096881Z","checksum":"70bedbef84f989368bfe62e09bbdaad19355b58a262b195baf6b1de69dc37a3e"},
    {"filename":"cn9u3d79.md","filenameStem":"cn9u3d79","path":"cn9u3d79.md","absPath":"/Users/khadd/mynotes/cn9u3d79.md","title":"Linux's kernel page table","link":"[[cn9u3d79]]","lead":"#linux #os","body":"#linux #os\n\nLinux's kernel image is direct-mapped to the virtual address space. Physical addresses within the kernel can be translated into virtual addresses by simply adding a `PAGE_OFFSET`\n\n```c\n// in asm/page.h\n#define __va(x)\t\t\t((void *)((unsigned long)(x)+PAGE_OFFSET))\n\n// in asm/io.h\nstatic inline void *phys_to_virt(phys_addr_t address)\n{\n\treturn __va(address);\n}\n```\n\n# References\n- [understand006](https://www.kernel.org/doc/gorman/html/understand/understand006.html)","snippets":["#linux #os"],"rawContent":"# Linux's kernel page table\n#linux #os\n\nLinux's kernel image is direct-mapped to the virtual address space. Physical addresses within the kernel can be translated into virtual addresses by simply adding a `PAGE_OFFSET`\n\n```c\n// in asm/page.h\n#define __va(x)\t\t\t((void *)((unsigned long)(x)+PAGE_OFFSET))\n\n// in asm/io.h\nstatic inline void *phys_to_virt(phys_addr_t address)\n{\n\treturn __va(address);\n}\n```\n\n# References\n- [understand006](https://www.kernel.org/doc/gorman/html/understand/understand006.html)\n","wordCount":59,"tags":["os","linux"],"metadata":{},"created":"2023-08-09T13:49:43.461939476Z","modified":"2023-08-09T13:49:43.461980685Z","checksum":"47a43d9394e581d4309cd4d9537a7aa55b14180cf54fc5e2474d81e5dd85afd6"},
    {"filename":"l80vag29.md","filenameStem":"l80vag29","path":"literature/l80vag29.md","absPath":"/Users/khadd/mynotes/literature/l80vag29.md","title":"Low-Fat Pointers: Compact Encoding and Efficient Gate-Level Implementation of Fat Pointers for Spatial Safety and Capability-based Security","link":"[[literature/l80vag29]]","lead":"#literature #capabilities\n[@kwon2013lowfat]","body":"#literature #capabilities\n[@kwon2013lowfat]\n\nURL: https://dl.acm.org/doi/pdf/10.1145/2508859.2516713\n## Context\nThis work introduces a new bound encoding scheme that encodes object-bound information into 64-bit pointers, and 46-bit address space. \nThe claim is that it introduces zero runtime overheads since the check is performed in parallel with the access.\n### Background \u0026 related work \n- [@wulf1974hydra] HYDRA system and C.mmp processor combine pointers and access right\n- [guarded pointers]:","snippets":["#literature #capabilities\n[@kwon2013lowfat]"],"rawContent":"# Low-Fat Pointers: Compact Encoding and Efficient Gate-Level Implementation of Fat Pointers for Spatial Safety and Capability-based Security\n#literature #capabilities\n[@kwon2013lowfat]\n\nURL: https://dl.acm.org/doi/pdf/10.1145/2508859.2516713\n## Context\nThis work introduces a new bound encoding scheme that encodes object-bound information into 64-bit pointers, and 46-bit address space. \nThe claim is that it introduces zero runtime overheads since the check is performed in parallel with the access.\n### Background \u0026 related work \n- [@wulf1974hydra] HYDRA system and C.mmp processor combine pointers and access right\n- [guarded pointers]: \n\n\n","wordCount":83,"tags":["capabilities","literature"],"metadata":{},"created":"2023-08-09T13:49:43.470127544Z","modified":"2023-08-09T13:49:43.470170045Z","checksum":"40f03059e79eaa0ac17c40e3d12f8b8b92402acc908ea08a8a717768b147c86d"},
    {"filename":"ouv5s2fi.md","filenameStem":"ouv5s2fi","path":"ouv5s2fi.md","absPath":"/Users/khadd/mynotes/ouv5s2fi.md","title":"Memory errors in Rust","link":"[[ouv5s2fi]]","lead":"#memory-safety #rust","body":"#memory-safety #rust\n\nRust seems like a memory-safe language, but due to the prevalent use of unsafe, memory corruption is quite common. In fact, except from compiler-introduced bugs, *all* of memory errors in Rust are triggered by unsafe (insight 4, @astrauskas2020how, @xu2021memorysafety).\n\nUnsafe Rust can trigger both spatial and temporal memory safety violation.\n\nMany of the bugs do not contain memory error, but only introduce unsoundness that violate Rust's memory safety @xu2021memorysafety.\n\n\n# Spatial safety\n## Integer overflow\nA lot of bugs are triggered by integer overflow, where the calculation for buffer size may overflow, leads to allocating a smaller buffer than expected.\n\nSince all dynamic array accesses in *safe* Rust  are bound-checked, such bug can only trigger for in cases where the array is used later in unsafe code @hua2021rupair. More specifically, only the pattern unsafe-\u003eunsafe and safe-\u003eunsafe (LHS: cause, RHS: effect) can trigger memory safety error with this bug @hua2021rupair.\n\nIn debug mode, integer overflow is checked at both compile-time (e.g., `u8 = 255 + 1` is not possile) and runtime. However, there is no runtime check in release mode. \n\nHere is an example for unsafe-\u003esafe case:\n```rust\nfn foo(int i, int j){\n  // may have integer overflow\n  let buf = Vec::with_capacity(i + j);\n  unsafe {\n    // May be out-of-bound access\n    let p = buf2.as_ptr();\n    *(p + i + 100) = 20;\n  }\n}\n```\n\n### CVE-2017-1000430 : integer overflow to heap-based buffer overflow in encode_config_buf\n\n```rust\n// Many possible integer overflow here\nfn encoded_size(bytes_len: usize, config: Config) -\u003e usize {\n  let rem = bytes_len % 3;\n\n  let complete_input_chunks = bytes_len / 3;\n  let complete_output_chars = complete_input_chunks * 4;\n  let printing_output_chars = if rem == 0 {\n    complete_output_chars\n  } else {\n    complete_output_chars + 4\n  };\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e 0,\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e printing_output_chars / n * 2,\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e printing_output_chars / n,\n  };\n  return printing_output_chars + line_ending_output_chars;\n}\npub fn encode_config\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config) -\u003e String {\n  // Integer overflow\n  let mut buf = String::with_capacity(encoded_size(input.as_ref().len(), config));\n  encode_config_buf(input, config, \u0026mut buf);\n  buf\n}\n\npub fn encode_config_buf\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config, buf: \u0026mut String) {\n  //...\n  // Another possible integer overflow\n  buf.reserve(encoded_size(input_bytes.len(), config));\n  // ...\n  let mut raw = unsafe { buf.as_mut_vec() };\n\n  // ...\n  // May access out-of-bound here due to unsafe !?!?!?!??!?!?!?!\n  let mut output_ptr = unsafe { raw.as_mut_ptr().offset(orig_buf_len as isize) };\n  let mut input_index: usize = 0;\n  if input_bytes.len() \u003e= 8 {\n    while input_index \u003c= last_fast_index {\n      let input_chunk = BigEndian::read_u64(\u0026input_bytes[input_index..(input_index + 8)]);\n      // strip off 6 bits at a time for the first 6 bytes\n      unsafe {\n        std::ptr::write(output_ptr, charset[((input_chunk \u003e\u003e 58) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(1), charset[((input_chunk \u003e\u003e 52) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(2), charset[((input_chunk \u003e\u003e 46) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(3), charset[((input_chunk \u003e\u003e 40) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(4), charset[((input_chunk \u003e\u003e 34) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(5), charset[((input_chunk \u003e\u003e 28) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(6), charset[((input_chunk \u003e\u003e 22) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(7), charset[((input_chunk \u003e\u003e 16) \u0026 0x3F) as usize]);\n        output_ptr = output_ptr.offset(8);\n      }\n      input_index += input_chunk_len;\n      fast_loop_output_buf_len += 8;\n    }\n  }\n  unsafe {\n    // expand len to include the bytes we just wrote\n    raw.set_len(fast_loop_output_buf_len);\n  }\n}\n```\nThe function `encoded_size` is used to calculate size for allocation. However, it could silently have integer overflow. In `encode_config` a buffer is allocated using the calculated size.\n\nThe fix for this is to use overflow-checked arithmetics. The patch for this changes the function to return `None` if overflow is detected:\n```rust\nfn encoded_size(bytes_len: usize, config: Config) -\u003e Option\u003cusize\u003e {\n  let printing_output_chars = bytes_len\n    .checked_add(2)\n    .map(|x| x / 3)\n    .and_then(|x| x.checked_mul(4));\n\n  //TODO this is subtly wrong but in a not dangerous way\n  //pushing patch with identical to previous behavior, then fixing\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e Some(0),\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e\n      printing_output_chars.map(|y| y / n).and_then(|y| y.checked_mul(2)),\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e\n      printing_output_chars.map(|y| y / n),\n  };\n\n  printing_output_chars.and_then(|x|\n    line_ending_output_chars.and_then(|y| x.checked_add(y))\n  )\n}\n```\n## Wrong usage of unsafe API\n### CVE-2018-21000: Vec-to-vec transmutations could lead to heap overflow/corruption\n\n```rust\n// Error\nVec::from_raw_parts(ptr as *mut T, capacity, len)\n// Fixed\nVec::from_raw_parts(ptr as *mut T, len, capacity)\n```\nThe above CVE swap the capacity and len arguments, which could lead to buffer overflow.\n\n# Temporal safety\n## Lifetime corruption\nUnsafe Rust can corrupt the ownership system by making invalid pointers or mutable aliases. Such pointers may propagate to the safe world, and is automatically freed by the ownership system, causing double-free or use-after-free.\n\n### CVE-2019-16140: dangling pointer created by unsafe\n```rust\nfn from(buffer: Buffer) -\u003e Vec\u003cu8\u003e {\n  let mut slice = Buffer::allocate(buffer.len);\n  let len = buffer.copy_to(\u0026mut slice);\n  unsafe {\n    Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len())\n  }\n}\n```\nThe above example from CVE-2019-16140 shows an example of lifetime corruption. In the example, `Vec::from_raw_parts` on line 5 obtain the ownership of `slice` allocated at line 2, and return the created `Vec`. This violate Rust ownership; line 5 and line 2 now share ownership to the underlying slice. When the function returns, `slice` at line 2 is automatically dropped. Any access to the returned value of `from` will now become use-after-free.\n\nThe fix to this is simple, `mem::forget` must be added to forget the previous slice (so that it will not be dropped after), before its ownership is being taken by constructing a new Vec.\n```rust\nunsafe {\n  let vec = Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len());\n  mem::forget(slice);\n  vec\n}\n```\n\nIn all, the cause of this bug is the use of raw pointer that bypass Rust ownership protection.\n\n### More\nMore examples are CVE-2019-15552 and CVE-2019-15553.\n\n# Panic/unwind safety\nAnother common memory issue is the unwinding code triggering unsound behaviors.","snippets":["#memory-safety #rust"],"rawContent":"# Memory errors in Rust\n#memory-safety #rust\n\nRust seems like a memory-safe language, but due to the prevalent use of unsafe, memory corruption is quite common. In fact, except from compiler-introduced bugs, *all* of memory errors in Rust are triggered by unsafe (insight 4, @astrauskas2020how, @xu2021memorysafety).\n\nUnsafe Rust can trigger both spatial and temporal memory safety violation.\n\nMany of the bugs do not contain memory error, but only introduce unsoundness that violate Rust's memory safety @xu2021memorysafety.\n\n\n# Spatial safety\n## Integer overflow\nA lot of bugs are triggered by integer overflow, where the calculation for buffer size may overflow, leads to allocating a smaller buffer than expected.\n\nSince all dynamic array accesses in *safe* Rust  are bound-checked, such bug can only trigger for in cases where the array is used later in unsafe code @hua2021rupair. More specifically, only the pattern unsafe-\u003eunsafe and safe-\u003eunsafe (LHS: cause, RHS: effect) can trigger memory safety error with this bug @hua2021rupair.\n\nIn debug mode, integer overflow is checked at both compile-time (e.g., `u8 = 255 + 1` is not possile) and runtime. However, there is no runtime check in release mode. \n\nHere is an example for unsafe-\u003esafe case:\n```rust\nfn foo(int i, int j){\n  // may have integer overflow\n  let buf = Vec::with_capacity(i + j);\n  unsafe {\n    // May be out-of-bound access\n    let p = buf2.as_ptr();\n    *(p + i + 100) = 20;\n  }\n}\n```\n\n### CVE-2017-1000430 : integer overflow to heap-based buffer overflow in encode_config_buf\n\n```rust\n// Many possible integer overflow here\nfn encoded_size(bytes_len: usize, config: Config) -\u003e usize {\n  let rem = bytes_len % 3;\n\n  let complete_input_chunks = bytes_len / 3;\n  let complete_output_chars = complete_input_chunks * 4;\n  let printing_output_chars = if rem == 0 {\n    complete_output_chars\n  } else {\n    complete_output_chars + 4\n  };\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e 0,\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e printing_output_chars / n * 2,\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e printing_output_chars / n,\n  };\n  return printing_output_chars + line_ending_output_chars;\n}\npub fn encode_config\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config) -\u003e String {\n  // Integer overflow\n  let mut buf = String::with_capacity(encoded_size(input.as_ref().len(), config));\n  encode_config_buf(input, config, \u0026mut buf);\n  buf\n}\n\npub fn encode_config_buf\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config, buf: \u0026mut String) {\n  //...\n  // Another possible integer overflow\n  buf.reserve(encoded_size(input_bytes.len(), config));\n  // ...\n  let mut raw = unsafe { buf.as_mut_vec() };\n\n  // ...\n  // May access out-of-bound here due to unsafe !?!?!?!??!?!?!?!\n  let mut output_ptr = unsafe { raw.as_mut_ptr().offset(orig_buf_len as isize) };\n  let mut input_index: usize = 0;\n  if input_bytes.len() \u003e= 8 {\n    while input_index \u003c= last_fast_index {\n      let input_chunk = BigEndian::read_u64(\u0026input_bytes[input_index..(input_index + 8)]);\n      // strip off 6 bits at a time for the first 6 bytes\n      unsafe {\n        std::ptr::write(output_ptr, charset[((input_chunk \u003e\u003e 58) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(1), charset[((input_chunk \u003e\u003e 52) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(2), charset[((input_chunk \u003e\u003e 46) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(3), charset[((input_chunk \u003e\u003e 40) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(4), charset[((input_chunk \u003e\u003e 34) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(5), charset[((input_chunk \u003e\u003e 28) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(6), charset[((input_chunk \u003e\u003e 22) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(7), charset[((input_chunk \u003e\u003e 16) \u0026 0x3F) as usize]);\n        output_ptr = output_ptr.offset(8);\n      }\n      input_index += input_chunk_len;\n      fast_loop_output_buf_len += 8;\n    }\n  }\n  unsafe {\n    // expand len to include the bytes we just wrote\n    raw.set_len(fast_loop_output_buf_len);\n  }\n}\n```\nThe function `encoded_size` is used to calculate size for allocation. However, it could silently have integer overflow. In `encode_config` a buffer is allocated using the calculated size.\n\nThe fix for this is to use overflow-checked arithmetics. The patch for this changes the function to return `None` if overflow is detected:\n```rust\nfn encoded_size(bytes_len: usize, config: Config) -\u003e Option\u003cusize\u003e {\n  let printing_output_chars = bytes_len\n    .checked_add(2)\n    .map(|x| x / 3)\n    .and_then(|x| x.checked_mul(4));\n\n  //TODO this is subtly wrong but in a not dangerous way\n  //pushing patch with identical to previous behavior, then fixing\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e Some(0),\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e\n      printing_output_chars.map(|y| y / n).and_then(|y| y.checked_mul(2)),\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e\n      printing_output_chars.map(|y| y / n),\n  };\n\n  printing_output_chars.and_then(|x|\n    line_ending_output_chars.and_then(|y| x.checked_add(y))\n  )\n}\n```\n## Wrong usage of unsafe API\n### CVE-2018-21000: Vec-to-vec transmutations could lead to heap overflow/corruption\n\n```rust\n// Error\nVec::from_raw_parts(ptr as *mut T, capacity, len)\n// Fixed\nVec::from_raw_parts(ptr as *mut T, len, capacity)\n```\nThe above CVE swap the capacity and len arguments, which could lead to buffer overflow.\n\n# Temporal safety\n## Lifetime corruption\nUnsafe Rust can corrupt the ownership system by making invalid pointers or mutable aliases. Such pointers may propagate to the safe world, and is automatically freed by the ownership system, causing double-free or use-after-free.\n\n### CVE-2019-16140: dangling pointer created by unsafe\n```rust\nfn from(buffer: Buffer) -\u003e Vec\u003cu8\u003e {\n  let mut slice = Buffer::allocate(buffer.len);\n  let len = buffer.copy_to(\u0026mut slice);\n  unsafe {\n    Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len())\n  }\n}\n```\nThe above example from CVE-2019-16140 shows an example of lifetime corruption. In the example, `Vec::from_raw_parts` on line 5 obtain the ownership of `slice` allocated at line 2, and return the created `Vec`. This violate Rust ownership; line 5 and line 2 now share ownership to the underlying slice. When the function returns, `slice` at line 2 is automatically dropped. Any access to the returned value of `from` will now become use-after-free.\n\nThe fix to this is simple, `mem::forget` must be added to forget the previous slice (so that it will not be dropped after), before its ownership is being taken by constructing a new Vec.\n```rust\nunsafe {\n  let vec = Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len());\n  mem::forget(slice);\n  vec\n}\n```\n\nIn all, the cause of this bug is the use of raw pointer that bypass Rust ownership protection.\n\n### More\nMore examples are CVE-2019-15552 and CVE-2019-15553.\n\n# Panic/unwind safety\nAnother common memory issue is the unwinding code triggering unsound behaviors.\n","wordCount":927,"tags":["rust","memory-safety"],"metadata":{},"created":"2023-08-09T13:49:43.471233048Z","modified":"2023-08-09T13:49:43.471298131Z","checksum":"5a52b300b838afd1f2d4e4add3062064b79cfefdd7273f432b49c46c0a6618c3"},
    {"filename":"h6c34egw.md","filenameStem":"h6c34egw","path":"h6c34egw.md","absPath":"/Users/khadd/mynotes/h6c34egw.md","title":"My nvim note taking workflow","link":"[[h6c34egw]]","lead":"#neovim #zettelkasten #note-taking","body":"#neovim #zettelkasten #note-taking\n\n[Zk](https://github.com/mickael-menu/zk) is a nice command-line application that has minimalistic features to take zettelkasten-style [[ae6fatms]] notes.\nWhat I like about Zk:\n- its seamless integration with neovim\n- plaintext storage with markdown\n\nIt is used in combination with [marksman LSP](https://github.com/artempyanykh/marksman) that provides a nice markdown editing experience.\n\n\n## Alternative\nI tried the Obsidian app but found its UI distracting. \n\n## Missing features\n- Some reference and citation is needed\n- I tried vim-pandoc but haven't found success.","snippets":["#neovim #zettelkasten #note-taking"],"rawContent":"# My nvim note taking workflow\n#neovim #zettelkasten #note-taking\n\n[Zk](https://github.com/mickael-menu/zk) is a nice command-line application that has minimalistic features to take zettelkasten-style [[ae6fatms]] notes.\nWhat I like about Zk:\n- its seamless integration with neovim\n- plaintext storage with markdown\n\nIt is used in combination with [marksman LSP](https://github.com/artempyanykh/marksman) that provides a nice markdown editing experience.\n\n\n## Alternative\nI tried the Obsidian app but found its UI distracting. \n\n## Missing features\n- Some reference and citation is needed\n- I tried vim-pandoc but haven't found success. \n\n\n\n","wordCount":85,"tags":["note-taking","zettelkasten","neovim"],"metadata":{},"created":"2023-08-09T13:49:43.468334705Z","modified":"2024-05-19T06:16:49.119919281Z","checksum":"b55087af8935dc83d9824b17b47c4d85efeafa22df738dec67a3a41a5552b1aa"},
    {"filename":"gbkc1fhy.md","filenameStem":"gbkc1fhy","path":"gbkc1fhy.md","absPath":"/Users/khadd/mynotes/gbkc1fhy.md","title":"Non-control Data Attacks","link":"[[gbkc1fhy]]","lead":"#data-only-attack #attack","body":"#data-only-attack #attack\n\n# Expressiveness\nIt is shown that data-only attack can achieve turing-complete execution under a certain condition [@hu2016dataoriented]. More specifically, there must be loop that is vulnerable to buffer overflow, that contain a corruptible switch condition. The original refer to this type of loop as a *gadget dispatcher*. \nThis is an example:\n```c\nwhile (...){\n  overflow(); // buffer overflow\n  if (*type == NONE) break;\n  if (*type == STREAM)\n    *size = *(srv-\u003ecur_max); // dereference\n  else {\n    srv-\u003etyp = *type;    // assignment\n    srv-\u003etotal += *size; // addition\n  }\n  ///...\n}\n```\nWhen the attacker can infinitely control the loop, he is able to set up the operands and run different instructions in a turing-complete manner.","snippets":["#data-only-attack #attack"],"rawContent":"# Non-control Data Attacks\n#data-only-attack #attack\n\n# Expressiveness\nIt is shown that data-only attack can achieve turing-complete execution under a certain condition [@hu2016dataoriented]. More specifically, there must be loop that is vulnerable to buffer overflow, that contain a corruptible switch condition. The original refer to this type of loop as a *gadget dispatcher*. \nThis is an example:\n```c\nwhile (...){\n  overflow(); // buffer overflow\n  if (*type == NONE) break;\n  if (*type == STREAM)\n    *size = *(srv-\u003ecur_max); // dereference\n  else {\n    srv-\u003etyp = *type;    // assignment\n    srv-\u003etotal += *size; // addition\n  }\n  ///...\n}\n```\nWhen the attacker can infinitely control the loop, he is able to set up the operands and run different instructions in a turing-complete manner. \n\n","wordCount":118,"tags":["attack","data-only-attack"],"metadata":{},"created":"2023-08-09T13:49:43.468077079Z","modified":"2023-08-09T13:49:43.468115871Z","checksum":"4383ed6e384b8d89bd2b346a24f2c6fe5c986aa05b9098daebe03a33511633dc"},
    {"filename":"j19hdkto.md","filenameStem":"j19hdkto","path":"j19hdkto.md","absPath":"/Users/khadd/mynotes/j19hdkto.md","title":"Norman Hardy","link":"[[j19hdkto]]","lead":"#capabilities #os","body":"#capabilities #os\n\nThe inventor of KeykOS, which laid foundation for many following microkernels such as EROS, sel4. He is also one of the grandfather of Capabilities.\n\nMaybe the first one to coin the term confused deputy [[y9wu5ut7]] in his paper [@hardy1988confused].\n\nIt is interesting that there exists no Wiki article for him.\n\nHis personal website, http://www.cap-lore.com/, contains pieces of notes on his ideas, is written in almost [[ae6fatms|Zettlekasten]] style. Ideas are separated into separated notes and linked together. \n[](2023-05-24_.md)","snippets":["#capabilities #os"],"rawContent":"# Norman Hardy\n#capabilities #os\n\nThe inventor of KeykOS, which laid foundation for many following microkernels such as EROS, sel4. He is also one of the grandfather of Capabilities.\n\nMaybe the first one to coin the term confused deputy [[y9wu5ut7]] in his paper [@hardy1988confused].\n\nIt is interesting that there exists no Wiki article for him.\n\nHis personal website, http://www.cap-lore.com/, contains pieces of notes on his ideas, is written in almost [[ae6fatms|Zettlekasten]] style. Ideas are separated into separated notes and linked together. \n[](2023-05-24_.md)\n","wordCount":82,"tags":["os","capabilities"],"metadata":{},"created":"2023-08-09T13:49:43.469091291Z","modified":"2023-08-09T13:49:43.469138541Z","checksum":"6c5f07a95194accec6be54e1ed0f2901cec76353115a3384a28fd46ee3e7405a"},
    {"filename":"m7plvtcv.md","filenameStem":"m7plvtcv","path":"m7plvtcv.md","absPath":"/Users/khadd/mynotes/m7plvtcv.md","title":"ORAM Algorithmic Optimizations","link":"[[m7plvtcv]]","lead":"#oram #oblivious","body":"#oram #oblivious\n\n## Superblock\nIn ORAM, because accesses are always shuffled, the locality is terrible, because individual block's position is shuffled at every access.\n\nSuperblock optimization (@ren2013design) ensures that a group of blocks are always in the stash together. This group of blocks is called the *superblock*. Accessing a block in a superblock would brings all block into the stash, which improve the locality. Note that the number of blocks in a superblock can be smaller than the height of the tree. \n\nAt initialization time, blocks on the superblock $S$ are placed on the same leaf. Whenever a block from the superblock is requested, the entire path is brought into the stash, so the blocks in $S$ is inside the stash. Like normal Path ORAM, the leaf index of the requested block in the position map is updated. This requested block is like a leader, which all blocks in the same superblock follow. Potition of blocks in the superblock are also updated to the leader block's path. Hence, when they are evicted, they would be evicted on the same leaf. \n\n### Security\n@ren2013design (3.2.2) argues that this does not affect the security of ORAM. On each access, superblocks are mapped to a random leaf. Same as normal path ORAM, the observer can only see randomized path accesses, regardless of the superblock. \n\n### Why posmap update for blocks other than the requested block is fine in this case?\nThis is fine fine because the superblock can be seen as a single block in the ORAM access.\n\nIn a more generalized scenario, when updating the position for blocks inside the stash, the new position should be random, or *independent* of the block content/access pattern (not sure if this is correct).","snippets":["#oram #oblivious"],"rawContent":"# ORAM Algorithmic Optimizations\n#oram #oblivious\n\n## Superblock\nIn ORAM, because accesses are always shuffled, the locality is terrible, because individual block's position is shuffled at every access.\n\nSuperblock optimization (@ren2013design) ensures that a group of blocks are always in the stash together. This group of blocks is called the *superblock*. Accessing a block in a superblock would brings all block into the stash, which improve the locality. Note that the number of blocks in a superblock can be smaller than the height of the tree. \n\nAt initialization time, blocks on the superblock $S$ are placed on the same leaf. Whenever a block from the superblock is requested, the entire path is brought into the stash, so the blocks in $S$ is inside the stash. Like normal Path ORAM, the leaf index of the requested block in the position map is updated. This requested block is like a leader, which all blocks in the same superblock follow. Potition of blocks in the superblock are also updated to the leader block's path. Hence, when they are evicted, they would be evicted on the same leaf. \n\n### Security\n@ren2013design (3.2.2) argues that this does not affect the security of ORAM. On each access, superblocks are mapped to a random leaf. Same as normal path ORAM, the observer can only see randomized path accesses, regardless of the superblock. \n\n### Why posmap update for blocks other than the requested block is fine in this case?\nThis is fine fine because the superblock can be seen as a single block in the ORAM access.\n\nIn a more generalized scenario, when updating the position for blocks inside the stash, the new position should be random, or *independent* of the block content/access pattern (not sure if this is correct).\n","wordCount":292,"tags":["oblivious","oram"],"metadata":{},"created":"2023-08-09T13:49:43.470682671Z","modified":"2023-08-09T13:49:43.470726713Z","checksum":"953e101067c5d4e0de6315c7c91e33075e9c2d5ff5cbb38277966faa7ca61130"},
    {"filename":"n9bxzpge.md","filenameStem":"n9bxzpge","path":"n9bxzpge.md","absPath":"/Users/khadd/mynotes/n9bxzpge.md","title":"Obfuscated execution techniques","link":"[[n9bxzpge]]","lead":"#oblivious","body":"#oblivious \n\nObfuscated execution techniques transform the program such that all code and memory accesses are constant regardless of sensitive input.\n\n\nThis type of protection commonly has very high overheads, due to the threat model being too strict (attackers with perfect observation of program counter and memory accesses).\nHowever, in practice, the observable side channels are usually more coarse-grained, at cache-line or page-fault-level. For instance, in SGX, attacker side-channels usually need page-fault-level trace before performing more fine-grained cache side-channel attacks. Hence, been works that only target page-fault-level leakage ([[5kzr3hwx]]), for more practical protection.\n\n# Raccoon\n@rane2015raccoon was the first to propose this idea. It transforms the program to use predicated execution to execute *both* branches of a sensitive-dependent branch.\nA transactional-like memory\n\nThis type of protection can protect both code and data accesses. \n\nOverheads of this is about 9X @zhang2020klotski.\n\n# Constantine\n@borrello2021constantine is currently the state-of-the-art.\n\n\n```c\nfn handle_pagefault(addr):\n  idx = virt_addr_to_oram_idx(addr);\n  oram_fetch_to_cache(idx);\n  map_vaddr_to_cache(addr, 0x1000);\n  return\n```","snippets":["#oblivious"],"rawContent":"# Obfuscated execution techniques\n#oblivious \n\nObfuscated execution techniques transform the program such that all code and memory accesses are constant regardless of sensitive input.\n\n\nThis type of protection commonly has very high overheads, due to the threat model being too strict (attackers with perfect observation of program counter and memory accesses).\nHowever, in practice, the observable side channels are usually more coarse-grained, at cache-line or page-fault-level. For instance, in SGX, attacker side-channels usually need page-fault-level trace before performing more fine-grained cache side-channel attacks. Hence, been works that only target page-fault-level leakage ([[5kzr3hwx]]), for more practical protection.\n\n# Raccoon\n@rane2015raccoon was the first to propose this idea. It transforms the program to use predicated execution to execute *both* branches of a sensitive-dependent branch.\nA transactional-like memory\n\nThis type of protection can protect both code and data accesses. \n\nOverheads of this is about 9X @zhang2020klotski.\n\n# Constantine\n@borrello2021constantine is currently the state-of-the-art.\n\n\n```c\nfn handle_pagefault(addr):\n  idx = virt_addr_to_oram_idx(addr);\n  oram_fetch_to_cache(idx);\n  map_vaddr_to_cache(addr, 0x1000);\n  return\n```\n\n","wordCount":161,"tags":["oblivious"],"metadata":{},"created":"2023-08-09T13:49:43.470937172Z","modified":"2023-08-09T13:49:43.470976922Z","checksum":"a609ec58f59e9bf37aeda61b4916cb8d954eedb99858ab345e8a4c9e07359207"},
    {"filename":"b4nls7up.md","filenameStem":"b4nls7up","path":"b4nls7up.md","absPath":"/Users/khadd/mynotes/b4nls7up.md","title":"Oblivious paging against controlled-channel","link":"[[b4nls7up]]","lead":"#tee #sgx #oblivous #controlled-channel","body":"#tee #sgx #oblivous #controlled-channel\n\nOblivious paging is a direction to tackle the paging control-channel in SGX, by enabling the enclave with the ability to perform page table management. \n\n\nPrevious work on this tries to implement *self-paging enclaves*. Self-paging enclaves let the enclaves manage their own memory mappings. Page faults to the enclave-managed pages are forwarded to the enclave fault handler, so the faulting address is hidden from the OS.\n\n\n\n\n\n@aga2019invisipage uses two page tables, as inspired by @costan2016sanctum, where one table is maintained by the enclave, and the other is maintained by the OS. The OS-maintained page table is similar to the traditional one. The enclave page table is used for paging of EPC pages.\nThe memory for enclave page table is stored in the EPC, and \nAn additional page table base register is added, and when an EPC page fault occur, the the private page table is walked instead.\n\n@orenbach2020autarky argue that ORAM-based oblivious paging requires intrusive hardware modifications to the CPU, thus is not practical.\n\n# Challenges\n## Supporting for demand paging\nDemand paging allows the OS to map the memory page into the address space only when the process actually touch the page. When it is touch, a page fault will be raised, informing the OS to map the page the the process's page table.\n\nDemand demand paging obviously conflict with the goal of hiding page faults from the OS.\n\nA simple solution is to statically separate public and private pages, such that fault from the enclaves are served by the enclave never served by the OS. This design creates an additional problem: it rob the ability to perform memory management from the OS. Once a private page has been mapped, the OS no longer hav the ability to reclaim the page from the enclave. A malicious enclave can prevent the OS from ever reusing the page. Moreover, once an enclave page is reclaimed, the OS can still learn about accesses on the page @aga2019invisipage.","snippets":["#tee #sgx #oblivous #controlled-channel"],"rawContent":"# Oblivious paging against controlled-channel\n#tee #sgx #oblivous #controlled-channel\n\nOblivious paging is a direction to tackle the paging control-channel in SGX, by enabling the enclave with the ability to perform page table management. \n\n\nPrevious work on this tries to implement *self-paging enclaves*. Self-paging enclaves let the enclaves manage their own memory mappings. Page faults to the enclave-managed pages are forwarded to the enclave fault handler, so the faulting address is hidden from the OS.\n\n\n\n\n\n@aga2019invisipage uses two page tables, as inspired by @costan2016sanctum, where one table is maintained by the enclave, and the other is maintained by the OS. The OS-maintained page table is similar to the traditional one. The enclave page table is used for paging of EPC pages.\nThe memory for enclave page table is stored in the EPC, and \nAn additional page table base register is added, and when an EPC page fault occur, the the private page table is walked instead.\n\n@orenbach2020autarky argue that ORAM-based oblivious paging requires intrusive hardware modifications to the CPU, thus is not practical.\n\n# Challenges\n## Supporting for demand paging\nDemand paging allows the OS to map the memory page into the address space only when the process actually touch the page. When it is touch, a page fault will be raised, informing the OS to map the page the the process's page table.\n\nDemand demand paging obviously conflict with the goal of hiding page faults from the OS.\n\nA simple solution is to statically separate public and private pages, such that fault from the enclaves are served by the enclave never served by the OS. This design creates an additional problem: it rob the ability to perform memory management from the OS. Once a private page has been mapped, the OS no longer hav the ability to reclaim the page from the enclave. A malicious enclave can prevent the OS from ever reusing the page. Moreover, once an enclave page is reclaimed, the OS can still learn about accesses on the page @aga2019invisipage.\n\n\n","wordCount":333,"tags":["tee","sgx","oblivous","controlled-channel"],"metadata":{},"created":"2023-08-09T13:49:43.46140785Z","modified":"2023-08-09T13:49:43.461466808Z","checksum":"f93160258229935ddfca7fff009d5256513c79af849988e55b2652cb7033d37c"},
    {"filename":"adn8i9cz.md","filenameStem":"adn8i9cz","path":"adn8i9cz.md","absPath":"/Users/khadd/mynotes/adn8i9cz.md","title":"One sentence paper summary","link":"[[adn8i9cz]]","lead":"#writing #reading","body":"#writing #reading\n\nMost papers can be summarized into one sentence that capture the highest-level ideas. For instance,\n\u003e Obliviate introduces an data-oblivious file system using ORAM primitives.\n\u003e Capacity retrofit PAC and MTE primitives to enable capability-based access control for file and memory.\n\nIdeas that cannot be consolidated into one sentence is either over-complicated, not well-defined, and not well-contained.\n\nKnowing this has implications for both reading and writing.\n\nFirst, when reading a paper try to find the main ideas of the paper and summarize it into one sentence.\n\nSecond, when writing papers, identify the core idea of the in one sentence first. This will determine the scope of the paper and avoid over-complicating things. Moreover, it allows for concise writing. Each sentence/paragraph should contributes to the main idea.","snippets":["#writing #reading"],"rawContent":"# One sentence paper summary\n#writing #reading\n\nMost papers can be summarized into one sentence that capture the highest-level ideas. For instance,\n\u003e Obliviate introduces an data-oblivious file system using ORAM primitives.\n\u003e Capacity retrofit PAC and MTE primitives to enable capability-based access control for file and memory.\n\nIdeas that cannot be consolidated into one sentence is either over-complicated, not well-defined, and not well-contained.\n\nKnowing this has implications for both reading and writing.\n\nFirst, when reading a paper try to find the main ideas of the paper and summarize it into one sentence.\n\nSecond, when writing papers, identify the core idea of the in one sentence first. This will determine the scope of the paper and avoid over-complicating things. Moreover, it allows for concise writing. Each sentence/paragraph should contributes to the main idea.\n\n","wordCount":133,"tags":["writing","reading"],"metadata":{},"created":"2023-08-09T13:49:43.461274641Z","modified":"2023-08-09T13:49:43.461327474Z","checksum":"e1f271e3267d4beef9083fa315dfe98590ed6e2062c1f0b03c9f78a96bea41ad"},
    {"filename":"5kzr3hwx.md","filenameStem":"5kzr3hwx","path":"5kzr3hwx.md","absPath":"/Users/khadd/mynotes/5kzr3hwx.md","title":"Page fault-based Side-channels Protection in SGX","link":"[[5kzr3hwx]]","lead":"#tee #sgx #side-channel","body":"#tee #sgx #side-channel\n\n# Comparision critera\n## Code \u0026 data\nSome work provides protection to only data accesses, while other protect both code and data accesses.\n\n## Granularity\nPerfect trace, Cache-line, Page-level.\n\n\n# Obfuscated execution techniques\nThe first line of defense is obfuscated execution ([[n9bxzpge]]), which guarantees that code and data accesses of a program looks the same, given a sensitive input.\nThey usually have high overheads and are considered impractical.\n\n\n# Detecting page faults\nOne class of defense is to treat all possible page fault triggered by the OS as malicious. This requires that the enclave pages are statically determined and mapped to enclave. Hence, demand paging is not possible in this model.\n\n\nMost of these defenses uses  Intel TSX [[dx7vz8d5]], due to its ability to supress page faults. \nFor more details, see [[fvom56lw]]. \n\nSince their introduction, there has been attacks that can leak secrets _without_ explicitly triggering page faults #cite-needed. Hence, these defenses are incomplete to today's standard.\n\n\n# Virtualizing Virtual Memory\nAnother category of defense is to replace all memory instructions of the enclave (through compiler instrumentation) with requests to a reference monitor that make the actual request indistinguishable to attackers (e.g., using ORAM primitives). \nThey have stronger guarantees than \n\nFor instance, the following LLVM IR could be instruments as follows:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n\n---\n%1 = call oblivious_load(%arg1)\n%2 = add %1, 100\ncall obliviou_call(\u0026foo)\ncall oblivious_store(%2, %1)\n```\n\n\n## Obfuscuro\n\n## Klotski\n\n## CosMIX\n\n\n\n# Self-paging enclaves\nAnother way to hide page faults from the OS is to the the enclave perform its own paging. Though, in SGX, this model is not possible without hardware extensions @orenbach2020autarky, @aga2019invisipage.\n\nThese defenses maintain a separated page table that is exclusively used to map EPC pages. This page table can only be updated by the trusted code inside the enclave.\n\nFor more, see [b4nls7up].","snippets":["#tee #sgx #side-channel"],"rawContent":"# Page fault-based Side-channels Protection in SGX\n#tee #sgx #side-channel\n\n# Comparision critera\n## Code \u0026 data\nSome work provides protection to only data accesses, while other protect both code and data accesses.\n\n## Granularity\nPerfect trace, Cache-line, Page-level.\n\n\n# Obfuscated execution techniques\nThe first line of defense is obfuscated execution ([[n9bxzpge]]), which guarantees that code and data accesses of a program looks the same, given a sensitive input.\nThey usually have high overheads and are considered impractical.\n\n\n# Detecting page faults\nOne class of defense is to treat all possible page fault triggered by the OS as malicious. This requires that the enclave pages are statically determined and mapped to enclave. Hence, demand paging is not possible in this model.\n\n\nMost of these defenses uses  Intel TSX [[dx7vz8d5]], due to its ability to supress page faults. \nFor more details, see [[fvom56lw]]. \n\nSince their introduction, there has been attacks that can leak secrets _without_ explicitly triggering page faults #cite-needed. Hence, these defenses are incomplete to today's standard.\n\n\n# Virtualizing Virtual Memory\nAnother category of defense is to replace all memory instructions of the enclave (through compiler instrumentation) with requests to a reference monitor that make the actual request indistinguishable to attackers (e.g., using ORAM primitives). \nThey have stronger guarantees than \n\nFor instance, the following LLVM IR could be instruments as follows:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n\n---\n%1 = call oblivious_load(%arg1)\n%2 = add %1, 100\ncall obliviou_call(\u0026foo)\ncall oblivious_store(%2, %1)\n```\n\n\n## Obfuscuro\n\n## Klotski\n\n## CosMIX\n\n\n\n# Self-paging enclaves\nAnother way to hide page faults from the OS is to the the enclave perform its own paging. Though, in SGX, this model is not possible without hardware extensions @orenbach2020autarky, @aga2019invisipage.\n\nThese defenses maintain a separated page table that is exclusively used to map EPC pages. This page table can only be updated by the trusted code inside the enclave.\n\nFor more, see [b4nls7up].\n","wordCount":331,"tags":["tee","sgx","side-channel","cite-needed"],"metadata":{},"created":"2023-08-09T13:49:43.46049118Z","modified":"2023-08-09T13:49:43.460540055Z","checksum":"df6e17b454bf5c64f98ace0c65d6bfb481c596cb5485663f8bd5c862bbdcbb16"},
    {"filename":"xpolyx1l.md","filenameStem":"xpolyx1l","path":"xpolyx1l.md","absPath":"/Users/khadd/mynotes/xpolyx1l.md","title":"Paging in Unikraft (x86)","link":"[[xpolyx1l]]","lead":"#unikraft #os","body":"#unikraft #os\n\n# Enabling paging\nPaging is enabled with the configuration PAGING, enabled by setting Platform Configuration -\u003e Platform Interface Option -\u003e Virtual memory API in `make menuconfig`.\n\n`PAGING` option affects `plat/kvm/x86/setup.c`, where `mem_init()` would calls `init_paging()`. \nThen, `ukplat_pt_init` is called to initialize the page table.\n- It calls `pgarch_init()` to initialize architectural-dependent info, such as checking 1GiB pages support, PAT support.\n\n\n# Initializing paging\n## `kernel_pt`\nThis global struct stores info for the initialization time kernel page table.\n\nLater, a virtual address space (VAS) is created, which also points to this page table.\n## `ukplat_bootinfo`\nAt build time, the linker prepare a `boot_info` structure.\nBoot info contains a list of *physical* memory regions (kernel image, uninitialized memory, ...).\n\n## `mem_init`\nThe function inserts the remaining memory from after the kernel image (after `__END`) to the remaining physical memory to the list of memory regions. This region flag is `UKPLAT_MEMRF_UNMAP`, which means that these pages are unmapped from the kernel page table, and are only mapped on-demand.\n```c\nrc = ukplat_memregion_list_insert(\u0026bi-\u003emrds,\n\t\t\u0026(struct ukplat_memregion_desc){\n\t\t\t.vbase = PAGE_ALIGN_UP(__END),\n\t\t\t.pbase = 0,\n\t\t\t.len   = PLATFORM_MAX_MEM_ADDR - PAGE_ALIGN_UP(__END),\n\t\t\t.type  = 0,\n\t\t\t.flags = UKPLAT_MEMRF_UNMAP,\n```\n\nIt then calls `paging_init`\n\n## `paging_init` \nThe function initializes the kernel's page table. On Linux, there is also the same function, but the process is a bit different  ([[cn9u3d79]]).\n\nFirst, it calls `ukplat_pt_init`, which initializes the page table facilities, using a free memory region.\n1. `pgarch_init()` setup the CPU features\n2. `pgarch_pt_init` initialize the frame allocator and adds all physical memory to it.\n\nAfter the page table\n\nFor every region with the flag `UKPLAT_MEMRF_UNMAP`, it unmaps them from the page table. Finally, it maps regions with the flag `UKPLAT_MEMRF_MAP` to memory. \n\n\n\n## `pgarch_pt_init`\nArchitectual-specific page table initialization is performed here. On X86, it reserves space for the frame allocator (`struct uk_falloc`), initializes the allocator, then adds the remaining physical memory to the frame allocator pool of memory.\n\n\n# Page fault handler\nThe page fault handler is defined separatedly as `do_page_fault` in `common/x86/traps.c`. It calls `rc = uk_raise_event(UKARCH_TRAP_PAGE_FAULT, \u0026ctx);` (more details is in event.h).\n\nThe handler for this event is found in `ukvmem/arch/x86_64/pagefault.c`, registered as\n```c\nUK_EVENT_HANDLER_PRIO(UKARCH_TRAP_PAGE_FAULT, vmem_arch_pagefault,\n\t\t      CONFIG_LIBUKVMEM_PAGEFAULT_HANDLER_PRIO);\n```\n\nSee [[1k9i1cr3]] for more about Unikraft's interrupt handling.\n\nwith `ukvmem`, different page fault handlers can be registered for different VMAs. On a page fault. the VMA for the faulting address is looked up, then the VMA's registered page fault handler is called. \n\n# ukvmem\nukvmem enables APIs for virtual memory management. It creates Virtual Address Spaces (VAS), which contains smaller regions called Virtual Memory Areas (VMAs).\n\nThere are APIs that are required for paging that are defined here. For example, the page fault handler above `vmem_arch_pagefault` would call `vmem_pagefault` defined in `vmem.c`.\n\n`pg_page_mapx` (`paging.c`) performs the allocating of page table entries. \n\n\n# Page table entry\n`pg_page_mapx` sets the \"template\" as 0, which is set in the new PTE on a fault.\n\n## Registering fault handler\n\n# Related notes\n- [[cn9u3d79]]","snippets":["#unikraft #os"],"rawContent":"# Paging in Unikraft (x86)\n#unikraft #os\n\n# Enabling paging\nPaging is enabled with the configuration PAGING, enabled by setting Platform Configuration -\u003e Platform Interface Option -\u003e Virtual memory API in `make menuconfig`.\n\n`PAGING` option affects `plat/kvm/x86/setup.c`, where `mem_init()` would calls `init_paging()`. \nThen, `ukplat_pt_init` is called to initialize the page table.\n- It calls `pgarch_init()` to initialize architectural-dependent info, such as checking 1GiB pages support, PAT support.\n\n\n# Initializing paging\n## `kernel_pt`\nThis global struct stores info for the initialization time kernel page table.\n\nLater, a virtual address space (VAS) is created, which also points to this page table.\n## `ukplat_bootinfo`\nAt build time, the linker prepare a `boot_info` structure.\nBoot info contains a list of *physical* memory regions (kernel image, uninitialized memory, ...).\n\n## `mem_init`\nThe function inserts the remaining memory from after the kernel image (after `__END`) to the remaining physical memory to the list of memory regions. This region flag is `UKPLAT_MEMRF_UNMAP`, which means that these pages are unmapped from the kernel page table, and are only mapped on-demand.\n```c\nrc = ukplat_memregion_list_insert(\u0026bi-\u003emrds,\n\t\t\u0026(struct ukplat_memregion_desc){\n\t\t\t.vbase = PAGE_ALIGN_UP(__END),\n\t\t\t.pbase = 0,\n\t\t\t.len   = PLATFORM_MAX_MEM_ADDR - PAGE_ALIGN_UP(__END),\n\t\t\t.type  = 0,\n\t\t\t.flags = UKPLAT_MEMRF_UNMAP,\n```\n\nIt then calls `paging_init`\n\n## `paging_init` \nThe function initializes the kernel's page table. On Linux, there is also the same function, but the process is a bit different  ([[cn9u3d79]]).\n\nFirst, it calls `ukplat_pt_init`, which initializes the page table facilities, using a free memory region.\n1. `pgarch_init()` setup the CPU features\n2. `pgarch_pt_init` initialize the frame allocator and adds all physical memory to it.\n\nAfter the page table\n\nFor every region with the flag `UKPLAT_MEMRF_UNMAP`, it unmaps them from the page table. Finally, it maps regions with the flag `UKPLAT_MEMRF_MAP` to memory. \n\n\n\n## `pgarch_pt_init`\nArchitectual-specific page table initialization is performed here. On X86, it reserves space for the frame allocator (`struct uk_falloc`), initializes the allocator, then adds the remaining physical memory to the frame allocator pool of memory.\n\n\n# Page fault handler\nThe page fault handler is defined separatedly as `do_page_fault` in `common/x86/traps.c`. It calls `rc = uk_raise_event(UKARCH_TRAP_PAGE_FAULT, \u0026ctx);` (more details is in event.h).\n\nThe handler for this event is found in `ukvmem/arch/x86_64/pagefault.c`, registered as\n```c\nUK_EVENT_HANDLER_PRIO(UKARCH_TRAP_PAGE_FAULT, vmem_arch_pagefault,\n\t\t      CONFIG_LIBUKVMEM_PAGEFAULT_HANDLER_PRIO);\n```\n\nSee [[1k9i1cr3]] for more about Unikraft's interrupt handling.\n\nwith `ukvmem`, different page fault handlers can be registered for different VMAs. On a page fault. the VMA for the faulting address is looked up, then the VMA's registered page fault handler is called. \n\n# ukvmem\nukvmem enables APIs for virtual memory management. It creates Virtual Address Spaces (VAS), which contains smaller regions called Virtual Memory Areas (VMAs).\n\nThere are APIs that are required for paging that are defined here. For example, the page fault handler above `vmem_arch_pagefault` would call `vmem_pagefault` defined in `vmem.c`.\n\n`pg_page_mapx` (`paging.c`) performs the allocating of page table entries. \n\n\n# Page table entry\n`pg_page_mapx` sets the \"template\" as 0, which is set in the new PTE on a fault.\n\n## Registering fault handler\n\n# Related notes\n- [[cn9u3d79]]\n\n","wordCount":495,"tags":["unikraft","os"],"metadata":{},"created":"2023-08-09T13:49:43.478472238Z","modified":"2023-08-09T13:49:43.478521696Z","checksum":"b2214267b8ad24d86979e31d37a61d8571d4a1d2294c9a60258b290b4d2832a3"},
    {"filename":"4zdjxws6.md","filenameStem":"4zdjxws6","path":"literature/4zdjxws6.md","absPath":"/Users/khadd/mynotes/literature/4zdjxws6.md","title":"Practical Program Modularization with Type-Based Dependence Analysis","link":"[[literature/4zdjxws6]]","lead":"#literature #analysis #compartmentalization\n@lu2023practical","body":"#literature #analysis #compartmentalization\n@lu2023practical\n\n# Main arguments\nData-flow-based dependence analyses are impractical on large programs due to incorrect results and scalability issues, and A type-based dependence analysis avoid data-flow analysis.\n- See [[dgdvhu1e]]\n- The proposed approach can handle multi-entry, multi-threaded programs, and does not rely on points-to analysis.\n\nModule-aware type-based dependence analysis enables practical dependence analysis. \n- If only the module boundaries are analyzed (function arguments and global variables), the inner complexity of module is does not matter.\n- The proposed analysis only analyses the two types of typed-based data-flow, through function arguments and through global variable.\n\nModule-based analysis and type-based analysis are complementary.\n- Module-aware analysis complement type-analysis:\n  - Previous type-only approaches @lu2019where are imprecise because they scan the entire program for a particular type.\n  - There are modules in programs that has contain same types, but not related at all\n  - The approach can further refine the CFI targets by using dependent module information\n- Type-aware analysis improves module-aware analysis:\n  - A module-only analysis would be highly imprecise (only identifying if module A can write into B), using the Type of argument further restrict the data flow, making it an effective approach.\n\nThe proposed analysis is effective and sound (as a dependence analysis)\n- It is effective (in restricting data-flow) because it is difficult to form the data flow between modules with a given type, and that there are also modules between a module.\n- It is sound (as a dependence analysis), since the approach will catch all cross-module data-flow if there is one.\n\nThe analysis improve upon existing security applications.\n- When used for indirect call target reduction, it have high reduction rate on large application (up to 70% on firefox).\n- It identify 90% write instructions in linux as non-sensitive, which can be enforced with techniques such as DFI, WIT. (No enforcement were tested).\n  \n# Observation\nThere is only two type of data-flow between modules: through function arguments/return values and through global variables \n\n# Type-based dependence analysis\nThe key idea is to perform type-based dependence analysis between modules (i.e., compilation unit). \nA *type-based dependence analysis* determine if modules of the programs may propagate the object of a certain types to a particular module.\n\nThe following types of dependencies are detected:\n\nDirect (through argument):\n- If M1 pass argument of type T1 to M2, there is direct data flow M1-\u003eM2.\n\nIndirect (through global)\n- If M1 write to global g type T, M2 read global type T, then there is data flow M1-\u003eg-\u003eM2.\n\nTransitive:\n- There can be chaining of cross-module data flow, e.g., M1-\u003eM2-\u003eg-\u003eM3-\u003eM4 \n\n# The analysis\nThe analysis takes a pair of type and module \u003ctype,module\u003e, and automatically all dependent modules. There are three main steps.\n- The first step collect castable types into a CastMap. This is to handle unsafe casting operations in C/C++, all possible casted types are also considered in the data flow.\n- The second step find out the direction and type of the data flow between two particular modules and store it into a `FlowMap`. Finding out the direction possible data flow ([[#direction]]).\n- The final step compute dependent modules and the dependent types.\n\nIt is also observe that type-based indirect calls can be further refined using module-awareness. The author use an iterative method to refine the indirect call targets:\n- In first iteration, find dependent modules of an indirect call\n- Next, limit the type-based call target matching to only using the dependent modules.\n- Repeat until no more refinement is made\n\n\n## Finding data flow direction \n[]{#direction}\n\nFor two modules $M$, $V$, and a use $U$ of type $T$:\n- If the use in $V$ is a *load* LLVM instruction, then the direction is $M-\u003eV$.\n- If it is a $store$ instruction, then the direction is $V-\u003eM$.\n- If it is the GEP instruction, also analyze the use of the instruction\n- Else, it is bidirectional.\n\nOn struct types and pointer types, the types of the field is also analyzed. This is done through recursion on GEP instructions.\n\nThe result is stored in a structure called the $FlowMap$ that record Type, Direction of data flow between two modules.\n\n## Type elevation\n*Type elevation* is also proposed to improve the precision. The idea is that instead of using the type of the use site, which might have many false possitive, *elevate* it to the type of the containing struct.\nFor example, when an indirect call type $T1$ in a struct $T2$ is called, we first find the set of dependent modules using the type $T1$. Then, we find the dependent modules using the struct type $T2$. Finally, we *intersect* the two set to have a more refined dependent module set for the type $T1$.\n\nThis approach is unsound for container types (*base type*) that can be created from within the module, because cross-module data-flow will not find dependent module for those types. The paper suggests a simple *externality analysis*: If the base type is ever assigned (through `store` and initilizers), it cannot be used for elevation.\n\nEssentially, it is just following chain of GEP instructions to get the outermost type as the *base type* (section 5)\n\n\n# Implementation notes\n## Type comparison\nThe authors found that type comparison in LLVM poses challenges: \n- Type may have different underlying memory objects so pointer comparison does not work\n- The same struct type might have different variants, so string comparison may not work.\n- Struct types may or may not have name.\n\n## Unions\nUnion types is handled by using the union type itself, instead of the instantiated type. This hurts precision but guarantee soundness.","snippets":["#literature #analysis #compartmentalization\n@lu2023practical"],"rawContent":"# Practical Program Modularization with Type-Based Dependence Analysis\n#literature #analysis #compartmentalization\n@lu2023practical\n\n# Main arguments\nData-flow-based dependence analyses are impractical on large programs due to incorrect results and scalability issues, and A type-based dependence analysis avoid data-flow analysis.\n- See [[dgdvhu1e]]\n- The proposed approach can handle multi-entry, multi-threaded programs, and does not rely on points-to analysis.\n\nModule-aware type-based dependence analysis enables practical dependence analysis. \n- If only the module boundaries are analyzed (function arguments and global variables), the inner complexity of module is does not matter.\n- The proposed analysis only analyses the two types of typed-based data-flow, through function arguments and through global variable.\n\nModule-based analysis and type-based analysis are complementary.\n- Module-aware analysis complement type-analysis:\n  - Previous type-only approaches @lu2019where are imprecise because they scan the entire program for a particular type.\n  - There are modules in programs that has contain same types, but not related at all\n  - The approach can further refine the CFI targets by using dependent module information\n- Type-aware analysis improves module-aware analysis:\n  - A module-only analysis would be highly imprecise (only identifying if module A can write into B), using the Type of argument further restrict the data flow, making it an effective approach.\n\nThe proposed analysis is effective and sound (as a dependence analysis)\n- It is effective (in restricting data-flow) because it is difficult to form the data flow between modules with a given type, and that there are also modules between a module.\n- It is sound (as a dependence analysis), since the approach will catch all cross-module data-flow if there is one.\n\nThe analysis improve upon existing security applications.\n- When used for indirect call target reduction, it have high reduction rate on large application (up to 70% on firefox).\n- It identify 90% write instructions in linux as non-sensitive, which can be enforced with techniques such as DFI, WIT. (No enforcement were tested).\n  \n# Observation\nThere is only two type of data-flow between modules: through function arguments/return values and through global variables \n\n# Type-based dependence analysis\nThe key idea is to perform type-based dependence analysis between modules (i.e., compilation unit). \nA *type-based dependence analysis* determine if modules of the programs may propagate the object of a certain types to a particular module.\n\nThe following types of dependencies are detected:\n\nDirect (through argument):\n- If M1 pass argument of type T1 to M2, there is direct data flow M1-\u003eM2.\n\nIndirect (through global)\n- If M1 write to global g type T, M2 read global type T, then there is data flow M1-\u003eg-\u003eM2.\n\nTransitive:\n- There can be chaining of cross-module data flow, e.g., M1-\u003eM2-\u003eg-\u003eM3-\u003eM4 \n\n# The analysis\nThe analysis takes a pair of type and module \u003ctype,module\u003e, and automatically all dependent modules. There are three main steps.\n- The first step collect castable types into a CastMap. This is to handle unsafe casting operations in C/C++, all possible casted types are also considered in the data flow.\n- The second step find out the direction and type of the data flow between two particular modules and store it into a `FlowMap`. Finding out the direction possible data flow ([[#direction]]).\n- The final step compute dependent modules and the dependent types.\n\nIt is also observe that type-based indirect calls can be further refined using module-awareness. The author use an iterative method to refine the indirect call targets:\n- In first iteration, find dependent modules of an indirect call\n- Next, limit the type-based call target matching to only using the dependent modules.\n- Repeat until no more refinement is made\n\n\n## Finding data flow direction \n[]{#direction}\n\nFor two modules $M$, $V$, and a use $U$ of type $T$:\n- If the use in $V$ is a *load* LLVM instruction, then the direction is $M-\u003eV$.\n- If it is a $store$ instruction, then the direction is $V-\u003eM$.\n- If it is the GEP instruction, also analyze the use of the instruction\n- Else, it is bidirectional.\n\nOn struct types and pointer types, the types of the field is also analyzed. This is done through recursion on GEP instructions.\n\nThe result is stored in a structure called the $FlowMap$ that record Type, Direction of data flow between two modules.\n\n## Type elevation\n*Type elevation* is also proposed to improve the precision. The idea is that instead of using the type of the use site, which might have many false possitive, *elevate* it to the type of the containing struct.\nFor example, when an indirect call type $T1$ in a struct $T2$ is called, we first find the set of dependent modules using the type $T1$. Then, we find the dependent modules using the struct type $T2$. Finally, we *intersect* the two set to have a more refined dependent module set for the type $T1$.\n\nThis approach is unsound for container types (*base type*) that can be created from within the module, because cross-module data-flow will not find dependent module for those types. The paper suggests a simple *externality analysis*: If the base type is ever assigned (through `store` and initilizers), it cannot be used for elevation.\n\nEssentially, it is just following chain of GEP instructions to get the outermost type as the *base type* (section 5)\n\n\n# Implementation notes\n## Type comparison\nThe authors found that type comparison in LLVM poses challenges: \n- Type may have different underlying memory objects so pointer comparison does not work\n- The same struct type might have different variants, so string comparison may not work.\n- Struct types may or may not have name.\n\n## Unions\nUnion types is handled by using the union type itself, instead of the instantiated type. This hurts precision but guarantee soundness.  \n\n\n","wordCount":943,"tags":["analysis","compartmentalization","literature","direction"],"metadata":{},"created":"2023-08-09T13:49:43.469855585Z","modified":"2023-08-09T13:49:43.46992521Z","checksum":"662216095694e5f63ea615a18c9434fdb3665f8c9b0a58bf6736947edcab9fb0"},
    {"filename":"lxm4bklm.md","filenameStem":"lxm4bklm","path":"literature/lxm4bklm.md","absPath":"/Users/khadd/mynotes/literature/lxm4bklm.md","title":"Preventing Kernel Hacks with HAKC","link":"[[literature/lxm4bklm]]","lead":"#literature #compartmentalization #os #pointer-authentication #mte","body":"#literature #compartmentalization #os #pointer-authentication #mte\n\n\n\n\n# Summary\nThe paper introduces a framework for comparmenting software called Hardware-assited Kernel Comparmentalization (HAKC). The goal is to divide code and data into partitions, and enforce access control on data access and control-flow between partitions. The hardware primitives assumed are PA and MTE.\n\n\nThe paper claims two main contributions, in *Comparmentalization Policy* and in *Enforcement* strategy.\n\nRegarding the Policy, a two-level partitioning scheme is proposed. At a high level, there are Cliques and Compartments. One compartment contains several Cliques (at most 15 -- MTE number of tags). Two types of policies must be defined by the programmer:  Clique Access Policy (CAP) and Compartment Transition Policy (CTP).\n\nCAP is defined per-Cliques. It define data and code from other Cliques, a clique can access. The system enforce that a Clique's code and data accesses always access memory (1) belong to its own compartment and (2) within its permissions.\n\nCTP allows a clique to transfer its control flow outside of the compartment. It specify which other compartment's clique, a clique is able to call. When a clique transfer its control outside, data in the argument need to also be recolored to the target.\n\nThe authors argue that such a two-level design enable several advantages:\n- First, it overcome the limited number of MTE tags, since all control/data flow outside of the compartment must be explicitly validated.\n- Second, it enable local data optimization. More particular, within a clique, the access control is more light-weight, while other heavy-weight checks and data copies are left to the cross-comartment transitions.\n- Third, it allows fine-grained security boundaries, for performance-security trade-off.\n\n## Enforcement\nUsing MTE, all pointer will be encoded with a tag (a.k.a., cojoined metadata (CM)), indicating which clique owns the underlying memory. HAKC's strategy is to check all pointer dereference, to enforce that the pointer access is in accordance with the specified policies (the memory belong to the current compartment, and the current clique has the permission to access this data).\n\nAt runtime, a *candidate* CM is computed to be compared with a pointer's CM. The candiate CM is basically what the CM should looks like, given the current clique/compartment permissions.\n\nPAC is used to ensure that p\u003enter is not tamperedwith.\n\n\nMore particularly, in PA and MTE terms, every pointers is tagged with the clique's color. The pointer is then signed with a *signing token* as the modifier (which is the color of the owning clique *XOR* the compartment ID).\nI.e.,  $Tok_{sign} = CompartmantmentID XOR (Pointer's tag)$.\nLater, when the pointer is used, an *authentication token* is reconstructed the pointer's tag and the permission bitmask $Tok_{acl}$.\nOr,  $Tok_{aut} = CompartmantmentID XOR (Pointer's tag AND Tok_{acl})$.\n\nFor instance, if a pointer's tag is 3, its bitmask is $100$. A $Tok_{acl}$ of $111$ means that a clique is able to access cliques of color 1, 2 and 3. Assuming compartment ID is 2.\nThen,\n$Tok_{sign} = $5 XOR 100$\nAt the use site,\n$Tok_{aut} = $5 XOR (100 AND 111)$\n\nWhy is MTE/PAC is even needed?","snippets":["#literature #compartmentalization #os #pointer-authentication #mte"],"rawContent":"# Preventing Kernel Hacks with HAKC\n#literature #compartmentalization #os #pointer-authentication #mte\n\n\n\n\n# Summary\nThe paper introduces a framework for comparmenting software called Hardware-assited Kernel Comparmentalization (HAKC). The goal is to divide code and data into partitions, and enforce access control on data access and control-flow between partitions. The hardware primitives assumed are PA and MTE.\n\n\nThe paper claims two main contributions, in *Comparmentalization Policy* and in *Enforcement* strategy.\n\nRegarding the Policy, a two-level partitioning scheme is proposed. At a high level, there are Cliques and Compartments. One compartment contains several Cliques (at most 15 -- MTE number of tags). Two types of policies must be defined by the programmer:  Clique Access Policy (CAP) and Compartment Transition Policy (CTP).\n\nCAP is defined per-Cliques. It define data and code from other Cliques, a clique can access. The system enforce that a Clique's code and data accesses always access memory (1) belong to its own compartment and (2) within its permissions.\n\nCTP allows a clique to transfer its control flow outside of the compartment. It specify which other compartment's clique, a clique is able to call. When a clique transfer its control outside, data in the argument need to also be recolored to the target.\n\nThe authors argue that such a two-level design enable several advantages:\n- First, it overcome the limited number of MTE tags, since all control/data flow outside of the compartment must be explicitly validated.\n- Second, it enable local data optimization. More particular, within a clique, the access control is more light-weight, while other heavy-weight checks and data copies are left to the cross-comartment transitions.\n- Third, it allows fine-grained security boundaries, for performance-security trade-off.\n\n## Enforcement\nUsing MTE, all pointer will be encoded with a tag (a.k.a., cojoined metadata (CM)), indicating which clique owns the underlying memory. HAKC's strategy is to check all pointer dereference, to enforce that the pointer access is in accordance with the specified policies (the memory belong to the current compartment, and the current clique has the permission to access this data).\n\nAt runtime, a *candidate* CM is computed to be compared with a pointer's CM. The candiate CM is basically what the CM should looks like, given the current clique/compartment permissions.\n\nPAC is used to ensure that p\u003enter is not tamperedwith.\n\n\nMore particularly, in PA and MTE terms, every pointers is tagged with the clique's color. The pointer is then signed with a *signing token* as the modifier (which is the color of the owning clique *XOR* the compartment ID).\nI.e.,  $Tok_{sign} = CompartmantmentID XOR (Pointer's tag)$.\nLater, when the pointer is used, an *authentication token* is reconstructed the pointer's tag and the permission bitmask $Tok_{acl}$.\nOr,  $Tok_{aut} = CompartmantmentID XOR (Pointer's tag AND Tok_{acl})$.\n\nFor instance, if a pointer's tag is 3, its bitmask is $100$. A $Tok_{acl}$ of $111$ means that a clique is able to access cliques of color 1, 2 and 3. Assuming compartment ID is 2.\nThen,\n$Tok_{sign} = $5 XOR 100$\nAt the use site,\n$Tok_{aut} = $5 XOR (100 AND 111)$\n\nWhy is MTE/PAC is even needed?\n\n\n","wordCount":511,"tags":["os","compartmentalization","literature","pointer-authentication","mte"],"metadata":{},"created":"2023-08-09T13:49:43.470192336Z","modified":"2023-08-09T13:49:43.470245545Z","checksum":"2450aec15baab8558cf4a28eab098f2681d9a01a9bfbed580c991c9132ada4da"},
    {"filename":"a0g41kid.md","filenameStem":"a0g41kid","path":"a0g41kid.md","absPath":"/Users/khadd/mynotes/a0g41kid.md","title":"Process","link":"[[a0g41kid]]","lead":"#os","body":"#os\n\nIn the most simple term, a process is a running program (that have been loaded from the disk into memory and launched by the OS). A running process is defined by its states, which includes its memory, its registers contents, and opening files.\n\nThe OS stores a process's state is stored in the process control block PCB (`task_struct` in linux). For instance, in xv6, the PCB contains:\n\n```c\n// Per-process state\nstruct proc {\n  uint sz;                     // Size of process memory (bytes)\n  pde_t* pgdir;                // Page table\n  char *kstack;                // Bottom of kernel stack for this process\n  enum procstate state;        // Process state\n  volatile int pid;            // Process ID\n  struct proc *parent;         // Parent process\n  struct trapframe *tf;        // Trap frame for current syscall\n  struct context *context;     // swtch() here to run process\n  void *chan;                  // If non-zero, sleeping on chan\n  int killed;                  // If non-zero, have been killed\n  struct file *ofile[NOFILE];  // Open files\n  struct inode *cwd;           // Current directory\n  struct shared *shared;       // Shared memory record (0 -\u003e none)\n  char name[16];               // Process name (debugging)\n};\n```\n\nThe list of all process is stored by the OS in a *process list* data structure.\n\n## APIs\nProcesses are created through process system call APIs. There are API for:\n- Creation\n  - `fork()` creates a new process identical to the current one\n  - `exec()` spawn a new process with a given executable and arguments\n- Destroy\n  - A process is controlled through *signals*. The `kill()` syscall send signals to a process (e.g., `SIGINT`) to control it.\n- Wait\n  - The `wait()` system call wait for a spawned process to finish.","snippets":["#os"],"rawContent":"# Process\n#os\n\nIn the most simple term, a process is a running program (that have been loaded from the disk into memory and launched by the OS). A running process is defined by its states, which includes its memory, its registers contents, and opening files.\n\nThe OS stores a process's state is stored in the process control block PCB (`task_struct` in linux). For instance, in xv6, the PCB contains:\n\n```c\n// Per-process state\nstruct proc {\n  uint sz;                     // Size of process memory (bytes)\n  pde_t* pgdir;                // Page table\n  char *kstack;                // Bottom of kernel stack for this process\n  enum procstate state;        // Process state\n  volatile int pid;            // Process ID\n  struct proc *parent;         // Parent process\n  struct trapframe *tf;        // Trap frame for current syscall\n  struct context *context;     // swtch() here to run process\n  void *chan;                  // If non-zero, sleeping on chan\n  int killed;                  // If non-zero, have been killed\n  struct file *ofile[NOFILE];  // Open files\n  struct inode *cwd;           // Current directory\n  struct shared *shared;       // Shared memory record (0 -\u003e none)\n  char name[16];               // Process name (debugging)\n};\n```\n\nThe list of all process is stored by the OS in a *process list* data structure.\n\n## APIs\nProcesses are created through process system call APIs. There are API for:\n- Creation\n  - `fork()` creates a new process identical to the current one\n  - `exec()` spawn a new process with a given executable and arguments\n- Destroy\n  - A process is controlled through *signals*. The `kill()` syscall send signals to a process (e.g., `SIGINT`) to control it.\n- Wait\n  - The `wait()` system call wait for a spawned process to finish.\n\n\n","wordCount":273,"tags":["os"],"metadata":{},"created":"2023-08-09T13:49:43.46113064Z","modified":"2023-08-09T13:49:43.461177307Z","checksum":"1e54a5726e5091951087d6d102327e7405e72eb29f46534994406ced5ed2c080"},
    {"filename":"l3lzsza3.md","filenameStem":"l3lzsza3","path":"l3lzsza3.md","absPath":"/Users/khadd/mynotes/l3lzsza3.md","title":"Project: Obfuscated execution against Controlled-channel attacks","link":"[[l3lzsza3]]","lead":"#project","body":"#project\n\n# Background\n# Controlled-channel attacks against confidential computing\nControlled-channel attacks [[1yhmh234]]\n\nControlled-channel attacks on SGX are the most well-studied\n\nThere has also been controlled-channel attack studies for AMD SEV.\n\n## Obfuscated execution\n### Obfuscated execution for SGX\n\n# Obfuscated execution for confidential VM: What is lacking\n### Handling large TCB\nDifferent from SGX, the whole OS now has to be included into the TCB. This enlarges the attack surfaces for controlled-channel attacks.\n\nHowever, most of the proposed work cannot be scaled to this level.\n\n\nObfuscuro @ahmad2019obfuscuro requires sensitive code and data to fit into 4KB.\n\nKlotski only evaluated on small applications. Is is not sure how it handles larger one. \n\nOne other issue is that it is not sure how the previous models can be adapted to a large amount of inter-connected code.\nFor instance, sensitive code/data can induce paging, which may leads to controlled-channel visible by the VMM. \nThis is worsen due to the extended interfaces between the OS and VM [[#extended-interfaces]].\n\nObliviate @ahmad2018obliviate obfuscates the file system accesses, which may leads to \n\n### Extended interfaces\nThe interfaces between enlave-OS is significantly smaller than the interfaces between OS\u003c-\u003eVMM. It is expected that this interface would create other controlled-channels.\n\n### Under-studied attack vectors\nTODO: read these\n[Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization](https://www.usenix.org/conference/usenixsecurity19/presentation/li-mengyuan)\n[The SEVerESt Of Them All: Inference Attacks Against Secure Virtual Enclaves](https://dl.acm.org/doi/10.1145/3321705.3329820)\n\n[Security Analysis of Encrypted Virtual Machines](https://dl.acm.org/doi/10.1145/3140607.3050763)\n\n@li2021crossline\n@li2021tlb\n@morbitzer2019extracting\n\nThere lacks a systematic study about side-channel threats in this interface. \n\n### Taming the overheads\nOne way forward is to determine all sensitive data-dependent control-flow and data-flow to selectively apply protectionl. This is explored in Constantine @borrello2021constantine, but for very fine-grained obfuscated execution. A specialized method for selective data protection for confidential computing would greatly reduces the overheads.\n\nAnother way is to trade-off the granularity of protection. Klotski @zhang2020klotski uses caches for data and code that is larger than the 4KB page size, which improve performance, but allows observers to extracts coarse-grained information.","snippets":["#project"],"rawContent":"# Project: Obfuscated execution against Controlled-channel attacks\n#project\n\n# Background\n# Controlled-channel attacks against confidential computing\nControlled-channel attacks [[1yhmh234]]\n\nControlled-channel attacks on SGX are the most well-studied\n\nThere has also been controlled-channel attack studies for AMD SEV.\n\n## Obfuscated execution\n### Obfuscated execution for SGX\n\n# Obfuscated execution for confidential VM: What is lacking\n### Handling large TCB\nDifferent from SGX, the whole OS now has to be included into the TCB. This enlarges the attack surfaces for controlled-channel attacks.\n\nHowever, most of the proposed work cannot be scaled to this level.\n\n\nObfuscuro @ahmad2019obfuscuro requires sensitive code and data to fit into 4KB.\n\nKlotski only evaluated on small applications. Is is not sure how it handles larger one. \n\nOne other issue is that it is not sure how the previous models can be adapted to a large amount of inter-connected code.\nFor instance, sensitive code/data can induce paging, which may leads to controlled-channel visible by the VMM. \nThis is worsen due to the extended interfaces between the OS and VM [[#extended-interfaces]].\n\nObliviate @ahmad2018obliviate obfuscates the file system accesses, which may leads to \n\n### Extended interfaces\nThe interfaces between enlave-OS is significantly smaller than the interfaces between OS\u003c-\u003eVMM. It is expected that this interface would create other controlled-channels.\n\n### Under-studied attack vectors\nTODO: read these\n[Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization](https://www.usenix.org/conference/usenixsecurity19/presentation/li-mengyuan)\n[The SEVerESt Of Them All: Inference Attacks Against Secure Virtual Enclaves](https://dl.acm.org/doi/10.1145/3321705.3329820)\n\n[Security Analysis of Encrypted Virtual Machines](https://dl.acm.org/doi/10.1145/3140607.3050763)\n\n@li2021crossline\n@li2021tlb\n@morbitzer2019extracting\n\nThere lacks a systematic study about side-channel threats in this interface. \n\n### Taming the overheads\nOne way forward is to determine all sensitive data-dependent control-flow and data-flow to selectively apply protectionl. This is explored in Constantine @borrello2021constantine, but for very fine-grained obfuscated execution. A specialized method for selective data protection for confidential computing would greatly reduces the overheads.\n\nAnother way is to trade-off the granularity of protection. Klotski @zhang2020klotski uses caches for data and code that is larger than the 4KB page size, which improve performance, but allows observers to extracts coarse-grained information. \n\n","wordCount":336,"tags":["project"],"metadata":{},"created":"2023-08-09T13:49:43.469539334Z","modified":"2023-08-09T13:49:43.469590584Z","checksum":"869deadb424e21993d6ddd3c7c9d5e77858ca02ecd18a98d516586567a1c4281"},
    {"filename":"013pr50f.md","filenameStem":"013pr50f","path":"013pr50f.md","absPath":"/Users/khadd/mynotes/013pr50f.md","title":"Pure functions in Rust","link":"[[013pr50f]]","lead":"# rust #pure-function","body":"# rust #pure-function\n\n\nPure functions are a concept from functional programming languages that marks that a function has no *side-effect*. More concretely, in the D programming language, Pure functions are functions that cannot access global variables, and cannot make changes to their arguments.\n\n\n[This issue](https://github.com/rust-lang/rfcs/issues/1631) discusses the possibility of adding pure function support in Rust a keyword (e.g., `pure fn foo()`). Pure functions were eventually deem not useful:\n- There are rarely any use cases for it, even in the D programming language.\n- There is no agreed-upon definition for pure functions.\n- Rust tried implementing this concept before but removed it.\n- Rust already has something similar to this concept as `const fn`. Those functions can take runtime arguments,  but cannot do anything related to runtime execution.","snippets":["# rust #pure-function"],"rawContent":"# Pure functions in Rust\n# rust #pure-function\n\n\nPure functions are a concept from functional programming languages that marks that a function has no *side-effect*. More concretely, in the D programming language, Pure functions are functions that cannot access global variables, and cannot make changes to their arguments.\n\n\n[This issue](https://github.com/rust-lang/rfcs/issues/1631) discusses the possibility of adding pure function support in Rust a keyword (e.g., `pure fn foo()`). Pure functions were eventually deem not useful:\n- There are rarely any use cases for it, even in the D programming language.\n- There is no agreed-upon definition for pure functions.\n- Rust tried implementing this concept before but removed it.\n- Rust already has something similar to this concept as `const fn`. Those functions can take runtime arguments,  but cannot do anything related to runtime execution. \n\n","wordCount":133,"tags":["pure-function"],"metadata":{},"created":"2023-08-09T13:49:43.459736761Z","modified":"2024-05-18T08:36:07.737991158Z","checksum":"790a6530b57e46125947a2001f8b05931cdb0ff238362df97bb1ee3c2acfa906"},
    {"filename":"7dzydfim.md","filenameStem":"7dzydfim","path":"7dzydfim.md","absPath":"/Users/khadd/mynotes/7dzydfim.md","title":"RLBox Implementation","link":"[[7dzydfim]]","lead":"# Tainted type","body":"# Tainted type\n\nTainted types includes `tainted` and `tainted_volatile`.\n\nThey inherits from the base class `tained_base_impl`\n## Signature\n## Overriding\n\n\n### internal_factory\n`internal_factory` is used to create new tainted values from the result of operators. Why is it \"internal?\" because it is only used internally. Sometimes values are created from pointers, which is considered dangerous. I guess they enforce that only `allocate_in_sandbox` can create pointers or something.\n\n\n\n### BinaryOpValAndPtr\ni.e., Binary operators for values and pointers. These include + and -.\n`tainted\u003cT, T_Sbx\u003e + T_Rhs -\u003e tainted\u003cT, T_Sbx\u003e`\n\nIf T is ptr (ptr + ptr or ptr + value):\n1. T must not be null\n2. Perform the operation\n3. Check if the result is within the sandbox. This check is sandbox-dependent\n4. call `internal_factory`  on the result to create a new `tainted` value.\n\n\n## BinaryOp\nBinaryOp contains the remaining binary operations only performed on primitive types\n\n## Dereference\n```cpp\nprivate:\n using T_OpDerefRet = tainted_volatile\u003cstd::remove_pointer_t\u003cT\u003e, T_Sbx\u003e;\n\npublic:\n  inline T_OpDerefRet\u0026 operator*() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e, \"Operator * only allowed on pointers\");\n    auto ret_ptr_const =\n      reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n    // Safe - If T_OpDerefRet is not a const ptr, this is trivially safe\n    //        If T_OpDerefRet is a const ptr, then the const is captured\n    //        inside the wrapper\n    auto ret_ptr = const_cast\u003cT_OpDerefRet*\u003e(ret_ptr_const);\n    return *ret_ptr;\n  }\n\n  // We need to implement the -\u003e operator even if T is not a struct\n  // So that we can support code patterns such as the below\n  // tainted\u003cT*\u003e a;\n  // a-\u003eUNSAFE_unverified();\n  inline const T_OpDerefRet* operator-\u003e() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e,\n                  \"Operator -\u003e only supported for pointer types\");\n    return reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n  }\n```","snippets":["# Tainted type"],"rawContent":"# RLBox Implementation\n\n# Tainted type\n\nTainted types includes `tainted` and `tainted_volatile`.\n\nThey inherits from the base class `tained_base_impl`\n## Signature\n## Overriding\n\n\n### internal_factory\n`internal_factory` is used to create new tainted values from the result of operators. Why is it \"internal?\" because it is only used internally. Sometimes values are created from pointers, which is considered dangerous. I guess they enforce that only `allocate_in_sandbox` can create pointers or something.\n\n\n\n### BinaryOpValAndPtr\ni.e., Binary operators for values and pointers. These include + and -.\n`tainted\u003cT, T_Sbx\u003e + T_Rhs -\u003e tainted\u003cT, T_Sbx\u003e`\n\nIf T is ptr (ptr + ptr or ptr + value):\n1. T must not be null\n2. Perform the operation\n3. Check if the result is within the sandbox. This check is sandbox-dependent\n4. call `internal_factory`  on the result to create a new `tainted` value.\n\n\n## BinaryOp\nBinaryOp contains the remaining binary operations only performed on primitive types\n\n## Dereference\n```cpp\nprivate:\n using T_OpDerefRet = tainted_volatile\u003cstd::remove_pointer_t\u003cT\u003e, T_Sbx\u003e;\n\npublic:\n  inline T_OpDerefRet\u0026 operator*() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e, \"Operator * only allowed on pointers\");\n    auto ret_ptr_const =\n      reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n    // Safe - If T_OpDerefRet is not a const ptr, this is trivially safe\n    //        If T_OpDerefRet is a const ptr, then the const is captured\n    //        inside the wrapper\n    auto ret_ptr = const_cast\u003cT_OpDerefRet*\u003e(ret_ptr_const);\n    return *ret_ptr;\n  }\n\n  // We need to implement the -\u003e operator even if T is not a struct\n  // So that we can support code patterns such as the below\n  // tainted\u003cT*\u003e a;\n  // a-\u003eUNSAFE_unverified();\n  inline const T_OpDerefRet* operator-\u003e() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e,\n                  \"Operator -\u003e only supported for pointer types\");\n    return reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n  }\n```\n","wordCount":265,"tags":[],"metadata":{},"created":"2023-08-09T13:49:43.460563764Z","modified":"2023-08-09T13:49:43.460614681Z","checksum":"f8af5dcd1dacc75ba8f5f51172e114602ed8240cbe694c72d41107c4ebdf74c5"},
    {"filename":"2dw6pwrd.md","filenameStem":"2dw6pwrd","path":"2dw6pwrd.md","absPath":"/Users/khadd/mynotes/2dw6pwrd.md","title":"Research Ideas","link":"[[2dw6pwrd]]","lead":"#research","body":"#research\n\n- [[fleeting/douswvq0]]\n\n- Better methods for hooking of syscalls\n- Carat Cake @suchy2022carat propose getting rid of paging, and use software instrumentation to provide OS-like abstractions. Capacity may be adaptable to this.","snippets":["#research"],"rawContent":"# Research Ideas\n#research\n\n- [[fleeting/douswvq0]]\n\n- Better methods for hooking of syscalls\n- Carat Cake @suchy2022carat propose getting rid of paging, and use software instrumentation to provide OS-like abstractions. Capacity may be adaptable to this.\n\n","wordCount":36,"tags":["research"],"metadata":{},"created":"2023-08-09T13:49:43.46010122Z","modified":"2023-08-09T13:49:43.46013997Z","checksum":"5120e4e2202e9dc26c211a0c4a1eae31c42b4512119e12ed43a418c7dff47d47"},
    {"filename":"0wijbapr.md","filenameStem":"0wijbapr","path":"fleeting/0wijbapr.md","absPath":"/Users/khadd/mynotes/fleeting/0wijbapr.md","title":"RustSan data flow analysis example","link":"[[fleeting/0wijbapr]]","lead":"#fleeting","body":"#fleeting\n\nGodbolt flags\n```\n -C llvm-args=\"--opaque-pointers=0\"  -Z mir-opt-level=0\n```\n\n```rust\nuse std::*;\n\nfn foo(arg: \u0026mut i32, arg2: \u0026i32){\n    let mut x: i32 = 0;\n    let y: i32 = *arg2;\n    \n    unsafe {\n        x = 20;\n        *arg = y + x;\n    }    \n\n}\n\n\n\npub fn main() {\n    let mut x: i32 = 5;\n    let y: i32 = 6;\n    hint::black_box(foo(\u0026mut x, \u0026y));\n}\n\n```\n \n``` llvm\ndefine internal void @_ZN7example3foo17h16d9ab8665c1c250E(i32* align 4 %arg, i32* align 4 %arg2) unnamed_addr #1 !dbg !15 {\nstart:\n  %x = alloca i32, align 4\n  store i32 0, i32* %x, align 4, !dbg !18\n  %y = load i32, i32* %arg2, align 4, !dbg !19, !noundef !11\n  store i32 20, i32* %x, align 4, !dbg !21\n  %_6 = load i32, i32* %x, align 4, !dbg !24, !noundef !11\n  %0 = call { i32, i1 } @llvm.sadd.with.overflow.i32(i32 %y, i32 %_6), !dbg !25\n  %_7.0 = extractvalue { i32, i1 } %0, 0, !dbg !25\n  %_7.1 = extractvalue { i32, i1 } %0, 1, !dbg !25\n  %1 = call i1 @llvm.expect.i1(i1 %_7.1, i1 false), !dbg !25\n  br i1 %1, label %panic, label %bb1, !dbg !25\n\nbb1:                                              ; preds = %start\n  store i32 %_7.0, i32* %arg, align 4, !dbg !26\n  ret void, !dbg !27\n\npanic:                                            ; preds = %start\n  call void @_ZN4core9panicking5panic17hcaff1f3d20618491E([0 x i8]* align 1 bitcast ([28 x i8]* @str.0 to [0 x i8]*), i64 28, %\"core::panic::location::Location\u003c'_\u003e\"* align 8 bitcast (\u003c{ i8*, [16 x i8] }\u003e* @alloc_9bc9feaf68b8c234019a4170dc48b236 to %\"core::panic::location::Location\u003c'_\u003e\"*)) #5, !dbg !25\n  unreachable, !dbg !25\n}\n```","snippets":["#fleeting"],"rawContent":"# RustSan data flow analysis example\n#fleeting\n\nGodbolt flags\n```\n -C llvm-args=\"--opaque-pointers=0\"  -Z mir-opt-level=0\n```\n\n```rust\nuse std::*;\n\nfn foo(arg: \u0026mut i32, arg2: \u0026i32){\n    let mut x: i32 = 0;\n    let y: i32 = *arg2;\n    \n    unsafe {\n        x = 20;\n        *arg = y + x;\n    }    \n\n}\n\n\n\npub fn main() {\n    let mut x: i32 = 5;\n    let y: i32 = 6;\n    hint::black_box(foo(\u0026mut x, \u0026y));\n}\n\n```\n \n``` llvm\ndefine internal void @_ZN7example3foo17h16d9ab8665c1c250E(i32* align 4 %arg, i32* align 4 %arg2) unnamed_addr #1 !dbg !15 {\nstart:\n  %x = alloca i32, align 4\n  store i32 0, i32* %x, align 4, !dbg !18\n  %y = load i32, i32* %arg2, align 4, !dbg !19, !noundef !11\n  store i32 20, i32* %x, align 4, !dbg !21\n  %_6 = load i32, i32* %x, align 4, !dbg !24, !noundef !11\n  %0 = call { i32, i1 } @llvm.sadd.with.overflow.i32(i32 %y, i32 %_6), !dbg !25\n  %_7.0 = extractvalue { i32, i1 } %0, 0, !dbg !25\n  %_7.1 = extractvalue { i32, i1 } %0, 1, !dbg !25\n  %1 = call i1 @llvm.expect.i1(i1 %_7.1, i1 false), !dbg !25\n  br i1 %1, label %panic, label %bb1, !dbg !25\n\nbb1:                                              ; preds = %start\n  store i32 %_7.0, i32* %arg, align 4, !dbg !26\n  ret void, !dbg !27\n\npanic:                                            ; preds = %start\n  call void @_ZN4core9panicking5panic17hcaff1f3d20618491E([0 x i8]* align 1 bitcast ([28 x i8]* @str.0 to [0 x i8]*), i64 28, %\"core::panic::location::Location\u003c'_\u003e\"* align 8 bitcast (\u003c{ i8*, [16 x i8] }\u003e* @alloc_9bc9feaf68b8c234019a4170dc48b236 to %\"core::panic::location::Location\u003c'_\u003e\"*)) #5, !dbg !25\n  unreachable, !dbg !25\n}\n```\n","wordCount":250,"tags":["fleeting"],"metadata":{},"created":"2023-08-09T13:49:43.467779537Z","modified":"2023-08-09T13:49:43.467825079Z","checksum":"93fcde9ab335e05339e5d1f71abbf778fed47d069490537315222d663e59da04"},
    {"filename":"0kmxhvf5.md","filenameStem":"0kmxhvf5","path":"archive/0kmxhvf5.md","absPath":"/Users/khadd/mynotes/archive/0kmxhvf5.md","title":"S\u0026P 2023","link":"[[archive/0kmxhvf5]]","lead":"#conference\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)\n# System-ish papers\nNew architecture\n- SecureCells: A Secure Compartmentalized Architecture\n- Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture","body":"#conference\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)\n# System-ish papers\nNew architecture\n- SecureCells: A Secure Compartmentalized Architecture\n- Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture\n\nSecure System\n- WaVe: A Verifiably Secure WebAssembly Sandboxing Runtime\n- uSWITCH: Fast Kernel Context Isolation with Implicit Context Switches\n\nSystem for ML\n- ShadowNet: A Secure and Efficient On-device Model Inference System for Convolutional Neural Networks\n\nExploits\n- WarpAttack: Bypassing CFI through Compiler-Introduced Double-Fetches\n\nKernel bugs\n- Precise Detection of Kernel Data Races with Probabilistic Lockset Analysis\n- When Top-down Meets Bottom-up: Detecting and Exploiting Use-After-Cleanup Bugs in Linux Kernel\n- AEM: Facilitating Cross-Version Exploitability Assessment of Linux Kernel Vulnerabilities\n\nProgram analysis, compartmentalization\n- Practical Program Modularization with Type-Based Dependence Analysis\n- EC: Embedded Systems Compartmentalization via Intra-Kernel Isolation\n- Low-Cost Privilege Separation with Compile Time Compartmentalization for Embedded Systems","snippets":["#conference\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)\n# System-ish papers\nNew architecture\n- SecureCells: A Secure Compartmentalized Architecture\n- Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture"],"rawContent":"# S\u0026P 2023\n#conference\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)\n# System-ish papers\nNew architecture\n- SecureCells: A Secure Compartmentalized Architecture\n- Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture\n\nSecure System\n- WaVe: A Verifiably Secure WebAssembly Sandboxing Runtime\n- uSWITCH: Fast Kernel Context Isolation with Implicit Context Switches\n\nSystem for ML\n- ShadowNet: A Secure and Efficient On-device Model Inference System for Convolutional Neural Networks\n\nExploits\n- WarpAttack: Bypassing CFI through Compiler-Introduced Double-Fetches\n\nKernel bugs\n- Precise Detection of Kernel Data Races with Probabilistic Lockset Analysis\n- When Top-down Meets Bottom-up: Detecting and Exploiting Use-After-Cleanup Bugs in Linux Kernel\n- AEM: Facilitating Cross-Version Exploitability Assessment of Linux Kernel Vulnerabilities\n\nProgram analysis, compartmentalization\n- Practical Program Modularization with Type-Based Dependence Analysis\n- EC: Embedded Systems Compartmentalization via Intra-Kernel Isolation\n- Low-Cost Privilege Separation with Compile Time Compartmentalization for Embedded Systems\n","wordCount":141,"tags":["conference"],"metadata":{},"created":"2023-08-09T13:49:43.459813386Z","modified":"2023-08-09T13:49:43.459865428Z","checksum":"976f60f6c0bf31ca85f498fdfc4be03db90e463f0c94c656998b861cbd7720db"},
    {"filename":"8igqoq32.md","filenameStem":"8igqoq32","path":"8igqoq32.md","absPath":"/Users/khadd/mynotes/8igqoq32.md","title":"Single Address Space systems","link":"[[8igqoq32]]","lead":"#os","body":"#os \n\n\n\n\n\n\n# Redleaf\n@narayanan2020redleaf\n\nMemory safety of Rust (without `unsafe`) guarantee the isolation between subsystems. \n\n# CARAT\nCARAT @suchy2020carat, @suchy2022carat,explore removing paging abstraction and the reliance on paging hardware (Page table walker, MMU, TLB). Instead, all software need to be compiled by a trusted compiler to use physical addressing.\n\nMemory protection is achieved by compiler-inserted guards.","snippets":["#os"],"rawContent":"# Single Address Space systems\n#os \n\n\n\n\n\n\n# Redleaf\n@narayanan2020redleaf\n\nMemory safety of Rust (without `unsafe`) guarantee the isolation between subsystems. \n\n# CARAT\nCARAT @suchy2020carat, @suchy2022carat,explore removing paging abstraction and the reliance on paging hardware (Page table walker, MMU, TLB). Instead, all software need to be compiled by a trusted compiler to use physical addressing.\n\nMemory protection is achieved by compiler-inserted guards.\n\n\n","wordCount":61,"tags":["os"],"metadata":{},"created":"2023-08-09T13:49:43.460855848Z","modified":"2023-08-09T13:49:43.460895348Z","checksum":"f395a20c71e386cdc65ad96cae6febf4e038a320a32f1b1fa7445b3dee76d941"},
    {"filename":"2j6s9zpm.md","filenameStem":"2j6s9zpm","path":"2j6s9zpm.md","absPath":"/Users/khadd/mynotes/2j6s9zpm.md","title":"State spill","link":"[[2j6s9zpm]]","lead":"#os #microkernel","body":"#os #microkernel\n\nState spills happen when a seemingly isolated and modularized software component change its state due to interactions with other components, such that future correctness depends on such state.\n\nState spills harms extensibility/migration of systems. This happens when an entity provides an abstraction layer for other entities. \n- For example, in Linux, the OS process abstraction stores state into members of `task_struct`, which might also contains objects from other OS entities. This prevents *process mitigation*, since the OS must keep track of all changes made to other OS entities. \n- In microkernels, abstraction layer is provided by userspace server. State spills into the userspace servers prevents their live update and hot-swapping, since other applications are depended on those states.\n\nState spills hurt availability of systems (it breaks fault isolation and fault tolerance). This happen when an entity acts as a *multiplexer* that allows multiple clients to access an underlying resource. \n- Corruptions caused by state spills in *Process management* entities in OS cause all process to be affected.\n- *Recovery* of servers is also hindered due to state spill, recovery on behalf of one client can affect other clients.\n\nAs a final note, removing state spill forces the caller to memory to allocate the context used for cross-compartment interaction. In a sense, it also improves the security of the per-compartment interface. See 1 and 4 in [[qti6u06p]].\n\n\n## References\n- @boos2017characterizationl: Introduce the term state spill and provides its classification.\n- @boos2020theseus (see [[literature/jfm8ud28]]): An operating system that aim to minimize state spill.","snippets":["#os #microkernel"],"rawContent":"# State spill\n#os #microkernel\n\nState spills happen when a seemingly isolated and modularized software component change its state due to interactions with other components, such that future correctness depends on such state.\n\nState spills harms extensibility/migration of systems. This happens when an entity provides an abstraction layer for other entities. \n- For example, in Linux, the OS process abstraction stores state into members of `task_struct`, which might also contains objects from other OS entities. This prevents *process mitigation*, since the OS must keep track of all changes made to other OS entities. \n- In microkernels, abstraction layer is provided by userspace server. State spills into the userspace servers prevents their live update and hot-swapping, since other applications are depended on those states.\n\nState spills hurt availability of systems (it breaks fault isolation and fault tolerance). This happen when an entity acts as a *multiplexer* that allows multiple clients to access an underlying resource. \n- Corruptions caused by state spills in *Process management* entities in OS cause all process to be affected.\n- *Recovery* of servers is also hindered due to state spill, recovery on behalf of one client can affect other clients.\n\nAs a final note, removing state spill forces the caller to memory to allocate the context used for cross-compartment interaction. In a sense, it also improves the security of the per-compartment interface. See 1 and 4 in [[qti6u06p]].\n\n\n## References\n- @boos2017characterizationl: Introduce the term state spill and provides its classification.\n- @boos2020theseus (see [[literature/jfm8ud28]]): An operating system that aim to minimize state spill. \n","wordCount":257,"tags":["os","microkernel"],"metadata":{},"created":"2023-08-09T13:49:43.460256804Z","modified":"2023-08-09T13:49:43.460327513Z","checksum":"25c6574a6f1038ace54ec6f43397708818272fd3435bf365b784d35017cb91ca"},
    {"filename":"fvom56lw.md","filenameStem":"fvom56lw","path":"fvom56lw.md","absPath":"/Users/khadd/mynotes/fvom56lw.md","title":"TSX-based control-channel defenses","link":"[[fvom56lw]]","lead":"#tsx #controlled-channel","body":"#tsx #controlled-channel\n\nFor more context, see [[5kzr3hwx]].\n\n# T-SGX\nT-SGX @shih2017tsgx uses Intel TSX  to prevent the OS from knowing the page fault, since TSX supresses page faults on during a transaction. The system transform the program such that (almost) all code is executed in a TSX transaction. Any page fault is treated as an attack attempt by the OS. \nReported overheads of the system is about 50%.\n\n\n# Deja Vu\n@chen2017detecting uses TSX to *detect* wheter an AEX has occured during the execution of critical code. The program is instrumented to periodically measure its execution time, and if the execution time deviate too much from its expected time, an AEX is detected.\n\n```c\nwhile (1) {\n  // update counter\n  if (_xbegin() == _XBEGIN_STARTED)\n  {\n      int rand = random();\n      for (int i =0; i \u003c rand; i++){\n        // rand cycles is performed\n      }\n      _xend();\n  }\n  else {\n    interrupted += 1;\n    continue;\n  }\n  timer += rand;\n}\n```\n\nA thread is used to continuously update a global timer variable.\nThe program is then instrumented to uses this timer to detect attacks (e.g., if a basic block takes too long to complete and the there was an interrupt, then there is a high chance that an AEX occurred).\nThe counter thread uses TSX to determine whether an interrupt happened.","snippets":["#tsx #controlled-channel"],"rawContent":"# TSX-based control-channel defenses\n#tsx #controlled-channel\n\nFor more context, see [[5kzr3hwx]].\n\n# T-SGX\nT-SGX @shih2017tsgx uses Intel TSX  to prevent the OS from knowing the page fault, since TSX supresses page faults on during a transaction. The system transform the program such that (almost) all code is executed in a TSX transaction. Any page fault is treated as an attack attempt by the OS. \nReported overheads of the system is about 50%.\n\n\n# Deja Vu\n@chen2017detecting uses TSX to *detect* wheter an AEX has occured during the execution of critical code. The program is instrumented to periodically measure its execution time, and if the execution time deviate too much from its expected time, an AEX is detected.\n\n```c\nwhile (1) {\n  // update counter\n  if (_xbegin() == _XBEGIN_STARTED)\n  {\n      int rand = random();\n      for (int i =0; i \u003c rand; i++){\n        // rand cycles is performed\n      }\n      _xend();\n  }\n  else {\n    interrupted += 1;\n    continue;\n  }\n  timer += rand;\n}\n```\n\nA thread is used to continuously update a global timer variable.\nThe program is then instrumented to uses this timer to detect attacks (e.g., if a basic block takes too long to complete and the there was an interrupt, then there is a high chance that an AEX occurred).\nThe counter thread uses TSX to determine whether an interrupt happened.\n","wordCount":221,"tags":["controlled-channel","tsx"],"metadata":{},"created":"2023-08-09T13:49:43.467997829Z","modified":"2023-08-09T13:49:43.468049954Z","checksum":"e8e1651786c7f285a789a1d3566323802e4d84166a16c5014f9e086adf30285f"},
    {"filename":"jsygj3tb.md","filenameStem":"jsygj3tb","path":"jsygj3tb.md","absPath":"/Users/khadd/mynotes/jsygj3tb.md","title":"The Second-system Effect","link":"[[jsygj3tb]]","lead":"#programming","body":"#programming\n\n[@brooks1975mythical] coins the term *the Second-System effect*: The second system that a system architect builds is the most *dangerous* (i.e., over-designed) one. The reasons are as follows. The first system ought to be carefully designed and clean. The designer would leave all the crazy ideas until \"next time\". With the confidence of the first successful system, the architect would go on and design the second system without any restriction.\n\nAs for third and later systems, the architect gains experience and generalized knowledge of what would work and would not work for the type of system.\n\nTo avoid this effect, @brooks1975mythical suggests designing the second system with self-discipline.","snippets":["#programming"],"rawContent":"# The Second-system Effect\n#programming\n\n[@brooks1975mythical] coins the term *the Second-System effect*: The second system that a system architect builds is the most *dangerous* (i.e., over-designed) one. The reasons are as follows. The first system ought to be carefully designed and clean. The designer would leave all the crazy ideas until \"next time\". With the confidence of the first successful system, the architect would go on and design the second system without any restriction.\n\nAs for third and later systems, the architect gains experience and generalized knowledge of what would work and would not work for the type of system.\n\nTo avoid this effect, @brooks1975mythical suggests designing the second system with self-discipline.\n","wordCount":112,"tags":["programming"],"metadata":{},"created":"2023-08-09T13:49:43.469234958Z","modified":"2024-05-18T08:41:51.54594673Z","checksum":"010ca452592401fa91388613a0b1281d09a803ddadd5669695c3037c3b99a569"},
    {"filename":"7t4jlnaq.md","filenameStem":"7t4jlnaq","path":"7t4jlnaq.md","absPath":"/Users/khadd/mynotes/7t4jlnaq.md","title":"The goals of an Operating System","link":"[[7t4jlnaq]]","lead":"#os","body":"#os\n\nThere are two main goals of an OS: abstraction and resource management.\n\nFrom the top-down view of the user, the OS provides abstraction over complex interactions with the hardware. \nIt turns an impossible task (write applications that interacts with the hardware directly) in to two manageable tasks: (1) design and implement the abstraction, and (2) use the abstraction to do works.\nTwo most fundamental abstractions provided by most OSes are *files* and *processes*. Files and file-related system calls abstract away the communication and management of data stored on the disk. Process is a unit of execution that enable multitasking (1.1, [@tanenbaum2015modern]). \n\n\nFrom a bottom-up view, an operating system enable fair resource sharing among multiple users. This is called *multiplexing*. There can be *space multiplexing*, sharing a part of a resource between users (e.g., memory), and *time multiplexing*, sharing time slices of a resource (e.g., cpu time) between users.\nAlso, from the user point of view, the resources are being *virtualized*: the OS give the user an *illusion* of having access to entire system (e.g., all of physical memory).\n\nSee also:\n- [[k60yjf6q]]","snippets":["#os"],"rawContent":"# The goals of an Operating System\n#os\n\nThere are two main goals of an OS: abstraction and resource management.\n\nFrom the top-down view of the user, the OS provides abstraction over complex interactions with the hardware. \nIt turns an impossible task (write applications that interacts with the hardware directly) in to two manageable tasks: (1) design and implement the abstraction, and (2) use the abstraction to do works.\nTwo most fundamental abstractions provided by most OSes are *files* and *processes*. Files and file-related system calls abstract away the communication and management of data stored on the disk. Process is a unit of execution that enable multitasking (1.1, [@tanenbaum2015modern]). \n\n\nFrom a bottom-up view, an operating system enable fair resource sharing among multiple users. This is called *multiplexing*. There can be *space multiplexing*, sharing a part of a resource between users (e.g., memory), and *time multiplexing*, sharing time slices of a resource (e.g., cpu time) between users.\nAlso, from the user point of view, the resources are being *virtualized*: the OS give the user an *illusion* of having access to entire system (e.g., all of physical memory).\n\nSee also:\n- [[k60yjf6q]]\n\n","wordCount":190,"tags":["os"],"metadata":{},"created":"2023-08-09T13:49:43.460775681Z","modified":"2023-08-09T13:49:43.460830765Z","checksum":"20d1c90b6d1df790b2f5e5a7f15b16d05b3e7c401ecdfeae2ba20094f2eb6ff6"},
    {"filename":"jfm8ud28.md","filenameStem":"jfm8ud28","path":"literature/jfm8ud28.md","absPath":"/Users/khadd/mynotes/literature/jfm8ud28.md","title":"Theseus: an Experiment in Operating System Structure and State Management","link":"[[literature/jfm8ud28]]","lead":"#literature #os #rust\n@boos2020theseus","body":"#literature #os #rust\n@boos2020theseus\n\n# Main arguments\nState spill harms availability and evolvability of system software (see [[2j6s9zpm]]).\n\nTo mitigate state spills, it is necessary to restructure the OS architecture\n- The proposed system rearchitect OS components into Cells that has *runtime-persistent* bound [[#cells]].\n- It then avoid state spill through exporting states to the clients in similar way to RESTful APIs [[#state-management]]\n\nProgramming language can statically ensure certain correctness invariants in the OS.\n- Theseus incorporates resource-specific invariants into Rust compiler checks. For instance, memory management is implemented via the `MappedPages` types that also introduce new static invariants for mapping memory (see 4.3).\n\nIt is necessary to match runtime execution environment with that of the language's runtime model (i.e., *intralingual* design) to take advantages of Rust\n- Cells in Theseus are single-address space, single-privilege level, and use a single allocator instance. \n- It enable compiler to assist resource management,\n- It enables compiler to assert safety checks without gaps in code behaviors.\n\n## Cells\nAll OS components are splitted into minimal cells, to be executed in single-address space (SAS), single privilege level (SPL), and are isolated using Rust. Cells in Theseus have *runtime-persistent* bounds, in that the bounds are persisted throughout compile time (crate bound), load time (memory regions), and runtime (by keeping track of dependency metadata).\n- This idea is opposite to the intertwined bounds introduces in monolithic kernels. Takes kernel modules as an example, they don't have clearly defined bounds; kernel module can access other OS entities in the code, and at runtime. \n- Persistent cell bounds allows for clean cell-swapping (aka migration) and cell evolution (aka live update) and fault recovery.\n\n\n## State management\nState spill is avoided by *opaque exportation*, which essentially means that the client owns the state for client, but cannot read, or modify the state due to Type safety.\n- This is similar to Object-capability systems (#capabilities), the callee might hold the capabilities to invoke a function, but not using the capabilities by themself. Due to Rust's type safety, variables are akin to capabilities. \n- Similarly, RESTful web architectures also employ a similar kind of *stateless communication*, where the client pass everything that is needed to handle the request to the server.\n- This is only possible when the client is enforced with Rust type safety.\n\nTheseus also enables *soft states* that can be discarded without error and *unavoidable states* (clientless state required by the hardware and states invoked by hardware). Those states are stored into a unique cell call `state_db`.\n- Static states are moved into state_db, and only a weak reference is used. This decouple the server cells that use hardware states from the hardware state lifetime, so they can be swapped.  \n- state_db cell must be serialized into non-volatile storage when swapping.\n\n\n## Cell swapping \u0026 evolution\nTODO","snippets":["#literature #os #rust\n@boos2020theseus"],"rawContent":"# Theseus: an Experiment in Operating System Structure and State Management\n#literature #os #rust\n@boos2020theseus\n\n# Main arguments\nState spill harms availability and evolvability of system software (see [[2j6s9zpm]]).\n\nTo mitigate state spills, it is necessary to restructure the OS architecture\n- The proposed system rearchitect OS components into Cells that has *runtime-persistent* bound [[#cells]].\n- It then avoid state spill through exporting states to the clients in similar way to RESTful APIs [[#state-management]]\n\nProgramming language can statically ensure certain correctness invariants in the OS.\n- Theseus incorporates resource-specific invariants into Rust compiler checks. For instance, memory management is implemented via the `MappedPages` types that also introduce new static invariants for mapping memory (see 4.3).\n\nIt is necessary to match runtime execution environment with that of the language's runtime model (i.e., *intralingual* design) to take advantages of Rust\n- Cells in Theseus are single-address space, single-privilege level, and use a single allocator instance. \n- It enable compiler to assist resource management,\n- It enables compiler to assert safety checks without gaps in code behaviors.\n\n## Cells\nAll OS components are splitted into minimal cells, to be executed in single-address space (SAS), single privilege level (SPL), and are isolated using Rust. Cells in Theseus have *runtime-persistent* bounds, in that the bounds are persisted throughout compile time (crate bound), load time (memory regions), and runtime (by keeping track of dependency metadata).\n- This idea is opposite to the intertwined bounds introduces in monolithic kernels. Takes kernel modules as an example, they don't have clearly defined bounds; kernel module can access other OS entities in the code, and at runtime. \n- Persistent cell bounds allows for clean cell-swapping (aka migration) and cell evolution (aka live update) and fault recovery.\n\n\n## State management\nState spill is avoided by *opaque exportation*, which essentially means that the client owns the state for client, but cannot read, or modify the state due to Type safety.\n- This is similar to Object-capability systems (#capabilities), the callee might hold the capabilities to invoke a function, but not using the capabilities by themself. Due to Rust's type safety, variables are akin to capabilities. \n- Similarly, RESTful web architectures also employ a similar kind of *stateless communication*, where the client pass everything that is needed to handle the request to the server.\n- This is only possible when the client is enforced with Rust type safety.\n\nTheseus also enables *soft states* that can be discarded without error and *unavoidable states* (clientless state required by the hardware and states invoked by hardware). Those states are stored into a unique cell call `state_db`.\n- Static states are moved into state_db, and only a weak reference is used. This decouple the server cells that use hardware states from the hardware state lifetime, so they can be swapped.  \n- state_db cell must be serialized into non-volatile storage when swapping.\n\n\n## Cell swapping \u0026 evolution\nTODO\n","wordCount":480,"tags":["os","rust","capabilities","literature"],"metadata":{},"created":"2023-08-09T13:49:43.470054419Z","modified":"2023-08-09T13:49:43.470104753Z","checksum":"4fa674038def9a92c9953808048b3263dcce546541f94d3e451726d75c99f422"},
    {"filename":"k60yjf6q.md","filenameStem":"k60yjf6q","path":"k60yjf6q.md","absPath":"/Users/khadd/mynotes/k60yjf6q.md","title":"Three pieces of an Operating System","link":"[[k60yjf6q]]","lead":"#os","body":"#os\n\nThere are three main concept in achieving an operating system: *virtualization*, *concurrency* and  *persistent* [@arpaci-dusseauoperating].\n\n## Virtualization\nVirtualization give an process an illusion of having access to the whole underlying resource. To do so, the OS take physical resources and transform them into virtual resources, and hand them out to the users.\n\nThis is the key in maximizing resource usage, since a single job rarely utilize all of the available hardware resource. Virtualization also make the system easier to use. \n\nThe key problem with virtualization is how to do it efficiently, how to attain fairness, and what hardware support is needed.\n\n## Concurrency\nConcurrency allows multiple jobs to execute at once. This is especially important in maximizing CPU efficiency: when waiting for slow I/O jobs, the CPU time is better used executing other tasks.\nIn a sense, concurrency is achieved by virtualizing CPU time?\n\nIn the OS, there is two granularity of concurrency, threads and processes.\n\nThe main problems with concurrency is correctness. Given multiple concurrent tasks that access to the same underlying resources, how to ensure a correct and consistent execution. To achieve this, the OS gives privimites. \n\n\n## Persistent\nFinally, persistent deals with how to reliably store and retrieve data in a persistent storage (e.g., disk). This is provided by the *file system*.\n\nThe main problems is how manage information on the disk efficiently, and how deal with failures.\n\n# See also\n- [[7t4jlnaq]]","snippets":["#os"],"rawContent":"# Three pieces of an Operating System\n#os\n\nThere are three main concept in achieving an operating system: *virtualization*, *concurrency* and  *persistent* [@arpaci-dusseauoperating].\n\n## Virtualization\nVirtualization give an process an illusion of having access to the whole underlying resource. To do so, the OS take physical resources and transform them into virtual resources, and hand them out to the users.\n\nThis is the key in maximizing resource usage, since a single job rarely utilize all of the available hardware resource. Virtualization also make the system easier to use. \n\nThe key problem with virtualization is how to do it efficiently, how to attain fairness, and what hardware support is needed.\n\n## Concurrency\nConcurrency allows multiple jobs to execute at once. This is especially important in maximizing CPU efficiency: when waiting for slow I/O jobs, the CPU time is better used executing other tasks.\nIn a sense, concurrency is achieved by virtualizing CPU time?\n\nIn the OS, there is two granularity of concurrency, threads and processes.\n\nThe main problems with concurrency is correctness. Given multiple concurrent tasks that access to the same underlying resources, how to ensure a correct and consistent execution. To achieve this, the OS gives privimites. \n\n\n## Persistent\nFinally, persistent deals with how to reliably store and retrieve data in a persistent storage (e.g., disk). This is provided by the *file system*.\n\nThe main problems is how manage information on the disk efficiently, and how deal with failures.\n\n# See also\n- [[7t4jlnaq]]\n\n\n\n","wordCount":244,"tags":["os"],"metadata":{},"created":"2023-08-09T13:49:43.469420792Z","modified":"2023-08-09T13:49:43.469463417Z","checksum":"d547fee0d1c262856348c3a48580e733965359f20312bf824f49ae5b5d3ed3d8"},
    {"filename":"cosmdjej.md","filenameStem":"cosmdjej","path":"cosmdjej.md","absPath":"/Users/khadd/mynotes/cosmdjej.md","title":"Transactional memory","link":"[[cosmdjej]]","lead":"#conccurency","body":"#conccurency\n\n\nTransactional memory is a technique that simplify concurrent programming by allowing critical sections to execute *optimistically* (i.e., [optimistic concurrency control](https://en.wikipedia.org/wiki/Optimistic_concurrency_control)).\n\n\nA transaction consists of series of intermediate *atomic* read and writes to some memory location. A transaction can be *commited*, as long as there is no conflicts.\nOn the otherhand, if there is any conflict during a transaction, the it is rolled back, and an error handler is invoked (e.g., to retry the transaction).\n\n\nA section of critical code marked as transactional can execute with minimal interventions (e.g., acquiring lock). This leads to a much simpler programming model, and also less error-prone (e.g., deadlocks), since the validity of transactions is guaranteed by tranactional memory mechanisms.","snippets":["#conccurency"],"rawContent":"# Transactional memory\n#conccurency\n\n\nTransactional memory is a technique that simplify concurrent programming by allowing critical sections to execute *optimistically* (i.e., [optimistic concurrency control](https://en.wikipedia.org/wiki/Optimistic_concurrency_control)).\n\n\nA transaction consists of series of intermediate *atomic* read and writes to some memory location. A transaction can be *commited*, as long as there is no conflicts.\nOn the otherhand, if there is any conflict during a transaction, the it is rolled back, and an error handler is invoked (e.g., to retry the transaction).\n\n\nA section of critical code marked as transactional can execute with minimal interventions (e.g., acquiring lock). This leads to a much simpler programming model, and also less error-prone (e.g., deadlocks), since the validity of transactions is guaranteed by tranactional memory mechanisms.\n","wordCount":119,"tags":["conccurency"],"metadata":{},"created":"2023-08-09T13:49:43.46200581Z","modified":"2023-08-09T13:49:43.462057768Z","checksum":"6b45a4d7969d52b49762cacccc1a118156b86d78f4a0c5f2d6de91478741ef7c"},
    {"filename":"cv3peid6.md","filenameStem":"cv3peid6","path":"cv3peid6.md","absPath":"/Users/khadd/mynotes/cv3peid6.md","title":"Turning reading notes to permanent notes","link":"[[cv3peid6]]","lead":"#note-taking #zettelkasten","body":"#note-taking #zettelkasten\n\n\n# Steps\n\n## While reading\nIt is useful to keep a physical notes.\n\n## After reading\n[create-zettel-from-reading-notes] suggested using three phases:\n- Pull all the notes out. The order do not matter.\n- Cluster the notes. What are the big ideas that emerges?\n- Write notes about the clusters that emerges.\n\n# References\n[create-zettel-from-reading-notes](https://zettelkasten.de/posts/create-zettel-from-reading-notes/)\n\n[How to process reading annotations into evergreen notes](https://notes.andymatuschak.org/z2PJ51tCXuPFxnfFVUxxgwjvZ1geu4YnYm7hK)\n\u003e\n1. Write a broad note which captures the “big idea” of one of your clusters.\n  - Are there multiple big ideas? Write multiple broad notes to maintain Evergreen notes should be atomic.\n2. Write finer-grained notes: Look through the individual scraps in that cluster. Write notes which capture more nuanced atomic ideas within that cluster.\n3. Connect: Search for relevant past notes which relate to these new notes. Link, merge, and revise as necessary to represent your new, synthesized conception of those ideas.\n  - See Evergreen notes should be densely linked and Create speculative outlines while you write.\n4. Revise: Return to the broad note and improve your summary based on what you’ve learned writing the detailed notes and the details you’ve unpacked, if it’s possible to do so without muddying their focus. Remove detailed notes that are no longer necessary; update others based on what you learned writing your updated broad note if appropriate.\n5. Loop","snippets":["#note-taking #zettelkasten"],"rawContent":"# Turning reading notes to permanent notes\n#note-taking #zettelkasten\n\n\n# Steps\n\n## While reading\nIt is useful to keep a physical notes.\n\n## After reading\n[create-zettel-from-reading-notes] suggested using three phases:\n- Pull all the notes out. The order do not matter.\n- Cluster the notes. What are the big ideas that emerges?\n- Write notes about the clusters that emerges.\n\n# References\n[create-zettel-from-reading-notes](https://zettelkasten.de/posts/create-zettel-from-reading-notes/)\n\n[How to process reading annotations into evergreen notes](https://notes.andymatuschak.org/z2PJ51tCXuPFxnfFVUxxgwjvZ1geu4YnYm7hK)\n\u003e\n1. Write a broad note which captures the “big idea” of one of your clusters.\n  - Are there multiple big ideas? Write multiple broad notes to maintain Evergreen notes should be atomic.\n2. Write finer-grained notes: Look through the individual scraps in that cluster. Write notes which capture more nuanced atomic ideas within that cluster.\n3. Connect: Search for relevant past notes which relate to these new notes. Link, merge, and revise as necessary to represent your new, synthesized conception of those ideas.\n  - See Evergreen notes should be densely linked and Create speculative outlines while you write.\n4. Revise: Return to the broad note and improve your summary based on what you’ve learned writing the detailed notes and the details you’ve unpacked, if it’s possible to do so without muddying their focus. Remove detailed notes that are no longer necessary; update others based on what you learned writing your updated broad note if appropriate.\n5. Loop\n\n\n","wordCount":229,"tags":["note-taking","zettelkasten"],"metadata":{},"created":"2023-08-09T13:49:43.46208881Z","modified":"2023-08-09T13:49:43.462145852Z","checksum":"697bbcc7e2d2a2efd3f08ab145bdf697116270f2a507e420abbb1fbb42d012b6"},
    {"filename":"k57qb7oh.md","filenameStem":"k57qb7oh","path":"k57qb7oh.md","absPath":"/Users/khadd/mynotes/k57qb7oh.md","title":"Ubuntu notes","link":"[[k57qb7oh]]","lead":"#linux #distro","body":"#linux #distro\n\n\n# Package manager\n## Maintaining apt mirror\n\nIt is unecessary to manually rewrite `/etc/apt/source.list` with the fastest one. Apt supports selecting from a list of mirrors. Just put this to the top of `/etc/apt/source.list`:\n```bash\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-updates main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-backports main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-security main restricted universe multiverse\n```","snippets":["#linux #distro"],"rawContent":"# Ubuntu notes\n#linux #distro\n\n\n# Package manager\n## Maintaining apt mirror\n\nIt is unecessary to manually rewrite `/etc/apt/source.list` with the fastest one. Apt supports selecting from a list of mirrors. Just put this to the top of `/etc/apt/source.list`:\n```bash\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-updates main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-backports main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-security main restricted universe multiverse\n```\n\n\n","wordCount":69,"tags":["linux","distro"],"metadata":{},"created":"2023-08-09T13:49:43.46936275Z","modified":"2023-08-09T13:49:43.469398209Z","checksum":"f4fc4626b56ad0e2779ce3478f78b432d4f325ae6126ddd6a246f0b4f84d9592"},
    {"filename":"e7p8xpz4.md","filenameStem":"e7p8xpz4","path":"e7p8xpz4.md","absPath":"/Users/khadd/mynotes/e7p8xpz4.md","title":"Unikernel Security","link":"[[e7p8xpz4]]","lead":"#unikernel #os #security #hardening","body":"#unikernel #os #security #hardening\n\n# The plus\nOverall, unikernels enables extreme attack surface reduction due to being specialized. Especially, attack surfaces are reduced in three aspect:\n- First, there is no shell implemented in unikernels, making attacks that aims to launch a shell infeasible.\n- Second, unikernels do not implement system calls, which can be an entry point for attacks. Hence, attackers are forced to use control-flow hijacking-based attacks to jump to unikernel functions,which can be mitigated through ASLR/CFI.  \n- Third, since the hardware are interfaces not emulated, attack against emulated hardware interface (the Venom attack (TODO)) is mitigated. \n- Forth, their infrastructures is *immutable*, to rebuild the unikernel app, the entire infrastructure (OS, application, libraries) need to be rebuilt. This avoid illegal modification, vulnerabilities from out-dated configurations.\n\n# The negative\nThe negatives (in security) of unikernels comes from two aspect: due to hardware virtualization, and due to lack of ring separation.\n- Because hardware is virtualized, entrophy suffers. Due to hardware being virtualized, random number generator based on hardware events lacks entropy. This leads to attacks on random number generator.\n- Second, due to the lack of ring separation, arbitrary execution attacks on application code enable access to kernel space, making privilege escalation unnecessary.\n- Moreover, many security features that are commonly deployed are missing on unikernels (maybe due to it being hard to maintain for both applications and kernel code). Examples are ASLR, __FORTIFY_SOURCE\n\n# References\n- @hindy2020security provides an overview of security of unikernels.","snippets":["#unikernel #os #security #hardening"],"rawContent":"# Unikernel Security\n#unikernel #os #security #hardening\n\n# The plus\nOverall, unikernels enables extreme attack surface reduction due to being specialized. Especially, attack surfaces are reduced in three aspect:\n- First, there is no shell implemented in unikernels, making attacks that aims to launch a shell infeasible.\n- Second, unikernels do not implement system calls, which can be an entry point for attacks. Hence, attackers are forced to use control-flow hijacking-based attacks to jump to unikernel functions,which can be mitigated through ASLR/CFI.  \n- Third, since the hardware are interfaces not emulated, attack against emulated hardware interface (the Venom attack (TODO)) is mitigated. \n- Forth, their infrastructures is *immutable*, to rebuild the unikernel app, the entire infrastructure (OS, application, libraries) need to be rebuilt. This avoid illegal modification, vulnerabilities from out-dated configurations.\n\n# The negative\nThe negatives (in security) of unikernels comes from two aspect: due to hardware virtualization, and due to lack of ring separation.\n- Because hardware is virtualized, entrophy suffers. Due to hardware being virtualized, random number generator based on hardware events lacks entropy. This leads to attacks on random number generator.\n- Second, due to the lack of ring separation, arbitrary execution attacks on application code enable access to kernel space, making privilege escalation unnecessary.\n- Moreover, many security features that are commonly deployed are missing on unikernels (maybe due to it being hard to maintain for both applications and kernel code). Examples are ASLR, __FORTIFY_SOURCE\n\n# References\n- @hindy2020security provides an overview of security of unikernels.\n","wordCount":250,"tags":["os","unikernel","security","hardening"],"metadata":{},"created":"2023-08-09T13:49:43.463364064Z","modified":"2023-08-09T13:49:43.463410648Z","checksum":"08f7aaf461dcf083ce967ebe97a84290974a8b2032ee7fede4a1a8e1d52c9a73"},
    {"filename":"fcf5pozg.md","filenameStem":"fcf5pozg","path":"fcf5pozg.md","absPath":"/Users/khadd/mynotes/fcf5pozg.md","title":"Unikraft development notes","link":"[[fcf5pozg]]","lead":"#unikraft #unikernel","body":"#unikraft #unikernel\n\n# Development environment\nThe kraft tutorials are completely broken (at this moment).\n\nTo set up a functional development, first create a directory structure like this. \n```\n- root\n  - unikraft // The unikraft repo\n  - apps // external application\n    - helloworld\n    - ...\n  - libs // external libraries\n    - lib_test  \n    - ... \n```\n`unikraft` is cloned from the main repo, and apps can be any applications. There must be an application for testing the unikernel. \nThe helloworld application is a good starting point for testing. \n\n```bash\ngit clone https://github.com/unikraft/unikraft.git\ncd apps\ngit clone https://github.com/unikraft/app-helloworld.git\n```\n# Building applications\nFirst, the application needs to be configured. Use \n```\nmake menuconfig\n```\nand walk through the configuration.\n\nAfter the kernel is configured, just run to build.\n```\nmake\n```\n\n\n## Running\n``` bash\nqemu-system-x86_64 -enable-kvm -nographic -cpu host -kernel build/helloworld_qemu-x86_64\n\n```\n# Coding convention\n## Variable definition\nUse `const` for constant variable.\n\n## Addresses\nPhysical addresses has the type `__paddr_t`. There is also `__vaddr_t`\n\n## Function definition\n`static inline` is used for short functions.\n\n\n## struct definition\nstructs are sometimes defined in C files, or header files.\n\n`typedef struct` is not used.\n\n## Private states\nModules contains a pointer to their private states. \n```c\nstatic struct uk_vas *vmem_active_vas;\n```\n\n# Debugging\nrun qemu with the flags `-S -s` on the non-debugging image.\n\nSoftware breakpoints does not work, so hardware breakpoints need to be used with `hbreak`.\n\n## Debugging test case\nTest case name will be concactenated like this: `_uk_testsuite_ukvmem_case_test_basic_vas_layout`\n\n## Printing raw bytes\n`uk_hexdumpk` dumps the content of some region to printk. \n\n# Other notes\n- [[7gbms9if]]\n- [[xpolyx1l]]\n- [[1k9i1cr3]]\n- [[projects/gel6dwih]]","snippets":["#unikraft #unikernel"],"rawContent":"# Unikraft development notes\n#unikraft #unikernel\n\n# Development environment\nThe kraft tutorials are completely broken (at this moment).\n\nTo set up a functional development, first create a directory structure like this. \n```\n- root\n  - unikraft // The unikraft repo\n  - apps // external application\n    - helloworld\n    - ...\n  - libs // external libraries\n    - lib_test  \n    - ... \n```\n`unikraft` is cloned from the main repo, and apps can be any applications. There must be an application for testing the unikernel. \nThe helloworld application is a good starting point for testing. \n\n```bash\ngit clone https://github.com/unikraft/unikraft.git\ncd apps\ngit clone https://github.com/unikraft/app-helloworld.git\n```\n# Building applications\nFirst, the application needs to be configured. Use \n```\nmake menuconfig\n```\nand walk through the configuration.\n\nAfter the kernel is configured, just run to build.\n```\nmake\n```\n\n\n## Running\n``` bash\nqemu-system-x86_64 -enable-kvm -nographic -cpu host -kernel build/helloworld_qemu-x86_64\n\n```\n# Coding convention\n## Variable definition\nUse `const` for constant variable.\n\n## Addresses\nPhysical addresses has the type `__paddr_t`. There is also `__vaddr_t`\n\n## Function definition\n`static inline` is used for short functions.\n\n\n## struct definition\nstructs are sometimes defined in C files, or header files.\n\n`typedef struct` is not used.\n\n## Private states\nModules contains a pointer to their private states. \n```c\nstatic struct uk_vas *vmem_active_vas;\n```\n\n# Debugging\nrun qemu with the flags `-S -s` on the non-debugging image.\n\nSoftware breakpoints does not work, so hardware breakpoints need to be used with `hbreak`.\n\n## Debugging test case\nTest case name will be concactenated like this: `_uk_testsuite_ukvmem_case_test_basic_vas_layout`\n\n## Printing raw bytes\n`uk_hexdumpk` dumps the content of some region to printk. \n\n# Other notes\n- [[7gbms9if]]\n- [[xpolyx1l]]\n- [[1k9i1cr3]]\n- [[projects/gel6dwih]]\n","wordCount":277,"tags":["unikraft","unikernel"],"metadata":{},"created":"2023-08-09T13:49:43.463564231Z","modified":"2023-08-09T13:49:43.463612815Z","checksum":"c4e66faa57f63ee2847288232b7c914e27df2715323aed97ef41cc7f8aa2968a"},
    {"filename":"7gbms9if.md","filenameStem":"7gbms9if","path":"7gbms9if.md","absPath":"/Users/khadd/mynotes/7gbms9if.md","title":"Unikraft's heap allocator","link":"[[7gbms9if]]","lead":"#unikraft","body":"#unikraft\n\n# Choice of allocator\nThe original paper says that Unikraft supports up to 5 allocator backends: buddy, TLFS, real-time, tinyalloc, mimalloc and Oscar\n\n@lupu2023nephele says tiny has the best performance among all\n\n# ukalloc\nUnikraft enables swapping of different allocator backends through the `ukalloc` interface. `ukalloc` keeps a linked-list pointers to `struct uk_alloc* _uk_alloc_head`, that points to the currently registered allocator.\n\n\n## Registration\nNew allocators must implement the interface\nAllocators are registered with `uk_alloc_register`, which assign `_uk_alloc_head` to the new allocator.\n\n\nIn `boot.c`, the allocators are hard-coded as:\n```c\n#if CONFIG_LIBUKBOOT_INITBBUDDY\n#include \u003cuk/allocbbuddy.h\u003e\n#define uk_alloc_init uk_allocbbuddy_init\n#elif CONFIG_LIBUKBOOT_INITREGION\n#include \u003cuk/allocregion.h\u003e\n#define uk_alloc_init uk_allocregion_init\n#elif CONFIG_LIBUKBOOT_INITMIMALLOC\n#include \u003cuk/mimalloc.h\u003e\n#define uk_alloc_init uk_mimalloc_init\n#elif CONFIG_LIBUKBOOT_INITTLSF\n#include \u003cuk/tlsf.h\u003e\n#define uk_alloc_init uk_tlsf_init\n#elif CONFIG_LIBUKBOOT_INITTINYALLOC\n#include \u003cuk/tinyalloc.h\u003e\n#define uk_alloc_init uk_tinyalloc_init\n#endif\n```\nHence, any allocator that are selected will be set as the heap allocator.\n\nThe `heap_init()` function takes the remaining memory (starting from `CONFIG_LIBUKBOOT_HEAP_BASE`), map them as anonymous pages, and adds them to the memory pool of the allocator.\n```c\n```\n\n\nFinally, `ukplat_memallocator_set()` set the current memory allocator\n\n## POSIX malloc\n`malloc` definition in `stdlib.h`:\n\n```c\nstatic inline void malloc(size_t size){\n  return uk_malloc(uk_alloc_get_default(), size);\n}\n```\nWhere `uk_alloc_get_default()` returns `_uk_alloc_head`.","snippets":["#unikraft"],"rawContent":"# Unikraft's heap allocator\n#unikraft\n\n# Choice of allocator\nThe original paper says that Unikraft supports up to 5 allocator backends: buddy, TLFS, real-time, tinyalloc, mimalloc and Oscar\n\n@lupu2023nephele says tiny has the best performance among all\n\n# ukalloc\nUnikraft enables swapping of different allocator backends through the `ukalloc` interface. `ukalloc` keeps a linked-list pointers to `struct uk_alloc* _uk_alloc_head`, that points to the currently registered allocator.\n\n\n## Registration\nNew allocators must implement the interface\nAllocators are registered with `uk_alloc_register`, which assign `_uk_alloc_head` to the new allocator.\n\n\nIn `boot.c`, the allocators are hard-coded as:\n```c\n#if CONFIG_LIBUKBOOT_INITBBUDDY\n#include \u003cuk/allocbbuddy.h\u003e\n#define uk_alloc_init uk_allocbbuddy_init\n#elif CONFIG_LIBUKBOOT_INITREGION\n#include \u003cuk/allocregion.h\u003e\n#define uk_alloc_init uk_allocregion_init\n#elif CONFIG_LIBUKBOOT_INITMIMALLOC\n#include \u003cuk/mimalloc.h\u003e\n#define uk_alloc_init uk_mimalloc_init\n#elif CONFIG_LIBUKBOOT_INITTLSF\n#include \u003cuk/tlsf.h\u003e\n#define uk_alloc_init uk_tlsf_init\n#elif CONFIG_LIBUKBOOT_INITTINYALLOC\n#include \u003cuk/tinyalloc.h\u003e\n#define uk_alloc_init uk_tinyalloc_init\n#endif\n```\nHence, any allocator that are selected will be set as the heap allocator.\n\nThe `heap_init()` function takes the remaining memory (starting from `CONFIG_LIBUKBOOT_HEAP_BASE`), map them as anonymous pages, and adds them to the memory pool of the allocator.\n```c\n```\n\n\nFinally, `ukplat_memallocator_set()` set the current memory allocator\n\n## POSIX malloc\n`malloc` definition in `stdlib.h`:\n\n```c\nstatic inline void malloc(size_t size){\n  return uk_malloc(uk_alloc_get_default(), size);\n}\n```\nWhere `uk_alloc_get_default()` returns `_uk_alloc_head`.\n\n\n","wordCount":200,"tags":["unikraft"],"metadata":{},"created":"2023-08-09T13:49:43.460638347Z","modified":"2023-08-09T13:49:43.460687847Z","checksum":"d1d4cc2ea29e61b8b349637b95abd9113cfbc852a0372a2c872eb49add41a1b5"},
    {"filename":"eqbigndi.md","filenameStem":"eqbigndi","path":"eqbigndi.md","absPath":"/Users/khadd/mynotes/eqbigndi.md","title":"Virtual Memory","link":"[[eqbigndi]]","lead":"#os #virtualization","body":"#os #virtualization\n\n\n\nVirtual memory eases the programming efforts.\n- First, it virtualizes and abstracts physical memory such that a single physical space can be shared among different processes.\n- Second, its facilitates communication between cores (shared memory mapping), and CPU-device communication (through DMA/MMIO).\n- Third, it enables memory access control between processes (each process use a different page table set up by the OS), and within a single process (RWX permissions).\n\n\n# Caveats\n## Address translation overheads\nAddress address translation creates significant overheads @yan20219translation. First, the OS needs to handle page faults in the software. Second, the CPU's MMU needs to walk the page table, which requires multiple memory accesses.\n\nModern architectures cope with this overhead by increasing the TLB size.\n\nChanges in hardware are proposed to address translation overheads.\n\nOne of the reasons for virtual memory is to couple access control with resource management. CARAT @suchy2022carat proposed using compiler-inserted checks to replace the MMU-provided access control.","snippets":["#os #virtualization"],"rawContent":"# Virtual Memory\n#os #virtualization\n\n\n\nVirtual memory eases the programming efforts.\n- First, it virtualizes and abstracts physical memory such that a single physical space can be shared among different processes.\n- Second, its facilitates communication between cores (shared memory mapping), and CPU-device communication (through DMA/MMIO).\n- Third, it enables memory access control between processes (each process use a different page table set up by the OS), and within a single process (RWX permissions).\n\n\n# Caveats\n## Address translation overheads\nAddress address translation creates significant overheads @yan20219translation. First, the OS needs to handle page faults in the software. Second, the CPU's MMU needs to walk the page table, which requires multiple memory accesses.\n\nModern architectures cope with this overhead by increasing the TLB size.\n\nChanges in hardware are proposed to address translation overheads.\n\nOne of the reasons for virtual memory is to couple access control with resource management. CARAT @suchy2022carat proposed using compiler-inserted checks to replace the MMU-provided access control.\n\n\n","wordCount":160,"tags":["os","virtualization"],"metadata":{},"created":"2023-08-09T13:49:43.463434148Z","modified":"2023-08-09T13:49:43.463479565Z","checksum":"671a699082178a379c5265e243204a4ae2affff2cffcfdb9002b330728027c4b"},
    {"filename":"s16ct1rj.md","filenameStem":"s16ct1rj","path":"s16ct1rj.md","absPath":"/Users/khadd/mynotes/s16ct1rj.md","title":"Virtualization","link":"[[s16ct1rj]]","lead":"#os #virtualization","body":"#os #virtualization\n\nVirtualization gives a subject (process, virtual machine) the illusion of having access to physical resource (memory, CPU time). \n\nVirtualization is obtained through two properties, *interposition* and *transparency*\n\n## Interposition\nInterposition (aka, trap-and-emulate) let the reference monitor (OS/Hypervisor) interject the control upon a certain action of the virtualized subject. This enable it to serve virtualized resources on-demand.\n\nFor instance, page faults allows the OS to interpose virtual to physical translation, and add missing page mapping on-demand.\n\nOn the other hand, the hypervisor can interpose hardware interrupts, page faults, VM enter and exit, and handle them in software (handling them in the actual hardware would affect the entire system). This give the illusion to virtual machine have actual access to those hardware resources. See [[d3nt6uix]].\n\nInterposition is achieved commonly through three means. \n- Binary translation interprete every executed instruction and interpose on the sensitive instructions (used in QEMU).\n- Para-virtualization requires patching the guest OS to delegate a certain action to the hypervisor.\n- Interposition through hardware events forward the interrupts from the VM to the hypervisor.\n\n## Transparency\nVirtualization enable transparency. The virtualized subject do not have knowledge it being virtualized (except for the paravirtualization case).","snippets":["#os #virtualization"],"rawContent":"# Virtualization\n#os #virtualization\n\nVirtualization gives a subject (process, virtual machine) the illusion of having access to physical resource (memory, CPU time). \n\nVirtualization is obtained through two properties, *interposition* and *transparency*\n\n## Interposition\nInterposition (aka, trap-and-emulate) let the reference monitor (OS/Hypervisor) interject the control upon a certain action of the virtualized subject. This enable it to serve virtualized resources on-demand.\n\nFor instance, page faults allows the OS to interpose virtual to physical translation, and add missing page mapping on-demand.\n\nOn the other hand, the hypervisor can interpose hardware interrupts, page faults, VM enter and exit, and handle them in software (handling them in the actual hardware would affect the entire system). This give the illusion to virtual machine have actual access to those hardware resources. See [[d3nt6uix]].\n\nInterposition is achieved commonly through three means. \n- Binary translation interprete every executed instruction and interpose on the sensitive instructions (used in QEMU).\n- Para-virtualization requires patching the guest OS to delegate a certain action to the hypervisor.\n- Interposition through hardware events forward the interrupts from the VM to the hypervisor.\n\n## Transparency\nVirtualization enable transparency. The virtualized subject do not have knowledge it being virtualized (except for the paravirtualization case).  \n\n\n","wordCount":199,"tags":["os","virtualization"],"metadata":{},"created":"2023-08-09T13:49:43.474743309Z","modified":"2023-08-09T13:49:43.474786893Z","checksum":"32a6854ccd137cae52ad9cee1686f11bfc87cf277b0de7597c81efec9d490729"},
    {"filename":"9sbjh4gy.md","filenameStem":"9sbjh4gy","path":"9sbjh4gy.md","absPath":"/Users/khadd/mynotes/9sbjh4gy.md","title":"Von Neumann Architecture","link":"[[9sbjh4gy]]","lead":"The von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device.","body":"The von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device.\n\nAt each cycle, the CPU fetch an instruction from memory, then execute it. The instruction may perform data read/write from memory, perform operations, or write to input/output devices.\n\nVon Neumann architecture has a bottleneck where instruction fetch and data operations cannot be performed in one cycle due to them using the same bus. Computer caches with separated icache and dcache mitigates this. There are also non-von Neumann architectures that significantly departure from the von Neumann model (to overcome this bottleneck?).","snippets":["The von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device."],"rawContent":"# Von Neumann Architecture\n\nThe von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device.\n\nAt each cycle, the CPU fetch an instruction from memory, then execute it. The instruction may perform data read/write from memory, perform operations, or write to input/output devices.\n\nVon Neumann architecture has a bottleneck where instruction fetch and data operations cannot be performed in one cycle due to them using the same bus. Computer caches with separated icache and dcache mitigates this. There are also non-von Neumann architectures that significantly departure from the von Neumann model (to overcome this bottleneck?).\n\n","wordCount":164,"tags":[],"metadata":{},"created":"2023-08-09T13:49:43.460988265Z","modified":"2023-08-09T13:49:43.461031557Z","checksum":"f0ef069f4eb9e6dbc715b9ca6672f6afb1a51ab59c9647d97f3875cb1da99693"},
    {"filename":"ae6fatms.md","filenameStem":"ae6fatms","path":"ae6fatms.md","absPath":"/Users/khadd/mynotes/ae6fatms.md","title":"Zettelkasten","link":"[[ae6fatms]]","lead":"#zettelkasten","body":"#zettelkasten","snippets":["#zettelkasten"],"rawContent":"# Zettelkasten\n#zettelkasten\n\n\n\n\n\n\n\n","wordCount":3,"tags":["zettelkasten"],"metadata":{},"created":"2023-08-09T13:49:43.461351474Z","modified":"2023-08-09T13:49:43.461384433Z","checksum":"731a00ca978ead7e13e2b7996d66ed08e6a616e2cf724df44858e7018d3c0069"},
    {"filename":"hog0h5z8.md","filenameStem":"hog0h5z8","path":"hog0h5z8.md","absPath":"/Users/khadd/mynotes/hog0h5z8.md","title":"sel4 Resources","link":"[[hog0h5z8]]","lead":"#sel4 #os #capabilities","body":"#sel4 #os #capabilities\n\n- [L4 microkernels: The lessons from 20 years of research and deployment](https://trustworthy.systems/publications/nictaabstracts/Heiser_Elphinstone_16.abstract): A summary of seL4 in the context of previous research such as EROS, KeykOS.\n- [seL4 Overview and Tutorial](http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf): tutorial slides","snippets":["#sel4 #os #capabilities"],"rawContent":"# sel4 Resources\n#sel4 #os #capabilities\n\n- [L4 microkernels: The lessons from 20 years of research and deployment](https://trustworthy.systems/publications/nictaabstracts/Heiser_Elphinstone_16.abstract): A summary of seL4 in the context of previous research such as EROS, KeykOS.\n- [seL4 Overview and Tutorial](http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf): tutorial slides\n\n","wordCount":39,"tags":["os","capabilities","sel4"],"metadata":{},"created":"2023-08-09T13:49:43.468399039Z","modified":"2023-08-09T13:49:43.468456289Z","checksum":"f34bc12d5fac842170f578aced5310a89266a99f4fc7d2527fdbfc7c7b47f0aa"},
    {"filename":"o53nse4p.md","filenameStem":"o53nse4p","path":"literature/o53nse4p.md","absPath":"/Users/khadd/mynotes/literature/o53nse4p.md","title":"vSGX: Virtualizing SGX Enclaves on AMD SEV","link":"[[literature/o53nse4p]]","lead":"#literature #sgx #tee #sev #virtualization","body":"#literature #sgx #tee #sev #virtualization\n\n\n\n\n# Main arguments \n## Benefits of virtualizing SGX on AMD\n- Binary compatiblity: unmodified applications be ran on AMD SEV machines, while having comparable security guarantees.\n- Finer-grain trust:  SGX model only places the trust in the small userspace enclave, and does not trust the OS and the untrusted part of the process. In ths paper, they *trust the OS in the VM that run the enclave (EVM)*, but do not trust the untrusted part of the enclave program.\n\n## SGX can be virtualized on AMD SEV","snippets":["#literature #sgx #tee #sev #virtualization"],"rawContent":"# vSGX: Virtualizing SGX Enclaves on AMD SEV \n#literature #sgx #tee #sev #virtualization\n\n\n\n\n# Main arguments \n## Benefits of virtualizing SGX on AMD\n- Binary compatiblity: unmodified applications be ran on AMD SEV machines, while having comparable security guarantees.\n- Finer-grain trust:  SGX model only places the trust in the small userspace enclave, and does not trust the OS and the untrusted part of the process. In ths paper, they *trust the OS in the VM that run the enclave (EVM)*, but do not trust the untrusted part of the enclave program.\n\n## SGX can be virtualized on AMD SEV\n","wordCount":100,"tags":["tee","sgx","sev","virtualization","literature"],"metadata":{},"created":"2023-08-09T13:49:43.470345212Z","modified":"2023-08-09T13:49:43.470384712Z","checksum":"08775c58c9139dae19c71506982746829a9e3028db5dc47a5a86e81bb1a7511d"},
    {"filename":"d22taxo6.md","filenameStem":"d22taxo6","path":"d22taxo6.md","absPath":"/Users/khadd/mynotes/d22taxo6.md","title":"x86 prefixes","link":"[[d22taxo6]]","lead":"#instruction-encoding #intel","body":"#instruction-encoding #intel\n\n\n\n\nPrefixes  are divided into 4 groups\n\n| Prefix                 | Group |\n|------------------------|-------|\n| F0, F2, F3             | Grp 1 |\n| 2E, 36, 3E, 26, 64, 67 | Grp 2 |\n| 66                     | Grp 3 |\n| 67                     | Grp 4 |\n\n\n\n```\nprefix\n▲  ┌► two-byte opcode prefix\n│  │  ┌─────────────►(Move Unaligned Packed Single-Precision Floating-Point Values)\n│  │  │\n│  │  │\n-- 0f 10             MOVUPS \txmm \txmm/m128\n\nGrp 3                (Move Unaligned Packed Double-Precision Floating-Point Values)\n▲\n│\n66 0f 11             MOVUPD   xmm   xmm/m128\n\nGrp 1 with REPNE/REPNZ encoded                (Move Unaligned Packed Single-Precision Floating-Point Values)\n▲\n│\nF2 0f 11                                      MOVSD    xmm   xmm/m64\n\nGrp 1 REPE/REPZ encoded                       (Move or Merge Scalar Single-Precision Floating-Point Value)\n▲\n│\nF3 0f 11                                      MOVSS    xmm   xmm/m32\n\n```","snippets":["#instruction-encoding #intel"],"rawContent":"# x86 prefixes\n#instruction-encoding #intel\n\n\n\n\nPrefixes  are divided into 4 groups\n\n| Prefix                 | Group |\n|------------------------|-------|\n| F0, F2, F3             | Grp 1 |\n| 2E, 36, 3E, 26, 64, 67 | Grp 2 |\n| 66                     | Grp 3 |\n| 67                     | Grp 4 |\n\n\n\n```\nprefix\n▲  ┌► two-byte opcode prefix\n│  │  ┌─────────────►(Move Unaligned Packed Single-Precision Floating-Point Values)\n│  │  │\n│  │  │\n-- 0f 10             MOVUPS \txmm \txmm/m128\n\nGrp 3                (Move Unaligned Packed Double-Precision Floating-Point Values)\n▲\n│\n66 0f 11             MOVUPD   xmm   xmm/m128\n\nGrp 1 with REPNE/REPNZ encoded                (Move Unaligned Packed Single-Precision Floating-Point Values)\n▲\n│\nF2 0f 11                                      MOVSD    xmm   xmm/m64\n\nGrp 1 REPE/REPZ encoded                       (Move or Merge Scalar Single-Precision Floating-Point Value)\n▲\n│\nF3 0f 11                                      MOVSS    xmm   xmm/m32\n\n```\n\n\n","wordCount":130,"tags":["instruction-encoding","intel"],"metadata":{},"created":"2023-08-09T13:49:43.46217756Z","modified":"2023-08-09T13:49:43.462228102Z","checksum":"7c24b41b7556c95f781ffbcde34e1d3d8140105f5c36356eb38641ad3f7e1856"}
  ],
  "links": [
    {"title":"fleeting/douswvq0","href":"fleeting/douswvq0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[fleeting/douswvq0]]","snippetStart":30,"snippetEnd":51,"sourceId":6,"sourcePath":"2dw6pwrd.md","targetId":55,"targetPath":"fleeting/douswvq0.md"},
    {"title":"013pr50f","href":"013pr50f","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Purity (e.g., always returns same value for the same input, have no side effect) (possibly related to [[013pr50f]])","snippetStart":1719,"snippetEnd":1834,"sourceId":7,"sourcePath":"2hnk4l00.md","targetId":1,"targetPath":"013pr50f.md"},
    {"title":"zzq5zy5v","href":"zzq5zy5v","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[zzq5zy5v]]","snippetStart":3343,"snippetEnd":3355,"sourceId":7,"sourcePath":"2hnk4l00.md","targetId":115,"targetPath":"zzq5zy5v.md"},
    {"title":"literature/jfm8ud28","href":"literature/jfm8ud28","type":"wiki-link","isExternal":false,"rels":[],"snippet":"@boos2020theseus (see [[literature/jfm8ud28]]): An operating system that aim to minimize state spill.","snippetStart":1617,"snippetEnd":1718,"sourceId":8,"sourcePath":"2j6s9zpm.md","targetId":79,"targetPath":"literature/jfm8ud28.md"},
    {"title":"qti6u06p","href":"qti6u06p","type":"wiki-link","isExternal":false,"rels":[],"snippet":"As a final note, removing state spill forces the caller to memory to allocate the context used for cross-compartment interaction. In a sense, it also improves the security of the per-compartment interface. See 1 and 4 in [[qti6u06p]].","snippetStart":1270,"snippetEnd":1504,"sourceId":8,"sourcePath":"2j6s9zpm.md","targetId":104,"targetPath":"qti6u06p.md"},
    {"title":"dx7vz8d5","href":"dx7vz8d5","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Most of these defenses uses  Intel TSX [[dx7vz8d5]], due to its ability to supress page faults. \nFor more details, see [[fvom56lw]].","snippetStart":793,"snippetEnd":925,"sourceId":11,"sourcePath":"5kzr3hwx.md","targetId":47,"targetPath":"dx7vz8d5.md"},
    {"title":"fvom56lw","href":"fvom56lw","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Most of these defenses uses  Intel TSX [[dx7vz8d5]], due to its ability to supress page faults. \nFor more details, see [[fvom56lw]].","snippetStart":793,"snippetEnd":925,"sourceId":11,"sourcePath":"5kzr3hwx.md","targetId":56,"targetPath":"fvom56lw.md"},
    {"title":"n9bxzpge","href":"n9bxzpge","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The first line of defense is obfuscated execution ([[n9bxzpge]]), which guarantees that code and data accesses of a program looks the same, given a sensitive input.\nThey usually have high overheads and are considered impractical.","snippetStart":306,"snippetEnd":535,"sourceId":11,"sourcePath":"5kzr3hwx.md","targetId":92,"targetPath":"n9bxzpge.md"},
    {"title":"k60yjf6q","href":"k60yjf6q","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[k60yjf6q]]","snippetStart":1209,"snippetEnd":1221,"sourceId":15,"sourcePath":"7t4jlnaq.md","targetId":71,"targetPath":"k60yjf6q.md"},
    {"title":"dyx2t4oz","href":"dyx2t4oz","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[dyx2t4oz]]","snippetStart":438,"snippetEnd":450,"sourceId":21,"sourcePath":"a6uh87al.md","targetId":48,"targetPath":"dyx2t4oz.md"},
    {"title":"zz3cedu0","href":"zz3cedu0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[zz3cedu0]]","snippetStart":453,"snippetEnd":465,"sourceId":21,"sourcePath":"a6uh87al.md","targetId":114,"targetPath":"zz3cedu0.md"},
    {"title":"y9wu5ut7","href":"y9wu5ut7","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Also, a strict hierarchical system leads to increasingly privileged system components, and therefore leads to a component that have the \"most privileged\" only because of it place in the system. This leads to confused deputy problems ([[y9wu5ut7]]) in those components.","snippetStart":726,"snippetEnd":994,"sourceId":26,"sourcePath":"c4icaua4.md","targetId":110,"targetPath":"y9wu5ut7.md"},
    {"title":"d3nt6uix","href":"d3nt6uix","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[d3nt6uix]]","snippetStart":3907,"snippetEnd":3919,"sourceId":28,"sourcePath":"c7cva598.md","targetId":35,"targetPath":"d3nt6uix.md"},
    {"title":"s16ct1rj","href":"s16ct1rj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[s16ct1rj]]","snippetStart":3922,"snippetEnd":3934,"sourceId":28,"sourcePath":"c7cva598.md","targetId":105,"targetPath":"s16ct1rj.md"},
    {"title":"zmt276jl","href":"zmt276jl","type":"wiki-link","isExternal":false,"rels":[],"snippet":"See [[zmt276jl]].","snippetStart":3870,"snippetEnd":3887,"sourceId":28,"sourcePath":"c7cva598.md","targetId":112,"targetPath":"zmt276jl.md"},
    {"title":"dyx2t4oz","href":"dyx2t4oz","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Using frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.","snippetStart":242,"snippetEnd":367,"sourceId":29,"sourcePath":"cemsxh4n.md","targetId":48,"targetPath":"dyx2t4oz.md"},
    {"title":"zz3cedu0","href":"zz3cedu0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Using frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.","snippetStart":242,"snippetEnd":367,"sourceId":29,"sourcePath":"cemsxh4n.md","targetId":114,"targetPath":"zz3cedu0.md"},
    {"title":"s16ct1rj#interposition","href":"s16ct1rj#interposition","type":"wiki-link","isExternal":false,"rels":[],"snippet":"It performs interposition ([[s16ct1rj#interposition]]) on a certain *interesting* instructions to *emulate* then, hence *trap-and-emulate*. Those interesting instruction can be:","snippetStart":121,"snippetEnd":298,"sourceId":35,"sourcePath":"d3nt6uix.md","targetId":105,"targetPath":"s16ct1rj.md"},
    {"title":"literature/4zdjxws6","href":"literature/4zdjxws6","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[@lu2023practical] ([[literature/4zdjxws6]]) notes several limitations with such an approach:","snippetStart":537,"snippetEnd":630,"sourceId":46,"sourcePath":"dgdvhu1e.md","targetId":77,"targetPath":"literature/4zdjxws6.md"},
    {"title":"cosmdjej","href":"cosmdjej","type":"wiki-link","isExternal":false,"rels":[],"snippet":"TSX simplifies concurrent programming with transactional memory ([[cosmdjej]]).","snippetStart":69,"snippetEnd":148,"sourceId":47,"sourcePath":"dx7vz8d5.md","targetId":31,"targetPath":"cosmdjej.md"},
    {"title":"fvom56lw","href":"fvom56lw","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Since page faults are supressed, the OS cannot know whether page faults occurs or not. This property has been exploited by defenses against control-channel attacks on SGX @shih2017tsgx. The enclave can stop execution, when ever it encounter a page fault. See [[fvom56lw]].","snippetStart":1671,"snippetEnd":1943,"sourceId":47,"sourcePath":"dx7vz8d5.md","targetId":56,"targetPath":"fvom56lw.md"},
    {"title":"Zettlekasten","href":"ae6fatms","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[This blog post](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) proposes a framework to think about [[ae6fatms|Zettlekasten]] notes.","snippetStart":47,"snippetEnd":213,"sourceId":48,"sourcePath":"dyx2t4oz.md","targetId":23,"targetPath":"ae6fatms.md"},
    {"title":"1k9i1cr3","href":"1k9i1cr3","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[1k9i1cr3]]","snippetStart":1914,"snippetEnd":1926,"sourceId":52,"sourcePath":"fcf5pozg.md","targetId":3,"targetPath":"1k9i1cr3.md"},
    {"title":"7gbms9if","href":"7gbms9if","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[7gbms9if]]","snippetStart":1884,"snippetEnd":1896,"sourceId":52,"sourcePath":"fcf5pozg.md","targetId":13,"targetPath":"7gbms9if.md"},
    {"title":"xpolyx1l","href":"xpolyx1l","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[xpolyx1l]]","snippetStart":1899,"snippetEnd":1911,"sourceId":52,"sourcePath":"fcf5pozg.md","targetId":109,"targetPath":"xpolyx1l.md"},
    {"title":"5kzr3hwx","href":"5kzr3hwx","type":"wiki-link","isExternal":false,"rels":[],"snippet":"For more context, see [[5kzr3hwx]].","snippetStart":63,"snippetEnd":98,"sourceId":56,"sourcePath":"fvom56lw.md","targetId":11,"targetPath":"5kzr3hwx.md"},
    {"title":"s16ct1rj","href":"s16ct1rj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Containers and virtual machines ([[s16ct1rj]]) are two main isolation primitives when it come to cloud isolation.","snippetStart":82,"snippetEnd":195,"sourceId":60,"sourcePath":"h3manv25.md","targetId":105,"targetPath":"s16ct1rj.md"},
    {"title":"ae6fatms","href":"ae6fatms","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[Zk](https://github.com/mickael-menu/zk) is a nice command-line application that has minimalistic features to take zettelkasten-style [[ae6fatms]] notes.\nWhat I like about Zk:","snippetStart":67,"snippetEnd":242,"sourceId":61,"sourcePath":"h6c34egw.md","targetId":23,"targetPath":"ae6fatms.md"},
    {"title":"literature/2a7l7odo","href":"literature/2a7l7odo","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[@gu2020armonizing] (see [[literature/2a7l7odo]]) performed a study of the source of overheads of such IPC. SQLite3 is run on Zircon and seL4 microkernels. It is found that total IPC time is 79% [of](2024-05-19_of.md) the time on Zircon and 44% of the time on seL4 (with KPTI).","snippetStart":660,"snippetEnd":937,"sourceId":63,"sourcePath":"i2blyo37.md","targetId":76,"targetPath":"literature/2a7l7odo.md"},
    {"title":"Norman Hardy","href":"j19hdkto","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes of capabilities by [[j19hdkto|Norman Hardy]] himself","snippetStart":28,"snippetEnd":158,"sourceId":64,"sourcePath":"icjubure.md","targetId":66,"targetPath":"j19hdkto.md"},
    {"title":"Zettlekasten","href":"ae6fatms","type":"wiki-link","isExternal":false,"rels":[],"snippet":"His personal website, http://www.cap-lore.com/, contains pieces of notes on his ideas, is written in almost [[ae6fatms|Zettlekasten]] style. Ideas are separated into separated notes and linked together. \n[](2023-05-24_.md)","snippetStart":348,"snippetEnd":570,"sourceId":66,"sourcePath":"j19hdkto.md","targetId":23,"targetPath":"ae6fatms.md"},
    {"title":"y9wu5ut7","href":"y9wu5ut7","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Maybe the first one to coin the term confused deputy [[y9wu5ut7]] in his paper [@hardy1988confused].","snippetStart":184,"snippetEnd":284,"sourceId":66,"sourcePath":"j19hdkto.md","targetId":110,"targetPath":"y9wu5ut7.md"},
    {"title":"hourglass structure of information","href":"b740rhio","type":"wiki-link","isExternal":false,"rels":[],"snippet":"In this step, it is also important to remember the  [[b740rhio|hourglass structure of information]], so spend more time on the beginning and the end of the section.","snippetStart":1096,"snippetEnd":1260,"sourceId":69,"sourcePath":"k0wjwjhg.md","targetId":25,"targetPath":"b740rhio.md"},
    {"title":"7t4jlnaq","href":"7t4jlnaq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[7t4jlnaq]]","snippetStart":1561,"snippetEnd":1573,"sourceId":71,"sourcePath":"k60yjf6q.md","targetId":15,"targetPath":"7t4jlnaq.md"},
    {"title":"1yhmh234","href":"1yhmh234","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Controlled-channel attacks [[1yhmh234]]","snippetStart":150,"snippetEnd":189,"sourceId":73,"sourcePath":"l3lzsza3.md","targetId":5,"targetPath":"1yhmh234.md"},
    {"title":"i2blyo37#Overhead analysis","href":"i2blyo37#Overhead analysis","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The paper argues that the cost of IPC in microkernels are too high, and proposed using MPK-based domains to reduce the number of context switches during IPCs.\nThe paper provides a motivation study by profiling the overheads of IPC in common microkernels (see [[i2blyo37#Overhead analysis]]).","snippetStart":185,"snippetEnd":476,"sourceId":76,"sourcePath":"literature/2a7l7odo.md","targetId":63,"targetPath":"i2blyo37.md"},
    {"title":"dgdvhu1e","href":"dgdvhu1e","type":"wiki-link","isExternal":false,"rels":[],"snippet":"See [[dgdvhu1e]]","snippetStart":334,"snippetEnd":350,"sourceId":77,"sourcePath":"literature/4zdjxws6.md","targetId":46,"targetPath":"dgdvhu1e.md"},
    {"title":"2j6s9zpm","href":"2j6s9zpm","type":"wiki-link","isExternal":false,"rels":[],"snippet":"State spill harms availability and evolvability of system software (see [[2j6s9zpm]]).","snippetStart":133,"snippetEnd":219,"sourceId":79,"sourcePath":"literature/jfm8ud28.md","targetId":8,"targetPath":"2j6s9zpm.md"},
    {"title":"qq4qcbos","href":"qq4qcbos","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Pattern matching stage uses the nested page fault side-channel [[qq4qcbos]] to determine which pages are being accessed when the VM serves the SSH packet. The hypervisor first sends an SSH packet to the VM, then clears the present bits in the NPT PTEs.\nIt collects the sequences of page fault accesses to build a _signature_ of the page accessed from the time of receiving the request, to the time right before sending the packet. It then uses this signature to determine the page containing the `sk_buff` structure that contains the packet.","snippetStart":1318,"snippetEnd":1859,"sourceId":82,"sourcePath":"literature/ncfh611p.md","targetId":103,"targetPath":"qq4qcbos.md"},
    {"title":"zmt276jl","href":"zmt276jl","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The target of the attack is an SSH service running inside a cVM. While the ssh packets are encrypted, due to unprotected I/O [[zmt276jl]], the hypervisor can observe and modify the TCP and IP headers.","snippetStart":611,"snippetEnd":811,"sourceId":82,"sourcePath":"literature/ncfh611p.md","targetId":112,"targetPath":"zmt276jl.md"},
    {"title":"c4icaua4","href":"c4icaua4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Hierarchical layering limits flexibility: See [[c4icaua4]].","snippetStart":132,"snippetEnd":191,"sourceId":86,"sourcePath":"literature/zecj938z.md","targetId":26,"targetPath":"c4icaua4.md"},
    {"title":"h3manv25","href":"h3manv25","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Containers and Virtual machines both have disadvantages for implementing isolation and sharing. See [[h3manv25]].","snippetStart":347,"snippetEnd":460,"sourceId":87,"sourcePath":"literature/zw0lj520.md","targetId":60,"targetPath":"h3manv25.md"},
    {"title":"5kzr3hwx","href":"5kzr3hwx","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This type of protection commonly has very high overheads, due to the threat model being too strict (attackers with perfect observation of program counter and memory accesses).\nHowever, in practice, the observable side channels are usually more coarse-grained, at cache-line or page-fault-level. For instance, in SGX, attacker side-channels usually need page-fault-level trace before performing more fine-grained cache side-channel attacks. Hence, been works that only target page-fault-level leakage ([[5kzr3hwx]]), for more practical protection.","snippetStart":186,"snippetEnd":732,"sourceId":92,"sourcePath":"n9bxzpge.md","targetId":11,"targetPath":"5kzr3hwx.md"},
    {"title":"d3nt6uix","href":"d3nt6uix","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Virtualization hardware enables two-stage translation process from gVA to gPA, and from gPA to hPA through the nested page table (NPT) ([[d3nt6uix]]). This is the same in SEV. Although there is no official documentation, many paper indicate that hypervisor cannot intercept guest page faults (gPF) and look for faulting address.","snippetStart":120,"snippetEnd":448,"sourceId":103,"sourcePath":"qq4qcbos.md","targetId":35,"targetPath":"d3nt6uix.md"},
    {"title":"literature/ncfh611p","href":"literature/ncfh611p","type":"wiki-link","isExternal":false,"rels":[],"snippet":"@li2019exploiting: [[literature/ncfh611p]]","snippetStart":1077,"snippetEnd":1119,"sourceId":103,"sourcePath":"qq4qcbos.md","targetId":82,"targetPath":"literature/ncfh611p.md"},
    {"title":"d3nt6uix","href":"d3nt6uix","type":"wiki-link","isExternal":false,"rels":[],"snippet":"On the other hand, the hypervisor can interpose hardware interrupts, page faults, VM enter and exit, and handle them in software (handling them in the actual hardware would affect the entire system). This give the illusion to virtual machine have actual access to those hardware resources. See [[d3nt6uix]].","snippetStart":610,"snippetEnd":917,"sourceId":105,"sourcePath":"s16ct1rj.md","targetId":35,"targetPath":"d3nt6uix.md"},
    {"title":"1k9i1cr3","href":"1k9i1cr3","type":"wiki-link","isExternal":false,"rels":[],"snippet":"See [[1k9i1cr3]] for more about Unikraft's interrupt handling.","snippetStart":2740,"snippetEnd":2802,"sourceId":109,"sourcePath":"xpolyx1l.md","targetId":3,"targetPath":"1k9i1cr3.md"},
    {"title":"cn9u3d79","href":"cn9u3d79","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The function initializes the kernel's page table. On Linux, there is also the same function, but the process is a bit different  ([[cn9u3d79]]).","snippetStart":1488,"snippetEnd":1632,"sourceId":109,"sourcePath":"xpolyx1l.md","targetId":30,"targetPath":"cn9u3d79.md"},
    {"title":"cn9u3d79","href":"cn9u3d79","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[cn9u3d79]]","snippetStart":3586,"snippetEnd":3598,"sourceId":109,"sourcePath":"xpolyx1l.md","targetId":30,"targetPath":"cn9u3d79.md"},
    {"title":"literature/ncfh611p","href":"literature/ncfh611p","type":"wiki-link","isExternal":false,"rels":[],"snippet":"@li2019exploiting: [[literature/ncfh611p]]","snippetStart":1876,"snippetEnd":1918,"sourceId":112,"sourcePath":"zmt276jl.md","targetId":82,"targetPath":"literature/ncfh611p.md"},
    {"title":"7isqcppd","href":"7isqcppd","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[7isqcppd]]","snippetStart":432,"snippetEnd":444,"sourceId":113,"sourcePath":"zy68i5ym.md","targetId":14,"targetPath":"7isqcppd.md"},
    {"title":"ae6fatms","href":"ae6fatms","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This idea comes from the lack of clear instructions for using the zettelkasten [[ae6fatms]] method. For instance, what should an idea contain? How do you connect it with other ideas?","snippetStart":1400,"snippetEnd":1582,"sourceId":114,"sourcePath":"zz3cedu0.md","targetId":23,"targetPath":"ae6fatms.md"},
    {"title":"cemsxh4n","href":"cemsxh4n","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This idea helps to discover the context of a Zettelkasten note. More importantly, helps writing notes easier [[cemsxh4n]]","snippetStart":1706,"snippetEnd":1827,"sourceId":114,"sourcePath":"zz3cedu0.md","targetId":29,"targetPath":"cemsxh4n.md"},
    {"title":"dyx2t4oz","href":"dyx2t4oz","type":"wiki-link","isExternal":false,"rels":[],"snippet":"WEST: *“What is similar to _X?”_ [This](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) introduces another technique called the *knowledge flower* [[dyx2t4oz]] that is more open for interpretation.","snippetStart":1872,"snippetEnd":2106,"sourceId":114,"sourcePath":"zz3cedu0.md","targetId":48,"targetPath":"dyx2t4oz.md"},
    {"title":"lfyjdfv4","href":"lfyjdfv4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[lfyjdfv4]]","snippetStart":46,"snippetEnd":58,"sourceId":129,"sourcePath":"mwf41frv.md","targetId":128,"targetPath":"lfyjdfv4.md"}
  ]
}
