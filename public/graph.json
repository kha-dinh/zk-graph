{
  "notes": [
    {"filename":"index.md","filenameStem":"index","path":"index.md","absPath":"/home/khadd/mynotes/index.md","title":"","link":"[[index]]","lead":"","body":"","snippets":[],"rawContent":"","wordCount":0,"tags":[],"metadata":{},"created":"2023-05-09T04:12:51.850644773Z","modified":"2024-05-20T07:55:02.23863692Z","checksum":"e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855"},
    {"filename":"README.md","filenameStem":"README","path":"styles/write-good/README.md","absPath":"/home/khadd/mynotes/styles/write-good/README.md","title":"","link":"[[styles/write-good/README]]","lead":"Based on [write-good](https://github.com/btford/write-good).","body":"Based on [write-good](https://github.com/btford/write-good).\n\n\u003e Naive linter for English prose for developers who can't write good and wanna learn to do other stuff good too.\n\n```\nThe MIT License (MIT)\n\nCopyright (c) 2014 Brian Ford\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n```","snippets":["Based on [write-good](https://github.com/btford/write-good)."],"rawContent":"Based on [write-good](https://github.com/btford/write-good).\n\n\u003e Naive linter for English prose for developers who can't write good and wanna learn to do other stuff good too.\n\n```\nThe MIT License (MIT)\n\nCopyright (c) 2014 Brian Ford\n\nPermission is hereby granted, free of charge, to any person obtaining a copy\nof this software and associated documentation files (the \"Software\"), to deal\nin the Software without restriction, including without limitation the rights\nto use, copy, modify, merge, publish, distribute, sublicense, and/or sell\ncopies of the Software, and to permit persons to whom the Software is\nfurnished to do so, subject to the following conditions:\n\nThe above copyright notice and this permission notice shall be included in all\ncopies or substantial portions of the Software.\n\nTHE SOFTWARE IS PROVIDED \"AS IS\", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR\nIMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,\nFITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE\nAUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER\nLIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,\nOUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE\nSOFTWARE.\n```\n","wordCount":197,"tags":[],"metadata":{},"created":"2023-07-03T03:19:12.459881699Z","modified":"2023-07-03T03:19:09.982931599Z","checksum":"8826e2193035d98c38a7ef1560f1677ce7e9c305e2de48d469276e877b2d42f7"},
    {"filename":"2023-05-26.md","filenameStem":"2023-05-26","path":"daily/2023-05-26.md","absPath":"/home/khadd/mynotes/daily/2023-05-26.md","title":"2023-05-26","link":"[[daily/2023-05-26]]","lead":"#daily","body":"#daily\n\nAssigned to MIA inference IITP project. Basically it tries to perform MIA on driver licenses dataset. \n\nVirtIO daemon security?","snippets":["#daily"],"rawContent":"# 2023-05-26\n#daily\n\nAssigned to MIA inference IITP project. Basically it tries to perform MIA on driver licenses dataset. \n\nVirtIO daemon security?\n\n","wordCount":22,"tags":["daily"],"metadata":{},"created":"2023-05-26T07:18:14.726643796Z","modified":"2023-05-26T07:20:19.019702516Z","checksum":"124e5ccb7f871396234f918fc9eca661ec0c1330880741e08f2ac67294c2a5ad"},
    {"filename":"2023-06-16.md","filenameStem":"2023-06-16","path":"daily/2023-06-16.md","absPath":"/home/khadd/mynotes/daily/2023-06-16.md","title":"2023-06-16","link":"[[daily/2023-06-16]]","lead":"#daily","body":"#daily\n\n- [ ] Learn about nested page fault attacks on SEV\n\n\n\nThere may be benefits from combining self-paging VMs with obfuscated execution / page fault protection.","snippets":["#daily"],"rawContent":"# 2023-06-16\n#daily\n\n- [ ] Learn about nested page fault attacks on SEV\n\n\n\nThere may be benefits from combining self-paging VMs with obfuscated execution / page fault protection.\n","wordCount":29,"tags":["daily"],"metadata":{},"created":"2023-06-16T08:39:24.387285291Z","modified":"2023-06-16T09:08:49.619979085Z","checksum":"702b109d7f444b06f455059ef35f12633fbd280f3f0966253e9a361bdfa5cd1d"},
    {"filename":"2023-06-19.md","filenameStem":"2023-06-19","path":"daily/2023-06-19.md","absPath":"/home/khadd/mynotes/daily/2023-06-19.md","title":"2023-06-19","link":"[[daily/2023-06-19]]","lead":"#daily","body":"#daily\n\n\n- [ ] Does SEV guarantee the mapping of huge pages?\n- [x] Check on CLG","snippets":["#daily"],"rawContent":"# 2023-06-19\n#daily\n\n\n- [ ] Does SEV guarantee the mapping of huge pages?\n- [x] Check on CLG  \n\n\n","wordCount":19,"tags":["daily"],"metadata":{},"created":"2023-06-19T06:12:44.575936889Z","modified":"2023-06-19T07:57:35.065499685Z","checksum":"c08e4de8e92bb7044da2c9bb82acc9611086249ab8b3ed86df891ba9aaee6037"},
    {"filename":"2023-07-06.md","filenameStem":"2023-07-06","path":"daily/2023-07-06.md","absPath":"/home/khadd/mynotes/daily/2023-07-06.md","title":"2023-07-06","link":"[[daily/2023-07-06]]","lead":"#daily","body":"#daily\n\nHi, I don't know where to ask this question so I'm gonna put it here. I'm trying to override the page fault handler for the heap memory region. For that, I created a new type of vma using `ukvmem` and replaced the `uk_vma_map_anon` with my vma type in `heap_init`. The problem is I want to access the previous PTE in my custom page fault handler, but it is cleared in `pg_page_mapx`, when the flag `PAGE_FLAG_KEEP_PTES` is not passed.","snippets":["#daily"],"rawContent":"# 2023-07-06\n#daily\n\nHi, I don't know where to ask this question so I'm gonna put it here. I'm trying to override the page fault handler for the heap memory region. For that, I created a new type of vma using `ukvmem` and replaced the `uk_vma_map_anon` with my vma type in `heap_init`. The problem is I want to access the previous PTE in my custom page fault handler, but it is cleared in `pg_page_mapx`, when the flag `PAGE_FLAG_KEEP_PTES` is not passed.\n\n\n","wordCount":81,"tags":["daily"],"metadata":{},"created":"2023-07-06T08:39:27.324639506Z","modified":"2023-07-07T02:53:30.515381038Z","checksum":"14717acaf5dd0cb351708e9d7ca56da2f70a7907a38a6928ec8307bcb3865e7e"},
    {"filename":"2023-07-09.md","filenameStem":"2023-07-09","path":"daily/2023-07-09.md","absPath":"/home/khadd/mynotes/daily/2023-07-09.md","title":"2023-07-09","link":"[[daily/2023-07-09]]","lead":"#daily","body":"#daily\n\nI don't know where to put this question so I'm gonna put it here. I am trying to make a page fault handler that serves physical memory from a pre-allocated physical memory region. To do that, I allocate memory at boot time using `pt-\u003efa-\u003efalloc()` and store the physical address. I then extended `ukvmem` to introduce a custom VMA type to register my page fault handler. E.g.,\n\n```c\nstatic int vma_op_custom_fault(__unused struct uk_vma *vma,\n                                     struct uk_vm_fault *fault)\n{\n  __paddr_t paddr = get_allocated_paddr();\n  /* initialize memory  */\n\tfault-\u003epaddr = paddr;\n  return 0;\n}\n```\n\nHowever, for some reason, memory write does not go through, and I got junk data when reading from the mapped address.\nHere is a simple test case:\n```c\n\tva = __VADDR_ANY;\n\tuk_vma_map_custom(vas, \u0026va, 0x10000, PROT_RW, UK_VMA_MAP_UNINITIALIZED,\n\t\t\t NULL);\n\tmemset((void *)va, 0xAB, 0x100);\n\tmemset((void *)va + 0x100, 0xCD, 0x100);\n\tuk_hexdumpk(KLVL_INFO, (void *)va, 0x1000,\n\t\t    UK_HXDF_COMPRESS | UK_HXDF_ADDR, UK_HXDF_GRPQWORD);\n```\nHere is the console output. The first `memset` would create the `20 07` pattern in memory. \n```\n[    0.304939] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07\n[    0.322053] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.326263] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.344048] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```\n\nStrangely enough, when I compile the test file with `isr` flag, or use `memset_isr`, the problem does not happen.\n\n```\n[    0.305990] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab\n[    0.323425] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.327827] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.345547] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```","snippets":["#daily"],"rawContent":"# 2023-07-09\n#daily\n\nI don't know where to put this question so I'm gonna put it here. I am trying to make a page fault handler that serves physical memory from a pre-allocated physical memory region. To do that, I allocate memory at boot time using `pt-\u003efa-\u003efalloc()` and store the physical address. I then extended `ukvmem` to introduce a custom VMA type to register my page fault handler. E.g.,\n\n```c\nstatic int vma_op_custom_fault(__unused struct uk_vma *vma,\n                                     struct uk_vm_fault *fault)\n{\n  __paddr_t paddr = get_allocated_paddr();\n  /* initialize memory  */\n\tfault-\u003epaddr = paddr;\n  return 0;\n}\n```\n\nHowever, for some reason, memory write does not go through, and I got junk data when reading from the mapped address.\nHere is a simple test case:\n```c\n\tva = __VADDR_ANY;\n\tuk_vma_map_custom(vas, \u0026va, 0x10000, PROT_RW, UK_VMA_MAP_UNINITIALIZED,\n\t\t\t NULL);\n\tmemset((void *)va, 0xAB, 0x100);\n\tmemset((void *)va + 0x100, 0xCD, 0x100);\n\tuk_hexdumpk(KLVL_INFO, (void *)va, 0x1000,\n\t\t    UK_HXDF_COMPRESS | UK_HXDF_ADDR, UK_HXDF_GRPQWORD);\n```\nHere is the console output. The first `memset` would create the `20 07` pattern in memory. \n```\n[    0.304939] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07 20 07\n[    0.322053] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.326263] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.344048] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```\n\nStrangely enough, when I compile the test file with `isr` flag, or use `memset_isr`, the problem does not happen.\n\n```\n[    0.305990] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000000  ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab ab\n[    0.323425] Info: [custom] \u003ctest_vma.c @  239\u003e *\n[    0.327827] Info: [custom] \u003ctest_vma.c @  239\u003e (void *)va: 1000000100  cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd cd\n[    0.345547] Info: [custom] \u003ctest_vma.c @  239\u003e *\n```\n\n","wordCount":390,"tags":["daily"],"metadata":{},"created":"2023-07-09T14:15:54.119097732Z","modified":"2023-07-09T14:41:06.058409603Z","checksum":"862851b9864f06f782badd0dda8cebfdd8cd73aea794fe85a38c24d772833f9e"},
    {"filename":"2023-07-12.md","filenameStem":"2023-07-12","path":"daily/2023-07-12.md","absPath":"/home/khadd/mynotes/daily/2023-07-12.md","title":"2023-07-12","link":"[[daily/2023-07-12]]","lead":"#daily","body":"#daily\n\n\n\n\n# Message to unikraft\n\nRegarding page table isolation. I plan to first implement the features we discussed earlier, randomization and page table unmapping/sealing.\n\nRandomization\n- Currently the page table's virtual addresses are direct-mapped by `pgarch_pt_map` and `pgarch_pt_unmap`. We probably only need to provide an alternative implementation that map to a random address.\n- To support this, we may use a secondary direct-mapped area address that is randomized at boot time.\n- Another approach is to use the heap memory space to map the page table addresses. The addresses are naturally randomized by the heap allocator. \n\nPage-table unmapping/sealing\n- We need to keep track of the virtual addresses of the page table, then unmap them when the page table update is finished, then re-map them on page faults or page table updates.\n- I guess we can insert a hook in `pg_pt_alloc` used to allocate the page table to collect the page table virtual addresses in a list. We can then insert the code to unmap/remap these pages where the page table is accessed.\n  - I see only 4 main entry points of the page table: `pg_page_mapx`, `pg_page_split`, `pg_page_setattr`, and `pg_page_unmmap`.\n- How are the direct-mapped pages mapped? I don't see the direct-mapped pages being mapped in the source.","snippets":["#daily"],"rawContent":"# 2023-07-12\n#daily\n\n\n\n\n# Message to unikraft\n\nRegarding page table isolation. I plan to first implement the features we discussed earlier, randomization and page table unmapping/sealing.\n\nRandomization\n- Currently the page table's virtual addresses are direct-mapped by `pgarch_pt_map` and `pgarch_pt_unmap`. We probably only need to provide an alternative implementation that map to a random address.\n- To support this, we may use a secondary direct-mapped area address that is randomized at boot time.\n- Another approach is to use the heap memory space to map the page table addresses. The addresses are naturally randomized by the heap allocator. \n\nPage-table unmapping/sealing\n- We need to keep track of the virtual addresses of the page table, then unmap them when the page table update is finished, then re-map them on page faults or page table updates.\n- I guess we can insert a hook in `pg_pt_alloc` used to allocate the page table to collect the page table virtual addresses in a list. We can then insert the code to unmap/remap these pages where the page table is accessed.\n  - I see only 4 main entry points of the page table: `pg_page_mapx`, `pg_page_split`, `pg_page_setattr`, and `pg_page_unmmap`.\n- How are the direct-mapped pages mapped? I don't see the direct-mapped pages being mapped in the source.\n\n\n","wordCount":211,"tags":["daily"],"metadata":{},"created":"2023-07-12T07:59:25.823625705Z","modified":"2023-07-17T02:05:52.337051928Z","checksum":"e32cdc1c1311c8b33f7f9bd7db0ea6b6c88960aeb7243a06c4bf99cc4c436fb4"},
    {"filename":"2023-07-25.md","filenameStem":"2023-07-25","path":"daily/2023-07-25.md","absPath":"/home/khadd/mynotes/daily/2023-07-25.md","title":"2023-07-25","link":"[[daily/2023-07-25]]","lead":"#daily","body":"#daily\n\n\n# Typst\n= Introduction\n\n==== Unsafe rust is not that dangerous compared to FFI \nRust has two main sources of unsafety: the code inside `unsafe` and the foreign function interface (FFI). However, unsafe code is well-contained and is used sparingly. Moreover, previous research proposed static analysis that can detect memory safety bugs triggered by `unsafe`. On the other hand, the FFI is written in unsafe languages and can easily trigger memory bugs. A bug in FFI can compromise the security guarantees of Rust. Hence, we argue that FFI is more harmful to Rust.\n\n==== Limitation of previous work\nPrevious proposals proposed systems that automatically separate memory used by safe rust and unsafe components. \n\n\n==== Our system\nIn response to the limitation of the previous wo","snippets":["#daily"],"rawContent":"# 2023-07-25\n#daily\n\n\n# Typst\n= Introduction\n\n==== Unsafe rust is not that dangerous compared to FFI \nRust has two main sources of unsafety: the code inside `unsafe` and the foreign function interface (FFI). However, unsafe code is well-contained and is used sparingly. Moreover, previous research proposed static analysis that can detect memory safety bugs triggered by `unsafe`. On the other hand, the FFI is written in unsafe languages and can easily trigger memory bugs. A bug in FFI can compromise the security guarantees of Rust. Hence, we argue that FFI is more harmful to Rust.\n\n==== Limitation of previous work\nPrevious proposals proposed systems that automatically separate memory used by safe rust and unsafe components. \n\n\n==== Our system\nIn response to the limitation of the previous wo\n\n\n","wordCount":128,"tags":["daily"],"metadata":{},"created":"2023-07-25T09:23:46.686133431Z","modified":"2023-07-25T09:24:00.582946895Z","checksum":"7a6fd23c5ce0d9eee134ae6bf9bb91574a5aa36e5988499904c53d7716c426d1"},
    {"filename":"2023-07-26.md","filenameStem":"2023-07-26","path":"daily/2023-07-26.md","absPath":"/home/khadd/mynotes/daily/2023-07-26.md","title":"2023-07-26","link":"[[daily/2023-07-26]]","lead":"#daily","body":"#daily\n\nThis figure is awesome (in [shared_mem_handling.h](https://github.com/ReMon-MVEE/ReMon/blob/master/MVEE/Inc/arch/amd64/shared_mem/shared_mem_handling.h))\n```c\n    /* +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     * | _ | _ | _ _ _ | _ | _ | _ | _ _ | _ _ _ _ | _ _ | _ _ | _ | _ | _ _ _ | _ _ | _ | _ | _ _ _ _ | _ |\n     * +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     *  \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         \\\n     *   \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         +-\u003e REX present\n     *    \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   +-\u003e REX prefixes [WRXB]\n     *     \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   +-\u003e prefix group 1 present\n     *      \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     +-\u003e prefix group 2 present\n     *       \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       +-\u003e prefix group 1\n     *        \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   +-\u003e prefix group 2\n     *         \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   +-\u003e prefix group 3\n     *          \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     +-\u003e prefix group 4\n     *           \\   \\   \\       \\   \\   \\   \\     \\         \\     +-\u003e VEX size\n     *            \\   \\   \\       \\   \\   \\   \\     \\         +-\u003e VEX.L\n     *             \\   \\   \\       \\   \\   \\   \\     +-\u003e VEX.vvvv\n     *              \\   \\   \\       \\   \\   \\   +-\u003e VEX.mmmmm\n     *               \\   \\   \\       \\   \\   +-\u003e EVEX.R'\n     *                \\   \\   \\       \\   +-\u003e EVEX.X\n     *                 \\   \\   \\       +-\u003e EVEX.V'\n     *                  \\   \\   +-\u003e EVEX.aaa\n     *                   \\   +-\u003e EVEX.z\n     *                    +-\u003e EVEX.b\n     *                    \n     *                    */\n```","snippets":["#daily"],"rawContent":"# 2023-07-26\n#daily\n\nThis figure is awesome (in [shared_mem_handling.h](https://github.com/ReMon-MVEE/ReMon/blob/master/MVEE/Inc/arch/amd64/shared_mem/shared_mem_handling.h))\n```c\n    /* +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     * | _ | _ | _ _ _ | _ | _ | _ | _ _ | _ _ _ _ | _ _ | _ _ | _ | _ | _ _ _ | _ _ | _ | _ | _ _ _ _ | _ |\n     * +---+---+-------+---+---+---+-----+---------+-----+-----+---+---+-------+-----+---+---+---------+---+\n     *  \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         \\\n     *   \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   \\         +-\u003e REX present\n     *    \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   \\   +-\u003e REX prefixes [WRXB]\n     *     \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     \\   +-\u003e prefix group 1 present\n     *      \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       \\     +-\u003e prefix group 2 present\n     *       \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   \\       +-\u003e prefix group 1\n     *        \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   \\   +-\u003e prefix group 2\n     *         \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     \\   +-\u003e prefix group 3\n     *          \\   \\   \\       \\   \\   \\   \\     \\         \\     \\     +-\u003e prefix group 4\n     *           \\   \\   \\       \\   \\   \\   \\     \\         \\     +-\u003e VEX size\n     *            \\   \\   \\       \\   \\   \\   \\     \\         +-\u003e VEX.L\n     *             \\   \\   \\       \\   \\   \\   \\     +-\u003e VEX.vvvv\n     *              \\   \\   \\       \\   \\   \\   +-\u003e VEX.mmmmm\n     *               \\   \\   \\       \\   \\   +-\u003e EVEX.R'\n     *                \\   \\   \\       \\   +-\u003e EVEX.X\n     *                 \\   \\   \\       +-\u003e EVEX.V'\n     *                  \\   \\   +-\u003e EVEX.aaa\n     *                   \\   +-\u003e EVEX.z\n     *                    +-\u003e EVEX.b\n     *                    \n     *                    */\n```\n\n\n","wordCount":314,"tags":["daily"],"metadata":{},"created":"2023-07-26T02:38:51.583773191Z","modified":"2023-07-26T02:40:19.753295681Z","checksum":"321e0803b887e255f3cd1e32fa742fb0c7520b7fdcd1bb4c18d7a66d25fb7c59"},
    {"filename":"2023-08-10.md","filenameStem":"2023-08-10","path":"daily/2023-08-10.md","absPath":"/home/khadd/mynotes/daily/2023-08-10.md","title":"2023-08-10","link":"[[daily/2023-08-10]]","lead":"#daily","body":"#daily\n\n- I feel lost after a week off. It feels like the momentum is gone.\n- There needs to be a task management system to tackle this; whenever you feel like you don't know what to do, just pick the most urgent task from the list.\n\n- Regarding ObliVM\n  - Need to port Unikraft to SEV\n  - Need to update writing\n  - Need to port real applications","snippets":["#daily"],"rawContent":"# 2023-08-10\n#daily\n\n- I feel lost after a week off. It feels like the momentum is gone.\n- There needs to be a task management system to tackle this; whenever you feel like you don't know what to do, just pick the most urgent task from the list.\n\n- Regarding ObliVM\n  - Need to port Unikraft to SEV\n  - Need to update writing\n  - Need to port real applications\n\n\n\n\n\n","wordCount":70,"tags":["daily"],"metadata":{},"created":"2023-08-10T07:33:38.089767774Z","modified":"2023-08-10T07:45:09.590361476Z","checksum":"5a3740cb2056bb4c70d9d11c7f8cec8438423544c908254a8edaeafdc58b5cd5"},
    {"filename":"2023-08-23.md","filenameStem":"2023-08-23","path":"daily/2023-08-23.md","absPath":"/home/khadd/mynotes/daily/2023-08-23.md","title":"2023-08-23","link":"[[daily/2023-08-23]]","lead":"#daily","body":"#daily\n\n# State of the things\n\n## Capacity \n- Github repo must be up, but the code can be delayed\n- A presentation is needed. Need to prepare for at least 1 month\n- Paper: Final version is almost done\n\n- Need to apply for VISA\n\n## Project: Oblv\n- Need to port unikraft to support SEV-SNP\n- Writing hasn't been touched for a while\n- Reading: important related works are not grokked\n  - Cosmix\n  - InvisiPage\n  - Klotski\n  - Autarky\n\n\n## CLG\n- writing is progressing, with some important points fleshed out\n- \n\n## Other\n- Rustsan?\n\n\n# Way forward\n\n-","snippets":["#daily"],"rawContent":"# 2023-08-23\n#daily\n\n# State of the things\n\n## Capacity \n- Github repo must be up, but the code can be delayed\n- A presentation is needed. Need to prepare for at least 1 month\n- Paper: Final version is almost done\n\n- Need to apply for VISA\n\n## Project: Oblv\n- Need to port unikraft to support SEV-SNP\n- Writing hasn't been touched for a while\n- Reading: important related works are not grokked\n  - Cosmix\n  - InvisiPage\n  - Klotski\n  - Autarky\n\n\n## CLG\n- writing is progressing, with some important points fleshed out\n- \n\n## Other\n- Rustsan?\n\n\n# Way forward\n\n- \n","wordCount":104,"tags":["daily"],"metadata":{},"created":"2023-08-23T08:51:56.182014346Z","modified":"2023-08-23T08:59:41.474378932Z","checksum":"cd30a654fad71871dd76045f298fdec907f05e6ea7e325ed89014048d7f66132"},
    {"filename":"k0wjwjhg.md","filenameStem":"k0wjwjhg","path":"k0wjwjhg.md","absPath":"/home/khadd/mynotes/k0wjwjhg.md","title":"A paper/book should be read in multiple passes","link":"[[k0wjwjhg]]","lead":"#reading #learning #zettelkasten","body":"#reading #learning #zettelkasten\n\nAn article/paper/book should be read in multiple passes for the best extraction of information.\nThe point of reading in many passes is to maximize the time efficiency when reading.   \n\n\n## The three passes\n[keshav] suggested that reading can be divided into three passes, that cover from high-level ideas to low-level details.\n### Inspectional reading\nThe first pass should establish the context around the article.\n[keshav] suggested that 5-10% of the time should be spent on this.\n\nThis step may have the following goals:\n- *Establishing context*: What is the background of this paper? What is the previous work, and what comes after this?\n- *Relavancy*: How is this related to your research? \n- *Importance*: Is this worth reading? If not then it is a waste of time to read the article.\n- *Usefulness*: What information do you want to extract from this paper? \n- *The main arguments*: that are the arguments of the paper/article? This helps establish the mental model before going into more detailed reading.\n\nIn this step, it is also important to remember the  [[b740rhio|hourglass structure of information]], so spend more time on the beginning and the end of the section.\n\n\n### Detailed reading\nWhile doing the detailed reading, we should pay attention to the main arguments of the paper. For instance, what argument/idea is this particular paragraph/sentence supporting? Is it a convincing argument? What other ideas does it contradict?\n\n### Synthesis\n\n\n## Reference\n[keshav]: https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf","snippets":["#reading #learning #zettelkasten"],"rawContent":"# A paper/book should be read in multiple passes\n#reading #learning #zettelkasten\n\nAn article/paper/book should be read in multiple passes for the best extraction of information.\nThe point of reading in many passes is to maximize the time efficiency when reading.   \n\n\n## The three passes\n[keshav] suggested that reading can be divided into three passes, that cover from high-level ideas to low-level details.\n### Inspectional reading\nThe first pass should establish the context around the article.\n[keshav] suggested that 5-10% of the time should be spent on this.\n\nThis step may have the following goals:\n- *Establishing context*: What is the background of this paper? What is the previous work, and what comes after this?\n- *Relavancy*: How is this related to your research? \n- *Importance*: Is this worth reading? If not then it is a waste of time to read the article.\n- *Usefulness*: What information do you want to extract from this paper? \n- *The main arguments*: that are the arguments of the paper/article? This helps establish the mental model before going into more detailed reading.\n\nIn this step, it is also important to remember the  [[b740rhio|hourglass structure of information]], so spend more time on the beginning and the end of the section.\n\n\n### Detailed reading\nWhile doing the detailed reading, we should pay attention to the main arguments of the paper. For instance, what argument/idea is this particular paragraph/sentence supporting? Is it a convincing argument? What other ideas does it contradict?\n\n### Synthesis\n\n\n## Reference\n[keshav]: https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf\n","wordCount":250,"tags":["zettelkasten","reading","learning"],"metadata":{},"created":"2023-05-05T06:32:39.659000588Z","modified":"2023-06-19T02:01:17.89523677Z","checksum":"c402720275f0fb1831d9b5e64ad2e4eeb64acf8e00427a2f4195be91f391cefa"},
    {"filename":"c7cva598.md","filenameStem":"c7cva598","path":"c7cva598.md","absPath":"/home/khadd/mynotes/c7cva598.md","title":"AMD Secure Encrypted Virtualization (SEV)","link":"[[c7cva598]]","lead":"#sev #virtualization #tee #amd","body":"#sev #virtualization #tee #amd\n\nAMD's Secure Encrypted Virtualization (SEV) enables TEEs at the granularity of virtual machines. \n\n# Memory encryption\nThe CPU employs a secure processor (SP) that transparently encrypts/decrypts data when they are written into the memory pages of the encrypted VMs.\n\nEncryption is performed with a per-cVM key maintained by the CPU,c called the VM encryption key (VEK). It is indexed by the ASID of the VM.\n\nA flag called the c-bit indicates whether a page should be encrypted or not. The location of the c-bit may be different depending on the platform. The Linux's support for SEV check for the c-bit location using `CPUID 8000_001F[EBX]`. (`get_sev_encryption_bit` in `x86/boot/compressed/mem_encrypt.S`).\n\n## Behavior\nAMD manual, volume 2, 15.34.5:\n\u003e Memory access on behalf of instruction fetches and guest page table walks are always treated as private, regardless of the software value of the C-bit.\n\nIn other words, implicit memory accesses performed by the hardware are always private (maybe prefetching is an exception). Making instruction fetches private prevents the host from injecting code into the virtual machine. \nMaking the page table walk private prevents the host from tampering with the Guest mapping. However, this is insufficient, due to the unprotected gPA-\u003ehPA mapping, as shown in some papers (@morbitzer2018severed). SEV-SNP remedied this issue by protecting this mapping.\n\nThis may have two implications in implementing kernel:\n- Before the software writes into the code page, (e. Howeverg., before relocation), the c-bit of those pages must be set (#need-verifivation), \n- Software operations on the page table must be careful, since sometimes c-bit may consume physical address bits.\n\n## Interaction between host and guest PTEs \nThe c-bit is stored in *both* the host PTEs and the guest PTEs. Its effect is determined from the combination of the two c-bit in gPT and NPT.\n\n|             | host c-bit               |                          |\n|-------------|--------------------------|--------------------------|\n| guest c-bit | 0                        | 1                        |\n|-------------|--------------------------|--------------------------|\n| 0           | not encrypted            | encrypted with host key  |\n| 1           | encrypted with guest key | encrypted with guest key |\n\n\n\n\n\n\n# SEV-ES\nThe original design of SEV does not encrypt the VM states upon VM exit. This leads to attacks that can extract information from the VM based on the register state.\n\nSEV-Encrypted State (ES) solve this issue by also encrypting the VM states upon VMEXIT. It splits the virtual machine control block (VMCB) into two areas, a control area and a save area (VMSA). The VMSA is encrypted with the VEK upon VMEXIT.\n\n## Automatic and non-automatic exits.\nNow, every exit from the guest into the hypervisor (`VMEXIT`) is categorized into Automatic Exit (AE) and Non-automatic Exit (NAE). \n\nAE consists of basically all interrupts that are trigger by the hypervisor. Since these interrupt does not require knowledge of VM register state, all of VM registers will be encrypted and stored into the VMSA.\n\nNAE are the remaining exits, i.e., faults triggered by the VM. Faults can be triggered by the hardware exception such as page fault, or executing a privilege instruction (e.g., write into CR3). \nIn this case, the guest might want to share some register states with the hypervisor.\n\nHence, a `VC` exception (VMM Communication Exception) is generated by the CPU, with the cauuse of exception. The VM then invoke the handler to handle the fault. The handler can copy the selected VM registers into a  shared page, called the  Guest Hypervisor Communication Block (GHCB), which is non-encrypted. It then triggers an AE with a call to  `VMGEXIT`, so that the host can serve the fault.\n\n# SEV-SNP\n## Mapping integrity protection\nSEV-Secure Nested Paging (SNP) adds integrity protection to SEV, that protect the encrypted pages from replaying (replaced with an old page), being mapped to two regions, and being remapped.\n\nIt uses an Reseve Page Mapping (RMP), which is a table maintained by the hardware to keep the mapping metatada for each physical pages.\nAll memory write accesses look up the RMP to verify the mapping correctness.\n\nEven with the RMP mapping protection, a malicious VMM could still tammper with the permission flags in the page table entries @qin2023protecting. For instance, a malicious hypervisor can overwrite the present bit in the NPT, that indicate wheter the page is inside memory. When the VM access the page, a nested page fault will be trigger.\n\n\n## VMPL\nSEV-SNP also includes the Virtual Machine Privilege Level (VMPL) security mechanism. It adds privilege levels within the encrypted VM.\n\n\nHecate @ge2022hecate uses this feature to implement an in-VM hypervisor that handle the VM-VMM interactions for an unmodified, un-enlighteneda OS. It puts the hypervisor in VMPL layer 0, and the guest VM in VMPL level 4, then have the VMM forwards all faults into the in-VM VMM for handling.\n\n# I/O operations in SEV\nSee [[zmt276jl]].\n\n# Related notes\n- [[d3nt6uix]]\n- [[s16ct1rj]]","snippets":["#sev #virtualization #tee #amd"],"rawContent":"# AMD Secure Encrypted Virtualization (SEV)\n#sev #virtualization #tee #amd\n\nAMD's Secure Encrypted Virtualization (SEV) enables TEEs at the granularity of virtual machines. \n\n# Memory encryption\nThe CPU employs a secure processor (SP) that transparently encrypts/decrypts data when they are written into the memory pages of the encrypted VMs.\n\nEncryption is performed with a per-cVM key maintained by the CPU,c called the VM encryption key (VEK). It is indexed by the ASID of the VM.\n\nA flag called the c-bit indicates whether a page should be encrypted or not. The location of the c-bit may be different depending on the platform. The Linux's support for SEV check for the c-bit location using `CPUID 8000_001F[EBX]`. (`get_sev_encryption_bit` in `x86/boot/compressed/mem_encrypt.S`).\n\n## Behavior\nAMD manual, volume 2, 15.34.5:\n\u003e Memory access on behalf of instruction fetches and guest page table walks are always treated as private, regardless of the software value of the C-bit.\n\nIn other words, implicit memory accesses performed by the hardware are always private (maybe prefetching is an exception). Making instruction fetches private prevents the host from injecting code into the virtual machine. \nMaking the page table walk private prevents the host from tampering with the Guest mapping. However, this is insufficient, due to the unprotected gPA-\u003ehPA mapping, as shown in some papers (@morbitzer2018severed). SEV-SNP remedied this issue by protecting this mapping.\n\nThis may have two implications in implementing kernel:\n- Before the software writes into the code page, (e. Howeverg., before relocation), the c-bit of those pages must be set (#need-verifivation), \n- Software operations on the page table must be careful, since sometimes c-bit may consume physical address bits.\n\n## Interaction between host and guest PTEs \nThe c-bit is stored in *both* the host PTEs and the guest PTEs. Its effect is determined from the combination of the two c-bit in gPT and NPT.\n\n|             | host c-bit               |                          |\n|-------------|--------------------------|--------------------------|\n| guest c-bit | 0                        | 1                        |\n|-------------|--------------------------|--------------------------|\n| 0           | not encrypted            | encrypted with host key  |\n| 1           | encrypted with guest key | encrypted with guest key |\n\n\n\n\n\n\n# SEV-ES\nThe original design of SEV does not encrypt the VM states upon VM exit. This leads to attacks that can extract information from the VM based on the register state.\n\nSEV-Encrypted State (ES) solve this issue by also encrypting the VM states upon VMEXIT. It splits the virtual machine control block (VMCB) into two areas, a control area and a save area (VMSA). The VMSA is encrypted with the VEK upon VMEXIT.\n\n## Automatic and non-automatic exits.\nNow, every exit from the guest into the hypervisor (`VMEXIT`) is categorized into Automatic Exit (AE) and Non-automatic Exit (NAE). \n\nAE consists of basically all interrupts that are trigger by the hypervisor. Since these interrupt does not require knowledge of VM register state, all of VM registers will be encrypted and stored into the VMSA.\n\nNAE are the remaining exits, i.e., faults triggered by the VM. Faults can be triggered by the hardware exception such as page fault, or executing a privilege instruction (e.g., write into CR3). \nIn this case, the guest might want to share some register states with the hypervisor.\n\nHence, a `VC` exception (VMM Communication Exception) is generated by the CPU, with the cauuse of exception. The VM then invoke the handler to handle the fault. The handler can copy the selected VM registers into a  shared page, called the  Guest Hypervisor Communication Block (GHCB), which is non-encrypted. It then triggers an AE with a call to  `VMGEXIT`, so that the host can serve the fault.\n\n# SEV-SNP\n## Mapping integrity protection\nSEV-Secure Nested Paging (SNP) adds integrity protection to SEV, that protect the encrypted pages from replaying (replaced with an old page), being mapped to two regions, and being remapped.\n\nIt uses an Reseve Page Mapping (RMP), which is a table maintained by the hardware to keep the mapping metatada for each physical pages.\nAll memory write accesses look up the RMP to verify the mapping correctness.\n\nEven with the RMP mapping protection, a malicious VMM could still tammper with the permission flags in the page table entries @qin2023protecting. For instance, a malicious hypervisor can overwrite the present bit in the NPT, that indicate wheter the page is inside memory. When the VM access the page, a nested page fault will be trigger.\n\n\n## VMPL\nSEV-SNP also includes the Virtual Machine Privilege Level (VMPL) security mechanism. It adds privilege levels within the encrypted VM.\n\n\nHecate @ge2022hecate uses this feature to implement an in-VM hypervisor that handle the VM-VMM interactions for an unmodified, un-enlighteneda OS. It puts the hypervisor in VMPL layer 0, and the guest VM in VMPL level 4, then have the VMM forwards all faults into the in-VM VMM for handling.\n\n# I/O operations in SEV\nSee [[zmt276jl]].\n\n# Related notes\n- [[d3nt6uix]]\n- [[s16ct1rj]]\n","wordCount":804,"tags":["tee","sev","virtualization","amd","need-verifivation"],"metadata":{},"created":"2023-05-26T07:17:27.667130146Z","modified":"2023-08-25T05:03:37.728978391Z","checksum":"e4ae6a48a7683420bd48987d50c3414efa1a5ac05e21bdc4d98585f356fcaf48"},
    {"filename":"64zyhko0.md","filenameStem":"64zyhko0","path":"64zyhko0.md","absPath":"/home/khadd/mynotes/64zyhko0.md","title":"Academic vocabularies (security)","link":"[[64zyhko0]]","lead":"#writing","body":"#writing\n\n- Curtail (verb): To impose restrictions on. \n  - E.g., Our proposed design curtailed the attacker's ability to hijack the control flow.","snippets":["#writing"],"rawContent":"# Academic vocabularies (security)\n#writing\n\n- Curtail (verb): To impose restrictions on. \n  - E.g., Our proposed design curtailed the attacker's ability to hijack the control flow.\n\n\n","wordCount":26,"tags":["writing"],"metadata":{},"created":"2023-08-30T08:03:57.104771544Z","modified":"2023-08-31T03:03:12.19461367Z","checksum":"6b63d5088e9d39cc6996ecd0d29ab34f32dde56fb308205564bb034f668d13ac"},
    {"filename":"2xsjor1o.md","filenameStem":"2xsjor1o","path":"2xsjor1o.md","absPath":"/home/khadd/mynotes/2xsjor1o.md","title":"Accessing user memory from Kernel","link":"[[2xsjor1o]]","lead":"#linux","body":"#linux\n\nLinux provides `__user` annotation to mark userspace pointers. *Transfer functions* such as `copy_from_user` can only operate on those pointers. User pointers are always compared against userspace address space to avoid kernel pointers. An example of `get_user`:\n``` assembly\n.text\nENTRY(__get_user_1)\n    mov PER_CPU_VAR(current_task), %_ASM_DX\n    cmp TASK_addr_limit(%_ASM_DX),%_ASM_AX\n    jae bad_get_user\n    ASM_STAC\n1:  movzbl (%_ASM_AX),%edx\n    xor %eax,%eax\n    ASM_CLAC\n    ret\nENDPROC(__get_user_1)\n\nbad_get_user:\n    xor %edx,%edx\n    mov $(-EFAULT),%_ASM_AX\n    ASM_CLAC\n    ret\nEND(bad_get_user)\n\n_ASM_EXTABLE(1b,bad_get_user)\n```\n\nThe first two instructions check the pointer against the process descriptor to make sure it's not pointer from usersapce. Then it disable SMAP (ASM_STAC) and access userspace memory (at 1: block)","snippets":["#linux"],"rawContent":"# Accessing user memory from Kernel\n#linux\n\nLinux provides `__user` annotation to mark userspace pointers. *Transfer functions* such as `copy_from_user` can only operate on those pointers. User pointers are always compared against userspace address space to avoid kernel pointers. An example of `get_user`:\n``` assembly\n.text\nENTRY(__get_user_1)\n    mov PER_CPU_VAR(current_task), %_ASM_DX\n    cmp TASK_addr_limit(%_ASM_DX),%_ASM_AX\n    jae bad_get_user\n    ASM_STAC\n1:  movzbl (%_ASM_AX),%edx\n    xor %eax,%eax\n    ASM_CLAC\n    ret\nENDPROC(__get_user_1)\n\nbad_get_user:\n    xor %edx,%edx\n    mov $(-EFAULT),%_ASM_AX\n    ASM_CLAC\n    ret\nEND(bad_get_user)\n\n_ASM_EXTABLE(1b,bad_get_user)\n```\n\nThe first two instructions check the pointer against the process descriptor to make sure it's not pointer from usersapce. Then it disable SMAP (ASM_STAC) and access userspace memory (at 1: block)\n\n\n","wordCount":104,"tags":["linux"],"metadata":{},"created":"2023-05-23T09:02:05.544541174Z","modified":"2023-05-23T09:05:34.43939562Z","checksum":"1ad3d4da984f85d73f04005f77941bd93e1d80a1842d87f790b9283e72b0c152"},
    {"filename":"2w43507r.md","filenameStem":"2w43507r","path":"2w43507r.md","absPath":"/home/khadd/mynotes/2w43507r.md","title":"Annotation vs. Language Syntax","link":"[[2w43507r]]","lead":"Checkers in C that require the programmer's annotations (@gudka2015clean) essentially try to emulate new programming language syntax. Modern languages like Rust incorporate these checks into the syntax itself.","body":"Checkers in C that require the programmer's annotations (@gudka2015clean) essentially try to emulate new programming language syntax. Modern languages like Rust incorporate these checks into the syntax itself.\n\nInventing new syntax is harder since it requires more considerations. Designing new annotations for C is easy, because they are optional.","snippets":["Checkers in C that require the programmer's annotations (@gudka2015clean) essentially try to emulate new programming language syntax. Modern languages like Rust incorporate these checks into the syntax itself."],"rawContent":"# Annotation vs. Language Syntax\n\nCheckers in C that require the programmer's annotations (@gudka2015clean) essentially try to emulate new programming language syntax. Modern languages like Rust incorporate these checks into the syntax itself.\n\nInventing new syntax is harder since it requires more considerations. Designing new annotations for C is easy, because they are optional.\n\n","wordCount":54,"tags":[],"metadata":{},"created":"2023-08-11T05:58:24.108169946Z","modified":"2023-08-11T06:24:00.447522995Z","checksum":"959c9c9532b8b5bc0280b13fdadc8ec65e10508b6de2e765ef1c2b6d00742017"},
    {"filename":"36d79g1n.md","filenameStem":"36d79g1n","path":"literature/36d79g1n.md","absPath":"/home/khadd/mynotes/literature/36d79g1n.md","title":"Autarky: Closing controlled channels with self-paging enclaves","link":"[[literature/36d79g1n]]","lead":"#literature #sgx #controlled-channel\n@orenbach2020autarky","body":"#literature #sgx #controlled-channel\n@orenbach2020autarky\n\n\n# Positioning\nThe paper's main argument against the previous work is that a *practical* solution for the control channels for SGX must be backward compatible with existing x86 software, and also the OS. Hence, solutions that employ two separate page tables, such as @aga2019invisipage, and @costan2016sanctum are not practical as they require changes to even the host OS. On the other hand, other software-only defenses (at the time of the paper, there are @shih2017tsgx, and @oleksenko2018varys) restrict the usability as forbid demand paging, have huge overheads, and are also susceptible to non-page-fault attacks that use the dirty bits [[1yhmh234]].\n\n# Non-intrusive hardware changes\nWhile introducing hardware changes, the work aims to do it in the least intrusive manner. It tries to *change only the same path that SGX's mechanisms change in x86 architectures*. This includes (1) SGX-specific checks that are performed after PTE checks during enclave mode, and (2) AEX page fault procedure ([[taztx2mo]]). \n\nFor the above reason, the paper also argues against using separated enclave page tables, as used in many clean-slate designs for TEEs (@costan2016sanctum). Such mechanisms (1) require complex collaborative page management between the host OS and the enclave (maybe @aga2019invisipage?), (2) requires new protection to prevent the enclave from mapping arbitrary host memory, and (3) require significant changes to the performance-critical portions of the MMU (e.g., the MMU need to be changed to differentiate between normal state and enclave states, and use different page tables). \n\nThe paper suggests three small changes to the current SGX scheme.\nFirst, instead of just masking the page offset in AEX page faults, the entire address is masked so that it is invisible to the host.\n\nSecond, an additional flag is introduced in the TCS called the *pending exception flag*. The bit is set when there is a page fault occurs. `ERESUME` will fail when this flag is set, and `EENTER` clears the flag. Hence, the OS is forced to use `EENTER` as a trusted enclave entry point that handles page faults. This handler can use the SSA frame to determine if an exception has occurred, and take appropriate actions defined by the software, such as ORAM-based paging. After, `EEXIT` passes the control back the the OS page fault handler, which can now use `ERESUME`, since the pending exception flag is cleared. \nOn the OS side, the EPC paging ISA (`EWB`, `ELDU`) can be used to perform enclave paging as normal. \n\n```\n  ┌────────────────────────────┐ ┌─────────────────────────────────┐\n  │ Set pending exception flag │ │ Check SSA frame to detect fault │\n  └────────────────────────────┘ └─────────────────────────────────┘\n                ▲                             ▲\n                │                             │\nEnclave      Page fault     ┌──────► Self-paging Runtime ────────┐       Fault handled\n                 │  AEX     │EENTER         │ ▲ Paging syscalls  │            ▲\n                 ▼          │  │            ▼ │                  │ EEXIT      │ ERESUME\nOS      Page fault handler ─┘  │    Autarky-aware syscalls       └─► Page fault handler\n                               ▼ \n                  ┌─────────────────────────┐\n                  │ Unset pending exception │\n                  └─────────────────────────┘\n\n```\n\n\nThe paper also suggested a *fast path* to omit the expensive context switching between enclave and OS (that includes TLB flushing): on a page fault, the CPU saves the context to the SSA, increments the SSA stack, and automatically performs enclave entry to the entry point.\n\nThird, to prevent the OS from using the dirty bit to infer page accesses, by adding a security check to *SGX-specific checks* the PTE is fetched. The check simply enforces that the access and dirty bit must be already set. This essentially renders these bits useless.\n\n*SUMMARY*: Together, these changes enable three properties: first, with the faulting address hidden, all-natural page faults are hidden from the host. Second, with the pending exception flag, all paging-related events must be notified to the enclave, so that there are no unexpected page faults. Third, the dirty/access bit in the PTE is irrelevant to an enclave's memory access pattern.\n\n# Software components\nWith the above changes, page faults on the EPC pages are hidden from the host. However, it renders demand-paging impossible, since the host does not know about faulting address. Autarky implements a *self-paging* runtime on top of the Graphine-SGX library OS so that the enclave can directly request the host OS for paging operations.\n\nFirst, Autarky split pages into OS-managed pages and enclave-managed pages.\n\nFor the first type, the access patterns are not considered sensitive, so the management of these pages is up to the OS. While it is not specified in the paper, maybe the paging runtime just forwards the faulting addresses of those pages to the OS's page fault handler, so that the OS can use `EWB`/`ELDU` to swap these pages in/out.\n\nFor the second type, page faults on these pages are considered hostile (except for the clustering and bounded leakage policiese), and the enclave may terminate the execution when there are faults. Hence, the OS must make sure that these pages are *memory-resident while the enclave is executing*. To reclaim these pages, the only option for the OS is to *swap the entire enclave out*.\n\nOn enclave-managed pages, the enclave may perform *self-paging* with the added system called `ay_fetch_pages` and `ay_evict_pages` that require the OS to fetch/evict a list of pages from/to the EPC memory. \n\nThree different policies are introduced that make use of the self-paging.\n## ORAM\nORAM policy enhanced the ORAM instrumentations used in @orenbach2019cosmix. In the original, ever memory instruction is instrumented to perform an ORAM access. \nSince enclave-managed pages are protected from the host, the paper uses those pages as a cache for ORAM. Hence, the new instrumentation looks for the page in the cache first, before requesting expensive ORAM accesses.  \n\nThis policy requires program instrumentations on memory access to perform ORAM accesses.\n\n## Clustering\nThe second policy clusters pages together so that a  group of pages is always fetched and evicted together. On a fault, the runtime requests all pages in a cluster together.\nClustering a group of pages hides the access pattern within a cluster.\n\n\nThis policy requires changes to the application to identify code/data pages that belong to a cluster.\n\n## Rate-limiting\nThe final policy aims to support unmodified applications. It clusters the code pages and introduces a page fault rate. Since there is no trusted clock inside the enclave, the rate is calculated using other events instead. The authors suggest using different rate metrics for each application; for example, page fault per socket received, or page fault per memory allocations.","snippets":["#literature #sgx #controlled-channel\n@orenbach2020autarky"],"rawContent":"# Autarky: Closing controlled channels with self-paging enclaves\n#literature #sgx #controlled-channel\n@orenbach2020autarky\n\n\n# Positioning\nThe paper's main argument against the previous work is that a *practical* solution for the control channels for SGX must be backward compatible with existing x86 software, and also the OS. Hence, solutions that employ two separate page tables, such as @aga2019invisipage, and @costan2016sanctum are not practical as they require changes to even the host OS. On the other hand, other software-only defenses (at the time of the paper, there are @shih2017tsgx, and @oleksenko2018varys) restrict the usability as forbid demand paging, have huge overheads, and are also susceptible to non-page-fault attacks that use the dirty bits [[1yhmh234]].\n\n# Non-intrusive hardware changes\nWhile introducing hardware changes, the work aims to do it in the least intrusive manner. It tries to *change only the same path that SGX's mechanisms change in x86 architectures*. This includes (1) SGX-specific checks that are performed after PTE checks during enclave mode, and (2) AEX page fault procedure ([[taztx2mo]]). \n\nFor the above reason, the paper also argues against using separated enclave page tables, as used in many clean-slate designs for TEEs (@costan2016sanctum). Such mechanisms (1) require complex collaborative page management between the host OS and the enclave (maybe @aga2019invisipage?), (2) requires new protection to prevent the enclave from mapping arbitrary host memory, and (3) require significant changes to the performance-critical portions of the MMU (e.g., the MMU need to be changed to differentiate between normal state and enclave states, and use different page tables). \n\nThe paper suggests three small changes to the current SGX scheme.\nFirst, instead of just masking the page offset in AEX page faults, the entire address is masked so that it is invisible to the host.\n\nSecond, an additional flag is introduced in the TCS called the *pending exception flag*. The bit is set when there is a page fault occurs. `ERESUME` will fail when this flag is set, and `EENTER` clears the flag. Hence, the OS is forced to use `EENTER` as a trusted enclave entry point that handles page faults. This handler can use the SSA frame to determine if an exception has occurred, and take appropriate actions defined by the software, such as ORAM-based paging. After, `EEXIT` passes the control back the the OS page fault handler, which can now use `ERESUME`, since the pending exception flag is cleared. \nOn the OS side, the EPC paging ISA (`EWB`, `ELDU`) can be used to perform enclave paging as normal. \n\n```\n  ┌────────────────────────────┐ ┌─────────────────────────────────┐\n  │ Set pending exception flag │ │ Check SSA frame to detect fault │\n  └────────────────────────────┘ └─────────────────────────────────┘\n                ▲                             ▲\n                │                             │\nEnclave      Page fault     ┌──────► Self-paging Runtime ────────┐       Fault handled\n                 │  AEX     │EENTER         │ ▲ Paging syscalls  │            ▲\n                 ▼          │  │            ▼ │                  │ EEXIT      │ ERESUME\nOS      Page fault handler ─┘  │    Autarky-aware syscalls       └─► Page fault handler\n                               ▼ \n                  ┌─────────────────────────┐\n                  │ Unset pending exception │\n                  └─────────────────────────┘\n\n```\n\n\nThe paper also suggested a *fast path* to omit the expensive context switching between enclave and OS (that includes TLB flushing): on a page fault, the CPU saves the context to the SSA, increments the SSA stack, and automatically performs enclave entry to the entry point.\n\nThird, to prevent the OS from using the dirty bit to infer page accesses, by adding a security check to *SGX-specific checks* the PTE is fetched. The check simply enforces that the access and dirty bit must be already set. This essentially renders these bits useless.\n\n*SUMMARY*: Together, these changes enable three properties: first, with the faulting address hidden, all-natural page faults are hidden from the host. Second, with the pending exception flag, all paging-related events must be notified to the enclave, so that there are no unexpected page faults. Third, the dirty/access bit in the PTE is irrelevant to an enclave's memory access pattern.\n\n# Software components\nWith the above changes, page faults on the EPC pages are hidden from the host. However, it renders demand-paging impossible, since the host does not know about faulting address. Autarky implements a *self-paging* runtime on top of the Graphine-SGX library OS so that the enclave can directly request the host OS for paging operations.\n\nFirst, Autarky split pages into OS-managed pages and enclave-managed pages.\n\nFor the first type, the access patterns are not considered sensitive, so the management of these pages is up to the OS. While it is not specified in the paper, maybe the paging runtime just forwards the faulting addresses of those pages to the OS's page fault handler, so that the OS can use `EWB`/`ELDU` to swap these pages in/out.\n\nFor the second type, page faults on these pages are considered hostile (except for the clustering and bounded leakage policiese), and the enclave may terminate the execution when there are faults. Hence, the OS must make sure that these pages are *memory-resident while the enclave is executing*. To reclaim these pages, the only option for the OS is to *swap the entire enclave out*.\n\nOn enclave-managed pages, the enclave may perform *self-paging* with the added system called `ay_fetch_pages` and `ay_evict_pages` that require the OS to fetch/evict a list of pages from/to the EPC memory. \n\nThree different policies are introduced that make use of the self-paging.\n## ORAM\nORAM policy enhanced the ORAM instrumentations used in @orenbach2019cosmix. In the original, ever memory instruction is instrumented to perform an ORAM access. \nSince enclave-managed pages are protected from the host, the paper uses those pages as a cache for ORAM. Hence, the new instrumentation looks for the page in the cache first, before requesting expensive ORAM accesses.  \n\nThis policy requires program instrumentations on memory access to perform ORAM accesses.\n\n## Clustering\nThe second policy clusters pages together so that a  group of pages is always fetched and evicted together. On a fault, the runtime requests all pages in a cluster together.\nClustering a group of pages hides the access pattern within a cluster.\n\n\nThis policy requires changes to the application to identify code/data pages that belong to a cluster.\n\n## Rate-limiting\nThe final policy aims to support unmodified applications. It clusters the code pages and introduces a page fault rate. Since there is no trusted clock inside the enclave, the rate is calculated using other events instead. The authors suggest using different rate metrics for each application; for example, page fault per socket received, or page fault per memory allocations.\n\n","wordCount":1058,"tags":["literature","sgx","controlled-channel"],"metadata":{},"created":"2023-08-30T05:27:15.018136911Z","modified":"2023-08-31T07:29:30.603033434Z","checksum":"34caaa80ecc49ac89b4de7be2d608018825309acbb747fb31bba174f3b8825eb"},
    {"filename":"lfyjdfv4.md","filenameStem":"lfyjdfv4","path":"lfyjdfv4.md","absPath":"/home/khadd/mynotes/lfyjdfv4.md","title":"Bit manipulation tricks","link":"[[lfyjdfv4]]","lead":"#programming #kernel #c #cxx","body":"#programming #kernel #c #cxx\n\n\n\n# Creating a mask with all N bit set\n```c\n#define mask(N) (1UL \u003c\u003c N) - 1\n```\nFor example, if N = 3, then the first shift will create ` 1000`. When subtracted by 1 bit, the result will be `111`\n\n# Checking if the Nth bit is set in a word\n\n```c\n#define check(word, N) (word \u0026 (1UL \u003c\u003c N))\n```\n# Clearing the Nth bit\n```c\n#define clear(word, N) (word \u0026 ~(1UL \u003c\u003c N))\n```\n# Check if a number is power of 2 \nThe key property is that if the number is the power of 2, it only has m bit set in the leftmost bit.\n```c\n#define is_power_of_2(n) ((n \u0026 (n - 1)) == 0)\n```","snippets":["#programming #kernel #c #cxx"],"rawContent":"# Bit manipulation tricks\n#programming #kernel #c #cxx\n\n\n\n# Creating a mask with all N bit set\n```c\n#define mask(N) (1UL \u003c\u003c N) - 1\n```\nFor example, if N = 3, then the first shift will create ` 1000`. When subtracted by 1 bit, the result will be `111`\n\n# Checking if the Nth bit is set in a word\n\n```c\n#define check(word, N) (word \u0026 (1UL \u003c\u003c N))\n```\n# Clearing the Nth bit\n```c\n#define clear(word, N) (word \u0026 ~(1UL \u003c\u003c N))\n```\n# Check if a number is power of 2 \nThe key property is that if the number is the power of 2, it only has m bit set in the leftmost bit.\n```c\n#define is_power_of_2(n) ((n \u0026 (n - 1)) == 0)\n```\n","wordCount":129,"tags":["programming","kernel","c","cxx"],"metadata":{},"created":"2023-07-07T04:18:00.556339409Z","modified":"2023-07-18T04:25:32.195948678Z","checksum":"4313c218c0b7504db9c206d496b2311930104e9d3632f7ac9e88f49247d3d54c"},
    {"filename":"1rqx4xia.md","filenameStem":"1rqx4xia","path":"1rqx4xia.md","absPath":"/home/khadd/mynotes/1rqx4xia.md","title":"Bits in page table entries","link":"[[1rqx4xia]]","lead":"#os #architecture","body":"#os #architecture\n\n\n# Present flag\nThe *present* flag indicates that there exists a backing physical frame for this page table entry. If the present bit is not set, a page fault will be triggered.\n\n\n# Access and dirty flags\nOn x86, bit 5 is the *accessed* flag, and bit 6 is the *dirty* flag.\n\nThe _accessed_ flag is set when a page is accessed by the CPU during address translation. The *dirty* flag is set when a page is written by the CPU. \n\nAfter being set, these flags need to be cleared by the software.\n\nThe dirty bit indicates that page must be written to the disk before the frame can be reused for other pages. Else, the page content is unchanged, so it is safe to reuse the page [standford-paging].\n\n# References\n- @2023intel\n- [standford-paging](https://web.stanford.edu/~ouster/cgi-bin/cs140-winter16/lecture.php?topic=paging)","snippets":["#os #architecture"],"rawContent":"# Bits in page table entries\n#os #architecture\n\n\n# Present flag\nThe *present* flag indicates that there exists a backing physical frame for this page table entry. If the present bit is not set, a page fault will be triggered.\n\n\n# Access and dirty flags\nOn x86, bit 5 is the *accessed* flag, and bit 6 is the *dirty* flag.\n\nThe _accessed_ flag is set when a page is accessed by the CPU during address translation. The *dirty* flag is set when a page is written by the CPU. \n\nAfter being set, these flags need to be cleared by the software.\n\nThe dirty bit indicates that page must be written to the disk before the frame can be reused for other pages. Else, the page content is unchanged, so it is safe to reuse the page [standford-paging].\n\n# References\n- @2023intel\n- [standford-paging](https://web.stanford.edu/~ouster/cgi-bin/cs140-winter16/lecture.php?topic=paging)\n","wordCount":143,"tags":["os","architecture"],"metadata":{},"created":"2023-07-20T08:50:44.822063007Z","modified":"2023-07-20T09:20:05.786649266Z","checksum":"d72e515f4683595e686ffd79b9de17de60fc9da1ecde62ce05d9883bbaaaa04d"},
    {"filename":"mwf41frv.md","filenameStem":"mwf41frv","path":"mwf41frv.md","absPath":"/home/khadd/mynotes/mwf41frv.md","title":"C programming notes","link":"[[mwf41frv]]","lead":"#programming #c #cxx","body":"#programming #c #cxx\n\n\n\n# See also\n- [[lfyjdfv4]]","snippets":["#programming #c #cxx"],"rawContent":"# C programming notes\n#programming #c #cxx\n\n\n\n# See also\n- [[lfyjdfv4]]\n\n\n","wordCount":12,"tags":["programming","c","cxx"],"metadata":{},"created":"2023-07-12T06:13:13.195027243Z","modified":"2023-07-12T06:12:46.548317919Z","checksum":"1752507878a3c1b32757ec5ee18f4977e24cf07265eb0ef57e6d5928978bff31"},
    {"filename":"zw0lj520.md","filenameStem":"zw0lj520","path":"literature/zw0lj520.md","absPath":"/home/khadd/mynotes/literature/zw0lj520.md","title":"CAP-VMs: Capability-Based Isolation and Sharing in the Cloud","link":"[[literature/zw0lj520]]","lead":"#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]","body":"#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]\n\n## One sentence summary\nThe paper built a container-like isolation abstraction on top of CHERI architecture for efficient sharing on and isolation.\n\n## Context\n### Containers vs. Virtual machines\nContainers and Virtual machines both have disadvantages for implementing isolation and sharing. See [[h3manv25]]. \n\n### Capabilities\nCheri capabilities enable in-process compartmentalization with the hybrid capability model.\n\n### Contributions\nThis paper proposed the best of both world with CHERI capabilities: *cVM*, new VM-like abstraction for cloud isolation with efficient, single-address space sharing.\n- Communication between cVMs bypass the OS with new in-process capabilities abstractions for trusted safe ipc.\n- Compatible with existing applications with the *hybrid* capability model. Only a subset of libC, the library OS, and the intravisor need to be capability-aware.\n- No namespace isolation is required, since the isolation boundary is in-process through capabilities. The OS is only needed for I/O, synchronization, execution context (similar to a VM).\n\n## System overview\nThe system introduces 2 layers of isolation. A *library OS* provides namespace isolation for and provides OS primitives for the cVMs. An *intravisor* manage cVMs instances, enable cross-communication and other primitives.\n\nThe program interacts with the libOS through the syscall interface provided by the musl libc. LibOS interact with intravisor through hostcall interface. Both interfaces are capability-ware.\n\n## APIs\nA set of APIs is provided to manage cVM and facilitate their communications.\n\nCP_FILE-based interfaces enable file-like access to other cVM memory through capability invocation.\nA cVM registers shared memory to be shared across other cVMs with a key. Other cVMs read and write into the CP-FILE obtained with the same key.\n\nCP_CALL-based interfaces allows for capability-based registration and invocation of external functions.\n\n## Capability management\nThe system revoke CAP_STORE from capabilities, preventing them from being stored into memory outside of the intra.","snippets":["#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]"],"rawContent":"# CAP-VMs: Capability-Based Isolation and Sharing in the Cloud \n#literature #capabilities #vm #os #cheri #ipc #libos #container\n[@sartakov2022capvms]\n\n## One sentence summary\nThe paper built a container-like isolation abstraction on top of CHERI architecture for efficient sharing on and isolation.\n\n## Context\n### Containers vs. Virtual machines\nContainers and Virtual machines both have disadvantages for implementing isolation and sharing. See [[h3manv25]]. \n\n### Capabilities\nCheri capabilities enable in-process compartmentalization with the hybrid capability model.\n\n### Contributions\nThis paper proposed the best of both world with CHERI capabilities: *cVM*, new VM-like abstraction for cloud isolation with efficient, single-address space sharing.\n- Communication between cVMs bypass the OS with new in-process capabilities abstractions for trusted safe ipc.\n- Compatible with existing applications with the *hybrid* capability model. Only a subset of libC, the library OS, and the intravisor need to be capability-aware.\n- No namespace isolation is required, since the isolation boundary is in-process through capabilities. The OS is only needed for I/O, synchronization, execution context (similar to a VM).\n\n## System overview\nThe system introduces 2 layers of isolation. A *library OS* provides namespace isolation for and provides OS primitives for the cVMs. An *intravisor* manage cVMs instances, enable cross-communication and other primitives.\n\nThe program interacts with the libOS through the syscall interface provided by the musl libc. LibOS interact with intravisor through hostcall interface. Both interfaces are capability-ware.\n\n## APIs\nA set of APIs is provided to manage cVM and facilitate their communications.\n\nCP_FILE-based interfaces enable file-like access to other cVM memory through capability invocation.\nA cVM registers shared memory to be shared across other cVMs with a key. Other cVMs read and write into the CP-FILE obtained with the same key.\n\nCP_CALL-based interfaces allows for capability-based registration and invocation of external functions.\n\n## Capability management\nThe system revoke CAP_STORE from capabilities, preventing them from being stored into memory outside of the intra.\n\n","wordCount":312,"tags":["literature","ipc","capabilities","vm","container","os","cheri","libos"],"metadata":{},"created":"2023-05-09T05:59:10.753515487Z","modified":"2023-05-25T05:38:14.967390445Z","checksum":"01a044e0390963119a730dacc7e174bd51f825a0dc26477d8dc8d9ea09fd18be"},
    {"filename":"icjubure.md","filenameStem":"icjubure","path":"icjubure.md","absPath":"/home/khadd/mynotes/icjubure.md","title":"Capabilities resources","link":"[[icjubure]]","lead":"- [Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes of capabilities by [[j19hdkto|Norman Hardy]] himself","body":"- [Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes of capabilities by [[j19hdkto|Norman Hardy]] himself","snippets":["- [Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes of capabilities by [[j19hdkto|Norman Hardy]] himself"],"rawContent":"# Capabilities resources\n\n- [Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes of capabilities by [[j19hdkto|Norman Hardy]] himself\n\n\n","wordCount":16,"tags":[],"metadata":{},"created":"2023-05-22T02:06:14.456402687Z","modified":"2023-05-17T05:11:30.05308355Z","checksum":"e4175df3f803f26504b342cf7a11b48ce48ab89eac869b81b8baba45f7f962be"},
    {"filename":"douswvq0.md","filenameStem":"douswvq0","path":"fleeting/douswvq0.md","absPath":"/home/khadd/mynotes/fleeting/douswvq0.md","title":"Compartment-aware hardening","link":"[[fleeting/douswvq0]]","lead":"#fleeting #idea","body":"#fleeting #idea\n \n\n# Background\nSoftware defenses such as DFI/CPI/CFI see the program at one unit.\n\nEfforts in compartmentalization brings the boundary to within the program. \n\n\n# Main arguments\nExisting software hardening techniques are not compartment-aware, so they miss classes of attacks on compartment interfaces.\n\nMaking them compartment-aware requires some static / runtime analysis at the boundary.\n\n\n# Compartment-aware CFI\nCFI type matching + compartment-aware narrowing for cross-compartment indirect calls\ne.g., A site can only call type B from compartment X.\n\n# Compartment-aware DFI\nAssuming data isolation between domains.\nDFI only for cross-domain objects.\n- Use static analysis to determine subset of sensitive objects.\n- We enforce DFI on them.\n\nThis has sanitizing effect, remove CIV.","snippets":["#fleeting #idea"],"rawContent":"# Compartment-aware hardening\n#fleeting #idea\n \n\n# Background\nSoftware defenses such as DFI/CPI/CFI see the program at one unit.\n\nEfforts in compartmentalization brings the boundary to within the program. \n\n\n# Main arguments\nExisting software hardening techniques are not compartment-aware, so they miss classes of attacks on compartment interfaces.\n\nMaking them compartment-aware requires some static / runtime analysis at the boundary.\n\n\n# Compartment-aware CFI\nCFI type matching + compartment-aware narrowing for cross-compartment indirect calls\ne.g., A site can only call type B from compartment X.\n\n# Compartment-aware DFI\nAssuming data isolation between domains.\nDFI only for cross-domain objects.\n- Use static analysis to determine subset of sensitive objects.\n- We enforce DFI on them.\n\nThis has sanitizing effect, remove CIV.\n\n\n\n\n\n\n\n\n\n\n\n\n","wordCount":118,"tags":["fleeting","idea"],"metadata":{},"created":"2023-05-22T02:06:14.454679208Z","modified":"2023-05-22T02:03:53.601483238Z","checksum":"06d48b7b6ff77b495bbc567181a1c7c9dc18cb64107de5dd989c6d98c4bbf5e2"},
    {"filename":"pc1fa30d.md","filenameStem":"pc1fa30d","path":"pc1fa30d.md","absPath":"/home/khadd/mynotes/pc1fa30d.md","title":"Concepts of an Operating System","link":"[[pc1fa30d]]","lead":"","body":"","snippets":[],"rawContent":"# Concepts of an Operating System\n\n\n","wordCount":6,"tags":[],"metadata":{},"created":"2023-05-24T06:18:34.119318615Z","modified":"2023-05-24T06:18:34.116650093Z","checksum":"6c2c4935bd31a4f174099abdfe2c80525dfc3a73f8d463122cf2ef6d7efd48d8"},
    {"filename":"y9wu5ut7.md","filenameStem":"y9wu5ut7","path":"y9wu5ut7.md","absPath":"/home/khadd/mynotes/y9wu5ut7.md","title":"Confused deputy","link":"[[y9wu5ut7]]","lead":"#capabilities #compartmentalization","body":"#capabilities #compartmentalization\n\n\nA confused deputy happens when a high-privilege system is tricked into performing a certain action on behalf of a lower-privilege system.\n\n## An example\nThe example used in the original paper [@hardy1988confused] is a compiler program. A user invoke the compiler with the name of the input file to compile a program, and also an output file to receive statistics.\nThe compiler is given the authority to write into its home directory. Let's say there is another file in the home directory of the compiler that contains the billing information. A malicious user of the compiler can invoke it to trick the compiler into writing into the billing file since it is within the authority of the compiler.\n\nIn a sense, a confused deputy happens due to the *ambient authority*. In the compiler case, the compiler user obtains more authority than needed (access to the whole home directory) to perfrom it job (read input, write output). \n\nTo solve this problem, a naive solution would be to switch the authority of the compiler (through some system call) to that of the invoker. However, such a system would leads to complexity when there is a high amount of authorities, and also hard to generalize [@hardy1988confused]. \n\n## Interface vulnerabilities\nInterface vulnerabilities is a manifestation of confused deputy problem, where different mutually distrusting entities interacts with each other through exposed interfaces [@lefeuvre2022assessing]. For instance, a malicious process can exploit the system call interface to tricking the kernel into corrupting itself. Interface vulnerabilites is also there at other boundaries, such as libraries, in-process compartments [@lefeuvre2022assessing].","snippets":["#capabilities #compartmentalization"],"rawContent":"# Confused deputy\n#capabilities #compartmentalization\n\n\nA confused deputy happens when a high-privilege system is tricked into performing a certain action on behalf of a lower-privilege system.\n\n## An example\nThe example used in the original paper [@hardy1988confused] is a compiler program. A user invoke the compiler with the name of the input file to compile a program, and also an output file to receive statistics.\nThe compiler is given the authority to write into its home directory. Let's say there is another file in the home directory of the compiler that contains the billing information. A malicious user of the compiler can invoke it to trick the compiler into writing into the billing file since it is within the authority of the compiler.\n\nIn a sense, a confused deputy happens due to the *ambient authority*. In the compiler case, the compiler user obtains more authority than needed (access to the whole home directory) to perfrom it job (read input, write output). \n\nTo solve this problem, a naive solution would be to switch the authority of the compiler (through some system call) to that of the invoker. However, such a system would leads to complexity when there is a high amount of authorities, and also hard to generalize [@hardy1988confused]. \n\n## Interface vulnerabilities\nInterface vulnerabilities is a manifestation of confused deputy problem, where different mutually distrusting entities interacts with each other through exposed interfaces [@lefeuvre2022assessing]. For instance, a malicious process can exploit the system call interface to tricking the kernel into corrupting itself. Interface vulnerabilites is also there at other boundaries, such as libraries, in-process compartments [@lefeuvre2022assessing].\n\n","wordCount":265,"tags":["capabilities","compartmentalization"],"metadata":{},"created":"2024-05-20T09:23:11.423316875Z","modified":"2024-05-20T09:23:22.665864589Z","checksum":"f2412294d4044c275255b20992776929fbc7f2230eb808d902eea569f3c574a5"},
    {"filename":"h3manv25.md","filenameStem":"h3manv25","path":"h3manv25.md","absPath":"/home/khadd/mynotes/h3manv25.md","title":"Containers vs. Virtual machines","link":"[[h3manv25]]","lead":"#vm #container #cloud #ipc #os #virtualization","body":"#vm #container #cloud #ipc #os #virtualization\n\nContainers and virtual machines ([[s16ct1rj]]) are two main isolation primitives when it come to cloud isolation.\n\nVirtual machines provides strong isolation between application components and a small TCB a small hypervisor need to be trusted. \nHowever, data sharing between VMs is challenging and commonly have high overheads (see [@yasukata2023exitless]).\n\nOn the other hand, containers allows application components to share the underlying OS. This enable richer IPC mechanisms for better data sharing. This comes at the cost of larger TCB: a shared OS have to implement namespace isolation and complex IPC primitives [@sartakov2022capvms]. \n\nStill, sharing is coarse-grained in both of the case, since the IPC interfaces are designed at page granularity. \nSharing is also expensive. VMFUNC-based sharing in VMs have expensive cost of VMEEXIT, which exit-less mechanisms tries to achieve [@yasukata2023exitless].","snippets":["#vm #container #cloud #ipc #os #virtualization"],"rawContent":"# Containers vs. Virtual machines\n#vm #container #cloud #ipc #os #virtualization\n\nContainers and virtual machines ([[s16ct1rj]]) are two main isolation primitives when it come to cloud isolation.\n\nVirtual machines provides strong isolation between application components and a small TCB a small hypervisor need to be trusted. \nHowever, data sharing between VMs is challenging and commonly have high overheads (see [@yasukata2023exitless]).\n\nOn the other hand, containers allows application components to share the underlying OS. This enable richer IPC mechanisms for better data sharing. This comes at the cost of larger TCB: a shared OS have to implement namespace isolation and complex IPC primitives [@sartakov2022capvms]. \n\nStill, sharing is coarse-grained in both of the case, since the IPC interfaces are designed at page granularity. \nSharing is also expensive. VMFUNC-based sharing in VMs have expensive cost of VMEEXIT, which exit-less mechanisms tries to achieve [@yasukata2023exitless].  \n\n\n\n\n\n\n","wordCount":141,"tags":["ipc","vm","cloud","container","os","virtualization"],"metadata":{},"created":"2023-05-10T06:48:13.569982345Z","modified":"2023-05-25T05:37:04.227136002Z","checksum":"fbca22c2e2781ec8e5c39520ee9fb9183c0eb3f916b11e35b36879691cdcbf2e"},
    {"filename":"c6cpkdl9.md","filenameStem":"c6cpkdl9","path":"c6cpkdl9.md","absPath":"/home/khadd/mynotes/c6cpkdl9.md","title":"Context-sensitive heap modeling","link":"[[c6cpkdl9]]","lead":"#analysis #points-to-analysis","body":"#analysis #points-to-analysis\n\nPoints-to analysis often requre heap modeling, which is essentially tracking which functions can allocate pointers. Commonly, you would hard-code the allocation function name (e.g., `malloc`), and assume that the function returns a heap object.\n\nHowever, things get compilated when allocator wrappers are used.\nThis is troublesome for automated analysis in certain cases. Consider the following code. Something like this is commonly seen in C libraries.\n\n\n\n```c \nkey_t* key_alloc(){\n  return malloc(sizeof(key_t));\n}\nvoid fee(){\n  void* buf = malloc(512);\n  unsafe_access(buf);\n}\nvoid foo(){ \n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\nIn Rust, there are also similar cases. `Box\u003cT\u003e` abstracts away the malloc call.\n\nLet say we want to replace all object touched by `unsafe_access` with a different allocator. Points-to analysis is needed for this case. For `fee`, it is straightforward, since the analysis can immediately find the allocation function. However, for `foo`, there is a complication. If we perform a *context-insensitive* points-to analysis on on the key access, the result will contains *all* pointers that are allocated using `key_alloc()`.\n\nHence, a *context-sensitve* analysis is needed for modeling the heap in this case.\n\nThere are two methods to achieve context sensitivity. The first is to just use a *context-senstive* analysis, which is very expensive.\n\nThe second is to perform cloning to introduce context senstivity. In the above example, cloning key_alloc into `unsafe_key_alloc` and `key_alloc_safe` , and replace the key_alloc call would differentiate the heap context between foo and bar. \n```c\nvoid foo(){ \n  key_t* key = key_alloc_unsafe();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc_safe();\n  safe_access(key);\n}\n```\n\nAnother challenge here is to identify which *depth* to clone. \n```c\nkey_t* special_key_alloc(){\n  key_t *key = key_alloc();\n  key-\u003etype = SPECIAL;\n  return key;\n}\nvoid fez(){\n  key_t  *key = special_key_alloc();\n  unsafe_access(key);\n}\nvoid fiz(){\n  key_t  *key = special_key_alloc();\n  safe_access(key);\n}\nvoid foo(){ \n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\nIn the above example, we need to clone the contexts for all 4 functions.","snippets":["#analysis #points-to-analysis"],"rawContent":"# Context-sensitive heap modeling\n#analysis #points-to-analysis\n\nPoints-to analysis often requre heap modeling, which is essentially tracking which functions can allocate pointers. Commonly, you would hard-code the allocation function name (e.g., `malloc`), and assume that the function returns a heap object.\n\nHowever, things get compilated when allocator wrappers are used.\nThis is troublesome for automated analysis in certain cases. Consider the following code. Something like this is commonly seen in C libraries.\n\n\n\n```c \nkey_t* key_alloc(){\n  return malloc(sizeof(key_t));\n}\nvoid fee(){\n  void* buf = malloc(512);\n  unsafe_access(buf);\n}\nvoid foo(){ \n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\nIn Rust, there are also similar cases. `Box\u003cT\u003e` abstracts away the malloc call.\n\nLet say we want to replace all object touched by `unsafe_access` with a different allocator. Points-to analysis is needed for this case. For `fee`, it is straightforward, since the analysis can immediately find the allocation function. However, for `foo`, there is a complication. If we perform a *context-insensitive* points-to analysis on on the key access, the result will contains *all* pointers that are allocated using `key_alloc()`.\n\nHence, a *context-sensitve* analysis is needed for modeling the heap in this case.\n\nThere are two methods to achieve context sensitivity. The first is to just use a *context-senstive* analysis, which is very expensive.\n\nThe second is to perform cloning to introduce context senstivity. In the above example, cloning key_alloc into `unsafe_key_alloc` and `key_alloc_safe` , and replace the key_alloc call would differentiate the heap context between foo and bar. \n```c\nvoid foo(){ \n  key_t* key = key_alloc_unsafe();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc_safe();\n  safe_access(key);\n}\n```\n\nAnother challenge here is to identify which *depth* to clone. \n```c\nkey_t* special_key_alloc(){\n  key_t *key = key_alloc();\n  key-\u003etype = SPECIAL;\n  return key;\n}\nvoid fez(){\n  key_t  *key = special_key_alloc();\n  unsafe_access(key);\n}\nvoid fiz(){\n  key_t  *key = special_key_alloc();\n  safe_access(key);\n}\nvoid foo(){ \n  key_t* key = key_alloc();\n  unsafe_access(key);\n}\nvoid bar(){\n  key_t* key = key_alloc();\n  safe_access(key);\n}\n```\nIn the above example, we need to clone the contexts for all 4 functions.\n","wordCount":338,"tags":["analysis","points-to-analysis"],"metadata":{},"created":"2023-06-01T02:38:33.806452991Z","modified":"2024-05-20T09:21:14.015132153Z","checksum":"dd09849fa144a099f92a7eee0e4a8060efaabff2e8cd8ebc6f16ea95099309cf"},
    {"filename":"1yhmh234.md","filenameStem":"1yhmh234","path":"1yhmh234.md","absPath":"/home/khadd/mynotes/1yhmh234.md","title":"Controlled-channel Attacks","link":"[[1yhmh234]]","lead":"#attack #tee #sgx","body":"#attack #tee #sgx\n\nControlled-channel attack refers to attacks launched by the higher-privilege system against the lower-privilege one. The confidential lower-privilege system (SGX, VM) lacks capabilities (e.g., paging, file access), and needs to request the higher-privilege system (OS, hypervisor) for resources. The higher-privilege can use this controlled channel to monitor the lower-privilege one. This scenario happens especially in a confidential execution environment, where the protected program does not trust the underlying infrastructure, or cloud service provider (CSP).","snippets":["#attack #tee #sgx"],"rawContent":"# Controlled-channel Attacks\n#attack #tee #sgx\n\nControlled-channel attack refers to attacks launched by the higher-privilege system against the lower-privilege one. The confidential lower-privilege system (SGX, VM) lacks capabilities (e.g., paging, file access), and needs to request the higher-privilege system (OS, hypervisor) for resources. The higher-privilege can use this controlled channel to monitor the lower-privilege one. This scenario happens especially in a confidential execution environment, where the protected program does not trust the underlying infrastructure, or cloud service provider (CSP).\n\n","wordCount":79,"tags":["sgx","tee","attack"],"metadata":{},"created":"2023-05-25T09:32:00.071940821Z","modified":"2023-08-30T05:50:29.805705301Z","checksum":"eb13b907208744cb3f652a0945829b7243c22e12cec2d4fb3d44f931ed4ba17c"},
    {"filename":"qq4qcbos.md","filenameStem":"qq4qcbos","path":"qq4qcbos.md","absPath":"/home/khadd/mynotes/qq4qcbos.md","title":"Controlled-channel attacks against SEV","link":"[[qq4qcbos]]","lead":"#controlled-channel #side-channel #sev #tee","body":"#controlled-channel #side-channel #sev #tee\n\n# Nested page fault side-channels\nVirtualization hardware enables two-stage translation process from gVA to gPA, and from gPA to hPA through the nested page table (NPT) ([[d3nt6uix]]). This is the same in SEV. Although there is no official documentation, many paper indicate that hypervisor cannot intercept guest page faults (gPF) and look for faulting address.\n\nPage fault attacks in SEV is similar to the controlled-channel attacks on SGX @xu2015controlledchannel. \nThe hypervisor can unset the present bit (`P` bit) in the NPT for particular physical pages, such that nested page fault (NPF) will be generated when the page is accessed by the VM, which the hypervisor can capture and analyze.\n\n# IO events\nSome applications requiring I/O events can leak certain behaviors of the program. For instance, @morbitzer2019extracting, @li2019exploiting use network packets to determine the start/end of a TLS connection, and disk I/O to determine disk encryption operation.\n\n\n# Related notes\n- @li2019exploiting: [[literature/ncfh611p]]","snippets":["#controlled-channel #side-channel #sev #tee"],"rawContent":"# Controlled-channel attacks against SEV\n#controlled-channel #side-channel #sev #tee\n\n# Nested page fault side-channels\nVirtualization hardware enables two-stage translation process from gVA to gPA, and from gPA to hPA through the nested page table (NPT) ([[d3nt6uix]]). This is the same in SEV. Although there is no official documentation, many paper indicate that hypervisor cannot intercept guest page faults (gPF) and look for faulting address.\n\nPage fault attacks in SEV is similar to the controlled-channel attacks on SGX @xu2015controlledchannel. \nThe hypervisor can unset the present bit (`P` bit) in the NPT for particular physical pages, such that nested page fault (NPF) will be generated when the page is accessed by the VM, which the hypervisor can capture and analyze.\n\n# IO events\nSome applications requiring I/O events can leak certain behaviors of the program. For instance, @morbitzer2019extracting, @li2019exploiting use network packets to determine the start/end of a TLS connection, and disk I/O to determine disk encryption operation.\n\n\n# Related notes\n- @li2019exploiting: [[literature/ncfh611p]]\n","wordCount":162,"tags":["tee","sev","controlled-channel","side-channel"],"metadata":{},"created":"2023-06-19T06:44:04.882184776Z","modified":"2023-07-04T04:09:27.095621492Z","checksum":"e3d7b4385bb89907a20faf04b9ffb37bf87bb5b6db63a8ed5f544fc66d2654a7"},
    {"filename":"i2blyo37.md","filenameStem":"i2blyo37","path":"i2blyo37.md","absPath":"/home/khadd/mynotes/i2blyo37.md","title":"Cost of IPC in microkernels","link":"[[i2blyo37]]","lead":"#microkernel #sel4 #ipc #kpti #os","body":"#microkernel #sel4 #ipc #kpti #os\n\nIn microkernels such as sel4, kernel code is kept to the minimum, and most of the system services such as file system, and networking is moved into the userspace as a *system server*. Applications that uses those services need to invoke them through *IPCs*.\nSince those services are in the userspace in different address spaces, an IPC would consists of:\n1. Privilege switch to from application the kernel\n2. Process switch to the callee process\n3. Privilege switch to the callee  \n2. Process switch back to the caller  process\n4. Privilege switch from kernel to the caller\n\n## Overhead analysis\n[@gu2020harmonizing] (see [[literature/2a7l7odo]]) performed a study of the source of overheads of such IPC. SQLite3 is ran on Zircon and seL4 microkernels. It is found that total IPC time is 79% of the time on Zircon and 44% of the time on seL4 (with KPTI).\n\nThe overheads of each component are also studied in the following table. \n\n|   Parts  | w/o KPTI    | w/ KPTI    |\n| ---------------- | --------------- | --------------- |\n| Privilege switch    | 158    | 690    |\n|  Process switch    | 295    | included above    |\n| Others   | 277   | 320   |\n| Total   | 730   | 1010   |\n\n*Privilege switch* is the overhead of a syscall instruction.\n*Process switch* is mostly changing the page table by writing into CR3 register (about 270 cycles). With KPTI enabled, an additional page table switch needs to be added to every user-to-kernel privilege switch, which adds another layer of overheads. \nAdditionally, there are also other types of overheads such permission checks, capabilities checks.","snippets":["#microkernel #sel4 #ipc #kpti #os"],"rawContent":"# Cost of IPC in microkernels\n#microkernel #sel4 #ipc #kpti #os\n\nIn microkernels such as sel4, kernel code is kept to the minimum, and most of the system services such as file system, and networking is moved into the userspace as a *system server*. Applications that uses those services need to invoke them through *IPCs*.\nSince those services are in the userspace in different address spaces, an IPC would consists of:\n1. Privilege switch to from application the kernel\n2. Process switch to the callee process\n3. Privilege switch to the callee  \n2. Process switch back to the caller  process\n4. Privilege switch from kernel to the caller\n\n## Overhead analysis\n[@gu2020harmonizing] (see [[literature/2a7l7odo]]) performed a study of the source of overheads of such IPC. SQLite3 is ran on Zircon and seL4 microkernels. It is found that total IPC time is 79% of the time on Zircon and 44% of the time on seL4 (with KPTI).\n\nThe overheads of each component are also studied in the following table. \n\n|   Parts  | w/o KPTI    | w/ KPTI    |\n| ---------------- | --------------- | --------------- |\n| Privilege switch    | 158    | 690    |\n|  Process switch    | 295    | included above    |\n| Others   | 277   | 320   |\n| Total   | 730   | 1010   |\n\n*Privilege switch* is the overhead of a syscall instruction.\n*Process switch* is mostly changing the page table by writing into CR3 register (about 270 cycles). With KPTI enabled, an additional page table switch needs to be added to every user-to-kernel privilege switch, which adds another layer of overheads. \nAdditionally, there are also other types of overheads such permission checks, capabilities checks.\n\n","wordCount":276,"tags":["microkernel","sel4","ipc","kpti","os"],"metadata":{},"created":"2023-05-08T04:00:25.410180908Z","modified":"2023-05-22T07:44:43.599535593Z","checksum":"50f0400b3dcba5e975fec68d64b638b9496351d6226f3aa278587b8a3c39bbb4"},
    {"filename":"v2qcb4lm.md","filenameStem":"v2qcb4lm","path":"projects/v2qcb4lm.md","absPath":"/home/khadd/mynotes/projects/v2qcb4lm.md","title":"Cryptographic Capabilities for efficient Microkernel Access Control","link":"[[projects/v2qcb4lm]]","lead":"#project","body":"#project\n\n## Introduction\n### Microkernel is efficient and secure\n\n### Main overheads in Microkernels is IPC \n\n### Capability management and permission checks is one of the main overheads\n\n### Cryptographic capabilities eliminates the need for capability management\n\n\n## References\n\n[@sartakov2022capvms]\n@gu2020harmonizing","snippets":["#project"],"rawContent":"# Cryptographic Capabilities for efficient Microkernel Access Control\n#project\n\n## Introduction\n### Microkernel is efficient and secure\n\n### Main overheads in Microkernels is IPC \n\n### Capability management and permission checks is one of the main overheads\n\n### Cryptographic capabilities eliminates the need for capability management\n\n\n## References\n\n[@sartakov2022capvms]\n@gu2020harmonizing\n","wordCount":49,"tags":["project"],"metadata":{},"created":"2023-05-08T05:18:51.280558789Z","modified":"2023-05-10T05:41:26.48601012Z","checksum":"6845fb5f5812719bd39d49dce6016b996b3c7e47abd1b99979e2d5f74bc4f5e1"},
    {"filename":"s1icecys.md","filenameStem":"s1icecys","path":"s1icecys.md","absPath":"/home/khadd/mynotes/s1icecys.md","title":"Danish conference Visa from Korea","link":"[[s1icecys]]","lead":"#visa","body":"#visa\n\n\n\nYou have to go through the Swedish embassy in Korea. The process is the same as applying for a Swedish visa.\n\n\n# Documents\n\n- have a passport that is valid for at least three months after the visa has expired, was issued in the last ten years and has at least two empty pages\n- be able to describe the purpose of your visit\n- have an invitation from the company or the person that is arranging the conference\n- have money to support yourself and for the return trip home (Sweden also requires you to have 450 SEK for each day you stay in Sweden, which can also be paid for by the company that has invited you)\n- have an individual medical travel insurance that covers all costs that may arise in connection with emergency medical treatment, urgent medical care or transportation to your home country for medical reasons (the insurance must cover costs of at least 30,000 EUR and be valid for all Schengen countries)\n- show that you intend to leave Sweden and the Schengen area on the last day before the visa expires\n- a photograph that is in passport format and taken with you facing the camera and which is not older than six months\n- other documents that the embassy may require.\n\n\n# Process\n1. Apply online at https://www.migrationsverket.se/\n2. Wait for result\n\n# References\n- https://www.migrationsverket.se/English/Private-individuals/Visiting-Sweden/Visit-Sweden-for-less-than-90-days---apply-for-a-visa.html","snippets":["#visa"],"rawContent":"# Danish conference Visa from Korea\n#visa\n\n\n\nYou have to go through the Swedish embassy in Korea. The process is the same as applying for a Swedish visa.\n\n\n# Documents\n\n- have a passport that is valid for at least three months after the visa has expired, was issued in the last ten years and has at least two empty pages\n- be able to describe the purpose of your visit\n- have an invitation from the company or the person that is arranging the conference\n- have money to support yourself and for the return trip home (Sweden also requires you to have 450 SEK for each day you stay in Sweden, which can also be paid for by the company that has invited you)\n- have an individual medical travel insurance that covers all costs that may arise in connection with emergency medical treatment, urgent medical care or transportation to your home country for medical reasons (the insurance must cover costs of at least 30,000 EUR and be valid for all Schengen countries)\n- show that you intend to leave Sweden and the Schengen area on the last day before the visa expires\n- a photograph that is in passport format and taken with you facing the camera and which is not older than six months\n- other documents that the embassy may require.\n\n\n# Process\n1. Apply online at https://www.migrationsverket.se/\n2. Wait for result\n\n# References\n- https://www.migrationsverket.se/English/Private-individuals/Visiting-Sweden/Visit-Sweden-for-less-than-90-days---apply-for-a-visa.html\n","wordCount":241,"tags":["visa"],"metadata":{},"created":"2023-08-21T04:30:49.689187197Z","modified":"2023-08-21T04:34:39.477270251Z","checksum":"a1285c40bf52fc80a4fa49311c435933d277894421d205575923c32c42a69bcd"},
    {"filename":"zzq5zy5v.md","filenameStem":"zzq5zy5v","path":"zzq5zy5v.md","absPath":"/home/khadd/mynotes/zzq5zy5v.md","title":"Detecting bugs in Rust","link":"[[zzq5zy5v]]","lead":"#rust","body":"#rust\n\n\n# Rudra\nRudra @bae2021rudra analyzes Rust HIR and MIR to have a *generic type-aware* analysis.\nGeneric type-awareness is necessary, because a certain bugs only happen for the implementation of specific types.\n\n```rust\nfn double_drop\u003cT\u003e (mut val: T){\n  unsafe {ptr::drop_in_place(\u0026mut val);}\n  drop(val);\n}\ndouble_drop(123); // no violation since drop on integer is no-op\ndouble_drop(vec![1, 2, 3]); // double-free happens\n```\n\nMore specifically, Rudra consider a generic function having bugs, if any of the instantiation has a safety bug.\n\n## Unsafe Dataflow Checker\nThis checker simply find if their exists a dataflow from the start of lifetime bypass to a suspicious function call. The hope is to find dataflwo from unsafe into functions that might `panic`, or functions that might implicitly requires some higher-order invariants (but not upholded by the unsafe caller).\n\nIt is suprising that this simple heuristic helps finds a lot of bugs. On the other hand, it has very high false positive rate (53.3% precision on highest precision). \nMoreover, this kind of heuristic is coarse-grained, it does not try to identify the *root cause* of the bug, but instead finds pattern that commonly have bugs,and rely on the programmer instead instead to filter out the bugs.\n\n\nThere are two heuristics used by this checker,  to determine the lifetime bypass locations, and to determine suspicious function calls.\n\n### Suspicious function calls\nThis check marks all *unresolvable generic function call* as suspicious. Unresolvable functions are functions that their definitions cannot be found without precise type parameters. \nAn example was:\n```rust\nfn foo\u003cT\u003e(reader: T)\n  where T: Reader {\n  reader::read();\n}\n\n```\n\nIn this case, to know the definition of `read()`, the type of `reader` must be known, but it is available at runtime. On the other hand, `Vec\u003cT\u003e::push()` has implementation of `push()` implemeted for all possible type `T`.\n\nThe author finds that those unresolable function are where programmers usually make mistake, since they have to *speculate* about the function behaviors.\n\n\n\n\n\n### Lifetime bypass locations\nThere are six classes of lifetime bypasses:\n- Unintialized value (created by extending `Vec` with `Vec::set_len()`)\n- Duplicating lifetime (e.g., `mem::read()`)\n- Overwriting memory (e.g., `mem::write`)\n- Copying values (e.g., buffer copy) (this has the effect of duplicating and overwriting)\n- Transmuting a type and its lifetime\n- Converting a pointer to a reference\n\nRudra uses three precision settings:\n- High precision only detect uninitialized values (e.g., `Vec::set_len()`)\n- Medium precision setting additionally find lifetime bypass using `read()`, `write()`, `copy()`.\n- Low precision setting find all `transmute()`a and raw pointer casting.","snippets":["#rust"],"rawContent":"# Detecting bugs in Rust\n#rust\n\n\n# Rudra\nRudra @bae2021rudra analyzes Rust HIR and MIR to have a *generic type-aware* analysis.\nGeneric type-awareness is necessary, because a certain bugs only happen for the implementation of specific types.\n\n```rust\nfn double_drop\u003cT\u003e (mut val: T){\n  unsafe {ptr::drop_in_place(\u0026mut val);}\n  drop(val);\n}\ndouble_drop(123); // no violation since drop on integer is no-op\ndouble_drop(vec![1, 2, 3]); // double-free happens\n```\n\nMore specifically, Rudra consider a generic function having bugs, if any of the instantiation has a safety bug.\n\n## Unsafe Dataflow Checker\nThis checker simply find if their exists a dataflow from the start of lifetime bypass to a suspicious function call. The hope is to find dataflwo from unsafe into functions that might `panic`, or functions that might implicitly requires some higher-order invariants (but not upholded by the unsafe caller).\n\nIt is suprising that this simple heuristic helps finds a lot of bugs. On the other hand, it has very high false positive rate (53.3% precision on highest precision). \nMoreover, this kind of heuristic is coarse-grained, it does not try to identify the *root cause* of the bug, but instead finds pattern that commonly have bugs,and rely on the programmer instead instead to filter out the bugs.\n\n\nThere are two heuristics used by this checker,  to determine the lifetime bypass locations, and to determine suspicious function calls.\n\n### Suspicious function calls\nThis check marks all *unresolvable generic function call* as suspicious. Unresolvable functions are functions that their definitions cannot be found without precise type parameters. \nAn example was:\n```rust\nfn foo\u003cT\u003e(reader: T)\n  where T: Reader {\n  reader::read();\n}\n\n```\n\nIn this case, to know the definition of `read()`, the type of `reader` must be known, but it is available at runtime. On the other hand, `Vec\u003cT\u003e::push()` has implementation of `push()` implemeted for all possible type `T`.\n\nThe author finds that those unresolable function are where programmers usually make mistake, since they have to *speculate* about the function behaviors.\n\n\n\n\n\n### Lifetime bypass locations\nThere are six classes of lifetime bypasses:\n- Unintialized value (created by extending `Vec` with `Vec::set_len()`)\n- Duplicating lifetime (e.g., `mem::read()`)\n- Overwriting memory (e.g., `mem::write`)\n- Copying values (e.g., buffer copy) (this has the effect of duplicating and overwriting)\n- Transmuting a type and its lifetime\n- Converting a pointer to a reference\n\nRudra uses three precision settings:\n- High precision only detect uninitialized values (e.g., `Vec::set_len()`)\n- Medium precision setting additionally find lifetime bypass using `read()`, `write()`, `copy()`.\n- Low precision setting find all `transmute()`a and raw pointer casting.\n","wordCount":419,"tags":["rust"],"metadata":{},"created":"2024-05-20T09:23:13.179473981Z","modified":"2023-06-15T08:32:42.341179398Z","checksum":"73cc8eb98a7406f0beea9e1dc18a6ff639f41d1e9f3c7555f7111514832e6da5"},
    {"filename":"f25v3txq.md","filenameStem":"f25v3txq","path":"f25v3txq.md","absPath":"/home/khadd/mynotes/f25v3txq.md","title":"Do only what only you can do","link":"[[f25v3txq]]","lead":"#quote","body":"#quote\n\nit the advice given by Dijkstra when asked how to select research topic.","snippets":["#quote"],"rawContent":"# Do only what only you can do\n#quote\n\nit the advice given by Dijkstra when asked how to select research topic. \n\n\n","wordCount":22,"tags":["quote"],"metadata":{},"created":"2023-05-26T02:17:58.496798368Z","modified":"2023-05-26T02:19:06.086842332Z","checksum":"8108c84fb453ce3c07f2dec916466bed2ff4ddab090647ae62bccdf84bae7d38"},
    {"filename":"nr81p506.md","filenameStem":"nr81p506","path":"nr81p506.md","absPath":"/home/khadd/mynotes/nr81p506.md","title":"EFI Stuff","link":"[[nr81p506]]","lead":"## Add boot order in UEFI shell\n```\n# List boot entries\nbcfg boot dump -b \n# Remove entry 0\nbcfg boot rm 0\nbcfg boot mv 2 3\n// Harcoding this to \nbcfg boot add 0 FS0:\\EFI\\BOOT\\BOOTX64.EFI \"unikraft\"\n```","body":"## Add boot order in UEFI shell\n```\n# List boot entries\nbcfg boot dump -b \n# Remove entry 0\nbcfg boot rm 0\nbcfg boot mv 2 3\n// Harcoding this to \nbcfg boot add 0 FS0:\\EFI\\BOOT\\BOOTX64.EFI \"unikraft\"\n```","snippets":["## Add boot order in UEFI shell\n```\n# List boot entries\nbcfg boot dump -b \n# Remove entry 0\nbcfg boot rm 0\nbcfg boot mv 2 3\n// Harcoding this to \nbcfg boot add 0 FS0:\\EFI\\BOOT\\BOOTX64.EFI \"unikraft\"\n```"],"rawContent":"# EFI Stuff\n\n## Add boot order in UEFI shell\n```\n# List boot entries\nbcfg boot dump -b \n# Remove entry 0\nbcfg boot rm 0\nbcfg boot mv 2 3\n// Harcoding this to \nbcfg boot add 0 FS0:\\EFI\\BOOT\\BOOTX64.EFI \"unikraft\"\n```\n\n\n","wordCount":43,"tags":[],"metadata":{},"created":"2023-09-22T11:04:45.490497794Z","modified":"2023-09-22T11:06:41.931532919Z","checksum":"edf9870fec31fe83a1ce5f23bec60f219d9ec0b992f5c57a93c56e1f102e5408"},
    {"filename":"9zudb41g.md","filenameStem":"9zudb41g","path":"9zudb41g.md","absPath":"/home/khadd/mynotes/9zudb41g.md","title":"Emulating x86 push and pop on ARM","link":"[[9zudb41g]]","lead":"#assembly #arm","body":"#assembly #arm\n\nAlthough there is no push and pop instructions, Arm support addressing modes that can both update and address memory. This can be used to implement stack push and pop\nMore concretely, post-indexing is used for push, and pre-indexing is used for pop\n\nPre-indexing update the address register *before* the store, which is essentialy the same as x86 push instruction that decrease the stack pointer, then store the value\n``` asm\nstr x1, [sp, -#16]!\n```\n\nPre-index addressing update the address register after the store. \n``` asm\nldr x1, [sp] #16\n```\n\nSource: [Addressing Lab](https://www.cs.uregina.ca/Links/class-info/301/ARM-addressing/lecture.html)","snippets":["#assembly #arm"],"rawContent":"# Emulating x86 push and pop on ARM\n#assembly #arm\n\nAlthough there is no push and pop instructions, Arm support addressing modes that can both update and address memory. This can be used to implement stack push and pop\nMore concretely, post-indexing is used for push, and pre-indexing is used for pop\n\nPre-indexing update the address register *before* the store, which is essentialy the same as x86 push instruction that decrease the stack pointer, then store the value\n``` asm\nstr x1, [sp, -#16]!\n```\n\nPre-index addressing update the address register after the store. \n``` asm\nldr x1, [sp] #16\n```\n\nSource: [Addressing Lab](https://www.cs.uregina.ca/Links/class-info/301/ARM-addressing/lecture.html)\n\n\n","wordCount":104,"tags":["assembly","arm"],"metadata":{},"created":"2023-05-23T08:55:30.365968581Z","modified":"2023-05-23T08:56:02.506779941Z","checksum":"91a6b4a805f8745061324a66dca4cc9a579675d644d25602edb6b50766d72e11"},
    {"filename":"mt8zp6w4.md","filenameStem":"mt8zp6w4","path":"mt8zp6w4.md","absPath":"/home/khadd/mynotes/mt8zp6w4.md","title":"Enforcing strict type checks in C","link":"[[mt8zp6w4]]","lead":"#c #cxx #programming","body":"#c #cxx #programming\n\n\n\n\n*Strict typedef*, or *Strong typedef*, enable strict checking of the aliased type. This is sometimes useful when you want to differentiate same underlying type, but different classes. For instance, different type of index all have the same int type.\nC and C++ does not support this at the language level.\n\nHowever, there is a trick to achieve this, by defining each type as a separated struct. \n\n```c\ntypedef struct {\n  int id; \n} int_type_a_t;\n\ntypedef struct {\n  int id; \n} int_type_a_t;\n```\n\nIn c++, there is the boost library `BOOST_STRONG_TYPEDEF`, which enable the strong typedef checking.\n\n# Reference\n- [enforce-strong-type-checking-in-c-type-strictness-for-typedefs](https://stackoverflow.com/questions/376452/enforce-strong-type-checking-in-c-type-strictness-for-typedefs)","snippets":["#c #cxx #programming"],"rawContent":"# Enforcing strict type checks in C\n#c #cxx #programming\n\n\n\n\n*Strict typedef*, or *Strong typedef*, enable strict checking of the aliased type. This is sometimes useful when you want to differentiate same underlying type, but different classes. For instance, different type of index all have the same int type.\nC and C++ does not support this at the language level.\n\nHowever, there is a trick to achieve this, by defining each type as a separated struct. \n\n```c\ntypedef struct {\n  int id; \n} int_type_a_t;\n\ntypedef struct {\n  int id; \n} int_type_a_t;\n```\n\nIn c++, there is the boost library `BOOST_STRONG_TYPEDEF`, which enable the strong typedef checking.\n\n# Reference\n- [enforce-strong-type-checking-in-c-type-strictness-for-typedefs](https://stackoverflow.com/questions/376452/enforce-strong-type-checking-in-c-type-strictness-for-typedefs)\n\n\n\n","wordCount":110,"tags":["programming","c","cxx"],"metadata":{},"created":"2023-07-12T06:13:13.193249148Z","modified":"2023-07-12T06:12:46.548317919Z","checksum":"1f165c6a30b5d7615f079104a7b82d2a64ac6024eb23736fcc3cdacdda4e7e0b"},
    {"filename":"d27hs51i.md","filenameStem":"d27hs51i","path":"d27hs51i.md","absPath":"/home/khadd/mynotes/d27hs51i.md","title":"EuroSys 2023","link":"[[d27hs51i]]","lead":"#conference","body":"#conference\n\nServerless\n- Groundhog: Efficient Request Isolation in FaaS\n- Unikernel Linux (UKL)","snippets":["#conference"],"rawContent":"# EuroSys 2023\n#conference\n\nServerless\n- Groundhog: Efficient Request Isolation in FaaS\n- Unikernel Linux (UKL)\n\n\n","wordCount":16,"tags":["conference"],"metadata":{},"created":"2023-05-22T02:06:14.45044837Z","modified":"2023-06-22T02:26:46.650475937Z","checksum":"a026e2fad79f4a4470d6bf0a276488c35d52e9014961a812132de70a2c569f5f"},
    {"filename":"go3kx7f1.md","filenameStem":"go3kx7f1","path":"go3kx7f1.md","absPath":"/home/khadd/mynotes/go3kx7f1.md","title":"Existing solutions against controlled-channel attacks","link":"[[go3kx7f1]]","lead":"#controlled-channel #sgx","body":"#controlled-channel #sgx\n\n\nMost of the existing solutions is for SGX.\n\nThere has been a vast amount of research on this topics.\n\nThere is not much you can do aside from preventing the OS from performing paging, or making the application memory access pattern oblivious. It is difficult to prevent the OS from performing paging without dedicated hardware extensions (@aga2019invisipage, @orenbach2020autarky). On the other hand, hiding memory access patterns through oblivious techniques have high overheads, requires recompilation (@zhang2020klotski). \n\n\n\n\n@shih2017tsgx\n@oleksenko2018varys\n@aga2019invisipage\n@zhang2020klotski\n@orenbach2020autarky\n\n@qin2023protecting","snippets":["#controlled-channel #sgx"],"rawContent":"# Existing solutions against controlled-channel attacks\n#controlled-channel #sgx\n\n\nMost of the existing solutions is for SGX.\n\nThere has been a vast amount of research on this topics.\n\nThere is not much you can do aside from preventing the OS from performing paging, or making the application memory access pattern oblivious. It is difficult to prevent the OS from performing paging without dedicated hardware extensions (@aga2019invisipage, @orenbach2020autarky). On the other hand, hiding memory access patterns through oblivious techniques have high overheads, requires recompilation (@zhang2020klotski). \n\n\n\n\n@shih2017tsgx\n@oleksenko2018varys\n@aga2019invisipage\n@zhang2020klotski\n@orenbach2020autarky\n\n@qin2023protecting\n \n\n\n\n","wordCount":89,"tags":["sgx","controlled-channel"],"metadata":{},"created":"2023-05-29T01:30:13.961859684Z","modified":"2023-05-29T06:45:54.070615512Z","checksum":"0dcbcdf1be670acc9353363f7158e4b7da9f695f0be5e83287821b2c0a1f4ad9"},
    {"filename":"jcoxpgnk.md","filenameStem":"jcoxpgnk","path":"jcoxpgnk.md","absPath":"/home/khadd/mynotes/jcoxpgnk.md","title":"Exitless system calls for SGX","link":"[[jcoxpgnk]]","lead":"#sgx #tee #system-call #performance #rpc","body":"#sgx #tee #system-call #performance #rpc\n\nTo perform system calls in SGX, the enclave must perform enclave exit and enter through `EEXIT`, `EENTER`. It is found that these two instructions have heavy overheads of about 3,300 and 3,800 cycles @orenbach2017eleos. This is much higher than the overheads of a normal system call, about 250 cycles.\n\nAnother cost of SGX is due to page fault, since in an enclave exit also need to be triggered.\n\n# Elos\n## RPC for system calls\n@orenbach2017eleos proposed using RPC instead to serve system calls on an enclave. The system employs a separated thread in the untrusted part of the application to serve system call. Ocalls in SGX for serving system call is then replaced with RPC to the system call-serving threads. \n\nMoreover, the system uses Intel Cache Allocation Technology (CAT) to allocate only 25% of the cache to the worker thread, while keeping 75% cache. This avoids LLC pollution.\n\n@orenbach2020autarky, @orenbach2019cosmix also adapts this.\n\n## User-managed virtual memory \nElos also includes a fine-grained page management system to avoid enclave exit on page faults. The idea is to cache the commonly used pages in the untrusted memory, and serve from it first, instead of relying on the OS.\n\n## Related note\n[[taztx2mo]]","snippets":["#sgx #tee #system-call #performance #rpc"],"rawContent":"# Exitless system calls for SGX\n#sgx #tee #system-call #performance #rpc\n\nTo perform system calls in SGX, the enclave must perform enclave exit and enter through `EEXIT`, `EENTER`. It is found that these two instructions have heavy overheads of about 3,300 and 3,800 cycles @orenbach2017eleos. This is much higher than the overheads of a normal system call, about 250 cycles.\n\nAnother cost of SGX is due to page fault, since in an enclave exit also need to be triggered.\n\n# Elos\n## RPC for system calls\n@orenbach2017eleos proposed using RPC instead to serve system calls on an enclave. The system employs a separated thread in the untrusted part of the application to serve system call. Ocalls in SGX for serving system call is then replaced with RPC to the system call-serving threads. \n\nMoreover, the system uses Intel Cache Allocation Technology (CAT) to allocate only 25% of the cache to the worker thread, while keeping 75% cache. This avoids LLC pollution.\n\n@orenbach2020autarky, @orenbach2019cosmix also adapts this.\n\n## User-managed virtual memory \nElos also includes a fine-grained page management system to avoid enclave exit on page faults. The idea is to cache the commonly used pages in the untrusted memory, and serve from it first, instead of relying on the OS.\n\n## Related note\n[[taztx2mo]]\n","wordCount":212,"tags":["sgx","tee","system-call","performance","rpc"],"metadata":{},"created":"2023-06-12T04:34:51.342439815Z","modified":"2023-08-30T08:00:05.019251718Z","checksum":"acfe3b5b48d7f9f2629755a2c88707f9e110964bcf220ce3896847af9928a8d0"},
    {"filename":"ncfh611p.md","filenameStem":"ncfh611p","path":"literature/ncfh611p.md","absPath":"/home/khadd/mynotes/literature/ncfh611p.md","title":"Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization","link":"[[literature/ncfh611p]]","lead":"#literature #side-channel #sev\n@li2019exploiting","body":"#literature #side-channel #sev\n@li2019exploiting\n\n\n# Summary\nThe paper proposes an attack method that exploits the unprotected I/O operations in AMD SEV. Here, *unprotected* means that the I/O operations (MMIO and DMA) must be performed on unencrypted memory that is visible by the hypervisor. The paper shows that by replacing ciphertext blocks in the VM memory, the hypervisor can create trick the VM into encrypting and decrypting arbitrary data, hence encryption/decryption oracles.\n\n\n# Attack overview\n## Encryption oracle\nThe target of the attack is an SSH service running inside a cVM. While the ssh packets are encrypted, due to unprotected I/O [[zmt276jl]], the hypervisor can observe and modify the TCP and IP headers.\n\nBriefly, the attack finds the *encrypted* page that contains the packet to be sent over the I/O channel. It then replaces the encrypted header (16B) with another encrypted block of data, right before the packet is copied into the unencrypted I/O memory observable by the hypervisor. Using this method, a decryption oracle is built that allows the decryption of any memory block.\n\nThe attack is performed in three steps: pattern matching, ciphertext replacement, and packet recovery.\n\n### Pattern matching\nPattern matching stage uses the nested page fault side-channel [[qq4qcbos]] to determine which pages are being accessed when the VM serves the SSH packet. The hypervisor first sends an SSH packet to the VM, then clears the present bits in the NPT PTEs.\nIt collects the sequences of page fault accesses to build a _signature_ of the page accessed from the time of receiving the request, to the time right before sending the packet. It then uses this signature to determine the page containing the `sk_buff` structure that contains the packet.\n\n### Ciphertext replacement\nCiphertext replacement replaces the ciphertext inside the header of the SSH packet and recovers the plaintext result. Since SEV's memory encryption applies a teak function based on the physical address, steps need to be done to recover plaintext:\nAssuming the ciphertext $c$ is copied from the address $P_c$. Plaintext must be obtained by:\n\n$m = d \\oplus  T(hPA((P_{priv}+16))/16*16) \\oplus T(P_c)$ \n\nWhere $d$ is the decrypted text of $c$, T is the tweak function. Essentially, this negates the effect of the teak of the current address and applies the teak of the target location.\n\n### Plaintext recovery\nThe original plaintext must be recovered so that the attack is stealthy. Since the attack only modifies the header of the SSH packet, which is public, it only needs to predict the content of the current header (replaced by the attack). Here, the ID of the packet is increased by 1 after each response, so it adds that to the response's header.\n\n\n# Mitigation\nThe attack in this paper is mitigated by SEV-SNP since the hypervisor cannot write into encrypted memory anymore.\n\nSince SNP did not exist at the time, the paper also suggests other mitigations. One of them is to make the VM encrypts the *entire* packets, and use a trusted proxy server to decrypt the packets, before forwarding them to the client.","snippets":["#literature #side-channel #sev\n@li2019exploiting"],"rawContent":"# Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization\n#literature #side-channel #sev\n@li2019exploiting\n\n\n# Summary\nThe paper proposes an attack method that exploits the unprotected I/O operations in AMD SEV. Here, *unprotected* means that the I/O operations (MMIO and DMA) must be performed on unencrypted memory that is visible by the hypervisor. The paper shows that by replacing ciphertext blocks in the VM memory, the hypervisor can create trick the VM into encrypting and decrypting arbitrary data, hence encryption/decryption oracles.\n\n\n# Attack overview\n## Encryption oracle\nThe target of the attack is an SSH service running inside a cVM. While the ssh packets are encrypted, due to unprotected I/O [[zmt276jl]], the hypervisor can observe and modify the TCP and IP headers.\n\nBriefly, the attack finds the *encrypted* page that contains the packet to be sent over the I/O channel. It then replaces the encrypted header (16B) with another encrypted block of data, right before the packet is copied into the unencrypted I/O memory observable by the hypervisor. Using this method, a decryption oracle is built that allows the decryption of any memory block.\n\nThe attack is performed in three steps: pattern matching, ciphertext replacement, and packet recovery.\n\n### Pattern matching\nPattern matching stage uses the nested page fault side-channel [[qq4qcbos]] to determine which pages are being accessed when the VM serves the SSH packet. The hypervisor first sends an SSH packet to the VM, then clears the present bits in the NPT PTEs.\nIt collects the sequences of page fault accesses to build a _signature_ of the page accessed from the time of receiving the request, to the time right before sending the packet. It then uses this signature to determine the page containing the `sk_buff` structure that contains the packet.\n\n### Ciphertext replacement\nCiphertext replacement replaces the ciphertext inside the header of the SSH packet and recovers the plaintext result. Since SEV's memory encryption applies a teak function based on the physical address, steps need to be done to recover plaintext:\nAssuming the ciphertext $c$ is copied from the address $P_c$. Plaintext must be obtained by:\n\n$m = d \\oplus  T(hPA((P_{priv}+16))/16*16) \\oplus T(P_c)$ \n\nWhere $d$ is the decrypted text of $c$, T is the tweak function. Essentially, this negates the effect of the teak of the current address and applies the teak of the target location.\n\n### Plaintext recovery\nThe original plaintext must be recovered so that the attack is stealthy. Since the attack only modifies the header of the SSH packet, which is public, it only needs to predict the content of the current header (replaced by the attack). Here, the ID of the packet is increased by 1 after each response, so it adds that to the response's header.\n\n\n# Mitigation\nThe attack in this paper is mitigated by SEV-SNP since the hypervisor cannot write into encrypted memory anymore.\n\nSince SNP did not exist at the time, the paper also suggests other mitigations. One of them is to make the VM encrypts the *entire* packets, and use a trusted proxy server to decrypt the packets, before forwarding them to the client.\n","wordCount":515,"tags":["literature","sev","side-channel"],"metadata":{},"created":"2023-07-04T02:37:50.006636198Z","modified":"2023-07-04T04:12:04.136245196Z","checksum":"c4fe4d78fb051afdaf047f2e46dceccd2a7d4f374db46f764f6a08e2ef9761fc"},
    {"filename":"a6uh87al.md","filenameStem":"a6uh87al","path":"a6uh87al.md","absPath":"/home/khadd/mynotes/a6uh87al.md","title":"Extending on an idea","link":"[[a6uh87al]]","lead":"#writing","body":"#writing\n\nSometimes it is hard to *determine what to write* for a particular idea. Using *frameworks* would helps in such cases. \n\nGenerally, following prompts helps: \n- Answering What, why, how\n- Give an example\n- What is this idea similar to\n- What contradicts this idea\n\nKeep in mind:\n- Why is this an important issue\n- Why reader has to know about this\n\n\n\n\nOther note taking frameworks might helps, such as: \n- [[dyx2t4oz]]\n- [[zz3cedu0]]","snippets":["#writing"],"rawContent":"# Extending on an idea\n#writing\n\nSometimes it is hard to *determine what to write* for a particular idea. Using *frameworks* would helps in such cases. \n\nGenerally, following prompts helps: \n- Answering What, why, how\n- Give an example\n- What is this idea similar to\n- What contradicts this idea\n\nKeep in mind:\n- Why is this an important issue\n- Why reader has to know about this\n\n\n\n\nOther note taking frameworks might helps, such as: \n- [[dyx2t4oz]]\n- [[zz3cedu0]]\n\n\n","wordCount":81,"tags":["writing"],"metadata":{},"created":"2023-05-22T02:06:14.449520757Z","modified":"2023-05-19T04:07:16.005118828Z","checksum":"7e51df8c7dabc81cf1bd782e69245187c898bf067f8079d8dfc18b4dc2a08764"},
    {"filename":"mqnreqwk.md","filenameStem":"mqnreqwk","path":"mqnreqwk.md","absPath":"/home/khadd/mynotes/mqnreqwk.md","title":"Failure in ORAM","link":"[[mqnreqwk]]","lead":"#oblivious","body":"#oblivious \n\nIn most ORAM algorithms, there is a chance of failure.\n\nThe design of ORAM tries to avoid this using some techniques.\n\n# Eviction strategy\n## Reversed path eviction\nIn the eviction phase (Path ORAM and Ring ORAM), blocks are pushed to the tree in the reversed order, starting from the leaves, and ending at the root. The reason for intuition is that blocks at higher levels are more likely to intersect with another path.\nFor example, in a tree with 3 levels, nodes on the last level (leaf nodes) correspond to only one path. node on the second level can be evicted on 2 paths (1 can be evicted on paths 0 and 1). Nodes on the first level can be evicted on any path.\n\n```\n              0\n          1       2\n      3       4       5\n---------------------------\npath: 0       1       2\n```\n\n## Background Eviction\n@ren2013design proposed a *background eviction* strategy. This happens when the free slots in the stash becomes smaller than $Height*BucketSize$, i.e., the minimum free blocks required in an ORAM access.\n\ndummy access is performed on random a path that read blocks into the stash, and opportunistically place blocks back into the tree. At worst, if the path is already filled, or no blocks can be evicted from the stash, the path is simply written back to the tree.\n\nAn advantage of this is that the background eviction access pattern is identical to an ORAM access, so attackers cannot know when background eviction happens.\n\n\n@renconstants also have a *early reshuffling* strategy.","snippets":["#oblivious"],"rawContent":"# Failure in ORAM\n#oblivious \n\nIn most ORAM algorithms, there is a chance of failure.\n\nThe design of ORAM tries to avoid this using some techniques.\n\n# Eviction strategy\n## Reversed path eviction\nIn the eviction phase (Path ORAM and Ring ORAM), blocks are pushed to the tree in the reversed order, starting from the leaves, and ending at the root. The reason for intuition is that blocks at higher levels are more likely to intersect with another path.\nFor example, in a tree with 3 levels, nodes on the last level (leaf nodes) correspond to only one path. node on the second level can be evicted on 2 paths (1 can be evicted on paths 0 and 1). Nodes on the first level can be evicted on any path.\n\n```\n              0\n          1       2\n      3       4       5\n---------------------------\npath: 0       1       2\n```\n\n## Background Eviction\n@ren2013design proposed a *background eviction* strategy. This happens when the free slots in the stash becomes smaller than $Height*BucketSize$, i.e., the minimum free blocks required in an ORAM access.\n\ndummy access is performed on random a path that read blocks into the stash, and opportunistically place blocks back into the tree. At worst, if the path is already filled, or no blocks can be evicted from the stash, the path is simply written back to the tree.\n\nAn advantage of this is that the background eviction access pattern is identical to an ORAM access, so attackers cannot know when background eviction happens.\n\n\n@renconstants also have a *early reshuffling* strategy.\n","wordCount":255,"tags":["oblivious"],"metadata":{},"created":"2023-07-19T02:45:03.353432335Z","modified":"2023-07-19T07:37:22.283965064Z","checksum":"28d0298120d3c8b5513665533e65153775d95ba143163873d4a031b1c7680677"},
    {"filename":"b8dhhxft.md","filenameStem":"b8dhhxft","path":"fleeting/b8dhhxft.md","absPath":"/home/khadd/mynotes/fleeting/b8dhhxft.md","title":"Flat vs. hierarchical notes","link":"[[fleeting/b8dhhxft]]","lead":"#fleeting","body":"#fleeting\n\n# Flat notes\nFlat notes make use of hashtag and linking for navigation\n\n## Arguments for flat notes\nFlat notes make every notes equally important.\n\nFlat notes is easier for linking.\n\nEasy to maintain. You can create a a grouping of concepts by just inserting a new hashtag.\n\n## Argument agaisnt\nHashtags can be cluttering.\n\nThis is related to a good hashtag system.\n\n# Hierarchical notes\nHierarchical notes group notes using folders/directories. It is great when you use a file system to maintain your zettel.\n\nHierarchical notes is good when the content within the directory is \n(1) well-maintained, \n(2) well-separated: though, this kind of go against the linking your thinking ideologies. \n(3) you need multiple \n\n## Argument for hierarchical notes\nVisually separated in the file system.\n\nEasy to move around. Though, you rarely need to move your notes.\n\nSupport multiple layers of grouping.\n\n```\n- Group A\n  - Note a.1  \n  - Note a.2\n  - Group A.1\n    - note A.1.1 \n- Group B\n  - Note b.1\n```\n\n## Arguments against\nYour conceptual grouping of notes might change over time.\n\nLinking requires an extra indirection (`\\[\\[directory/note\\]\\]`). This might be dependent on the note manager you are using.\n\n\n\n# Conclusion\n\nIf you are sure the grouping of notes is permanent, and you want to clearly and visually separate those notes from the rest, using a directory is fine. For instance, generally Zettlekasten gurus recommends you to separate fleeting, literature, and permanent notes.\n\nFor notes where their grouping might change overtime, it is best to use flat notes plus hashtags.","snippets":["#fleeting"],"rawContent":"# Flat vs. hierarchical notes\n#fleeting\n\n# Flat notes\nFlat notes make use of hashtag and linking for navigation\n\n## Arguments for flat notes\nFlat notes make every notes equally important.\n\nFlat notes is easier for linking.\n\nEasy to maintain. You can create a a grouping of concepts by just inserting a new hashtag.\n\n## Argument agaisnt\nHashtags can be cluttering.\n\nThis is related to a good hashtag system.\n\n# Hierarchical notes\nHierarchical notes group notes using folders/directories. It is great when you use a file system to maintain your zettel.\n\nHierarchical notes is good when the content within the directory is \n(1) well-maintained, \n(2) well-separated: though, this kind of go against the linking your thinking ideologies. \n(3) you need multiple \n\n## Argument for hierarchical notes\nVisually separated in the file system.\n\nEasy to move around. Though, you rarely need to move your notes.\n\nSupport multiple layers of grouping.\n\n```\n- Group A\n  - Note a.1  \n  - Note a.2\n  - Group A.1\n    - note A.1.1 \n- Group B\n  - Note b.1\n```\n\n## Arguments against\nYour conceptual grouping of notes might change over time.\n\nLinking requires an extra indirection (`\\[\\[directory/note\\]\\]`). This might be dependent on the note manager you are using.\n\n\n\n# Conclusion\n\nIf you are sure the grouping of notes is permanent, and you want to clearly and visually separate those notes from the rest, using a directory is fine. For instance, generally Zettlekasten gurus recommends you to separate fleeting, literature, and permanent notes.\n\nFor notes where their grouping might change overtime, it is best to use flat notes plus hashtags. \n\n\n","wordCount":262,"tags":["fleeting"],"metadata":{},"created":"2023-05-25T05:51:35.232130605Z","modified":"2023-05-26T03:24:45.528578304Z","checksum":"1fe224eda1d1b71c80dbdd67ed9111497e5f5120d18e3e6f7770d72d4ef9343b"},
    {"filename":"nitymocd.md","filenameStem":"nitymocd","path":"nitymocd.md","absPath":"/home/khadd/mynotes/nitymocd.md","title":"Force function inline in LLVM","link":"[[nitymocd]]","lead":"#llvm","body":"#llvm\n\nThe problem: I'm trying to instrument the program's load and store instruction with wrapper that modify the pointer in the value. Since there are a lot of load/store, and the wrapper is short, I expect inlining would leads to better performance.\n\nI tried to force inline with the function attribute `__attribute__((__always_inline__))` but it did not work. LLVM would not listen.\n\nLuckily `Lib/Transform/Utils/Cloning.h` provide a function call `InlineFunction(CallInst, ...)` when invoked it would try to inline the call instruction. \n\nHence I used two step to inline every calls. The first step instrument the function call normally, but store the inserted LLVM's CallInst in an array. After instrumentation is done, I loop through the array to invoke `InlineFunction` on them.","snippets":["#llvm"],"rawContent":"# Force function inline in LLVM\n#llvm\n\nThe problem: I'm trying to instrument the program's load and store instruction with wrapper that modify the pointer in the value. Since there are a lot of load/store, and the wrapper is short, I expect inlining would leads to better performance.\n\nI tried to force inline with the function attribute `__attribute__((__always_inline__))` but it did not work. LLVM would not listen.\n\nLuckily `Lib/Transform/Utils/Cloning.h` provide a function call `InlineFunction(CallInst, ...)` when invoked it would try to inline the call instruction. \n\nHence I used two step to inline every calls. The first step instrument the function call normally, but store the inserted LLVM's CallInst in an array. After instrumentation is done, I loop through the array to invoke `InlineFunction` on them.\n\n\n\n","wordCount":125,"tags":["llvm"],"metadata":{},"created":"2023-05-23T08:51:18.357019284Z","modified":"2023-05-23T08:52:00.159014592Z","checksum":"d2166fbac553e21b365cdba8b07d34c6efd0baa64bfe8bd7daa00105f3f858e6"},
    {"filename":"l56og3zt.md","filenameStem":"l56og3zt","path":"l56og3zt.md","absPath":"/home/khadd/mynotes/l56og3zt.md","title":"Foreach pattern in C macro","link":"[[l56og3zt]]","lead":"You can define a foreach macro like this. Useful when iterating over custom structures. \n```c","body":"You can define a foreach macro like this. Useful when iterating over custom structures. \n```c\n\n#define FOREACH(var)\\\n  for (var = 0; var \u003c PREDEFINED_LEN; var++)\n\n#define FOREACH(var, len)\\\n  for (var = 0; var \u003c len; var++)\n\n#define FOREACH_TYPE_T(ptr)\\\n  for (ptr = begin(); ptr != end(); ptr = get_next_ptr(ptr))\n```","snippets":["You can define a foreach macro like this. Useful when iterating over custom structures. \n```c"],"rawContent":"# Foreach pattern in C macro\n\n\n\nYou can define a foreach macro like this. Useful when iterating over custom structures. \n```c\n\n#define FOREACH(var)\\\n  for (var = 0; var \u003c PREDEFINED_LEN; var++)\n\n#define FOREACH(var, len)\\\n  for (var = 0; var \u003c len; var++)\n\n#define FOREACH_TYPE_T(ptr)\\\n  for (ptr = begin(); ptr != end(); ptr = get_next_ptr(ptr))\n```\n","wordCount":55,"tags":[],"metadata":{},"created":"2023-07-12T06:13:13.191076529Z","modified":"2023-07-12T06:12:46.548317919Z","checksum":"d16bf8147c1cf446c69a10a0537ff88d74fdb37e08607b4419a22993f634ec67"},
    {"filename":"zecj938z.md","filenameStem":"zecj938z","path":"literature/zecj938z.md","absPath":"/home/khadd/mynotes/literature/zecj938z.md","title":"HYDRA:The Kernel of a Multiprocessor Operating System","link":"[[literature/zecj938z]]","lead":"#literature #os #capabilities\n@wulf1974hydra","body":"#literature #os #capabilities\n@wulf1974hydra\n\n\n\n## Noteworthy arguments\n### Hierarchical layering limits flexibility: See [[c4icaua4]].\nHowever, maintaining order in a non-hierarchical manner is challenging in traditional systems. HYDRA's capability model enable flexibility by rejecting hierarchical structuring. In HYDRA, a *template* define the security checking mechanism of a procedure, and allows a procedure to *derive* higher capabilities from the argument capabilities (belong to the caller). This way, a callee function might have greater capabilities than the caller, but the caller have no way of obtaining those capabilities by itself. This enable invocation of procedures in any orders, as long as the callee adhere to the rules defined by the system designer.\n\nAs a downside, such a system must have the support from the kernel. HYDRA uses a kernel-assisted CALL mechanism. The kernel checks for the parameter capabilities with the according to the security requirements. It then derives new capabilities and place it in the callee's environment. Finally, the kernel transfer the control to the callee function.\n\n### Protection (mechanism) should be separated from security (policy)\nThe paper argue that the protection mechanism does not necessary grant security. Take password for example, the password checking mechanism does not guarantee that the user will use a strong enough password.\n\nHence, HYDRA aims to provides primitives (mechanisms) to implements the policy (security), but not to provide  the security by itself.","snippets":["#literature #os #capabilities\n@wulf1974hydra"],"rawContent":"# HYDRA:The Kernel of a Multiprocessor Operating System\n#literature #os #capabilities\n@wulf1974hydra\n\n\n\n## Noteworthy arguments\n### Hierarchical layering limits flexibility: See [[c4icaua4]].\nHowever, maintaining order in a non-hierarchical manner is challenging in traditional systems. HYDRA's capability model enable flexibility by rejecting hierarchical structuring. In HYDRA, a *template* define the security checking mechanism of a procedure, and allows a procedure to *derive* higher capabilities from the argument capabilities (belong to the caller). This way, a callee function might have greater capabilities than the caller, but the caller have no way of obtaining those capabilities by itself. This enable invocation of procedures in any orders, as long as the callee adhere to the rules defined by the system designer.\n\nAs a downside, such a system must have the support from the kernel. HYDRA uses a kernel-assisted CALL mechanism. The kernel checks for the parameter capabilities with the according to the security requirements. It then derives new capabilities and place it in the callee's environment. Finally, the kernel transfer the control to the callee function.\n\n### Protection (mechanism) should be separated from security (policy)\nThe paper argue that the protection mechanism does not necessary grant security. Take password for example, the password checking mechanism does not guarantee that the user will use a strong enough password.\n\nHence, HYDRA aims to provides primitives (mechanisms) to implements the policy (security), but not to provide  the security by itself.\n","wordCount":233,"tags":["literature","capabilities","os"],"metadata":{},"created":"2023-05-11T02:46:23.578528399Z","modified":"2023-05-24T02:28:49.329862837Z","checksum":"ef8d49672048a3a1fffb41b086f8d21d4f2cc910b21f2024b789e977377c3b9e"},
    {"filename":"2a7l7odo.md","filenameStem":"2a7l7odo","path":"literature/2a7l7odo.md","absPath":"/home/khadd/mynotes/literature/2a7l7odo.md","title":"Harmonizing Performance and Isolation in Microkernels with Efficient Intra-kernel Isolation and Communication","link":"[[literature/2a7l7odo]]","lead":"#literature #mpk #microkernel #sel4 #os\n[@gu2020harmonizing]","body":"#literature #mpk #microkernel #sel4 #os\n[@gu2020harmonizing]\n\n## Context\nThe paper argues that the cost of IPC in microkernels are too high, and proposed using MPK-based domains to reduce the number of context switches during IPCs.\nThe paper provides a motivation study by profiling the overheads of IPC in common microkernels (see [[i2blyo37#Overhead analysis]]).\n\n### Background\nPrevious systems use MPK for single address-space isolation.\n\nPrevious state-of-the-art [@mi2019skybridge] enables fast IPC by retrofitting VMFUNC., but still have high overheads due to Page table switching\n\n### Contributions\nThe proposed system tackles three main challenges in the context of microkernels that previous work did not solve. \n- The first is to prevent illegal IPC calls, since intel MPK does not check for permission before executing code. This is solved by secure IPC gates for the specific connections between two specific servers (a *system server* is an application that provides system-level services) in the trusted domain (core kernel). \n- Second is the limited number of domains. The paper designs a *server migration* technique that allows a server to be migrated between userspace (same as normal microkernel) and kernel space.\n- Third, due to the server executing in the privileged space, the system needs to prevent it from executing privileged instructions.","snippets":["#literature #mpk #microkernel #sel4 #os\n[@gu2020harmonizing]"],"rawContent":"# Harmonizing Performance and Isolation in Microkernels with Efficient Intra-kernel Isolation and Communication\n#literature #mpk #microkernel #sel4 #os\n[@gu2020harmonizing]\n\n## Context\nThe paper argues that the cost of IPC in microkernels are too high, and proposed using MPK-based domains to reduce the number of context switches during IPCs.\nThe paper provides a motivation study by profiling the overheads of IPC in common microkernels (see [[i2blyo37#Overhead analysis]]).\n\n### Background\nPrevious systems use MPK for single address-space isolation.\n\nPrevious state-of-the-art [@mi2019skybridge] enables fast IPC by retrofitting VMFUNC., but still have high overheads due to Page table switching\n\n### Contributions\nThe proposed system tackles three main challenges in the context of microkernels that previous work did not solve. \n- The first is to prevent illegal IPC calls, since intel MPK does not check for permission before executing code. This is solved by secure IPC gates for the specific connections between two specific servers (a *system server* is an application that provides system-level services) in the trusted domain (core kernel). \n- Second is the limited number of domains. The paper designs a *server migration* technique that allows a server to be migrated between userspace (same as normal microkernel) and kernel space.\n- Third, due to the server executing in the privileged space, the system needs to prevent it from executing privileged instructions. \n","wordCount":218,"tags":["literature","mpk","microkernel","sel4","os"],"metadata":{},"created":"2023-05-08T03:56:37.967695576Z","modified":"2023-05-10T08:02:06.450603126Z","checksum":"4732db3c6999f83832e45188b2b1f85489a2dbbfc668c561ef73ab38606a134b"},
    {"filename":"c4icaua4.md","filenameStem":"c4icaua4","path":"c4icaua4.md","absPath":"/home/khadd/mynotes/c4icaua4.md","title":"Hierarchical layering limits flexibility","link":"[[c4icaua4]]","lead":"#capabilities #os","body":"#capabilities #os\n\nMany systems uses the strict hierarchical layering for resource allocation. In those systems, the rule enforced by the kernel is that \n(1) a process can only allocate resources that it own to its children, \n(2) can only start/stop/remove its own childrens, and \n(3) A process's resources must be returned to its parent when it terminates.\nThis can be seen in modern UNIX system.\n\nHowever, [@wulf1974hydra] found that hierarchical layering of a system limits its flexibility. For example, while resource allocation might contains hierarchical layering, as shown above,  the *control* (e.g., starting/stopping subprocesses) need not to have the same hierarchical. \n\nAlso, a strict hierarchical system leads to increasingly privileged system components, and therefore leads to a component that have the \"most privileged\" only because of it place in the system. This leads to confused deputy problems ([[y9wu5ut7]]) in those components.","snippets":["#capabilities #os"],"rawContent":"# Hierarchical layering limits flexibility\n#capabilities #os\n\nMany systems uses the strict hierarchical layering for resource allocation. In those systems, the rule enforced by the kernel is that \n(1) a process can only allocate resources that it own to its children, \n(2) can only start/stop/remove its own childrens, and \n(3) A process's resources must be returned to its parent when it terminates.\nThis can be seen in modern UNIX system.\n\nHowever, [@wulf1974hydra] found that hierarchical layering of a system limits its flexibility. For example, while resource allocation might contains hierarchical layering, as shown above,  the *control* (e.g., starting/stopping subprocesses) need not to have the same hierarchical. \n\nAlso, a strict hierarchical system leads to increasingly privileged system components, and therefore leads to a component that have the \"most privileged\" only because of it place in the system. This leads to confused deputy problems ([[y9wu5ut7]]) in those components.\n\n\n\n","wordCount":146,"tags":["capabilities","os"],"metadata":{},"created":"2023-05-24T01:48:35.84434459Z","modified":"2023-05-24T02:23:57.832102238Z","checksum":"00f6434fbe55887338b0a871b830f6fb7ea5a0bdbfad0363dd672ab06d456422"},
    {"filename":"b740rhio.md","filenameStem":"b740rhio","path":"b740rhio.md","absPath":"/home/khadd/mynotes/b740rhio.md","title":"Hourglass structure of information","link":"[[b740rhio]]","lead":"#reading #learning","body":"#reading #learning\n\nIn articles, information is usually structured in an hourglass structure ([keshav]).\nIt is usually high-level information at the beginning and the end, and more specific information in the middle.\nUsually, the importance of information also follows this structure.\n\nHence, during reading, more time should be spent on the begining and the end of the whole chapter, the sections, or even each paragraph.\n\n# References\n[keshav]: https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf","snippets":["#reading #learning"],"rawContent":"# Hourglass structure of information\n#reading #learning\n\nIn articles, information is usually structured in an hourglass structure ([keshav]).\nIt is usually high-level information at the beginning and the end, and more specific information in the middle.\nUsually, the importance of information also follows this structure.\n\nHence, during reading, more time should be spent on the begining and the end of the whole chapter, the sections, or even each paragraph.\n\n# References\n[keshav]: https://web.stanford.edu/class/ee384m/Handouts/HowtoReadPaper.pdf\n","wordCount":73,"tags":["reading","learning"],"metadata":{},"created":"2023-05-05T06:54:52.6054501Z","modified":"2023-05-22T08:21:43.450698307Z","checksum":"6f1aabe29b5cb961c89bd8bee93c75a287731b140d685ee83a1dcaee9d25fd5d"},
    {"filename":"8v4evysc.md","filenameStem":"8v4evysc","path":"8v4evysc.md","absPath":"/home/khadd/mynotes/8v4evysc.md","title":"How I handle quotes","link":"[[8v4evysc]]","lead":"#quote #note-taking #zettelkasten","body":"#quote #note-taking #zettelkasten\n\nFirst, the title of the note contains the quote itself. This will make the entire quote a first-class content.\n\nSecond, a `#quote` tag is attached to the note. This allows for better indexing. \n\nThird, the note contains description of the note. For instance, who is it from, in what context.\n\nFinally, other notes create link to the quote in the appropriate context. Since the title is the quote it self, it can be searched easily.\n\nThe only thing left is to maintain authors of quotes. There are two approaches, linking to the (may empty) note about author, or use hash tag, both of which have trade-off. Linking force you to create a note on the author, which may not be populated. using hashtags kind of clutter you tags. Searching using hashtags may not be ideal (I might change my mind later).","snippets":["#quote #note-taking #zettelkasten"],"rawContent":"# How I handle quotes\n#quote #note-taking #zettelkasten\n\nFirst, the title of the note contains the quote itself. This will make the entire quote a first-class content.\n\nSecond, a `#quote` tag is attached to the note. This allows for better indexing. \n\nThird, the note contains description of the note. For instance, who is it from, in what context.\n\nFinally, other notes create link to the quote in the appropriate context. Since the title is the quote it self, it can be searched easily.\n\nThe only thing left is to maintain authors of quotes. There are two approaches, linking to the (may empty) note about author, or use hash tag, both of which have trade-off. Linking force you to create a note on the author, which may not be populated. using hashtags kind of clutter you tags. Searching using hashtags may not be ideal (I might change my mind later). \n","wordCount":149,"tags":["zettelkasten","note-taking","quote"],"metadata":{},"created":"2023-05-26T02:29:00.70063893Z","modified":"2023-05-26T02:29:03.332441485Z","checksum":"7195f7120eeafa98eae782370a14a02bee0305778b5e4e6b46049c7be5af69fe"},
    {"filename":"7isqcppd.md","filenameStem":"7isqcppd","path":"7isqcppd.md","absPath":"/home/khadd/mynotes/7isqcppd.md","title":"How to Speak","link":"[[7isqcppd]]","lead":"# Slides\n- The less text, the better. Cut out headers, footer, unneccessary visual cluttering (e.g., bullet points).\n- Figures should be simple.","body":"# Slides\n- The less text, the better. Cut out headers, footer, unneccessary visual cluttering (e.g., bullet points).\n- Figures should be simple.\n\n# Crimes\n- Hands in pocket\n- Pointers to the slide\n\n\n\n# References\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s)","snippets":["# Slides\n- The less text, the better. Cut out headers, footer, unneccessary visual cluttering (e.g., bullet points).\n- Figures should be simple."],"rawContent":"# How to Speak\n\n\n\n\n\n# Slides\n- The less text, the better. Cut out headers, footer, unneccessary visual cluttering (e.g., bullet points).\n- Figures should be simple.\n\n# Crimes\n- Hands in pocket\n- Pointers to the slide\n\n\n\n# References\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s)\n\n","wordCount":42,"tags":[],"metadata":{},"created":"2023-07-03T02:43:48.499639362Z","modified":"2023-07-03T02:42:12.086856668Z","checksum":"bf5388ea49df707b3eb47c03fde840dd75bb21c59014fadd0f5ac6c859c642fe"},
    {"filename":"gmp22r4e.md","filenameStem":"gmp22r4e","path":"gmp22r4e.md","absPath":"/home/khadd/mynotes/gmp22r4e.md","title":"How to do research","link":"[[gmp22r4e]]","lead":"# References","body":"# References\n\n\n- [How to look for ideas in Computer Science Research](https://medium.com/digital-diplomacy/how-to-look-for-ideas-in-computer-science-research-7a3fa6f4696f)","snippets":["# References"],"rawContent":"# How to do research\n\n\n\n# References\n\n\n- [How to look for ideas in Computer Science Research](https://medium.com/digital-diplomacy/how-to-look-for-ideas-in-computer-science-research-7a3fa6f4696f)\n","wordCount":17,"tags":[],"metadata":{},"created":"2023-06-09T07:37:26.870843698Z","modified":"2023-06-09T07:38:08.339481793Z","checksum":"21935ac911bf116968688658d23b5acaa31f42ebb4ca3413608b91d7c360e752"},
    {"filename":"zy68i5ym.md","filenameStem":"zy68i5ym","path":"zy68i5ym.md","absPath":"/home/khadd/mynotes/zy68i5ym.md","title":"How to explain an idea","link":"[[zy68i5ym]]","lead":"# Heuristics\n[How-to-Speak] describes two heuristics.\n1. *Cycling*: If something is important, it is worth revisiting at least *3* times. This is because people's attention is short.\n2. *Build a fence*: Clearly differentiate the idea and other may-similar ideas.","body":"# Heuristics\n[How-to-Speak] describes two heuristics.\n1. *Cycling*: If something is important, it is worth revisiting at least *3* times. This is because people's attention is short.\n2. *Build a fence*: Clearly differentiate the idea and other may-similar ideas. \n\n\n# How to get your work recognized\n[How-to-Speak] mentioned 5 pillars:\n1. Symbol: A symbol helps \n2. Slogan\n3. Supprise\n4. Salient\n5. Story\n\n[[7isqcppd]]\n\n# References\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s)","snippets":["# Heuristics\n[How-to-Speak] describes two heuristics.\n1. *Cycling*: If something is important, it is worth revisiting at least *3* times. This is because people's attention is short.\n2. *Build a fence*: Clearly differentiate the idea and other may-similar ideas."],"rawContent":"# How to explain an idea\n\n# Heuristics\n[How-to-Speak] describes two heuristics.\n1. *Cycling*: If something is important, it is worth revisiting at least *3* times. This is because people's attention is short.\n2. *Build a fence*: Clearly differentiate the idea and other may-similar ideas. \n\n\n# How to get your work recognized\n[How-to-Speak] mentioned 5 pillars:\n1. Symbol: A symbol helps \n2. Slogan\n3. Supprise\n4. Salient\n5. Story\n\n[[7isqcppd]]\n\n# References\n- [How-to-Speak](https://www.youtube.com/watch?v=Unzc731iCUY\u0026t=276s) \n\n\n","wordCount":74,"tags":[],"metadata":{},"created":"2024-05-20T09:23:13.152630533Z","modified":"2023-07-03T02:42:12.090190015Z","checksum":"097b000c645a46d74cbb09806a242c74fdb8916c9ecb7488adb05db7995e4f60"},
    {"filename":"cemsxh4n.md","filenameStem":"cemsxh4n","path":"cemsxh4n.md","absPath":"/home/khadd/mynotes/cemsxh4n.md","title":"How to write a note","link":"[[cemsxh4n]]","lead":"#zettelkasten #note-taking","body":"#zettelkasten #note-taking\n\n#todo: Need more research \n\nThe note content should have three main parts:\n- The idea \n- The observation\n- The conclusion\nThis is which is also similar to how academic papers are structured.\n\nUsing frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.","snippets":["#zettelkasten #note-taking"],"rawContent":"# How to write a note\n#zettelkasten #note-taking\n\n#todo: Need more research \n\nThe note content should have three main parts:\n- The idea \n- The observation\n- The conclusion\nThis is which is also similar to how academic papers are structured.\n\nUsing frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.\n","wordCount":58,"tags":["zettelkasten","todo:","note-taking"],"metadata":{},"created":"2023-05-03T03:47:47.578591088Z","modified":"2023-07-04T05:14:43.082758247Z","checksum":"fb21dbe626763343fe640738e06778e42719a3dd4f747c3865f65081e369afeb"},
    {"filename":"km0j8gtr.md","filenameStem":"km0j8gtr","path":"km0j8gtr.md","absPath":"/home/khadd/mynotes/km0j8gtr.md","title":"Huge pages in SEV","link":"[[km0j8gtr]]","lead":"","body":"","snippets":[],"rawContent":"# Huge pages in SEV\n\n\n","wordCount":5,"tags":[],"metadata":{},"created":"2023-06-19T06:31:23.707207083Z","modified":"2023-06-19T06:31:23.703573043Z","checksum":"94ab18894217fe6af49352512e5be42a7abf5c5b6b6ff69e3c995e15fd87b0e6"},
    {"filename":"d3nt6uix.md","filenameStem":"d3nt6uix","path":"d3nt6uix.md","absPath":"/home/khadd/mynotes/d3nt6uix.md","title":"Hypervisor (VMM)","link":"[[d3nt6uix]]","lead":"#virtualization","body":"#virtualization\n\nA hypervisor, also known as virtual machine monitor (VMM) manage virtual machines. \n\nIt performs interposition ([[s16ct1rj#interposition]]) on a certain *interesting* instructions to *emulate* then, hence *trap-and-emulate*. Those interesting instruction can be:\n- Access to hardware devices\n- Special instructions (e.g., CPUID)\n- Access to important and dangerous registers that have global effect \n\nHypervisor works by exploiting modern hardware supports that allows trapping of those important instructions.\n\n## Launching VM\nProcessor state of the VM is stored in a Virtual Machine Control structure/block (VMCS/VMCB) (see [VMCS](https://shhoya.github.io/hv_vmcsdata.html)). VMCS is a complex structure containing informations related to a VM's state. A pointer to the current VMCS is stored in a dedicated register, loaded with `VMPTRLD` instruction ([VMPTR](https://www.felixcloutier.com/x86/vmptrld.)).\n\nThe hypervisor is required to setup the VMCS correctly with necessary information.\n\nThe `VMLAUNCH\\VMRESUME` instruction is then used to lanch the VM based on the current VMCS.\n\n## Memory management\n### Legacy\nPreviously, all access to physical memory in the Guest need to be interposed and emulated, which causes a lot of overheads. Address translation and paging need to be perform twice.\n\n### Shadow Page Table\nTo avoid this, Shadow page table (SPT) is a per-VM page table used by the hypervisor to translate guest virtual memory to host physical memory. \nIt maintain a copy of the guest page table in a *shadow* page table, and mirror every page table update from the guest. \n\nThis shadow page table is pointed to by CR3, and contains the actual mapping.\n\nUpon a guest page fault (aka, shadow page fault):\n- The hypervisor trap it, then forward it to the guest for it to update its page table since there is no entry yet.\n- The guest update its page table (which will not be used by hardware translation). This may trigger a real page fault if guest page table is set at Read-only. Here the hypervisor can intercept and update the shadow page table.\n- The guest then access the memory. Since the mapping is now contained in the shadow page table, it can access it. \n\nNote that this process bypass the two-time address translation.\n\nStill, this is expensive when there is a lot of paging in the guest VM, since every page fault in the guest is forwarded to the host.\n\nNowaday it is still used in nested virtualization.\n\n### EPT/NPT\nExtended page table (EPT), aka Nested page table (NPT), is a hardware extension implementing second-level address translation (SLAT). \nEach VM will have an additional extended page table translate from guest physical address (gPAddr) into host physical address (hPAddr).\nThis extended page table is stored in the VMCS. \nIn virtualization mode, the MMU now walk the guest VM page table first to translate gVAddr to gPAddr. Then the MMU, without stopping, translate the second page table in the host. Hence, host page table is *nested* within the guest page table to translate (gPAddr-\u003ehVAddr-\u003ehPAddr). \nIf there is a page fault, the host OS simply update the nested table with the mapping.\nThis allows more efficient translation.\n\nWith the technology, when there is on guest's page fault, there is no exit to the hypervisor; the CPU automatically wals both page table.\n\nFor more implementation details of the feature, see [bhyve](https://people.freebsd.org/~neel/bhyve/bhyve_nested_paging.pdf)'s implementation.\n\n# More resources\n- [High-level introduction to the Low-Level virtualization](http://haifux.org/lectures/312/High-Level%20Introduction%20to%20the%20Low-Level%20of%20Virtualization.pdf)\n- Intel manual?","snippets":["#virtualization"],"rawContent":"# Hypervisor (VMM)\n#virtualization\n\nA hypervisor, also known as virtual machine monitor (VMM) manage virtual machines. \n\nIt performs interposition ([[s16ct1rj#interposition]]) on a certain *interesting* instructions to *emulate* then, hence *trap-and-emulate*. Those interesting instruction can be:\n- Access to hardware devices\n- Special instructions (e.g., CPUID)\n- Access to important and dangerous registers that have global effect \n\nHypervisor works by exploiting modern hardware supports that allows trapping of those important instructions.\n\n## Launching VM\nProcessor state of the VM is stored in a Virtual Machine Control structure/block (VMCS/VMCB) (see [VMCS](https://shhoya.github.io/hv_vmcsdata.html)). VMCS is a complex structure containing informations related to a VM's state. A pointer to the current VMCS is stored in a dedicated register, loaded with `VMPTRLD` instruction ([VMPTR](https://www.felixcloutier.com/x86/vmptrld.)).\n\nThe hypervisor is required to setup the VMCS correctly with necessary information.\n\nThe `VMLAUNCH\\VMRESUME` instruction is then used to lanch the VM based on the current VMCS.\n\n## Memory management\n### Legacy\nPreviously, all access to physical memory in the Guest need to be interposed and emulated, which causes a lot of overheads. Address translation and paging need to be perform twice.\n\n### Shadow Page Table\nTo avoid this, Shadow page table (SPT) is a per-VM page table used by the hypervisor to translate guest virtual memory to host physical memory. \nIt maintain a copy of the guest page table in a *shadow* page table, and mirror every page table update from the guest. \n\nThis shadow page table is pointed to by CR3, and contains the actual mapping.\n\nUpon a guest page fault (aka, shadow page fault):\n- The hypervisor trap it, then forward it to the guest for it to update its page table since there is no entry yet.\n- The guest update its page table (which will not be used by hardware translation). This may trigger a real page fault if guest page table is set at Read-only. Here the hypervisor can intercept and update the shadow page table.\n- The guest then access the memory. Since the mapping is now contained in the shadow page table, it can access it. \n\nNote that this process bypass the two-time address translation.\n\nStill, this is expensive when there is a lot of paging in the guest VM, since every page fault in the guest is forwarded to the host.\n\nNowaday it is still used in nested virtualization.\n\n### EPT/NPT\nExtended page table (EPT), aka Nested page table (NPT), is a hardware extension implementing second-level address translation (SLAT). \nEach VM will have an additional extended page table translate from guest physical address (gPAddr) into host physical address (hPAddr).\nThis extended page table is stored in the VMCS. \nIn virtualization mode, the MMU now walk the guest VM page table first to translate gVAddr to gPAddr. Then the MMU, without stopping, translate the second page table in the host. Hence, host page table is *nested* within the guest page table to translate (gPAddr-\u003ehVAddr-\u003ehPAddr). \nIf there is a page fault, the host OS simply update the nested table with the mapping.\nThis allows more efficient translation.\n\nWith the technology, when there is on guest's page fault, there is no exit to the hypervisor; the CPU automatically wals both page table.\n\nFor more implementation details of the feature, see [bhyve](https://people.freebsd.org/~neel/bhyve/bhyve_nested_paging.pdf)'s implementation.\n\n# More resources\n- [High-level introduction to the Low-Level virtualization](http://haifux.org/lectures/312/High-Level%20Introduction%20to%20the%20Low-Level%20of%20Virtualization.pdf)\n- Intel manual?\n","wordCount":549,"tags":["virtualization"],"metadata":{},"created":"2023-05-24T08:20:59.378521317Z","modified":"2023-06-16T08:52:45.382602588Z","checksum":"f06a3e57df55fbc12d032b585df60bed56ea674bf49f28efaebfcbb52e9e84f6"},
    {"filename":"zmt276jl.md","filenameStem":"zmt276jl","path":"zmt276jl.md","absPath":"/home/khadd/mynotes/zmt276jl.md","title":"I/O operations in AMD SEV","link":"[[zmt276jl]]","lead":"#sev #io #tee","body":"#sev #io #tee\n\nSEV VMs interacts with virtualized hardware through QEMU. More particularly, QEMU-KVM on the host side will serve I/O requests of the VM.\n\nSupported common I/O operations are PIO, MMIO, DMA.\n\n# DMA\nThe IOMMU maps DMA-capable I/O buses of hardware devices to the physical memory. Because the IOMMU only supports memory encryption with ASID=0 (host ID), DMA operations must be done on pages that are shared between VM and host. Those pages are called the Software  I/O Translation Look-aside Buffer SWIOTLB.\n\nOn a read DMA request from the guest VM, QEMU-KVM instructs the IOMMU to perform DMA transfer from device into the SWIOTLB (e.g., swapping pages from the disk). The guest VM then copy the pages inside SWIOTLB into its own memory.\n\nOn a write DMA request, the guest need to copy its data into the SWIOTLB first. QEMU-KVM then commands the IOMMU to transfer those pages to the devices.\n\n# Security\nBecause I/O is unencrypted, the cVM needs to encrypt the I/O data using the software. If I/O is not corrupted, the hypervisor can corrupt contents (e.g., binary) loaded from the disk into memory. @li2019exploiting shows an example where a malicious hypervisor patches the `sshd` binaries to bypass the authentication.\n\nHowever, certain types of data cannot be encrypted. For instance, packets for DHF key exchange are not encrypted. \n\n@li2019exploiting took a closer look at I/O operations that must not be encrypted:\n- In network I/O, the header of IP or TCP cannot be encrypted. Hence, the attacker can forge the header.\n- In display I/O (e.g., VNC), QEMU-KVM redirects the VGA display from the guest to the VNC protocol.\n- Disk I/O can be encrypted with a secret key provisioned by the cVM owner. However, the key is stored in memory and can be extracted using the encryption oracle described in the paper.\n\n\n# Related notes\n- @li2019exploiting: [[literature/ncfh611p]]","snippets":["#sev #io #tee"],"rawContent":"# I/O operations in AMD SEV\n#sev #io #tee\n\nSEV VMs interacts with virtualized hardware through QEMU. More particularly, QEMU-KVM on the host side will serve I/O requests of the VM.\n\nSupported common I/O operations are PIO, MMIO, DMA.\n\n# DMA\nThe IOMMU maps DMA-capable I/O buses of hardware devices to the physical memory. Because the IOMMU only supports memory encryption with ASID=0 (host ID), DMA operations must be done on pages that are shared between VM and host. Those pages are called the Software  I/O Translation Look-aside Buffer SWIOTLB.\n\nOn a read DMA request from the guest VM, QEMU-KVM instructs the IOMMU to perform DMA transfer from device into the SWIOTLB (e.g., swapping pages from the disk). The guest VM then copy the pages inside SWIOTLB into its own memory.\n\nOn a write DMA request, the guest need to copy its data into the SWIOTLB first. QEMU-KVM then commands the IOMMU to transfer those pages to the devices.\n\n# Security\nBecause I/O is unencrypted, the cVM needs to encrypt the I/O data using the software. If I/O is not corrupted, the hypervisor can corrupt contents (e.g., binary) loaded from the disk into memory. @li2019exploiting shows an example where a malicious hypervisor patches the `sshd` binaries to bypass the authentication.\n\nHowever, certain types of data cannot be encrypted. For instance, packets for DHF key exchange are not encrypted. \n\n@li2019exploiting took a closer look at I/O operations that must not be encrypted:\n- In network I/O, the header of IP or TCP cannot be encrypted. Hence, the attacker can forge the header.\n- In display I/O (e.g., VNC), QEMU-KVM redirects the VGA display from the guest to the VNC protocol.\n- Disk I/O can be encrypted with a secret key provisioned by the cVM owner. However, the key is stored in memory and can be extracted using the encryption oracle described in the paper.\n\n\n# Related notes\n- @li2019exploiting: [[literature/ncfh611p]]\n","wordCount":319,"tags":["tee","sev","io"],"metadata":{},"created":"2024-05-20T09:23:13.145941814Z","modified":"2023-07-04T03:20:47.738212862Z","checksum":"7fad94d993edb39ad13ae0386de03b028bb46afe01ab672f934e6441992aac94"},
    {"filename":"syn2yulc.md","filenameStem":"syn2yulc","path":"syn2yulc.md","absPath":"/home/khadd/mynotes/syn2yulc.md","title":"IP configuration in Linux distributions","link":"[[syn2yulc]]","lead":"#admin #linux","body":"#admin #linux\n\n\n\n\n# Ubuntu\nUbuntu uses `netplan` for network configurations (https://ubuntu.com/server/docs/network-configuration). To create a network configuration, create a file named `/etc/netplan/99_config.yaml` (or change the existing config file.).\n\n```yaml\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      addresses:\n        - 10.10.10.2/24\n      routes:\n        - to: default\n          via: 10.10.10.1\n      nameservers:\n          search: [mydomain, otherdomain]\n          addresses: [10.10.10.1, 1.1.1.1]\n```\n\nAfter, runs `sudo netplan apply` to apply the configuration.","snippets":["#admin #linux"],"rawContent":"# IP configuration in Linux distributions\n#admin #linux\n\n\n\n\n# Ubuntu\nUbuntu uses `netplan` for network configurations (https://ubuntu.com/server/docs/network-configuration). To create a network configuration, create a file named `/etc/netplan/99_config.yaml` (or change the existing config file.).\n\n```yaml\nnetwork:\n  version: 2\n  renderer: networkd\n  ethernets:\n    eth0:\n      addresses:\n        - 10.10.10.2/24\n      routes:\n        - to: default\n          via: 10.10.10.1\n      nameservers:\n          search: [mydomain, otherdomain]\n          addresses: [10.10.10.1, 1.1.1.1]\n```\n\nAfter, runs `sudo netplan apply` to apply the configuration.\n\n\n\n\n\n","wordCount":67,"tags":["linux","admin"],"metadata":{},"created":"2023-09-01T03:11:58.119340057Z","modified":"2023-09-01T03:16:04.349956538Z","checksum":"32be60b4c91c81134763f3037d258c9f9f2768fd665a1b60acdce95e71fbe96e"},
    {"filename":"ns7lcn8t.md","filenameStem":"ns7lcn8t","path":"ns7lcn8t.md","absPath":"/home/khadd/mynotes/ns7lcn8t.md","title":"Iago attack","link":"[[ns7lcn8t]]","lead":"#todo","body":"#todo","snippets":["#todo"],"rawContent":"# Iago attack\n#todo\n\n","wordCount":4,"tags":["todo"],"metadata":{},"created":"2023-05-22T08:13:08.92854484Z","modified":"2023-05-22T08:13:14.832114658Z","checksum":"cdfa011862c86231870f01187ea32ee2d6dcc850b7858f2342bf8bc514158774"},
    {"filename":"zz3cedu0.md","filenameStem":"zz3cedu0","path":"zz3cedu0.md","absPath":"/home/khadd/mynotes/zz3cedu0.md","title":"Idea Compass","link":"[[zz3cedu0]]","lead":"#zettelkasten #note-taking","body":"#zettelkasten #note-taking\n\nIdea Compass is a thinking tool that helps define how to think about a particular idea. In particular, it is described in [Compass of Zettelkasten Thinking](https://feeei.substack.com/i/48707291/the-compass-of-zettelkasten-thinking) as follows:\n\n\u003e\n1.  take one idea (X) and put it in the centre\n2. imagine the four compass directions. each direction helps give definition to the idea in different ways.\n  - NORTH: *“Where does X come from?”* what are its origin? what group/category does X belong to? what exists an order of magnitude higher? zoom out. what gave birth to X? what causes X\n  - WEST: *“What is similar to X?”* what other disciplines could X already exist in? what other disciplines could benefit from X? what are other ways to say/do X?\n  - SOUTH: *“Where can X lead to?”* what does X contribute to? what group/category could X be the headline of? what exists an order of magnitude lower? zoom in. what does X nurture?\n  - EAST: *“What competes with X?”* what is the opposite of X? what is X missing? its disadvantage? what could supercharge X?\n3. The Zettelkasten structure created around the idea could look something like this:\n  - NORTH\n    - The Idea\n      - SOUTH\n      - EAST\n      - WEST\n\n\nTakes the idea of the *idea compass* itself for example. We can start from the NORTH:\n- NORTH: *\"Where does X come from?\"* \n  - This idea comes from the lack of clear instructions for using the zettelkasten [[ae6fatms]] method. For instance, what should an idea contain? How do you connect it with other ideas?\n  - Hence, the author introduces a framework for finding the *context* of an idea.\n  - SOUTH: *What can X leads to?*\n    - This idea helps to discover the context of a Zettelkasten note. More importantly, helps writing notes easier [[cemsxh4n]]\n  - EAST: *“What competes with X?”*\n  - WEST: *“What is similar to _X?”_ [This](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) introduces another technique called the *knowledge flower* [[dyx2t4oz]] that is more open for interpretation.","snippets":["#zettelkasten #note-taking"],"rawContent":"# Idea Compass\n#zettelkasten #note-taking\n\nIdea Compass is a thinking tool that helps define how to think about a particular idea. In particular, it is described in [Compass of Zettelkasten Thinking](https://feeei.substack.com/i/48707291/the-compass-of-zettelkasten-thinking) as follows:\n\n\u003e\n1.  take one idea (X) and put it in the centre\n2. imagine the four compass directions. each direction helps give definition to the idea in different ways.\n  - NORTH: *“Where does X come from?”* what are its origin? what group/category does X belong to? what exists an order of magnitude higher? zoom out. what gave birth to X? what causes X\n  - WEST: *“What is similar to X?”* what other disciplines could X already exist in? what other disciplines could benefit from X? what are other ways to say/do X?\n  - SOUTH: *“Where can X lead to?”* what does X contribute to? what group/category could X be the headline of? what exists an order of magnitude lower? zoom in. what does X nurture?\n  - EAST: *“What competes with X?”* what is the opposite of X? what is X missing? its disadvantage? what could supercharge X?\n3. The Zettelkasten structure created around the idea could look something like this:\n  - NORTH\n    - The Idea\n      - SOUTH\n      - EAST\n      - WEST\n\n\nTakes the idea of the *idea compass* itself for example. We can start from the NORTH:\n- NORTH: *\"Where does X come from?\"* \n  - This idea comes from the lack of clear instructions for using the zettelkasten [[ae6fatms]] method. For instance, what should an idea contain? How do you connect it with other ideas?\n  - Hence, the author introduces a framework for finding the *context* of an idea.\n  - SOUTH: *What can X leads to?*\n    - This idea helps to discover the context of a Zettelkasten note. More importantly, helps writing notes easier [[cemsxh4n]]\n  - EAST: *“What competes with X?”*\n  - WEST: *“What is similar to _X?”_ [This](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) introduces another technique called the *knowledge flower* [[dyx2t4oz]] that is more open for interpretation.\n","wordCount":326,"tags":["zettelkasten","note-taking"],"metadata":{},"created":"2024-05-20T09:23:13.162600914Z","modified":"2023-05-25T05:55:59.484936197Z","checksum":"3f1da98e11e3b412cb56702b44b4a44bd1f160989ee3b447d24269a428d19d37"},
    {"filename":"u55zie42.md","filenameStem":"u55zie42","path":"literature/u55zie42.md","absPath":"/home/khadd/mynotes/literature/u55zie42.md","title":"InkTag: Secure Applications on an Untrusted Operating System","link":"[[literature/u55zie42]]","lead":"#literature #hypervisor","body":"#literature #hypervisor\n\n# Background\nAt the time of this paper, SGX that have the same functionality but without hypervisor have yet to exist.\n\nPrevious system on protection against untrusted OS, OverShadow [@chen2008overshadow] only focus on isolation of memory (code and data) from the OS. This papers provides methods for verifying OS behaviors, allowing the protected program to use OS services securely.\n\n\n\n\n\n\n\n![hologram](../images/hologram.png)\n\n\n\n\n\n\n\n# Main arguments\n## Verifying OS behaviors with the hypervisors is more simple than reimplementing OS services inside the hypervisor\n- OS services often have simple specifications.\n- Only implementing verification in the kernel reduces the TCB of hypervisor.\n- The introduced technique called *paraverification* to verify the unstrusted OS. Essentially, the OS is changed to cooperate with the hypervisor for verifiable OS services (e.g., page management). \n\n## Untrusted OS verification leads to security\n- This directly address the Iago Attack [[ns7lcn8t]] where the untrusted OS feeds incorrect values to trusted application.\n- InkTag enable crash consistency\n- InkTag is able to secure files with defined access control policies. \n\n# Control flow\nThe High assurance programs (HAPs) and the operating system interacts through a *untrusted trampoline*. The application first invoke the hypervisor to request system call. The hypervisor switch the control to an untrusted trampoline that actually invoke the system call. \n\nThis allows the untrusted OS to schedule among the untrusted trampolines and other contexts.\n\nNOTE: Not quite understand.\n\n# Memory isolation\nInkTag provides two layers of memory isolation: kernel to High assurance programs (HAPs), and between the HAPs.\nMemory isolation are provided by EPT virtualization plus paraverfication.\nThis isolation is maintained from the file system up to the memory pages.\n\nThe *object* abstraction represents files. Each object is given a unique ID (*OID*).\nAn objects consists of *secure pages (S-pages)* that contains metadata about the owner object and the offset within the object (*\u003cOID, offset\u003e*), and also the *hash* of the data (for verification).\n\n## Two EPTs\nTwo EPTs are used for trusted context (HAPs) and untrusted context (kernel / normal apps). The trusted EPT maps the plaintext S-page physical frames. The untrusted EPT maps the other frames.  \n- When OS / untrusted applications access a mapped S-pages in trusted EPT (not mapped in untrusted), the hypervisor unmap it in trusted EPT, take the hash, encrypt the page, then map it to untrusted EPT.\n- When HAP access the frame, hypervisor decrypt the page, verify the hash, map it to trusted EPT, unmap it from untrusted EPT. \n\n## Isolation between HAPs\nThe hypervisor manage page table updates for HAPs, to enforce access control policies of objects. For normal pages, the OS can map without intervention.","snippets":["#literature #hypervisor"],"rawContent":"# InkTag: Secure Applications on an Untrusted Operating System\n#literature #hypervisor\n\n# Background\nAt the time of this paper, SGX that have the same functionality but without hypervisor have yet to exist.\n\nPrevious system on protection against untrusted OS, OverShadow [@chen2008overshadow] only focus on isolation of memory (code and data) from the OS. This papers provides methods for verifying OS behaviors, allowing the protected program to use OS services securely.\n\n\n\n\n\n\n\n![hologram](../images/hologram.png)\n\n\n\n\n\n\n\n# Main arguments\n## Verifying OS behaviors with the hypervisors is more simple than reimplementing OS services inside the hypervisor\n- OS services often have simple specifications.\n- Only implementing verification in the kernel reduces the TCB of hypervisor.\n- The introduced technique called *paraverification* to verify the unstrusted OS. Essentially, the OS is changed to cooperate with the hypervisor for verifiable OS services (e.g., page management). \n\n## Untrusted OS verification leads to security\n- This directly address the Iago Attack [[ns7lcn8t]] where the untrusted OS feeds incorrect values to trusted application.\n- InkTag enable crash consistency\n- InkTag is able to secure files with defined access control policies. \n\n# Control flow\nThe High assurance programs (HAPs) and the operating system interacts through a *untrusted trampoline*. The application first invoke the hypervisor to request system call. The hypervisor switch the control to an untrusted trampoline that actually invoke the system call. \n\nThis allows the untrusted OS to schedule among the untrusted trampolines and other contexts.\n\nNOTE: Not quite understand.\n\n# Memory isolation\nInkTag provides two layers of memory isolation: kernel to High assurance programs (HAPs), and between the HAPs.\nMemory isolation are provided by EPT virtualization plus paraverfication.\nThis isolation is maintained from the file system up to the memory pages.\n\nThe *object* abstraction represents files. Each object is given a unique ID (*OID*).\nAn objects consists of *secure pages (S-pages)* that contains metadata about the owner object and the offset within the object (*\u003cOID, offset\u003e*), and also the *hash* of the data (for verification).\n\n## Two EPTs\nTwo EPTs are used for trusted context (HAPs) and untrusted context (kernel / normal apps). The trusted EPT maps the plaintext S-page physical frames. The untrusted EPT maps the other frames.  \n- When OS / untrusted applications access a mapped S-pages in trusted EPT (not mapped in untrusted), the hypervisor unmap it in trusted EPT, take the hash, encrypt the page, then map it to untrusted EPT.\n- When HAP access the frame, hypervisor decrypt the page, verify the hash, map it to trusted EPT, unmap it from untrusted EPT. \n\n## Isolation between HAPs\nThe hypervisor manage page table updates for HAPs, to enforce access control policies of objects. For normal pages, the OS can map without intervention. \n","wordCount":447,"tags":["literature","hypervisor"],"metadata":{},"created":"2023-05-22T07:39:17.945711869Z","modified":"2023-08-10T07:32:09.746787544Z","checksum":"e6009e3f5d75b04eb6ec20c35e7b3da786c76e19521cd47d43d8868bd3aa3d67"},
    {"filename":"llhmwuim.md","filenameStem":"llhmwuim","path":"llhmwuim.md","absPath":"/home/khadd/mynotes/llhmwuim.md","title":"Inside of Linux support for AMD SEV","link":"[[llhmwuim]]","lead":"#sev #virtualization #os #linux","body":"#sev #virtualization #os #linux\n\n\n\nConfiguration for SEV starts at, where kernel initialization starts. This is called after the kernel have been decompressed and loaded into memory (`kernel/arch/x86/boot/compressed/head_64.S`).\n\n\n## Configuration\n`CONFIG_AMD_MEM_ENCRYPT` \n\n## Booting\n\n### Protected mode\n### Long mode\nIn `startup_64`, `kernel/arch/x86/boot/compressed/head_64.S`, which is the booting code in 64-bit long mode that performs kernel decompression, there is this code;\n```c\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\t/*\n\t * Now that the stage1 interrupt handlers are set up, #VC exceptions from\n\t * CPUID instructions can be properly handled for SEV-ES guests.\n\t *\n\t * For SEV-SNP, the CPUID table also needs to be set up in advance of any\n\t * CPUID instructions being issued, so go ahead and do that now via\n\t * sev_enable(), which will also handle the rest of the SEV-related\n\t * detection/setup to ensure that has been done in advance of any dependent\n\t * code.\n\t */\n\tpushq\t%rsi\n\tmovq\t%rsi, %rdi\t\t/* real mode address */\n\tcall\tsev_enable\n\tpopq\t%rsi\n#endif\n```\n\n\n`sev_enable` first checks whether SEV is supported using `native_cpuid`, which calls `cpuid` instruction.\nThen, it call `snp_init`. The function looks for the struct `cc_blob_sev_info` defined as follows:\n```c\n/*\n * AMD SEV Confidential computing blob structure. The structure is\n * defined in OVMF UEFI firmware header:\n * https://github.com/tianocore/edk2/blob/master/OvmfPkg/Include/Guid/ConfidentialComputingSevSnpBlob.h\n */\n#define CC_BLOB_SEV_HDR_MAGIC\t0x45444d41\nstruct cc_blob_sev_info {\n\tu32 magic;\n\tu16 version;\n\tu16 reserved;\n\tu64 secrets_phys;\n\tu32 secrets_len;\n\tu32 rsvd1;\n\tu64 cpuid_phys;\n\tu32 cpuid_len;\n\tu32 rsvd2;\n} __packed;\n\n```\nIn this struct's definition, you can notice `secrets_phys` and `cpuid_phys` fields, which correspond to the physical address of the *special pages* inserted into the guest memory ([AMD manual](https://www.amd.com/system/files/TechDocs/56860.pdf), 4.5).  The command `SNP_LAUNCH_UPDATE` is used by the hypervisor to insert a *secrets* page and a *CPUID* page. The secrets page contains encryption keys that the guest can use to interact with the firmware. The CPUID page contains the hypervisor-provided CPUID information, which the guest can request the firmware to validate.\n \nThe blob for this struct is contained in the vendor in the EFI configuration table (https://uefi.org/specs/UEFI/2.10/04_EFI_System_Table.html#efi-configuration-table). The table is set up by AMD UEFI-compatible firmware (I think?). The table is indexed using GUID ([check](https://github.com/tianocore/edk2/blob/master/OvmfPkg/Include/Guid/ConfidentialComputingSevSnpBlob.h)). If a lookup using the GUID for this specific structure (`EFI_CC_BLOB_GUID`) succeed, then it indicates that SNP feature is enabled. Note that the *physical* address of the blob is returned.\nHere is the implementation of `snp_init`\n```c\n/*\n * Indicate SNP based on presence of SNP-specific CC blob. Subsequent checks\n * will verify the SNP CPUID/MSR bits.\n */\nbool snp_init(struct boot_params *bp)\n{\n\tstruct cc_blob_sev_info *cc_info;\n\n\tif (!bp)\n\t\treturn false;\n\n\tcc_info = find_cc_blob(bp);\n\tif (!cc_info)\n\t\treturn false;\n\n\t/*\n\t * If a SNP-specific Confidential Computing blob is present, then\n\t * firmware/bootloader have indicated SNP support. Verifying this\n\t * involves CPUID checks which will be more reliable if the SNP\n\t * CPUID table is used. See comments over snp_setup_cpuid_table() for\n\t * more details.\n\t */\n\tsetup_cpuid_table(cc_info);\n\n\t/*\n\t * Pass run-time kernel a pointer to CC info via boot_params so EFI\n\t * config table doesn't need to be searched again during early startup\n\t * phase.\n\t */\n\tbp-\u003ecc_blob_address = (u32)(unsigned long)cc_info;\n\n\treturn true;\n}\n```\n\nAfter, `snp_init` set `cc_blob_address` in `boot_params` to the address of the `cc_blob_sev_info` struct. This address is used later to initialize the SEV-related parts of the kernel.\n\nAfter, booting occurs as normal, and the control flow eventually reaches the `startup_64`` function (`arch/x86/kernel/head_64.S`) for kernel initialization.\n\n## Kernel initialization\n\nIn `startup_64` (`arch/x86/kernel/head64.S`), you will see the following code, \n```c\nSYM_CODE_START_NOALIGN(startup_64)\n  // ...\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\t/*\n\t * Activate SEV/SME memory encryption if supported/enabled. This needs to\n\t * be done now, since this also includes setup of the SEV-SNP CPUID table,\n\t * which needs to be done before any CPUID instructions are executed in\n\t * subsequent code.\n\t */\n\tmovq\t%rsi, %rdi\n\tpushq\t%rsi\n\tcall\tsme_enable\n\tpopq\t%rsi\n#endif\n\t/* Sanitize CPU configuration */\n\tcall verify_cpu\n\n\t/*\n\t * Perform pagetable fixups. Additionally, if SME is active, encrypt\n\t * the kernel and retrieve the modifier (SME encryption mask if SME\n\t * is active) to be added to the initial pgdir entry that will be\n\t * programmed into CR3.\n\t */\n\tleaq\t_text(%rip), %rdi\n\tpushq\t%rsi\n\tcall\t__startup_64\n\tpopq\t%rsi\n\n\t/* Form the CR3 value being sure to include the CR3 modifier */\n\taddq\t$(early_top_pgt - __START_KERNEL_map), %rax\n\tjmp 1f\nSYM_CODE_END(startup_64)\n```\n\nIf the config `CONFIG_AMD_MEM_ENCRYPT` is enabled, it calls `sme_enable` (`mem_encrypt_idendity.c`) to enable the Secure memory encryption (SME) feature. \n\nThe function calls `snp_init` (`x86/kernel/sev.c`). Note that this function is for the *kernel initialization* of SEV, which is different from *boot time initialization* in `boot/compressed/sev.c`. It uses `find_cc_blob` check for the value of `bp-\u003ecc_blob_address` initialized previously by the boot time `snp_init`. If not found, it checks for setup_data defined by Linux boot protocol.\n\n```c\nvoid __init sme_enable(struct boot_params *bp)\n{\n  //...\n\t/* Check the SEV MSR whether SEV or SME is enabled */\n\tsev_status   = __rdmsr(MSR_AMD64_SEV);\n\tfeature_mask = (sev_status \u0026 MSR_AMD64_SEV_ENABLED) ? AMD_SEV_BIT : AMD_SME_BIT;\n\n\t/* The SEV-SNP CC blob should never be present unless SEV-SNP is enabled. */\n\tif (snp \u0026\u0026 !(sev_status \u0026 MSR_AMD64_SEV_SNP_ENABLED))\n\t\tsnp_abort();\n\n\t/* Check if memory encryption is enabled */\n\tif (feature_mask == AMD_SME_BIT) {\n    //...\n\t} else {\n\t\t/* SEV state cannot be controlled by a command line option */\n\t\tsme_me_mask = me_mask;\n\t\tgoto out;\n\t}\n  //...\n\nout:\n\tif (sme_me_mask) {\n\t\tphysical_mask \u0026= ~sme_me_mask;\n\t\tcc_vendor = CC_VENDOR_AMD;\n\t\tcc_set_mask(sme_me_mask);\n\t}\n}\n\n```\n\n\nLinux provides an abstraction abstract of the capabilities of confidential computing platforms, under namespace `x86/coco/core.c`. The interface defines the `cc_attr`` enum that represents confidential computing features. The current list of features are:\n```c\nenum cc_attr {\n\t/**\n\t * @CC_ATTR_MEM_ENCRYPT: Memory encryption is active\n\t *\n\t * The platform/OS is running with active memory encryption. This\n\t * includes running either as a bare-metal system or a hypervisor\n\t * and actively using memory encryption or as a guest/virtual machine\n\t * and actively using memory encryption.\n\t *\n\t * Examples include SME, SEV and SEV-ES.\n\t */\n\tCC_ATTR_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_HOST_MEM_ENCRYPT: Host memory encryption is active\n\t *\n\t * The platform/OS is running as a bare-metal system or a hypervisor\n\t * and actively using memory encryption.\n\t *\n\t * Examples include SME.\n\t */\n\tCC_ATTR_HOST_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_MEM_ENCRYPT: Guest memory encryption is active\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using memory encryption.\n\t *\n\t * Examples include SEV and SEV-ES.\n\t */\n\tCC_ATTR_GUEST_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_STATE_ENCRYPT: Guest state encryption is active\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using memory encryption and register state encryption.\n\t *\n\t * Examples include SEV-ES.\n\t */\n\tCC_ATTR_GUEST_STATE_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_UNROLL_STRING_IO: String I/O is implemented with\n\t *                                  IN/OUT instructions\n\t *\n\t * The platform/OS is running as a guest/virtual machine and uses\n\t * IN/OUT instructions in place of string I/O.\n\t *\n\t * Examples include TDX guest \u0026 SEV.\n\t */\n\tCC_ATTR_GUEST_UNROLL_STRING_IO,\n\n\t/**\n\t * @CC_ATTR_SEV_SNP: Guest SNP is active.\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using AMD SEV-SNP features.\n\t */\n\tCC_ATTR_GUEST_SEV_SNP,\n\n\t/**\n\t * @CC_ATTR_HOTPLUG_DISABLED: Hotplug is not supported or disabled.\n\t *\n\t * The platform/OS is running as a guest/virtual machine does not\n\t * support CPU hotplug feature.\n\t *\n\t * Examples include TDX Guest.\n\t */\n\tCC_ATTR_HOTPLUG_DISABLED,\n};\n\n\n```\n\n\nThe `cc_set_mask` set the global `cc_mask` variable. The `cc_mask` variable is defined in `x86/coco/core.c`, which provides an architectural-independent interface to control memory encryption in different architecture. `cc_mask` holds the mask for the bit in the page table entry that indicates memory encryption should be performed.\n\n\n```c\n\n// arch/x86/include/asm/pgtable.h\n#define pgprot_encrypted(prot)\t__pgprot(cc_mkenc(pgprot_val(prot)))\n#define pgprot_decrypted(prot)\t__pgprot(cc_mkdec(pgprot_val(prot)))\n\n// arch/x86/coco/core.c\nu64 cc_mkenc(u64 val)\n{\n\t/*\n\t * Both AMD and Intel use a bit in the page table to indicate\n\t * encryption status of the page.\n\t *\n\t * - for AMD, bit *set* means the page is encrypted\n\t * - for AMD with vTOM and for Intel, *clear* means encrypted\n\t */\n\tswitch (cc_vendor) {\n\tcase CC_VENDOR_AMD:\n\t\tif (sev_status \u0026 MSR_AMD64_SNP_VTOM)\n\t\t\treturn val \u0026 ~cc_mask;\n\t\telse\n\t\t\treturn val | cc_mask;\n\tcase CC_VENDOR_INTEL:\n\t\treturn val \u0026 ~cc_mask;\n\tdefault:\n\t\treturn val;\n\t}\n}\n```\n\nTo enable SME, the mask has to be set according to the bit position in the page table entry, returned by CPUID. In `sme_enable`, line 528, you can see\n```c\t/*\n\t/*\n\t * Check for the SME/SEV feature:\n\t *   CPUID Fn8000_001F[EAX]\n\t *   - Bit 0 - Secure Memory Encryption support\n\t *   - Bit 1 - Secure Encrypted Virtualization support\n\t *   CPUID Fn8000_001F[EBX]\n\t *   - Bits 5:0 - Pagetable bit position used to indicate encryption\n\t */\n\teax = 0x8000001f;\n\tecx = 0;\n\tnative_cpuid(\u0026eax, \u0026ebx, \u0026ecx, \u0026edx);\n\t/* Check whether SEV or SME is supported */\n\tif (!(eax \u0026 (AMD_SEV_BIT | AMD_SME_BIT)))\n\t\treturn;\n\n\tme_mask = 1UL \u003c\u003c (ebx \u0026 0x3f);\n```\nThe bit operation clears the other bits in ebx  (`ebx \u0026 0b11111`), then shift the bit right according to the value in bits 5:0. For example, if bits 5:0 in ebx is 0b000011, it means the encryption bit  (c-bit) is bit 3 of the page table entry, and the mask should be 0b0...01000.","snippets":["#sev #virtualization #os #linux"],"rawContent":"# Inside of Linux support for AMD SEV\n#sev #virtualization #os #linux\n\n\n\nConfiguration for SEV starts at, where kernel initialization starts. This is called after the kernel have been decompressed and loaded into memory (`kernel/arch/x86/boot/compressed/head_64.S`).\n\n\n## Configuration\n`CONFIG_AMD_MEM_ENCRYPT` \n\n## Booting\n\n### Protected mode\n### Long mode\nIn `startup_64`, `kernel/arch/x86/boot/compressed/head_64.S`, which is the booting code in 64-bit long mode that performs kernel decompression, there is this code;\n```c\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\t/*\n\t * Now that the stage1 interrupt handlers are set up, #VC exceptions from\n\t * CPUID instructions can be properly handled for SEV-ES guests.\n\t *\n\t * For SEV-SNP, the CPUID table also needs to be set up in advance of any\n\t * CPUID instructions being issued, so go ahead and do that now via\n\t * sev_enable(), which will also handle the rest of the SEV-related\n\t * detection/setup to ensure that has been done in advance of any dependent\n\t * code.\n\t */\n\tpushq\t%rsi\n\tmovq\t%rsi, %rdi\t\t/* real mode address */\n\tcall\tsev_enable\n\tpopq\t%rsi\n#endif\n```\n\n\n`sev_enable` first checks whether SEV is supported using `native_cpuid`, which calls `cpuid` instruction.\nThen, it call `snp_init`. The function looks for the struct `cc_blob_sev_info` defined as follows:\n```c\n/*\n * AMD SEV Confidential computing blob structure. The structure is\n * defined in OVMF UEFI firmware header:\n * https://github.com/tianocore/edk2/blob/master/OvmfPkg/Include/Guid/ConfidentialComputingSevSnpBlob.h\n */\n#define CC_BLOB_SEV_HDR_MAGIC\t0x45444d41\nstruct cc_blob_sev_info {\n\tu32 magic;\n\tu16 version;\n\tu16 reserved;\n\tu64 secrets_phys;\n\tu32 secrets_len;\n\tu32 rsvd1;\n\tu64 cpuid_phys;\n\tu32 cpuid_len;\n\tu32 rsvd2;\n} __packed;\n\n```\nIn this struct's definition, you can notice `secrets_phys` and `cpuid_phys` fields, which correspond to the physical address of the *special pages* inserted into the guest memory ([AMD manual](https://www.amd.com/system/files/TechDocs/56860.pdf), 4.5).  The command `SNP_LAUNCH_UPDATE` is used by the hypervisor to insert a *secrets* page and a *CPUID* page. The secrets page contains encryption keys that the guest can use to interact with the firmware. The CPUID page contains the hypervisor-provided CPUID information, which the guest can request the firmware to validate.\n \nThe blob for this struct is contained in the vendor in the EFI configuration table (https://uefi.org/specs/UEFI/2.10/04_EFI_System_Table.html#efi-configuration-table). The table is set up by AMD UEFI-compatible firmware (I think?). The table is indexed using GUID ([check](https://github.com/tianocore/edk2/blob/master/OvmfPkg/Include/Guid/ConfidentialComputingSevSnpBlob.h)). If a lookup using the GUID for this specific structure (`EFI_CC_BLOB_GUID`) succeed, then it indicates that SNP feature is enabled. Note that the *physical* address of the blob is returned.\nHere is the implementation of `snp_init`\n```c\n/*\n * Indicate SNP based on presence of SNP-specific CC blob. Subsequent checks\n * will verify the SNP CPUID/MSR bits.\n */\nbool snp_init(struct boot_params *bp)\n{\n\tstruct cc_blob_sev_info *cc_info;\n\n\tif (!bp)\n\t\treturn false;\n\n\tcc_info = find_cc_blob(bp);\n\tif (!cc_info)\n\t\treturn false;\n\n\t/*\n\t * If a SNP-specific Confidential Computing blob is present, then\n\t * firmware/bootloader have indicated SNP support. Verifying this\n\t * involves CPUID checks which will be more reliable if the SNP\n\t * CPUID table is used. See comments over snp_setup_cpuid_table() for\n\t * more details.\n\t */\n\tsetup_cpuid_table(cc_info);\n\n\t/*\n\t * Pass run-time kernel a pointer to CC info via boot_params so EFI\n\t * config table doesn't need to be searched again during early startup\n\t * phase.\n\t */\n\tbp-\u003ecc_blob_address = (u32)(unsigned long)cc_info;\n\n\treturn true;\n}\n```\n\nAfter, `snp_init` set `cc_blob_address` in `boot_params` to the address of the `cc_blob_sev_info` struct. This address is used later to initialize the SEV-related parts of the kernel.\n\nAfter, booting occurs as normal, and the control flow eventually reaches the `startup_64`` function (`arch/x86/kernel/head_64.S`) for kernel initialization.\n\n## Kernel initialization\n\nIn `startup_64` (`arch/x86/kernel/head64.S`), you will see the following code, \n```c\nSYM_CODE_START_NOALIGN(startup_64)\n  // ...\n#ifdef CONFIG_AMD_MEM_ENCRYPT\n\t/*\n\t * Activate SEV/SME memory encryption if supported/enabled. This needs to\n\t * be done now, since this also includes setup of the SEV-SNP CPUID table,\n\t * which needs to be done before any CPUID instructions are executed in\n\t * subsequent code.\n\t */\n\tmovq\t%rsi, %rdi\n\tpushq\t%rsi\n\tcall\tsme_enable\n\tpopq\t%rsi\n#endif\n\t/* Sanitize CPU configuration */\n\tcall verify_cpu\n\n\t/*\n\t * Perform pagetable fixups. Additionally, if SME is active, encrypt\n\t * the kernel and retrieve the modifier (SME encryption mask if SME\n\t * is active) to be added to the initial pgdir entry that will be\n\t * programmed into CR3.\n\t */\n\tleaq\t_text(%rip), %rdi\n\tpushq\t%rsi\n\tcall\t__startup_64\n\tpopq\t%rsi\n\n\t/* Form the CR3 value being sure to include the CR3 modifier */\n\taddq\t$(early_top_pgt - __START_KERNEL_map), %rax\n\tjmp 1f\nSYM_CODE_END(startup_64)\n```\n\nIf the config `CONFIG_AMD_MEM_ENCRYPT` is enabled, it calls `sme_enable` (`mem_encrypt_idendity.c`) to enable the Secure memory encryption (SME) feature. \n\nThe function calls `snp_init` (`x86/kernel/sev.c`). Note that this function is for the *kernel initialization* of SEV, which is different from *boot time initialization* in `boot/compressed/sev.c`. It uses `find_cc_blob` check for the value of `bp-\u003ecc_blob_address` initialized previously by the boot time `snp_init`. If not found, it checks for setup_data defined by Linux boot protocol.\n\n```c\nvoid __init sme_enable(struct boot_params *bp)\n{\n  //...\n\t/* Check the SEV MSR whether SEV or SME is enabled */\n\tsev_status   = __rdmsr(MSR_AMD64_SEV);\n\tfeature_mask = (sev_status \u0026 MSR_AMD64_SEV_ENABLED) ? AMD_SEV_BIT : AMD_SME_BIT;\n\n\t/* The SEV-SNP CC blob should never be present unless SEV-SNP is enabled. */\n\tif (snp \u0026\u0026 !(sev_status \u0026 MSR_AMD64_SEV_SNP_ENABLED))\n\t\tsnp_abort();\n\n\t/* Check if memory encryption is enabled */\n\tif (feature_mask == AMD_SME_BIT) {\n    //...\n\t} else {\n\t\t/* SEV state cannot be controlled by a command line option */\n\t\tsme_me_mask = me_mask;\n\t\tgoto out;\n\t}\n  //...\n\nout:\n\tif (sme_me_mask) {\n\t\tphysical_mask \u0026= ~sme_me_mask;\n\t\tcc_vendor = CC_VENDOR_AMD;\n\t\tcc_set_mask(sme_me_mask);\n\t}\n}\n\n```\n\n\nLinux provides an abstraction abstract of the capabilities of confidential computing platforms, under namespace `x86/coco/core.c`. The interface defines the `cc_attr`` enum that represents confidential computing features. The current list of features are:\n```c\nenum cc_attr {\n\t/**\n\t * @CC_ATTR_MEM_ENCRYPT: Memory encryption is active\n\t *\n\t * The platform/OS is running with active memory encryption. This\n\t * includes running either as a bare-metal system or a hypervisor\n\t * and actively using memory encryption or as a guest/virtual machine\n\t * and actively using memory encryption.\n\t *\n\t * Examples include SME, SEV and SEV-ES.\n\t */\n\tCC_ATTR_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_HOST_MEM_ENCRYPT: Host memory encryption is active\n\t *\n\t * The platform/OS is running as a bare-metal system or a hypervisor\n\t * and actively using memory encryption.\n\t *\n\t * Examples include SME.\n\t */\n\tCC_ATTR_HOST_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_MEM_ENCRYPT: Guest memory encryption is active\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using memory encryption.\n\t *\n\t * Examples include SEV and SEV-ES.\n\t */\n\tCC_ATTR_GUEST_MEM_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_STATE_ENCRYPT: Guest state encryption is active\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using memory encryption and register state encryption.\n\t *\n\t * Examples include SEV-ES.\n\t */\n\tCC_ATTR_GUEST_STATE_ENCRYPT,\n\n\t/**\n\t * @CC_ATTR_GUEST_UNROLL_STRING_IO: String I/O is implemented with\n\t *                                  IN/OUT instructions\n\t *\n\t * The platform/OS is running as a guest/virtual machine and uses\n\t * IN/OUT instructions in place of string I/O.\n\t *\n\t * Examples include TDX guest \u0026 SEV.\n\t */\n\tCC_ATTR_GUEST_UNROLL_STRING_IO,\n\n\t/**\n\t * @CC_ATTR_SEV_SNP: Guest SNP is active.\n\t *\n\t * The platform/OS is running as a guest/virtual machine and actively\n\t * using AMD SEV-SNP features.\n\t */\n\tCC_ATTR_GUEST_SEV_SNP,\n\n\t/**\n\t * @CC_ATTR_HOTPLUG_DISABLED: Hotplug is not supported or disabled.\n\t *\n\t * The platform/OS is running as a guest/virtual machine does not\n\t * support CPU hotplug feature.\n\t *\n\t * Examples include TDX Guest.\n\t */\n\tCC_ATTR_HOTPLUG_DISABLED,\n};\n\n\n```\n\n\nThe `cc_set_mask` set the global `cc_mask` variable. The `cc_mask` variable is defined in `x86/coco/core.c`, which provides an architectural-independent interface to control memory encryption in different architecture. `cc_mask` holds the mask for the bit in the page table entry that indicates memory encryption should be performed.\n\n\n```c\n\n// arch/x86/include/asm/pgtable.h\n#define pgprot_encrypted(prot)\t__pgprot(cc_mkenc(pgprot_val(prot)))\n#define pgprot_decrypted(prot)\t__pgprot(cc_mkdec(pgprot_val(prot)))\n\n// arch/x86/coco/core.c\nu64 cc_mkenc(u64 val)\n{\n\t/*\n\t * Both AMD and Intel use a bit in the page table to indicate\n\t * encryption status of the page.\n\t *\n\t * - for AMD, bit *set* means the page is encrypted\n\t * - for AMD with vTOM and for Intel, *clear* means encrypted\n\t */\n\tswitch (cc_vendor) {\n\tcase CC_VENDOR_AMD:\n\t\tif (sev_status \u0026 MSR_AMD64_SNP_VTOM)\n\t\t\treturn val \u0026 ~cc_mask;\n\t\telse\n\t\t\treturn val | cc_mask;\n\tcase CC_VENDOR_INTEL:\n\t\treturn val \u0026 ~cc_mask;\n\tdefault:\n\t\treturn val;\n\t}\n}\n```\n\nTo enable SME, the mask has to be set according to the bit position in the page table entry, returned by CPUID. In `sme_enable`, line 528, you can see\n```c\t/*\n\t/*\n\t * Check for the SME/SEV feature:\n\t *   CPUID Fn8000_001F[EAX]\n\t *   - Bit 0 - Secure Memory Encryption support\n\t *   - Bit 1 - Secure Encrypted Virtualization support\n\t *   CPUID Fn8000_001F[EBX]\n\t *   - Bits 5:0 - Pagetable bit position used to indicate encryption\n\t */\n\teax = 0x8000001f;\n\tecx = 0;\n\tnative_cpuid(\u0026eax, \u0026ebx, \u0026ecx, \u0026edx);\n\t/* Check whether SEV or SME is supported */\n\tif (!(eax \u0026 (AMD_SEV_BIT | AMD_SME_BIT)))\n\t\treturn;\n\n\tme_mask = 1UL \u003c\u003c (ebx \u0026 0x3f);\n```\nThe bit operation clears the other bits in ebx  (`ebx \u0026 0b11111`), then shift the bit right according to the value in bits 5:0. For example, if bits 5:0 in ebx is 0b000011, it means the encryption bit  (c-bit) is bit 3 of the page table entry, and the mask should be 0b0...01000.  \n","wordCount":1478,"tags":["os","linux","sev","virtualization"],"metadata":{},"created":"2023-08-21T08:35:46.084633189Z","modified":"2023-08-30T05:26:27.95337573Z","checksum":"d63e8ed3964f44d9a0fd9082f51f491a5dbe3eecf87c154c9fd3b630cd446c81"},
    {"filename":"nxznwhum.md","filenameStem":"nxznwhum","path":"nxznwhum.md","absPath":"/home/khadd/mynotes/nxznwhum.md","title":"Instrumenting function prologue and epilogue with LLVM","link":"[[nxznwhum]]","lead":"#llvm #ir","body":"#llvm #ir\n\nInstrumenting functions' prologue and epilogue is not as straight forward as it seem.\n\nTo instrument every function's prologue: \n```c\n   auto FirstI = \u0026*F.getEntryBlock().begin();\n   IRBuilder\u003c\u003e ProIRB(FirstI);\n   CallInst *Prologue = ProIRB.CreateCall(CapacPrologue);\n\n   DILocation *Loc =\n       DILocation::get(F.getParent()-\u003egetContext(), 0, 0,\n       F.getSubprogram());\n  Prologue-\u003esetDebugLoc(Loc);\n```\nNote that The debug location is needed because of this error:\n\u003e inlinable function call in a function with debug info must have a !dbg location\n\nThe epilogue must cover all exit points of the function. This can be done by scanning for return instructions in the basic blocks. \n```c\n\n   // Collect possible exit points\n   std::vector\u003cBasicBlock *\u003e ReturningBlocks;\n   for (BasicBlock \u0026I : F)\n     if (isa\u003cReturnInst\u003e(I.getTerminator()))\n       ReturningBlocks.push_back(\u0026I);\n\n   // Insert epilogue to all blocks\n   if (ReturningBlocks.size() != 0) {\n     for (BasicBlock *BB : ReturningBlocks) {\n       IRBuilder\u003c\u003e EpiIRB(BB-\u003egetTerminator());\n       CallInst *Epi = EpiIRB.CreateCall(CapacEpilogue);\n       Epi-\u003esetDebugLoc(EpiIRB.getCurrentDebugLocation());\n     }\n   }\n```","snippets":["#llvm #ir"],"rawContent":"# Instrumenting function prologue and epilogue with LLVM\n#llvm #ir\n\nInstrumenting functions' prologue and epilogue is not as straight forward as it seem.\n\nTo instrument every function's prologue: \n```c\n   auto FirstI = \u0026*F.getEntryBlock().begin();\n   IRBuilder\u003c\u003e ProIRB(FirstI);\n   CallInst *Prologue = ProIRB.CreateCall(CapacPrologue);\n\n   DILocation *Loc =\n       DILocation::get(F.getParent()-\u003egetContext(), 0, 0,\n       F.getSubprogram());\n  Prologue-\u003esetDebugLoc(Loc);\n```\nNote that The debug location is needed because of this error:\n\u003e inlinable function call in a function with debug info must have a !dbg location\n\nThe epilogue must cover all exit points of the function. This can be done by scanning for return instructions in the basic blocks. \n```c\n\n   // Collect possible exit points\n   std::vector\u003cBasicBlock *\u003e ReturningBlocks;\n   for (BasicBlock \u0026I : F)\n     if (isa\u003cReturnInst\u003e(I.getTerminator()))\n       ReturningBlocks.push_back(\u0026I);\n\n   // Insert epilogue to all blocks\n   if (ReturningBlocks.size() != 0) {\n     for (BasicBlock *BB : ReturningBlocks) {\n       IRBuilder\u003c\u003e EpiIRB(BB-\u003egetTerminator());\n       CallInst *Epi = EpiIRB.CreateCall(CapacEpilogue);\n       Epi-\u003esetDebugLoc(EpiIRB.getCurrentDebugLocation());\n     }\n   }\n```\n","wordCount":141,"tags":["llvm","ir"],"metadata":{},"created":"2023-05-23T08:56:35.452616966Z","modified":"2023-05-23T08:58:57.810953007Z","checksum":"49da2fae570697d814f22a567c57d17972b27c206c42f1e17c0a1cd9079d5041"},
    {"filename":"taztx2mo.md","filenameStem":"taztx2mo","path":"taztx2mo.md","absPath":"/home/khadd/mynotes/taztx2mo.md","title":"Intel SGX","link":"[[taztx2mo]]","lead":"#sgx","body":"#sgx\n\n\n# Execution flow\n\nAn enclave is entered with the instruction `EENTER` (https://www.felixcloutier.com/x86/eenter), which launches the enclave at a predefined and attested entry point. CENTER is invoked with `ENCLU`, with the index for it contained in the eax register (i.e., `ENCLU[EENTER]`). \n\n## `EENTER`\n`EENTER` takes RBX and RCX as an argument. \nRBX contains the memory region for the thread control block (TCS) of the enclave to be executed. \nRCX contains the address of the Asynchronous exit pointer (AEP), which is a handler that will be executed when the host serves faults from the enclave through asynchronous enclave exit. \n`EENTER` flushes the TLB, then put the processor into the enclave mode. Note that more checks are also performed, such as disabling Precise Event Based Sampling ([SGX Internals](https://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html)).\n\n\n\n## EAX \u0026 `ERESUME`\nOn a fault, an Asynchronous enclave exit (AEX) happens, which (1) saves the current context into a region called the state save area (SSA), pointed to by the OS, fill the context (register content) with dummy ones, and invoke the OS exception handler. \n\n`ERESUME` restores the context saved by AEX and resumes the enclave's execution. AEX and `ERESUME` mechanisms are transparent to the enclave \n\nThe SSA is managed as a stack: the TCS contains the counter for the current SSA, and the counter is increased for each AEX. The size of an SSA is in the `SSAFRAMESIZE` inside the enclave's SECS. `ERESUME` decreases the counter to pop the stack of SSAs. The SSA stack allows for the reentering (`EENTER`) of the enclave during an AEX while preserving the SSA for the previous AEX. For instance, calling `EENTER` to query an enclave's information used to serve AEX? \n\n# Memory management\n\n## EPCM\nThe processor uses an Enclave page cache (EPC) map (EPCM) to kep track of the status of EPC pages. The EPCM contains an entry for each EPC page to keep track of the owner enclave and the allocation status:\n\n| field       | bit | description                 |\n|-------------|-----|-----------------------------|\n| VALID       | 1   | 0 for unallocated EPC pages |\n| PT          | 8   | Page type                   |\n| ENCLAVESECS |     | identify the owner enclave  |\n\nWhen the processor is in enclave mode, after the PTE is fetched and PTE permissions are checked, the MMU is modified to look up the EPCM. Hence, the enclave is protected from the OS mapping pages incorrectly: mapping another enclave's page, or mapping two pages to the same virtual address.\n\n## Demand paging\nSGX has two isntructions to support demand-paging:\n- `EWB` evicts a page from the EPC memory and stores it in normal memory. This encrypts the page and also integrity-protect it. It takes `PAGEINFO` in RBX, EPC page address in `RCX` and the VA of normal memory in `RDX`. \n- `ELDU` restores the encrypted page into EPC memory.\n\n\n## SGXv1\nIn SGXv1, the EPCM is updated by SGX instructions `EADD`, which adds a page to an enclave's initial memory. This allocation is static and can be attested. It only works if the VALID bit is not set.\n\n`EADD` takes a `PAGEINFO` structure as the parameter, which contains \n1. The virtual address\n2. The source non-EPC page\n3. The virtual address of the SECS of the enclave\n3. The virtual address of the Security information (SECINFO) of the page\n\n\n\n### SGXv2 extensions\nSGXv2 included instructions to dynamically allocate/deallocate EPC pages at runtime. \nThe OS uses the following instructions to manage EPC pages.\n- `EAUG` add a page. It takes `SECINFO` and the virtual address of the EPC page as the argument.\n- `EMODT` deallocate a page\n- `EMODPR` changes the permissions\n\nThe enclave can then use additional instructions to confirm the allocation requests by the OS: `EACCEPT` and `EACCEPTCOPY`.\n- `EACCEPT` [felixcloutier](https://www.felixcloutier.com/x86/eaccept) takes the same arguments as `EAUG`.\n\n\n# Related\n- [[fvom56lw]]\n- [[1yhmh234]]\n\n# References\n- [Quarks lab SGX Internals](https://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html)\n- [SGX 101](https://sgx101.gitbook.io/sgx101/)","snippets":["#sgx"],"rawContent":"# Intel SGX\n#sgx\n\n\n# Execution flow\n\nAn enclave is entered with the instruction `EENTER` (https://www.felixcloutier.com/x86/eenter), which launches the enclave at a predefined and attested entry point. CENTER is invoked with `ENCLU`, with the index for it contained in the eax register (i.e., `ENCLU[EENTER]`). \n\n## `EENTER`\n`EENTER` takes RBX and RCX as an argument. \nRBX contains the memory region for the thread control block (TCS) of the enclave to be executed. \nRCX contains the address of the Asynchronous exit pointer (AEP), which is a handler that will be executed when the host serves faults from the enclave through asynchronous enclave exit. \n`EENTER` flushes the TLB, then put the processor into the enclave mode. Note that more checks are also performed, such as disabling Precise Event Based Sampling ([SGX Internals](https://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html)).\n\n\n\n## EAX \u0026 `ERESUME`\nOn a fault, an Asynchronous enclave exit (AEX) happens, which (1) saves the current context into a region called the state save area (SSA), pointed to by the OS, fill the context (register content) with dummy ones, and invoke the OS exception handler. \n\n`ERESUME` restores the context saved by AEX and resumes the enclave's execution. AEX and `ERESUME` mechanisms are transparent to the enclave \n\nThe SSA is managed as a stack: the TCS contains the counter for the current SSA, and the counter is increased for each AEX. The size of an SSA is in the `SSAFRAMESIZE` inside the enclave's SECS. `ERESUME` decreases the counter to pop the stack of SSAs. The SSA stack allows for the reentering (`EENTER`) of the enclave during an AEX while preserving the SSA for the previous AEX. For instance, calling `EENTER` to query an enclave's information used to serve AEX? \n\n# Memory management\n\n## EPCM\nThe processor uses an Enclave page cache (EPC) map (EPCM) to kep track of the status of EPC pages. The EPCM contains an entry for each EPC page to keep track of the owner enclave and the allocation status:\n\n| field       | bit | description                 |\n|-------------|-----|-----------------------------|\n| VALID       | 1   | 0 for unallocated EPC pages |\n| PT          | 8   | Page type                   |\n| ENCLAVESECS |     | identify the owner enclave  |\n\nWhen the processor is in enclave mode, after the PTE is fetched and PTE permissions are checked, the MMU is modified to look up the EPCM. Hence, the enclave is protected from the OS mapping pages incorrectly: mapping another enclave's page, or mapping two pages to the same virtual address.\n\n## Demand paging\nSGX has two isntructions to support demand-paging:\n- `EWB` evicts a page from the EPC memory and stores it in normal memory. This encrypts the page and also integrity-protect it. It takes `PAGEINFO` in RBX, EPC page address in `RCX` and the VA of normal memory in `RDX`. \n- `ELDU` restores the encrypted page into EPC memory.\n\n\n## SGXv1\nIn SGXv1, the EPCM is updated by SGX instructions `EADD`, which adds a page to an enclave's initial memory. This allocation is static and can be attested. It only works if the VALID bit is not set.\n\n`EADD` takes a `PAGEINFO` structure as the parameter, which contains \n1. The virtual address\n2. The source non-EPC page\n3. The virtual address of the SECS of the enclave\n3. The virtual address of the Security information (SECINFO) of the page\n\n\n\n### SGXv2 extensions\nSGXv2 included instructions to dynamically allocate/deallocate EPC pages at runtime. \nThe OS uses the following instructions to manage EPC pages.\n- `EAUG` add a page. It takes `SECINFO` and the virtual address of the EPC page as the argument.\n- `EMODT` deallocate a page\n- `EMODPR` changes the permissions\n\nThe enclave can then use additional instructions to confirm the allocation requests by the OS: `EACCEPT` and `EACCEPTCOPY`.\n- `EACCEPT` [felixcloutier](https://www.felixcloutier.com/x86/eaccept) takes the same arguments as `EAUG`.\n\n\n# Related\n- [[fvom56lw]]\n- [[1yhmh234]]\n\n# References\n- [Quarks lab SGX Internals](https://blog.quarkslab.com/overview-of-intel-sgx-part-1-sgx-internals.html)\n- [SGX 101](https://sgx101.gitbook.io/sgx101/)\n\n\n\n","wordCount":644,"tags":["sgx"],"metadata":{},"created":"2023-08-30T07:26:51.72985824Z","modified":"2023-08-31T05:34:18.664621601Z","checksum":"d1267a1b90e84368c23fae206f733264b60bc4299a390ec472b21d262a4c1473"},
    {"filename":"dx7vz8d5.md","filenameStem":"dx7vz8d5","path":"dx7vz8d5.md","absPath":"/home/khadd/mynotes/dx7vz8d5.md","title":"Intel Transactional Synchronization Extensions (TSX)","link":"[[dx7vz8d5]]","lead":"#intel #tsx","body":"#intel #tsx\n\n\nTSX simplifies concurrent programming with transactional memory ([[cosmdjej]]).\n\nIt introduce two modes of execution, hardware lock elision (HLE), which \n\n# Restricted Transactional Memory (RTM)\nRTM adds 4 instructions: `XBEGIN`, `XEND`, `XABORT` and `XTEST`\n\nA thread can initiate transaction with the `XBEGIN` instruction, and terminate with `XEND`. \n\n```c\nif ((status = _xbegin()) == XBEGIN_STARTED)\n  // Perform transaction\n  // ...\n  // commit to memory\n  _xend();\nelse {\n  // handle transaction error\n}\n```\n\nIn the above example, a transaction begin by calling `_xbegin()`. If it can happen, the code inside the `if` block is executed. During the execution, if conflicts or exceptions occur, the transaction is rolled back to `_xbegin()`, and the program execute the `else` block, which handle the error.\n\n\nTSX uses the L1 cache as the intermediate buffer for transaction. Hence, the existing cache coherence protocols can be used to detect conflicts (e.g., memory is modified by two transactions) without introducing new hardware logics. \n\n## Faults during transactions\nA transaction is also aborted when an interrupt occur. For synchronous exceptions (e.g., page faults), TSX *supress* the transaction and does not deliver it to the OS. \nFor asynchronous exceptions (e.g., timer/IO interrupts), the exception is delivered to the OS *after* the transaction is rolled back and aborted, since blocking it would interfere with OS scheduling.\n\n\nHowever, TSX does not allows the program know which type of exception happened. Hence, page fault, divided-by-zero, conflicts, ..., are treated equally.\n\nSince page faults are supressed, the OS cannot know whether page faults occurs or not. This property has been exploited by defenses against control-channel attacks on SGX @shih2017tsgx. The enclave can stop execution, when ever it encounter a page fault. See [[fvom56lw]].","snippets":["#intel #tsx"],"rawContent":"# Intel Transactional Synchronization Extensions (TSX)\n#intel #tsx\n\n\nTSX simplifies concurrent programming with transactional memory ([[cosmdjej]]).\n\nIt introduce two modes of execution, hardware lock elision (HLE), which \n\n# Restricted Transactional Memory (RTM)\nRTM adds 4 instructions: `XBEGIN`, `XEND`, `XABORT` and `XTEST`\n\nA thread can initiate transaction with the `XBEGIN` instruction, and terminate with `XEND`. \n\n```c\nif ((status = _xbegin()) == XBEGIN_STARTED)\n  // Perform transaction\n  // ...\n  // commit to memory\n  _xend();\nelse {\n  // handle transaction error\n}\n```\n\nIn the above example, a transaction begin by calling `_xbegin()`. If it can happen, the code inside the `if` block is executed. During the execution, if conflicts or exceptions occur, the transaction is rolled back to `_xbegin()`, and the program execute the `else` block, which handle the error.\n\n\nTSX uses the L1 cache as the intermediate buffer for transaction. Hence, the existing cache coherence protocols can be used to detect conflicts (e.g., memory is modified by two transactions) without introducing new hardware logics. \n\n## Faults during transactions\nA transaction is also aborted when an interrupt occur. For synchronous exceptions (e.g., page faults), TSX *supress* the transaction and does not deliver it to the OS. \nFor asynchronous exceptions (e.g., timer/IO interrupts), the exception is delivered to the OS *after* the transaction is rolled back and aborted, since blocking it would interfere with OS scheduling.\n\n\nHowever, TSX does not allows the program know which type of exception happened. Hence, page fault, divided-by-zero, conflicts, ..., are treated equally.\n\nSince page faults are supressed, the OS cannot know whether page faults occurs or not. This property has been exploited by defenses against control-channel attacks on SGX @shih2017tsgx. The enclave can stop execution, when ever it encounter a page fault. See [[fvom56lw]].\n\n\n","wordCount":286,"tags":["intel","tsx"],"metadata":{},"created":"2023-06-19T03:04:24.8909816Z","modified":"2023-06-19T02:01:17.89523677Z","checksum":"f1972f01e76d179abcdf34b5d33621def2003a3c90159cf46023a8255b8f14f0"},
    {"filename":"qti6u06p.md","filenameStem":"qti6u06p","path":"qti6u06p.md","absPath":"/home/khadd/mynotes/qti6u06p.md","title":"Interface design for distrust","link":"[[qti6u06p]]","lead":"#compartmentalization","body":"#compartmentalization\n\n[@lefeuvre2022assessing] proposed 8 guidelines for designing safe interface that helps reduce the interface vulnerabilities.\n\n## 1. Clearly segregate resources\nThis means that each component must be responsible for allocating and freeing their own resources. In other words, they should *not* expose a malloc-like interface to other compartments. Doing so, attackers from a compartment can exploit the allocator (e.g., heap feng shui), or trigger arbitrary use-after-free (if the allocated data is used at both side).\n\n## 2. Always copy cross boundary objects\nIn other words, never let two compartments concurrently modify data. Doing so leads to TOCTOU issues, and the need of cross-compartment synchronization.\n\n\n## 3. Simplifying API-crossing objects\nAPIs should not contains private states of the compartment, since they can easily corrupted.\n\nMoreover, private states are very hard to check for correctness, especially pointer data.\n\nMaintaining immutability of those state is also a hard problem.\n\n\n## 4. Trusted-components allocates\nThe trusted component must allocates memory. \n\nThis guideline is to avoid validating may-corrupted data from other components. \nEspecially, for strings, since the trusted component allocate, it knows the size of the buffer, so checking NULL-termination is not needed. \n\nIt is not sure if it is applicable to other data except from String. A more generalized version is that the trusted component must allocate memory where the size is unknown.\n\n## 5. Trusted interface functions must be thread-safe\nThis is to avoid temporal attacks.\n\n## 6. Ordering requirements \nInterface must enforce ordering requirements if possible.\n\n\n## 7. No sharing of unintialized data\nThis is to avoid leaking of private data in uninitalized memory. \n\n## 8. Check for CIV ASAP\nSafety checks should be performed as soon as the untrusted data is received. This is because it is very hard to ensure the safety once the data is propagated throughout the program, which leads to duplicated checks. \n\nMoreover, it prevent untrusted data from flowing to other compartments.","snippets":["#compartmentalization"],"rawContent":"# Interface design for distrust \n#compartmentalization\n\n[@lefeuvre2022assessing] proposed 8 guidelines for designing safe interface that helps reduce the interface vulnerabilities.\n\n## 1. Clearly segregate resources\nThis means that each component must be responsible for allocating and freeing their own resources. In other words, they should *not* expose a malloc-like interface to other compartments. Doing so, attackers from a compartment can exploit the allocator (e.g., heap feng shui), or trigger arbitrary use-after-free (if the allocated data is used at both side).\n\n## 2. Always copy cross boundary objects\nIn other words, never let two compartments concurrently modify data. Doing so leads to TOCTOU issues, and the need of cross-compartment synchronization.\n\n\n## 3. Simplifying API-crossing objects\nAPIs should not contains private states of the compartment, since they can easily corrupted.\n\nMoreover, private states are very hard to check for correctness, especially pointer data.\n\nMaintaining immutability of those state is also a hard problem.\n\n\n## 4. Trusted-components allocates\nThe trusted component must allocates memory. \n\nThis guideline is to avoid validating may-corrupted data from other components. \nEspecially, for strings, since the trusted component allocate, it knows the size of the buffer, so checking NULL-termination is not needed. \n\nIt is not sure if it is applicable to other data except from String. A more generalized version is that the trusted component must allocate memory where the size is unknown.\n\n## 5. Trusted interface functions must be thread-safe\nThis is to avoid temporal attacks.\n\n## 6. Ordering requirements \nInterface must enforce ordering requirements if possible.\n\n\n## 7. No sharing of unintialized data\nThis is to avoid leaking of private data in uninitalized memory. \n\n## 8. Check for CIV ASAP\nSafety checks should be performed as soon as the untrusted data is received. This is because it is very hard to ensure the safety once the data is propagated throughout the program, which leads to duplicated checks. \n\nMoreover, it prevent untrusted data from flowing to other compartments.\n","wordCount":320,"tags":["compartmentalization"],"metadata":{},"created":"2023-05-24T04:12:18.744165461Z","modified":"2023-05-25T06:08:46.25478388Z","checksum":"61a12eaecb53b1d9ef90113594861015d20ebce30a7600afe95a6c81fb978cbf"},
    {"filename":"1k9i1cr3.md","filenameStem":"1k9i1cr3","path":"1k9i1cr3.md","absPath":"/home/khadd/mynotes/1k9i1cr3.md","title":"Interrupt handling in Unikraft (x86)","link":"[[1k9i1cr3]]","lead":"#unikraft","body":"#unikraft\n\nOn x86, `lidt %0` loads the IDT address into IDT register ([osdev]).\n\nOn unikraft, `traps_table_init` initialize the traps vector table, a.k.a the IDT ([osdev]). It writes into the `cpu_idt` table, with the corresponding trap index.\n\nThe function pointer to the handler in IDT is set to a stub, named `asm_trap_{trapname}` (defined by the macro `ASM_TRAP_SYM`). E.g., `asm_trap_page_fault`.\n\nThe stubs are defined in `cpu_vectors_x86_64.S`. Its implementation stores the register states into `struct __reg` and calls the function with the name `do_{trapname}`. Declarations of these `do_*` functions can be found in `plat/x86/traps.c`. \n\nThe following macro create implementations for the trap that actually call a `_raise_event_{event}` function. \n```c\n#define DECLARE_TRAP(name, str, event)\t\t\t\t\t\\\nvoid do_##name(struct __regs *regs)\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tint rc;\t\t\t\t\t\t\t\t\\\n\trc = _raise_event_##event(TRAP_##name, regs, 0);\t\t\\\n\tif (unlikely(rc \u003c 0))\t\t\t\t\t\t\\\n\t\tuk_pr_crit(\"trap handler returned error: %d\\n\", rc);\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (!rc)\t\t\t\t\t\t\t\\\n\t\tdo_unhandled_trap(TRAP_##name, str, regs, 0);\t\t\\\n}\n```\n\n```c\nDECLARE_TRAP   (debug,           \"debug\",                UKARCH_TRAP_DEBUG)\nDECLARE_TRAP_EC(int3,            \"int3\",                 UKARCH_TRAP_DEBUG)\n```\n \nWhen raise_event is called, it invoke the list of handlers registered for the event. For example, `do_page_fault` invoke the registered handler for `UKARCH_TRAP_PAGE_FAULT`.\nThe handler is registered in `ukvmem/arch/x86_64/pagefault.c` with `UK_EVENT_HANDLER_PRIO`.\n\nThis design enables an architectural event to be handled in many stages.\n\n# References\n- [osdev]: [url](https://wiki.osdev.org/Interrupt_Descriptor_Table)","snippets":["#unikraft"],"rawContent":"# Interrupt handling in Unikraft (x86)\n#unikraft\n\nOn x86, `lidt %0` loads the IDT address into IDT register ([osdev]).\n\nOn unikraft, `traps_table_init` initialize the traps vector table, a.k.a the IDT ([osdev]). It writes into the `cpu_idt` table, with the corresponding trap index.\n\nThe function pointer to the handler in IDT is set to a stub, named `asm_trap_{trapname}` (defined by the macro `ASM_TRAP_SYM`). E.g., `asm_trap_page_fault`.\n\nThe stubs are defined in `cpu_vectors_x86_64.S`. Its implementation stores the register states into `struct __reg` and calls the function with the name `do_{trapname}`. Declarations of these `do_*` functions can be found in `plat/x86/traps.c`. \n\nThe following macro create implementations for the trap that actually call a `_raise_event_{event}` function. \n```c\n#define DECLARE_TRAP(name, str, event)\t\t\t\t\t\\\nvoid do_##name(struct __regs *regs)\t\t\t\t\t\\\n{\t\t\t\t\t\t\t\t\t\\\n\tint rc;\t\t\t\t\t\t\t\t\\\n\trc = _raise_event_##event(TRAP_##name, regs, 0);\t\t\\\n\tif (unlikely(rc \u003c 0))\t\t\t\t\t\t\\\n\t\tuk_pr_crit(\"trap handler returned error: %d\\n\", rc);\t\\\n\t\t\t\t\t\t\t\t\t\\\n\tif (!rc)\t\t\t\t\t\t\t\\\n\t\tdo_unhandled_trap(TRAP_##name, str, regs, 0);\t\t\\\n}\n```\n\n```c\nDECLARE_TRAP   (debug,           \"debug\",                UKARCH_TRAP_DEBUG)\nDECLARE_TRAP_EC(int3,            \"int3\",                 UKARCH_TRAP_DEBUG)\n```\n \nWhen raise_event is called, it invoke the list of handlers registered for the event. For example, `do_page_fault` invoke the registered handler for `UKARCH_TRAP_PAGE_FAULT`.\nThe handler is registered in `ukvmem/arch/x86_64/pagefault.c` with `UK_EVENT_HANDLER_PRIO`.\n\nThis design enables an architectural event to be handled in many stages.\n\n# References\n- [osdev]: [url](https://wiki.osdev.org/Interrupt_Descriptor_Table)\n\n\n","wordCount":213,"tags":["unikraft"],"metadata":{},"created":"2023-07-03T02:43:48.497989255Z","modified":"2023-09-22T05:43:39.514176384Z","checksum":"83709f8545d15002b004035547b032d4698f83cfeaa944b3175c6ca47289b377"},
    {"filename":"2hnk4l00.md","filenameStem":"2hnk4l00","path":"2hnk4l00.md","absPath":"/home/khadd/mynotes/2hnk4l00.md","title":"Invariants in Rust","link":"[[2hnk4l00]]","lead":"#rust","body":"#rust\n\nRalf Jung described two types of *invariants* in Rust in [this post](https://www.ralfj.de/blog/2018/08/22/two-kinds-of-invariants.html), *safety* and *validity*.\n\n# Safety invariant\nEssentially, *safety invariants* are the invariants of a particualr types, that must be upholded, such that that *no matter what safe code does, it must not cause undefine behaviors*.\n\nOne example of this for any primitive type `T`, the invariant is that the object having the type must be initialized (accesing unintialized data is an undefined behavior). Another example is that reference types must be aligned, non-null, and points to an allocated memory that have no other pointer accesses.\n\n\n## Custom/higher-order safety invariants\nThere can also be *custom* safety invariants -- *higher-order* invariants that are not maintained by the compiler, but must be maintained by the unsafe code @bae2021rudra. For example, *Vec*, defined as \n```rust\npub struct Vec\u003cT\u003e {\n    ptr: Unique\u003cT\u003e, // pointing to the heap-allocated backing store holding all the data\n    cap: usize, // number of elements that fit the backing store\n    len: usize, // number of elements that are actually initialized in the backing store\n}\n```\n, must uphold that `ptr` must points to valid memory size of `cap*sizeof(T)`, . The difference between invariants of Vec and other primitive types is that it is defined by the owner, and that the implementer of the type and the unsafe users must uphold them.\n\nMore specifically, for those types, the Rust compiler only guarantee the corectnesses of the signature. Some higher-order invariants can related to (see @bae2021rudra): \n1. Logical consistency (e.g., respecting total ordering)\n2. Purity (e.g., always returns same value for the same input, have no side effect) (possibly related to [[013pr50f]])\n3. Semantic restrictions (e.g., only write to the arguments because it may contains unintialized memory)\nNOTE: It seems that the first and second types of higher-order invariants cannot trigger undefined behaviors by themself. It is not sure we should consider them safety invariants, even. [There has been discussion among Rust community about this](https://users.rust-lang.org/t/should-i-use-unsafe-merely-to-encourage-users-to-maintain-invariants/27856/4). The conclusion was that they should *not* be unsafe invariants.\n\n### Invariant boundaries of unsafe\nThe unsafe code writter to make sure that they are correct *only at the boundaries* with safe code.\nThis boundary highly depends on the unsafe user. Generally, if an *unsafe* block is well-contained, the safety invariants should be upholded *at the end* of the unsafe scope.\nOn the other hand, for some libraries that use unsafe, but provide safe wrapper for safe code to use, the safety\n\n---\n\n# Validity invariants\nThe other type of invariant is the validity invariant. Validity invariants are the invariants that must be maintained between Rust and the compiler, so that the optimization can be performed safely. For instance, `Option\u003cbool\u003e` can be stored in 1 byte of memory, because it can only have three possible values (`true`, `false` and `None`).\n\n\nDifferent from safety invariant that the unsafe code must uphold only at the boundaries with safe code, validity invariants are the invariants unsafe must *always* uphold.\n\n\n# Related notes\n[[zzq5zy5v]]","snippets":["#rust"],"rawContent":"# Invariants in Rust\n#rust\n\nRalf Jung described two types of *invariants* in Rust in [this post](https://www.ralfj.de/blog/2018/08/22/two-kinds-of-invariants.html), *safety* and *validity*.\n\n# Safety invariant\nEssentially, *safety invariants* are the invariants of a particualr types, that must be upholded, such that that *no matter what safe code does, it must not cause undefine behaviors*.\n\nOne example of this for any primitive type `T`, the invariant is that the object having the type must be initialized (accesing unintialized data is an undefined behavior). Another example is that reference types must be aligned, non-null, and points to an allocated memory that have no other pointer accesses.\n\n\n## Custom/higher-order safety invariants\nThere can also be *custom* safety invariants -- *higher-order* invariants that are not maintained by the compiler, but must be maintained by the unsafe code @bae2021rudra. For example, *Vec*, defined as \n```rust\npub struct Vec\u003cT\u003e {\n    ptr: Unique\u003cT\u003e, // pointing to the heap-allocated backing store holding all the data\n    cap: usize, // number of elements that fit the backing store\n    len: usize, // number of elements that are actually initialized in the backing store\n}\n```\n, must uphold that `ptr` must points to valid memory size of `cap*sizeof(T)`, . The difference between invariants of Vec and other primitive types is that it is defined by the owner, and that the implementer of the type and the unsafe users must uphold them.\n\nMore specifically, for those types, the Rust compiler only guarantee the corectnesses of the signature. Some higher-order invariants can related to (see @bae2021rudra): \n1. Logical consistency (e.g., respecting total ordering)\n2. Purity (e.g., always returns same value for the same input, have no side effect) (possibly related to [[013pr50f]])\n3. Semantic restrictions (e.g., only write to the arguments because it may contains unintialized memory)\nNOTE: It seems that the first and second types of higher-order invariants cannot trigger undefined behaviors by themself. It is not sure we should consider them safety invariants, even. [There has been discussion among Rust community about this](https://users.rust-lang.org/t/should-i-use-unsafe-merely-to-encourage-users-to-maintain-invariants/27856/4). The conclusion was that they should *not* be unsafe invariants.\n\n### Invariant boundaries of unsafe\nThe unsafe code writter to make sure that they are correct *only at the boundaries* with safe code.\nThis boundary highly depends on the unsafe user. Generally, if an *unsafe* block is well-contained, the safety invariants should be upholded *at the end* of the unsafe scope.\nOn the other hand, for some libraries that use unsafe, but provide safe wrapper for safe code to use, the safety\n\n---\n\n# Validity invariants\nThe other type of invariant is the validity invariant. Validity invariants are the invariants that must be maintained between Rust and the compiler, so that the optimization can be performed safely. For instance, `Option\u003cbool\u003e` can be stored in 1 byte of memory, because it can only have three possible values (`true`, `false` and `None`).\n\n\nDifferent from safety invariant that the unsafe code must uphold only at the boundaries with safe code, validity invariants are the invariants unsafe must *always* uphold.\n\n\n# Related notes\n[[zzq5zy5v]]\n","wordCount":500,"tags":["rust"],"metadata":{},"created":"2023-06-14T07:36:42.073457893Z","modified":"2023-06-15T08:33:27.124694469Z","checksum":"1468dd3e35c1a379f0ed798005a56db9710f6f4909d272d1c34e3ce2731f8114"},
    {"filename":"w0weqamx.md","filenameStem":"w0weqamx","path":"literature/w0weqamx.md","absPath":"/home/khadd/mynotes/literature/w0weqamx.md","title":"InvisiPage: Oblivious Demand Paging for Secure Enclaves","link":"[[literature/w0weqamx]]","lead":"#literature\n@aga2019invisipage","body":"#literature\n@aga2019invisipage\n\n# Summary\nTwo-page tables are assumed: one to map EPC pages, and the other to map normal pages. The EPC page table is safely stored within the EPC, and only the enclave can maintain it. Moreover, page faults are handled by the in-enclave page fault handler, so that the faulting address is not learned by the OS.\nBased on this, InvisiPage then supports the oblivious *demand paging* for the EPC pages.  It supports the spilling of EPC pages into non-EPC memory and uses ORAM to decide which pages to spill.\n\n\n# Oblivious page management\nThe goal is to allow the OS to control how many pages that are allocated to an enclave, but not which virtual address that are mapped.\n\nFirst, it maintains two page tables, one to map the EPC pages, the other is for normal use. This approach already exists in @costan2016sanctum. However, the new thing is that it allows the OS to swap EPC pages into non-EPC memory *obliviously.\n\nTo do this, the enclave and the OS have to collaborate for memory management.\n## Collaborative memory management\n### Spilling EPC page to non-EPC\nThe OS provides interface to spill a list of provided virtual addresses to non-EPC memory (`opam_access(o-vpn[])`)\n\nThe ORAM tree is maintained by the OS in a separate tree data structure. This tree is indexed by the oblivious page number (`o-vpn`), which is essentially the block ID in the ORAM tree. \n\nOn receiving the `opam_access()` request, the OS has to keep the requested pages *memory-resident*. The enclave runtime then spills/fetches the EPC pages according to the ORAM algorithm. \n\nOn a spill, data from EPC pages are copied into non-EPC pages. For fetches, data from non-EPC pages are copied into EPC pages.\nFor this step, there is one optimization introduced: only one page is copied from thea non-EPC into EPC memory. The rest of the non-EPC pages are reshuffled within the non-EPC memory.\nTo the OS, it only seems like a path is accessed. It cannot tell which page is actually copied into the EPC. \n\n\nThe page table is retrofitted to store position map information.\n\n\n### Freeing an EPC page\nTo free a EPC page, the OS request a free request to the enclave, but the actual page that get freed is schosen by the enclave.","snippets":["#literature\n@aga2019invisipage"],"rawContent":"# InvisiPage: Oblivious Demand Paging for Secure Enclaves\n#literature\n@aga2019invisipage\n\n# Summary\nTwo-page tables are assumed: one to map EPC pages, and the other to map normal pages. The EPC page table is safely stored within the EPC, and only the enclave can maintain it. Moreover, page faults are handled by the in-enclave page fault handler, so that the faulting address is not learned by the OS.\nBased on this, InvisiPage then supports the oblivious *demand paging* for the EPC pages.  It supports the spilling of EPC pages into non-EPC memory and uses ORAM to decide which pages to spill.\n\n\n# Oblivious page management\nThe goal is to allow the OS to control how many pages that are allocated to an enclave, but not which virtual address that are mapped.\n\nFirst, it maintains two page tables, one to map the EPC pages, the other is for normal use. This approach already exists in @costan2016sanctum. However, the new thing is that it allows the OS to swap EPC pages into non-EPC memory *obliviously.\n\nTo do this, the enclave and the OS have to collaborate for memory management.\n## Collaborative memory management\n### Spilling EPC page to non-EPC\nThe OS provides interface to spill a list of provided virtual addresses to non-EPC memory (`opam_access(o-vpn[])`)\n\nThe ORAM tree is maintained by the OS in a separate tree data structure. This tree is indexed by the oblivious page number (`o-vpn`), which is essentially the block ID in the ORAM tree. \n\nOn receiving the `opam_access()` request, the OS has to keep the requested pages *memory-resident*. The enclave runtime then spills/fetches the EPC pages according to the ORAM algorithm. \n\nOn a spill, data from EPC pages are copied into non-EPC pages. For fetches, data from non-EPC pages are copied into EPC pages.\nFor this step, there is one optimization introduced: only one page is copied from thea non-EPC into EPC memory. The rest of the non-EPC pages are reshuffled within the non-EPC memory.\nTo the OS, it only seems like a path is accessed. It cannot tell which page is actually copied into the EPC. \n\n\nThe page table is retrofitted to store position map information.\n\n\n### Freeing an EPC page\nTo free a EPC page, the OS request a free request to the enclave, but the actual page that get freed is schosen by the enclave.\n","wordCount":390,"tags":["literature"],"metadata":{},"created":"2023-06-19T03:04:24.902716374Z","modified":"2023-08-31T05:15:06.704335549Z","checksum":"dbbbc44372e228647c714c29fd466a31613e523c842802e38d522bdbfa525175"},
    {"filename":"d8hi0u6t.md","filenameStem":"d8hi0u6t","path":"literature/d8hi0u6t.md","absPath":"/home/khadd/mynotes/literature/d8hi0u6t.md","title":"Klotski: Efficient Obfuscated Execution against Controlled-Channel Attacks","link":"[[literature/d8hi0u6t]]","lead":"#literature #controlled-channel #oblivious #sgx \n@zhang2020klotski","body":"#literature #controlled-channel #oblivious #sgx \n@zhang2020klotski\n\n\n\n\n\n# Noteworthy Arguments\n## Positioning\n- Previous solutions for controlled-channel protection are either (0) incomplete against attacks, (2) have incomplete protection for code and data, and (3) has high overheads.\n- Incompleteness against attack:\n    - TXS-based solutions @shih2017tsgx, , that tries to detect interrupts of enclaves, but there has been attacks that can trigger without enclave exit.\n\n -Incomplete protection for code and data\n  - Some only protect data accesses @sasy2018zerotrace @drsgx\n  - Other only protect code access @zizagger, and can be defeated fine-grained attack\n\n- High overheads\n  - @shinde2016preventing places sensitive code and data inside one page, but has high overheads (4000x)\n vim.lsp.diagnostic.show_line_diagnostics() - Obfuscuro @ahmad2019obfuscuro only support small code and data size (8KB).\n\n\n- #todo Subpage-level code and data randomization\n\n\n\n\n# Oblivious memory subsystem scheme\n## Memory subsystem\nKlotski's memory subsystem consists of three levels (akin to the actual memory subsystem). The first is the code and data caches, that has reconfigurable sizes, called the *vCache*. The second level is the ORAM *stashes* for code and data. The final layer is the *ORAM tree*.\n\nThe stash and the tree are parts of an ORAM scheme.\n\nMemory from the higher level is evicted into the lower level, with some policies.\n\nThe main reason for *vCache* is to trade-off security for some performance. This is the main difference with Obfuscuro @ahmad2019obfuscuro vCache can be configure to be larger than the page size.\n- ❓Why do you need three levels, why not just configure the stash size then?\n  - ORAM algorithms requires the stash to be certain sizes, or else it will not work (e.g., the path does not fit into the stash).\n  - The stash in untrusted memory, an can span several pages. \n\nIs there a scheme for storing data into untrusted storage, like in @sasy2018zerotrace?\n- This paper assume all memory is within the enclave, and there is no spilling into untrusted storage.\n\n\n## Memory access hierarchy\n\n### Logical addresses\nLogical addresses are the address that the instructions use (i.e., virtual addresses).\n\nKlotski use 32-bit addresses in their implementation, maybe to limit the number of entries in the software PT?\n\n### Logical address translation\nThe program is instrumented to *translate* the logical address on every operations into *real address*, which is an address inside the execution cache.\n\nLogical addresses are translated using a software page table using same method as real page table. The following function translates logical address into page table index:\n\n``` cpp\nsize_t getRealAddress(size_t logicAddr){\n    size_t index = logicAddr\u003e\u003eSHADOWPAGEWIDE;\n    //if the page does not exist in cache,swap the page in\n    if(!pagetable[index]){\n        struct OramPool * oramPool;\n        size_t blockIndex;\n        if(isBigObject(index)){\n            LOGIC_INDEX_TO_BLOCK_INDEX_FOR_BIG(index,blockIndex)\n            oramPool = \u0026DataPool_bigData;\n        }else{\n            LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)\n            oramPool = \u0026DataPool_smallData;\n        }\n        handleObliviousPageExchangeData(index,blockIndex,oramPool);\n    }\n    return pagetable[index]+logicAddr;\n}\n```\nThe address itself also seems to contain the block ID. `LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)` gets the correct block ID from the position map index.\n\nIn this translation function, if page is not in the page table, then it is not in the cache, so address translation happen. This is not what is described in the paper: a PTE also contains the path ID. Maybe this function is only used for static data...\n\nThe real translation function seems to be `dereference_data()`.\n\n### ORAM access\nOn a page miss, ORAM access is triggered to fetch block into the vCache. \nFirst, the ORAM block (2KB *minipage*) is fetched in to the *stash*, and the position map is updated. The block is then moved to the vCache, and a block inside vCache is swapped out.  \n#### Stash\u003c-\u003eORAM\nRing ORAM evict the blocks after $k$ accesses. On eviction, blocks inside the stash is flushed into the ORAM tree.\n\n#### vCache\u003c-\u003eStash\nThe minipage is then swapped into the vCache, where a block is *randomly* evicted from the vCache to make space.\n\nThe paper argue that *LRU* cache eviction may leak information.\n\nThere is also a reconfigurable re-randomization of the vCache: the user can configure such that the vCache is flushed after $n$ accesses. \n\n\n\n\n## Address translation\nKlotski uses a scheme to *translate* logical address to the actual address inside vCache, in the same way a MMU translate physical to virtual address.\n\n\n```c\n// virtual addr use in Klotski-instrumented program\nloadImm R1, logicalAddr\ncall vPTE_lookup(R1)\n// use pointer\nload R2, R1 \n...\n\nv_addr vPTE_lookup(v_addr logicalAddr){\n    vPTE_t vPTE = position_map_scan(logicalAddr);\n    if (vPTE.cached)\n        return vPTE.addr;\n    else\n        // slow path\n       if (vPTE.in_stash) \n           vPTE = stash_fetch(vPTE.oramIndex);\n       else\n           vPTE = oram_read(vPTE.oramIndex);\n       return vPTE.addr;\n}\n```\n## Operations\n### vCache and Stash\n\n- `LoadCache` reads the target minipage\n- \n\n### Address translation\n\n# Compiler \u0026 runtime\nCompiler changes all memory instructions, call, return, into calls into the runtime functions. \nImplementation: [Here](https://github.com/nczhang88pan/KlotskiSGX/tree/master/klotski/llvmProgram/llvm/lib/Transforms/Instrumentation/Klotski)\nMaybe the compiler transformation would looks like this:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n\n---\n%1 = call mmu_load(%arg1)\n%2 = add %1, 100\ncall mmu_call(\u0026foo)\ncall mmu_store(%2, %1)\n```\n\nThe compiler also split code and data into blocks of 2KB, which is also the ORAM block size. The code is compiled as relocatable code, so that it can be relocated to any virtual addresses.\n- ❓ Why do you need relocatable code here?\n- ❓ What is effiective virtual address, why does it change at runtime?\n\nThe runtime functions acts as a memory subsystem: given a virtual address, it look up \n\n\n# ORAM Accesses\nThe paper uses Ring ORAM for its ORAM algorithm. However, there are several noteworthy extensions. Because the memory used for posmap (virtual page  table) and stash is in untrusted memory, attackers can find out which stash slot and posmap entry is accessed.\n\n## ORead\nAn `ORead` operation is introduced to lineary scan over all data that must be touched to remain oblivious, similar to a `cmov`. The data is stored into a 256-bit  ymm registers. 1 register is reserved for reading unused data, and the remainings is used to store the required data.\n\nNOTE: it is not exactly similar to `CMOV`, you only need to actually touch the data in `ORead`, but not write it back.\n\n---\n\nThe `ReadPath` operation that read from ORAM path into stash uses this to bring data into the stash without revealing the actual bucket/block that is accessed.\n\nFor example, consider fetching of a path in traditional Ring ORAM. On each bucket along the path, a block is fetched, but discarded. On the block that contain non-dummy data, it is actually read into the stash. With visibility over stash and tree, the attacker can see that there is a read from the tree, following by a write into the stash. This means that the block that is just read contains the requested data.\n\nBy fetching all data into YMM registers, and delay the write back to the stash to the last moment, this can be hidden.\n\n---\n\n`LoadCache` that load an entry from stash into cache also needs this (for same reason above). It must scan over all stash entries, and only copy the one needed into the vCache.\n\n## WriteStash\nThe WriteStash operation, that write into the stash, is also made oblivious. There are two potential leakage, when the attacker learns about the stash access:\n1. If data is written into a slot, it means that the slot is empty, so it must have been evicted recently.\n2. If data is written into a stash slot twice (without being read), it can be infered that the slot contained dummy blocks. ❓ Is there actually dummy blocks in the stash?\n\nTo solve this, every (1) block must only be written once (before being reshuffled), and (2) a write to a slot must not reveal the last block being evicted\nKlotski solve this by keeping a pointer to slot that is last written, and increment the pointer to the next slot at every write. When the pointer move to the last empty blocks, the stash is reshuffled.\n\n```\n      Spare stash ptr\n            |\n            v\n| 2 | 5 | 3 | \u003cempty\u003e | 4 | \u003cempty\u003e | \n```\n\nAfter write:\n```\n                      v \n| 2 | 5 | 3 | *6* | 4 | \u003c empty \u003e | \n```\n\nPointer moved to the last empty block, so reshuffle:\n```\n                           v\n| 2 | \u003cevited\u003e | \u003cevicted\u003e | 6 | 4 | *1* | \n```\n\nReshuffling moves actual blocks to the begining and update the spare stash ptr.\n```\n                v\n| 6 | 1 | 4 | 2 | \u003cempty\u003e | \u003cempty\u003e | \n```","snippets":["#literature #controlled-channel #oblivious #sgx \n@zhang2020klotski"],"rawContent":"# Klotski: Efficient Obfuscated Execution against Controlled-Channel Attacks \n#literature #controlled-channel #oblivious #sgx \n@zhang2020klotski\n\n\n\n\n\n# Noteworthy Arguments\n## Positioning\n- Previous solutions for controlled-channel protection are either (0) incomplete against attacks, (2) have incomplete protection for code and data, and (3) has high overheads.\n- Incompleteness against attack:\n    - TXS-based solutions @shih2017tsgx, , that tries to detect interrupts of enclaves, but there has been attacks that can trigger without enclave exit.\n\n -Incomplete protection for code and data\n  - Some only protect data accesses @sasy2018zerotrace @drsgx\n  - Other only protect code access @zizagger, and can be defeated fine-grained attack\n\n- High overheads\n  - @shinde2016preventing places sensitive code and data inside one page, but has high overheads (4000x)\n vim.lsp.diagnostic.show_line_diagnostics() - Obfuscuro @ahmad2019obfuscuro only support small code and data size (8KB).\n\n\n- #todo Subpage-level code and data randomization\n\n\n\n\n# Oblivious memory subsystem scheme\n## Memory subsystem\nKlotski's memory subsystem consists of three levels (akin to the actual memory subsystem). The first is the code and data caches, that has reconfigurable sizes, called the *vCache*. The second level is the ORAM *stashes* for code and data. The final layer is the *ORAM tree*.\n\nThe stash and the tree are parts of an ORAM scheme.\n\nMemory from the higher level is evicted into the lower level, with some policies.\n\nThe main reason for *vCache* is to trade-off security for some performance. This is the main difference with Obfuscuro @ahmad2019obfuscuro vCache can be configure to be larger than the page size.\n- ❓Why do you need three levels, why not just configure the stash size then?\n  - ORAM algorithms requires the stash to be certain sizes, or else it will not work (e.g., the path does not fit into the stash).\n  - The stash in untrusted memory, an can span several pages. \n\nIs there a scheme for storing data into untrusted storage, like in @sasy2018zerotrace?\n- This paper assume all memory is within the enclave, and there is no spilling into untrusted storage.\n\n\n## Memory access hierarchy\n\n### Logical addresses\nLogical addresses are the address that the instructions use (i.e., virtual addresses).\n\nKlotski use 32-bit addresses in their implementation, maybe to limit the number of entries in the software PT?\n\n### Logical address translation\nThe program is instrumented to *translate* the logical address on every operations into *real address*, which is an address inside the execution cache.\n\nLogical addresses are translated using a software page table using same method as real page table. The following function translates logical address into page table index:\n\n``` cpp\nsize_t getRealAddress(size_t logicAddr){\n    size_t index = logicAddr\u003e\u003eSHADOWPAGEWIDE;\n    //if the page does not exist in cache,swap the page in\n    if(!pagetable[index]){\n        struct OramPool * oramPool;\n        size_t blockIndex;\n        if(isBigObject(index)){\n            LOGIC_INDEX_TO_BLOCK_INDEX_FOR_BIG(index,blockIndex)\n            oramPool = \u0026DataPool_bigData;\n        }else{\n            LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)\n            oramPool = \u0026DataPool_smallData;\n        }\n        handleObliviousPageExchangeData(index,blockIndex,oramPool);\n    }\n    return pagetable[index]+logicAddr;\n}\n```\nThe address itself also seems to contain the block ID. `LOGIC_INDEX_TO_BLOCK_INDEX(index,blockIndex)` gets the correct block ID from the position map index.\n\nIn this translation function, if page is not in the page table, then it is not in the cache, so address translation happen. This is not what is described in the paper: a PTE also contains the path ID. Maybe this function is only used for static data...\n\nThe real translation function seems to be `dereference_data()`.\n\n### ORAM access\nOn a page miss, ORAM access is triggered to fetch block into the vCache. \nFirst, the ORAM block (2KB *minipage*) is fetched in to the *stash*, and the position map is updated. The block is then moved to the vCache, and a block inside vCache is swapped out.  \n#### Stash\u003c-\u003eORAM\nRing ORAM evict the blocks after $k$ accesses. On eviction, blocks inside the stash is flushed into the ORAM tree.\n\n#### vCache\u003c-\u003eStash\nThe minipage is then swapped into the vCache, where a block is *randomly* evicted from the vCache to make space.\n\nThe paper argue that *LRU* cache eviction may leak information.\n\nThere is also a reconfigurable re-randomization of the vCache: the user can configure such that the vCache is flushed after $n$ accesses. \n\n\n\n\n## Address translation\nKlotski uses a scheme to *translate* logical address to the actual address inside vCache, in the same way a MMU translate physical to virtual address.\n\n\n```c\n// virtual addr use in Klotski-instrumented program\nloadImm R1, logicalAddr\ncall vPTE_lookup(R1)\n// use pointer\nload R2, R1 \n...\n\nv_addr vPTE_lookup(v_addr logicalAddr){\n    vPTE_t vPTE = position_map_scan(logicalAddr);\n    if (vPTE.cached)\n        return vPTE.addr;\n    else\n        // slow path\n       if (vPTE.in_stash) \n           vPTE = stash_fetch(vPTE.oramIndex);\n       else\n           vPTE = oram_read(vPTE.oramIndex);\n       return vPTE.addr;\n}\n```\n## Operations\n### vCache and Stash\n\n- `LoadCache` reads the target minipage\n- \n\n### Address translation\n\n# Compiler \u0026 runtime\nCompiler changes all memory instructions, call, return, into calls into the runtime functions. \nImplementation: [Here](https://github.com/nczhang88pan/KlotskiSGX/tree/master/klotski/llvmProgram/llvm/lib/Transforms/Instrumentation/Klotski)\nMaybe the compiler transformation would looks like this:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n\n---\n%1 = call mmu_load(%arg1)\n%2 = add %1, 100\ncall mmu_call(\u0026foo)\ncall mmu_store(%2, %1)\n```\n\nThe compiler also split code and data into blocks of 2KB, which is also the ORAM block size. The code is compiled as relocatable code, so that it can be relocated to any virtual addresses.\n- ❓ Why do you need relocatable code here?\n- ❓ What is effiective virtual address, why does it change at runtime?\n\nThe runtime functions acts as a memory subsystem: given a virtual address, it look up \n\n\n# ORAM Accesses\nThe paper uses Ring ORAM for its ORAM algorithm. However, there are several noteworthy extensions. Because the memory used for posmap (virtual page  table) and stash is in untrusted memory, attackers can find out which stash slot and posmap entry is accessed.\n\n## ORead\nAn `ORead` operation is introduced to lineary scan over all data that must be touched to remain oblivious, similar to a `cmov`. The data is stored into a 256-bit  ymm registers. 1 register is reserved for reading unused data, and the remainings is used to store the required data.\n\nNOTE: it is not exactly similar to `CMOV`, you only need to actually touch the data in `ORead`, but not write it back.\n\n---\n\nThe `ReadPath` operation that read from ORAM path into stash uses this to bring data into the stash without revealing the actual bucket/block that is accessed.\n\nFor example, consider fetching of a path in traditional Ring ORAM. On each bucket along the path, a block is fetched, but discarded. On the block that contain non-dummy data, it is actually read into the stash. With visibility over stash and tree, the attacker can see that there is a read from the tree, following by a write into the stash. This means that the block that is just read contains the requested data.\n\nBy fetching all data into YMM registers, and delay the write back to the stash to the last moment, this can be hidden.\n\n---\n\n`LoadCache` that load an entry from stash into cache also needs this (for same reason above). It must scan over all stash entries, and only copy the one needed into the vCache.\n\n## WriteStash\nThe WriteStash operation, that write into the stash, is also made oblivious. There are two potential leakage, when the attacker learns about the stash access:\n1. If data is written into a slot, it means that the slot is empty, so it must have been evicted recently.\n2. If data is written into a stash slot twice (without being read), it can be infered that the slot contained dummy blocks. ❓ Is there actually dummy blocks in the stash?\n\nTo solve this, every (1) block must only be written once (before being reshuffled), and (2) a write to a slot must not reveal the last block being evicted\nKlotski solve this by keeping a pointer to slot that is last written, and increment the pointer to the next slot at every write. When the pointer move to the last empty blocks, the stash is reshuffled.\n\n```\n      Spare stash ptr\n            |\n            v\n| 2 | 5 | 3 | \u003cempty\u003e | 4 | \u003cempty\u003e | \n```\n\nAfter write:\n```\n                      v \n| 2 | 5 | 3 | *6* | 4 | \u003c empty \u003e | \n```\n\nPointer moved to the last empty block, so reshuffle:\n```\n                           v\n| 2 | \u003cevited\u003e | \u003cevicted\u003e | 6 | 4 | *1* | \n```\n\nReshuffling moves actual blocks to the begining and update the spare stash ptr.\n```\n                v\n| 6 | 1 | 4 | 2 | \u003cempty\u003e | \u003cempty\u003e | \n```\n\n","wordCount":1410,"tags":["todo","literature","sgx","controlled-channel","oblivious"],"metadata":{},"created":"2023-06-12T04:34:51.348147016Z","modified":"2023-12-18T07:39:41.621972982Z","checksum":"65e58d7a79627c7d29a32945fbd407aeeac8e4027ce509ec14d8272ae0e5520c"},
    {"filename":"dyx2t4oz.md","filenameStem":"dyx2t4oz","path":"dyx2t4oz.md","absPath":"/home/khadd/mynotes/dyx2t4oz.md","title":"Knowledge flower","link":"[[dyx2t4oz]]","lead":"#zettelkasten #note-taking","body":"#zettelkasten #note-taking\n\n[This blog post](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) proposes a framework to think about [[ae6fatms|Zettlekasten]] notes.\n\n\n1. Choose an idea and place it in the center.\n2. Think of each leaf as an aspect of the thought that is needed to fully develop it. The thought blossoms like a flower.\n  - Truth: Are there arguments for its truth? Is there empirical evidence for its truth? Is it free of self-contradiction?\n  - Relevance: To whom is the thought important? To whom is it not?\n  - Usefulness: What problem can be solved by the thought? Can it become a tool?\n  - Beauty: How does the thought promote harmony and elegance?\n  - Simplicity: How can you make the thought simpler and easier to understand? Can the thought be used to simplify something else?","snippets":["#zettelkasten #note-taking"],"rawContent":"# Knowledge flower\n#zettelkasten #note-taking\n\n[This blog post](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) proposes a framework to think about [[ae6fatms|Zettlekasten]] notes.\n\n\n1. Choose an idea and place it in the center.\n2. Think of each leaf as an aspect of the thought that is needed to fully develop it. The thought blossoms like a flower.\n  - Truth: Are there arguments for its truth? Is there empirical evidence for its truth? Is it free of self-contradiction?\n  - Relevance: To whom is the thought important? To whom is it not?\n  - Usefulness: What problem can be solved by the thought? Can it become a tool?\n  - Beauty: How does the thought promote harmony and elegance?\n  - Simplicity: How can you make the thought simpler and easier to understand? Can the thought be used to simplify something else?\n","wordCount":130,"tags":["zettelkasten","note-taking"],"metadata":{},"created":"2023-05-03T03:47:47.579037486Z","modified":"2023-05-25T05:54:57.004657241Z","checksum":"ec8dacb8b511db2809c15b84fe8f191a2d8088fb2eaf208006354fca4b460062"},
    {"filename":"vne1zoi3.md","filenameStem":"vne1zoi3","path":"vne1zoi3.md","absPath":"/home/khadd/mynotes/vne1zoi3.md","title":"LLVM register data flow graph","link":"[[vne1zoi3]]","lead":"#llvm #analysis #backend","body":"#llvm #analysis #backend\n\nLLVM provides a Register Data Flow Graph that contains the flow of registers between instructions. [LLVM: include/llvm/CodeGen/RDFGraph.h Source File](https://llvm.org/doxygen/RDFGraph_8h_source.html). Probably useful for some backend analysis tasks.\n\nThe graph is a collection of **Nodes**, where each node can be either a **code node** or a **reference node**.\n- A **code node** is a collection of other nodes. E.g., A **basic block** code node contains **instruction** code nodes, and instruction code node contains **Reference nodes**\n- **Reference node** describe the register reference. It can either be a **DefNode** or a **UseNode**\n\t- DefNode defines the register\n\t- UseNode uses the register\n\nDefNode contains:\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node\n- First reached use: the first node that use this definition.\n\t- To traverse other register uses, we can use the slibing of the UseNode\n- First reached definition: First node after this that redefine the register\nUseNode contains :\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node","snippets":["#llvm #analysis #backend"],"rawContent":"# LLVM register data flow graph\n#llvm #analysis #backend\n\nLLVM provides a Register Data Flow Graph that contains the flow of registers between instructions. [LLVM: include/llvm/CodeGen/RDFGraph.h Source File](https://llvm.org/doxygen/RDFGraph_8h_source.html). Probably useful for some backend analysis tasks.\n\nThe graph is a collection of **Nodes**, where each node can be either a **code node** or a **reference node**.\n- A **code node** is a collection of other nodes. E.g., A **basic block** code node contains **instruction** code nodes, and instruction code node contains **Reference nodes**\n- **Reference node** describe the register reference. It can either be a **DefNode** or a **UseNode**\n\t- DefNode defines the register\n\t- UseNode uses the register\n\nDefNode contains:\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node\n- First reached use: the first node that use this definition.\n\t- To traverse other register uses, we can use the slibing of the UseNode\n- First reached definition: First node after this that redefine the register\nUseNode contains :\n- Reaching definitions: Nodes that this definition uses\n- Sibling: nodes with the same reaching definition as this node\n","wordCount":188,"tags":["analysis","llvm","backend"],"metadata":{},"created":"2023-05-23T08:54:41.12084436Z","modified":"2023-05-24T05:38:55.780815183Z","checksum":"af0b3286f985e081fd9ae6dbb902dbb6dde92658a53acc459e6f4f4b4b80acc3"},
    {"filename":"dgdvhu1e.md","filenameStem":"dgdvhu1e","path":"dgdvhu1e.md","absPath":"/home/khadd/mynotes/dgdvhu1e.md","title":"Limitations of Data-flow-based Dependence analysis","link":"[[dgdvhu1e]]","lead":"#analysis #compartmentalization #data-flow-analysis","body":"#analysis #compartmentalization #data-flow-analysis\n\nProgram compartmentalization techniques such as [@liu2017ptrsplit] often relies on dependence analysis to determine the data flow between code locations, then separate the program based code dependency. Commonly it is done by first identify all *control dependencies* of instructions, which form a reachable control-flow graph. Then, on the reachable control-flow graph, data-flow analysis is performed to find data dependencies.\n\n[@lu2023practical] ([[literature/4zdjxws6]]) notes several limitations with such an approach:\n\nFirst, control dependencies does not reflect all data dependencies.\n- System calls and interrupt handlers is invoked at arbitrary time, and don't have a control-flow edge on the CFG. \n- Two control-independent functions can still pass data through global variables or shared memory.\n[](2023-05-26_.md)\nSecond, data-flow analysis requires points-to analysis.\n- Points-to analysis is expensive can cannot scale to large programs.\n- Points-to analysis produces a large amount of false positive on large programs.","snippets":["#analysis #compartmentalization #data-flow-analysis"],"rawContent":"# Limitations of Data-flow-based Dependence analysis\n#analysis #compartmentalization #data-flow-analysis\n\nProgram compartmentalization techniques such as [@liu2017ptrsplit] often relies on dependence analysis to determine the data flow between code locations, then separate the program based code dependency. Commonly it is done by first identify all *control dependencies* of instructions, which form a reachable control-flow graph. Then, on the reachable control-flow graph, data-flow analysis is performed to find data dependencies.\n\n[@lu2023practical] ([[literature/4zdjxws6]]) notes several limitations with such an approach:\n\nFirst, control dependencies does not reflect all data dependencies.\n- System calls and interrupt handlers is invoked at arbitrary time, and don't have a control-flow edge on the CFG. \n- Two control-independent functions can still pass data through global variables or shared memory.\n[](2023-05-26_.md)\nSecond, data-flow analysis requires points-to analysis.\n- Points-to analysis is expensive can cannot scale to large programs.\n- Points-to analysis produces a large amount of false positive on large programs.\n\n\n\n\n","wordCount":150,"tags":["analysis","compartmentalization","data-flow-analysis"],"metadata":{},"created":"2023-05-22T02:06:14.451358792Z","modified":"2023-06-09T08:45:34.665273135Z","checksum":"2d5f5e201c3677af41a6149311cca066905def6d78ebaa1987631de037cbec76"},
    {"filename":"3ciove99.md","filenameStem":"3ciove99","path":"3ciove99.md","absPath":"/home/khadd/mynotes/3ciove99.md","title":"Link-time Optimization in LLVM","link":"[[3ciove99]]","lead":"#lto  #llvm","body":"#lto  #llvm\n\nTo enable LTO:\n1. Register the pass so that it happen during LTO (`EP_FullLinkTimeOptimizaitonLast` or `Early`).\n2. Enable `-flto` flag at compile-time, load the pass in Clang, change linker to lld (not sure about gold linker). \n  e.g., `clang -flto -fuse-ld=lld -Wl,-mllvm=-load=pass.so`\n\nNote:\n- `-flegacy-pass-manager` must be passed  when the pass is registrated with legacy APIs","snippets":["#lto  #llvm"],"rawContent":"# Link-time Optimization in LLVM\n#lto  #llvm\n\nTo enable LTO:\n1. Register the pass so that it happen during LTO (`EP_FullLinkTimeOptimizaitonLast` or `Early`).\n2. Enable `-flto` flag at compile-time, load the pass in Clang, change linker to lld (not sure about gold linker). \n  e.g., `clang -flto -fuse-ld=lld -Wl,-mllvm=-load=pass.so`\n\nNote:\n- `-flegacy-pass-manager` must be passed  when the pass is registrated with legacy APIs\n\n\n","wordCount":62,"tags":["llvm","lto"],"metadata":{},"created":"2023-05-23T08:52:32.389751217Z","modified":"2023-05-23T08:54:31.636324685Z","checksum":"1f65028fb5685908d784b73c1ba4f36b4c421234c3dd0b20f8f38b9697ce8f8e"},
    {"filename":"nobagcn6.md","filenameStem":"nobagcn6","path":"nobagcn6.md","absPath":"/home/khadd/mynotes/nobagcn6.md","title":"Linux Support for SEV-SNP","link":"[[nobagcn6]]","lead":"#linux #sev","body":"#linux #sev\n\n\n# Guest\n\n# Kernel\n- [amd-memory-encryption](https://www.kernel.org/doc/Documentation/virt/kvm/amd-memory-encryption.rst)\n- The patch for hypervisor support is found [here](https://lwn.net/Articles/923844/)","snippets":["#linux #sev"],"rawContent":"# Linux Support for SEV-SNP\n#linux #sev\n\n\n# Guest\n\n# Kernel\n- [amd-memory-encryption](https://www.kernel.org/doc/Documentation/virt/kvm/amd-memory-encryption.rst)\n- The patch for hypervisor support is found [here](https://lwn.net/Articles/923844/) \n\n\n","wordCount":22,"tags":["linux","sev"],"metadata":{},"created":"2023-06-19T05:34:27.373501309Z","modified":"2024-05-20T08:53:45.510671971Z","checksum":"342edfdfc5064fcd68afdbbe075df26045a416d46a590dbdbe19153e70bbed4f"},
    {"filename":"cn9u3d79.md","filenameStem":"cn9u3d79","path":"cn9u3d79.md","absPath":"/home/khadd/mynotes/cn9u3d79.md","title":"Linux's kernel page table","link":"[[cn9u3d79]]","lead":"#linux #os","body":"#linux #os\n\nLinux's kernel image is direct-mapped to the virtual address space. Physical addresses within the kernel can be translated into virtual addresses by simply adding a `PAGE_OFFSET`\n\n```c\n// in asm/page.h\n#define __va(x)\t\t\t((void *)((unsigned long)(x)+PAGE_OFFSET))\n\n// in asm/io.h\nstatic inline void *phys_to_virt(phys_addr_t address)\n{\n\treturn __va(address);\n}\n```\n\n# References\n- [understand006](https://www.kernel.org/doc/gorman/html/understand/understand006.html)","snippets":["#linux #os"],"rawContent":"# Linux's kernel page table\n#linux #os\n\nLinux's kernel image is direct-mapped to the virtual address space. Physical addresses within the kernel can be translated into virtual addresses by simply adding a `PAGE_OFFSET`\n\n```c\n// in asm/page.h\n#define __va(x)\t\t\t((void *)((unsigned long)(x)+PAGE_OFFSET))\n\n// in asm/io.h\nstatic inline void *phys_to_virt(phys_addr_t address)\n{\n\treturn __va(address);\n}\n```\n\n# References\n- [understand006](https://www.kernel.org/doc/gorman/html/understand/understand006.html)\n","wordCount":59,"tags":["os","linux"],"metadata":{},"created":"2023-07-06T02:37:17.661608506Z","modified":"2023-07-20T08:50:35.155839415Z","checksum":"47a43d9394e581d4309cd4d9537a7aa55b14180cf54fc5e2474d81e5dd85afd6"},
    {"filename":"l80vag29.md","filenameStem":"l80vag29","path":"literature/l80vag29.md","absPath":"/home/khadd/mynotes/literature/l80vag29.md","title":"Low-Fat Pointers: Compact Encoding and Efficient Gate-Level Implementation of Fat Pointers for Spatial Safety and Capability-based Security","link":"[[literature/l80vag29]]","lead":"#literature #capabilities\n[@kwon2013lowfat]","body":"#literature #capabilities\n[@kwon2013lowfat]\n\nURL: https://dl.acm.org/doi/pdf/10.1145/2508859.2516713\n## Context\nThis work introduces a new bound encoding scheme that encodes object-bound information into 64-bit pointers, and 46-bit address space. \nThe claim is that it introduces zero runtime overheads since the check is performed in parallel with the access.\n### Background \u0026 related work \n- [@wulf1974hydra] HYDRA system and C.mmp processor combine pointers and access right\n- [guarded pointers]:","snippets":["#literature #capabilities\n[@kwon2013lowfat]"],"rawContent":"# Low-Fat Pointers: Compact Encoding and Efficient Gate-Level Implementation of Fat Pointers for Spatial Safety and Capability-based Security\n#literature #capabilities\n[@kwon2013lowfat]\n\nURL: https://dl.acm.org/doi/pdf/10.1145/2508859.2516713\n## Context\nThis work introduces a new bound encoding scheme that encodes object-bound information into 64-bit pointers, and 46-bit address space. \nThe claim is that it introduces zero runtime overheads since the check is performed in parallel with the access.\n### Background \u0026 related work \n- [@wulf1974hydra] HYDRA system and C.mmp processor combine pointers and access right\n- [guarded pointers]: \n\n\n","wordCount":83,"tags":["literature","capabilities"],"metadata":{},"created":"2023-05-05T07:05:46.636593168Z","modified":"2023-05-11T01:19:05.483362859Z","checksum":"40f03059e79eaa0ac17c40e3d12f8b8b92402acc908ea08a8a717768b147c86d"},
    {"filename":"ouv5s2fi.md","filenameStem":"ouv5s2fi","path":"ouv5s2fi.md","absPath":"/home/khadd/mynotes/ouv5s2fi.md","title":"Memory errors in Rust","link":"[[ouv5s2fi]]","lead":"#memory-safety #rust","body":"#memory-safety #rust\n\nRust seems like a memory-safe language, but due to the prevalent use of unsafe, memory corruption is quite common. In fact, except from compiler-introduced bugs, *all* of memory errors in Rust are triggered by unsafe (insight 4, @astrauskas2020how, @xu2021memorysafety).\n\nUnsafe Rust can trigger both spatial and temporal memory safety violation.\n\nMany of the bugs do not contain memory error, but only introduce unsoundness that violate Rust's memory safety @xu2021memorysafety.\n\n\n# Spatial safety\n## Integer overflow\nA lot of bugs are triggered by integer overflow, where the calculation for buffer size may overflow, leads to allocating a smaller buffer than expected.\n\nSince all dynamic array accesses in *safe* Rust  are bound-checked, such bug can only trigger for in cases where the array is used later in unsafe code @hua2021rupair. More specifically, only the pattern unsafe-\u003eunsafe and safe-\u003eunsafe (LHS: cause, RHS: effect) can trigger memory safety error with this bug @hua2021rupair.\n\nIn debug mode, integer overflow is checked at both compile-time (e.g., `u8 = 255 + 1` is not possile) and runtime. However, there is no runtime check in release mode. \n\nHere is an example for unsafe-\u003esafe case:\n```rust\nfn foo(int i, int j){\n  // may have integer overflow\n  let buf = Vec::with_capacity(i + j);\n  unsafe {\n    // May be out-of-bound access\n    let p = buf2.as_ptr();\n    *(p + i + 100) = 20;\n  }\n}\n```\n\n### CVE-2017-1000430 : integer overflow to heap-based buffer overflow in encode_config_buf\n\n```rust\n// Many possible integer overflow here\nfn encoded_size(bytes_len: usize, config: Config) -\u003e usize {\n  let rem = bytes_len % 3;\n\n  let complete_input_chunks = bytes_len / 3;\n  let complete_output_chars = complete_input_chunks * 4;\n  let printing_output_chars = if rem == 0 {\n    complete_output_chars\n  } else {\n    complete_output_chars + 4\n  };\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e 0,\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e printing_output_chars / n * 2,\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e printing_output_chars / n,\n  };\n  return printing_output_chars + line_ending_output_chars;\n}\npub fn encode_config\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config) -\u003e String {\n  // Integer overflow\n  let mut buf = String::with_capacity(encoded_size(input.as_ref().len(), config));\n  encode_config_buf(input, config, \u0026mut buf);\n  buf\n}\n\npub fn encode_config_buf\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config, buf: \u0026mut String) {\n  //...\n  // Another possible integer overflow\n  buf.reserve(encoded_size(input_bytes.len(), config));\n  // ...\n  let mut raw = unsafe { buf.as_mut_vec() };\n\n  // ...\n  // May access out-of-bound here due to unsafe !?!?!?!??!?!?!?!\n  let mut output_ptr = unsafe { raw.as_mut_ptr().offset(orig_buf_len as isize) };\n  let mut input_index: usize = 0;\n  if input_bytes.len() \u003e= 8 {\n    while input_index \u003c= last_fast_index {\n      let input_chunk = BigEndian::read_u64(\u0026input_bytes[input_index..(input_index + 8)]);\n      // strip off 6 bits at a time for the first 6 bytes\n      unsafe {\n        std::ptr::write(output_ptr, charset[((input_chunk \u003e\u003e 58) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(1), charset[((input_chunk \u003e\u003e 52) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(2), charset[((input_chunk \u003e\u003e 46) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(3), charset[((input_chunk \u003e\u003e 40) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(4), charset[((input_chunk \u003e\u003e 34) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(5), charset[((input_chunk \u003e\u003e 28) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(6), charset[((input_chunk \u003e\u003e 22) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(7), charset[((input_chunk \u003e\u003e 16) \u0026 0x3F) as usize]);\n        output_ptr = output_ptr.offset(8);\n      }\n      input_index += input_chunk_len;\n      fast_loop_output_buf_len += 8;\n    }\n  }\n  unsafe {\n    // expand len to include the bytes we just wrote\n    raw.set_len(fast_loop_output_buf_len);\n  }\n}\n```\nThe function `encoded_size` is used to calculate size for allocation. However, it could silently have integer overflow. In `encode_config` a buffer is allocated using the calculated size.\n\nThe fix for this is to use overflow-checked arithmetics. The patch for this changes the function to return `None` if overflow is detected:\n```rust\nfn encoded_size(bytes_len: usize, config: Config) -\u003e Option\u003cusize\u003e {\n  let printing_output_chars = bytes_len\n    .checked_add(2)\n    .map(|x| x / 3)\n    .and_then(|x| x.checked_mul(4));\n\n  //TODO this is subtly wrong but in a not dangerous way\n  //pushing patch with identical to previous behavior, then fixing\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e Some(0),\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e\n      printing_output_chars.map(|y| y / n).and_then(|y| y.checked_mul(2)),\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e\n      printing_output_chars.map(|y| y / n),\n  };\n\n  printing_output_chars.and_then(|x|\n    line_ending_output_chars.and_then(|y| x.checked_add(y))\n  )\n}\n```\n## Wrong usage of unsafe API\n### CVE-2018-21000: Vec-to-vec transmutations could lead to heap overflow/corruption\n\n```rust\n// Error\nVec::from_raw_parts(ptr as *mut T, capacity, len)\n// Fixed\nVec::from_raw_parts(ptr as *mut T, len, capacity)\n```\nThe above CVE swap the capacity and len arguments, which could lead to buffer overflow.\n\n# Temporal safety\n## Lifetime corruption\nUnsafe Rust can corrupt the ownership system by making invalid pointers or mutable aliases. Such pointers may propagate to the safe world, and is automatically freed by the ownership system, causing double-free or use-after-free.\n\n### CVE-2019-16140: dangling pointer created by unsafe\n```rust\nfn from(buffer: Buffer) -\u003e Vec\u003cu8\u003e {\n  let mut slice = Buffer::allocate(buffer.len);\n  let len = buffer.copy_to(\u0026mut slice);\n  unsafe {\n    Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len())\n  }\n}\n```\nThe above example from CVE-2019-16140 shows an example of lifetime corruption. In the example, `Vec::from_raw_parts` on line 5 obtain the ownership of `slice` allocated at line 2, and return the created `Vec`. This violate Rust ownership; line 5 and line 2 now share ownership to the underlying slice. When the function returns, `slice` at line 2 is automatically dropped. Any access to the returned value of `from` will now become use-after-free.\n\nThe fix to this is simple, `mem::forget` must be added to forget the previous slice (so that it will not be dropped after), before its ownership is being taken by constructing a new Vec.\n```rust\nunsafe {\n  let vec = Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len());\n  mem::forget(slice);\n  vec\n}\n```\n\nIn all, the cause of this bug is the use of raw pointer that bypass Rust ownership protection.\n\n### More\nMore examples are CVE-2019-15552 and CVE-2019-15553.\n\n# Panic/unwind safety\nAnother common memory issue is the unwinding code triggering unsound behaviors.","snippets":["#memory-safety #rust"],"rawContent":"# Memory errors in Rust\n#memory-safety #rust\n\nRust seems like a memory-safe language, but due to the prevalent use of unsafe, memory corruption is quite common. In fact, except from compiler-introduced bugs, *all* of memory errors in Rust are triggered by unsafe (insight 4, @astrauskas2020how, @xu2021memorysafety).\n\nUnsafe Rust can trigger both spatial and temporal memory safety violation.\n\nMany of the bugs do not contain memory error, but only introduce unsoundness that violate Rust's memory safety @xu2021memorysafety.\n\n\n# Spatial safety\n## Integer overflow\nA lot of bugs are triggered by integer overflow, where the calculation for buffer size may overflow, leads to allocating a smaller buffer than expected.\n\nSince all dynamic array accesses in *safe* Rust  are bound-checked, such bug can only trigger for in cases where the array is used later in unsafe code @hua2021rupair. More specifically, only the pattern unsafe-\u003eunsafe and safe-\u003eunsafe (LHS: cause, RHS: effect) can trigger memory safety error with this bug @hua2021rupair.\n\nIn debug mode, integer overflow is checked at both compile-time (e.g., `u8 = 255 + 1` is not possile) and runtime. However, there is no runtime check in release mode. \n\nHere is an example for unsafe-\u003esafe case:\n```rust\nfn foo(int i, int j){\n  // may have integer overflow\n  let buf = Vec::with_capacity(i + j);\n  unsafe {\n    // May be out-of-bound access\n    let p = buf2.as_ptr();\n    *(p + i + 100) = 20;\n  }\n}\n```\n\n### CVE-2017-1000430 : integer overflow to heap-based buffer overflow in encode_config_buf\n\n```rust\n// Many possible integer overflow here\nfn encoded_size(bytes_len: usize, config: Config) -\u003e usize {\n  let rem = bytes_len % 3;\n\n  let complete_input_chunks = bytes_len / 3;\n  let complete_output_chars = complete_input_chunks * 4;\n  let printing_output_chars = if rem == 0 {\n    complete_output_chars\n  } else {\n    complete_output_chars + 4\n  };\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e 0,\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e printing_output_chars / n * 2,\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e printing_output_chars / n,\n  };\n  return printing_output_chars + line_ending_output_chars;\n}\npub fn encode_config\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config) -\u003e String {\n  // Integer overflow\n  let mut buf = String::with_capacity(encoded_size(input.as_ref().len(), config));\n  encode_config_buf(input, config, \u0026mut buf);\n  buf\n}\n\npub fn encode_config_buf\u003cT: ?Sized + AsRef\u003c[u8]\u003e\u003e(input: \u0026T, config: Config, buf: \u0026mut String) {\n  //...\n  // Another possible integer overflow\n  buf.reserve(encoded_size(input_bytes.len(), config));\n  // ...\n  let mut raw = unsafe { buf.as_mut_vec() };\n\n  // ...\n  // May access out-of-bound here due to unsafe !?!?!?!??!?!?!?!\n  let mut output_ptr = unsafe { raw.as_mut_ptr().offset(orig_buf_len as isize) };\n  let mut input_index: usize = 0;\n  if input_bytes.len() \u003e= 8 {\n    while input_index \u003c= last_fast_index {\n      let input_chunk = BigEndian::read_u64(\u0026input_bytes[input_index..(input_index + 8)]);\n      // strip off 6 bits at a time for the first 6 bytes\n      unsafe {\n        std::ptr::write(output_ptr, charset[((input_chunk \u003e\u003e 58) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(1), charset[((input_chunk \u003e\u003e 52) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(2), charset[((input_chunk \u003e\u003e 46) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(3), charset[((input_chunk \u003e\u003e 40) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(4), charset[((input_chunk \u003e\u003e 34) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(5), charset[((input_chunk \u003e\u003e 28) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(6), charset[((input_chunk \u003e\u003e 22) \u0026 0x3F) as usize]);\n        std::ptr::write(output_ptr.offset(7), charset[((input_chunk \u003e\u003e 16) \u0026 0x3F) as usize]);\n        output_ptr = output_ptr.offset(8);\n      }\n      input_index += input_chunk_len;\n      fast_loop_output_buf_len += 8;\n    }\n  }\n  unsafe {\n    // expand len to include the bytes we just wrote\n    raw.set_len(fast_loop_output_buf_len);\n  }\n}\n```\nThe function `encoded_size` is used to calculate size for allocation. However, it could silently have integer overflow. In `encode_config` a buffer is allocated using the calculated size.\n\nThe fix for this is to use overflow-checked arithmetics. The patch for this changes the function to return `None` if overflow is detected:\n```rust\nfn encoded_size(bytes_len: usize, config: Config) -\u003e Option\u003cusize\u003e {\n  let printing_output_chars = bytes_len\n    .checked_add(2)\n    .map(|x| x / 3)\n    .and_then(|x| x.checked_mul(4));\n\n  //TODO this is subtly wrong but in a not dangerous way\n  //pushing patch with identical to previous behavior, then fixing\n  let line_ending_output_chars = match config.line_wrap {\n    LineWrap::NoWrap =\u003e Some(0),\n    LineWrap::Wrap(n, LineEnding::CRLF) =\u003e\n      printing_output_chars.map(|y| y / n).and_then(|y| y.checked_mul(2)),\n    LineWrap::Wrap(n, LineEnding::LF) =\u003e\n      printing_output_chars.map(|y| y / n),\n  };\n\n  printing_output_chars.and_then(|x|\n    line_ending_output_chars.and_then(|y| x.checked_add(y))\n  )\n}\n```\n## Wrong usage of unsafe API\n### CVE-2018-21000: Vec-to-vec transmutations could lead to heap overflow/corruption\n\n```rust\n// Error\nVec::from_raw_parts(ptr as *mut T, capacity, len)\n// Fixed\nVec::from_raw_parts(ptr as *mut T, len, capacity)\n```\nThe above CVE swap the capacity and len arguments, which could lead to buffer overflow.\n\n# Temporal safety\n## Lifetime corruption\nUnsafe Rust can corrupt the ownership system by making invalid pointers or mutable aliases. Such pointers may propagate to the safe world, and is automatically freed by the ownership system, causing double-free or use-after-free.\n\n### CVE-2019-16140: dangling pointer created by unsafe\n```rust\nfn from(buffer: Buffer) -\u003e Vec\u003cu8\u003e {\n  let mut slice = Buffer::allocate(buffer.len);\n  let len = buffer.copy_to(\u0026mut slice);\n  unsafe {\n    Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len())\n  }\n}\n```\nThe above example from CVE-2019-16140 shows an example of lifetime corruption. In the example, `Vec::from_raw_parts` on line 5 obtain the ownership of `slice` allocated at line 2, and return the created `Vec`. This violate Rust ownership; line 5 and line 2 now share ownership to the underlying slice. When the function returns, `slice` at line 2 is automatically dropped. Any access to the returned value of `from` will now become use-after-free.\n\nThe fix to this is simple, `mem::forget` must be added to forget the previous slice (so that it will not be dropped after), before its ownership is being taken by constructing a new Vec.\n```rust\nunsafe {\n  let vec = Vec::from_raw_parts(slice.as_mut_ptr(), len, slice.len());\n  mem::forget(slice);\n  vec\n}\n```\n\nIn all, the cause of this bug is the use of raw pointer that bypass Rust ownership protection.\n\n### More\nMore examples are CVE-2019-15552 and CVE-2019-15553.\n\n# Panic/unwind safety\nAnother common memory issue is the unwinding code triggering unsound behaviors.\n","wordCount":927,"tags":["rust","memory-safety"],"metadata":{},"created":"2023-06-14T03:24:35.052210621Z","modified":"2023-06-14T03:23:52.665943026Z","checksum":"5a52b300b838afd1f2d4e4add3062064b79cfefdd7273f432b49c46c0a6618c3"},
    {"filename":"h6c34egw.md","filenameStem":"h6c34egw","path":"h6c34egw.md","absPath":"/home/khadd/mynotes/h6c34egw.md","title":"My nvim note taking workflow","link":"[[h6c34egw]]","lead":"#neovim #zettelkasten #note-taking","body":"#neovim #zettelkasten #note-taking\n\n[Zk](https://github.com/mickael-menu/zk) is a nice command-line application that has minimalistic features to take zettelkasten-style [[ae6fatms]] notes.\nWhat I like about Zk:\n- its seamless integration with neovim\n- plaintext storage with markdown\n\nIt is used in combination with [marksman LSP](https://github.com/artempyanykh/marksman) that provides a nice markdown editing experience.\n\n\n## Alternative\nI tried the Obsidian app but found its UI distracting. \n\n## Missing features\n- Some reference and citation is needed\n- I tried vim-pandoc but haven't found success.","snippets":["#neovim #zettelkasten #note-taking"],"rawContent":"# My nvim note taking workflow\n#neovim #zettelkasten #note-taking\n\n[Zk](https://github.com/mickael-menu/zk) is a nice command-line application that has minimalistic features to take zettelkasten-style [[ae6fatms]] notes.\nWhat I like about Zk:\n- its seamless integration with neovim\n- plaintext storage with markdown\n\nIt is used in combination with [marksman LSP](https://github.com/artempyanykh/marksman) that provides a nice markdown editing experience.\n\n\n## Alternative\nI tried the Obsidian app but found its UI distracting. \n\n## Missing features\n- Some reference and citation is needed\n- I tried vim-pandoc but haven't found success. \n\n\n\n","wordCount":85,"tags":["zettelkasten","neovim","note-taking"],"metadata":{},"created":"2023-05-05T05:46:12.290506095Z","modified":"2023-05-25T05:54:41.29458635Z","checksum":"b55087af8935dc83d9824b17b47c4d85efeafa22df738dec67a3a41a5552b1aa"},
    {"filename":"s5ss13en.md","filenameStem":"s5ss13en","path":"s5ss13en.md","absPath":"/home/khadd/mynotes/s5ss13en.md","title":"Neccessary OS support for SEV","link":"[[s5ss13en]]","lead":"#sev","body":"#sev\n\n\n# Boot time\nIn linux, the\n\n# Related\n- [[llhmwuim]]\n- [[nobagcn6]]","snippets":["#sev"],"rawContent":"# Neccessary OS support for SEV\n#sev\n\n\n# Boot time\nIn linux, the\n\n# Related\n- [[llhmwuim]]\n- [[nobagcn6]]\n","wordCount":19,"tags":["sev"],"metadata":{},"created":"2023-08-24T05:20:05.062443572Z","modified":"2023-08-24T05:28:39.023114545Z","checksum":"9bf394a51dd7ce44ef95f75e8ef42373c87ee387c5eb9f0825b431c6dfaf97b7"},
    {"filename":"gbkc1fhy.md","filenameStem":"gbkc1fhy","path":"gbkc1fhy.md","absPath":"/home/khadd/mynotes/gbkc1fhy.md","title":"Non-control Data Attacks","link":"[[gbkc1fhy]]","lead":"#data-only-attack #attack","body":"#data-only-attack #attack\n\n# Expressiveness\nIt is shown that data-only attack can achieve turing-complete execution under a certain condition [@hu2016dataoriented]. More specifically, there must be loop that is vulnerable to buffer overflow, that contain a corruptible switch condition. The original refer to this type of loop as a *gadget dispatcher*. \nThis is an example:\n```c\nwhile (...){\n  overflow(); // buffer overflow\n  if (*type == NONE) break;\n  if (*type == STREAM)\n    *size = *(srv-\u003ecur_max); // dereference\n  else {\n    srv-\u003etyp = *type;    // assignment\n    srv-\u003etotal += *size; // addition\n  }\n  ///...\n}\n```\nWhen the attacker can infinitely control the loop, he is able to set up the operands and run different instructions in a turing-complete manner.","snippets":["#data-only-attack #attack"],"rawContent":"# Non-control Data Attacks\n#data-only-attack #attack\n\n# Expressiveness\nIt is shown that data-only attack can achieve turing-complete execution under a certain condition [@hu2016dataoriented]. More specifically, there must be loop that is vulnerable to buffer overflow, that contain a corruptible switch condition. The original refer to this type of loop as a *gadget dispatcher*. \nThis is an example:\n```c\nwhile (...){\n  overflow(); // buffer overflow\n  if (*type == NONE) break;\n  if (*type == STREAM)\n    *size = *(srv-\u003ecur_max); // dereference\n  else {\n    srv-\u003etyp = *type;    // assignment\n    srv-\u003etotal += *size; // addition\n  }\n  ///...\n}\n```\nWhen the attacker can infinitely control the loop, he is able to set up the operands and run different instructions in a turing-complete manner. \n\n","wordCount":118,"tags":["data-only-attack","attack"],"metadata":{},"created":"2023-05-25T08:42:24.056505066Z","modified":"2023-05-25T08:55:04.443440172Z","checksum":"4383ed6e384b8d89bd2b346a24f2c6fe5c986aa05b9098daebe03a33511633dc"},
    {"filename":"j19hdkto.md","filenameStem":"j19hdkto","path":"j19hdkto.md","absPath":"/home/khadd/mynotes/j19hdkto.md","title":"Norman Hardy","link":"[[j19hdkto]]","lead":"#capabilities #os","body":"#capabilities #os\n\nThe inventor of KeykOS, which laid foundation for many following microkernels such as EROS, sel4. He is also one of the grandfather of Capabilities.\n\nMaybe the first one to coin the term confused deputy [[y9wu5ut7]] in his paper [@hardy1988confused].\n\nIt is interesting that there exists no Wiki article for him.\n\nHis personal website, http://www.cap-lore.com/, contains pieces of notes on his ideas, is written in almost [[ae6fatms|Zettlekasten]] style. Ideas are separated into separated notes and linked together. \n[](2023-05-24_.md)","snippets":["#capabilities #os"],"rawContent":"# Norman Hardy\n#capabilities #os\n\nThe inventor of KeykOS, which laid foundation for many following microkernels such as EROS, sel4. He is also one of the grandfather of Capabilities.\n\nMaybe the first one to coin the term confused deputy [[y9wu5ut7]] in his paper [@hardy1988confused].\n\nIt is interesting that there exists no Wiki article for him.\n\nHis personal website, http://www.cap-lore.com/, contains pieces of notes on his ideas, is written in almost [[ae6fatms|Zettlekasten]] style. Ideas are separated into separated notes and linked together. \n[](2023-05-24_.md)\n","wordCount":82,"tags":["capabilities","os"],"metadata":{},"created":"2023-05-22T02:06:14.457930559Z","modified":"2023-05-24T02:30:33.740255349Z","checksum":"6c5f07a95194accec6be54e1ed0f2901cec76353115a3384a28fd46ee3e7405a"},
    {"filename":"m7plvtcv.md","filenameStem":"m7plvtcv","path":"m7plvtcv.md","absPath":"/home/khadd/mynotes/m7plvtcv.md","title":"ORAM Algorithmic Optimizations","link":"[[m7plvtcv]]","lead":"#oram #oblivious","body":"#oram #oblivious\n\n## Superblock\nIn ORAM, because accesses are always shuffled, the locality is terrible, because individual block's position is shuffled at every access.\n\nSuperblock optimization (@ren2013design) ensures that a group of blocks are always in the stash together. This group of blocks is called the *superblock*. Accessing a block in a superblock would brings all block into the stash, which improve the locality. Note that the number of blocks in a superblock can be smaller than the height of the tree. \n\nAt initialization time, blocks on the superblock $S$ are placed on the same leaf. Whenever a block from the superblock is requested, the entire path is brought into the stash, so the blocks in $S$ is inside the stash. Like normal Path ORAM, the leaf index of the requested block in the position map is updated. This requested block is like a leader, which all blocks in the same superblock follow. Potition of blocks in the superblock are also updated to the leader block's path. Hence, when they are evicted, they would be evicted on the same leaf. \n\n### Security\n@ren2013design (3.2.2) argues that this does not affect the security of ORAM. On each access, superblocks are mapped to a random leaf. Same as normal path ORAM, the observer can only see randomized path accesses, regardless of the superblock. \n\n### Why posmap update for blocks other than the requested block is fine in this case?\nThis is fine fine because the superblock can be seen as a single block in the ORAM access.\n\nIn a more generalized scenario, when updating the position for blocks inside the stash, the new position should be random, or *independent* of the block content/access pattern (not sure if this is correct).","snippets":["#oram #oblivious"],"rawContent":"# ORAM Algorithmic Optimizations\n#oram #oblivious\n\n## Superblock\nIn ORAM, because accesses are always shuffled, the locality is terrible, because individual block's position is shuffled at every access.\n\nSuperblock optimization (@ren2013design) ensures that a group of blocks are always in the stash together. This group of blocks is called the *superblock*. Accessing a block in a superblock would brings all block into the stash, which improve the locality. Note that the number of blocks in a superblock can be smaller than the height of the tree. \n\nAt initialization time, blocks on the superblock $S$ are placed on the same leaf. Whenever a block from the superblock is requested, the entire path is brought into the stash, so the blocks in $S$ is inside the stash. Like normal Path ORAM, the leaf index of the requested block in the position map is updated. This requested block is like a leader, which all blocks in the same superblock follow. Potition of blocks in the superblock are also updated to the leader block's path. Hence, when they are evicted, they would be evicted on the same leaf. \n\n### Security\n@ren2013design (3.2.2) argues that this does not affect the security of ORAM. On each access, superblocks are mapped to a random leaf. Same as normal path ORAM, the observer can only see randomized path accesses, regardless of the superblock. \n\n### Why posmap update for blocks other than the requested block is fine in this case?\nThis is fine fine because the superblock can be seen as a single block in the ORAM access.\n\nIn a more generalized scenario, when updating the position for blocks inside the stash, the new position should be random, or *independent* of the block content/access pattern (not sure if this is correct).\n","wordCount":292,"tags":["oblivious","oram"],"metadata":{},"created":"2023-07-22T12:44:47.615861403Z","modified":"2023-07-23T15:11:40.424034242Z","checksum":"953e101067c5d4e0de6315c7c91e33075e9c2d5ff5cbb38277966faa7ca61130"},
    {"filename":"tjftw12c.md","filenameStem":"tjftw12c","path":"tjftw12c.md","absPath":"/home/khadd/mynotes/tjftw12c.md","title":"OVMF Whitepaper","link":"[[tjftw12c]]","lead":"#uefi #archive","body":"#uefi #archive\n\nI'm making a copy here since this is entirely in text format.\n\n----------------\n\nOpen Virtual Machine Firmware (OVMF) Status Report\nJuly 2014 (with updates in August 2014 - January 2015)\n\nAuthor: Laszlo Ersek \u003clersek@redhat.com\u003e\nCopyright (C) 2014-2015, Red Hat, Inc.\nCC BY-SA 4.0 \u003chttp://creativecommons.org/licenses/by-sa/4.0/\u003e\n\nAbstract\n--------\n\nThe Unified Extensible Firmware Interface (UEFI) is a specification that\ndefines a software interface between an operating system and platform firmware.\nUEFI is designed to replace the Basic Input/Output System (BIOS) firmware\ninterface.\n\nHardware platform vendors have been increasingly adopting the UEFI\nSpecification to govern their boot firmware developments. OVMF (Open Virtual\nMachine Firmware), a sub-project of Intel's EFI Development Kit II (edk2),\nenables UEFI support for Ia32 and X64 Virtual Machines.\n\nThis paper reports on the status of the OVMF project, treats features and\nlimitations, gives end-user hints, and examines some areas in-depth.\n\nKeywords: ACPI, boot options, CSM, edk2, firmware, flash, fw_cfg, KVM, memory\nmap, non-volatile variables, OVMF, PCD, QEMU, reset vector, S3, Secure Boot,\nSmbios, SMM, TianoCore, UEFI, VBE shim, Virtio\n\nTable of Contents\n-----------------\n\n- Motivation\n- Scope\n- Example qemu invocation\n- Installation of OVMF guests with virt-manager and virt-install\n- Supported guest operating systems\n- Compatibility Support Module (CSM)\n- Phases of the boot process\n- Project structure\n- Platform Configuration Database (PCD)\n- Firmware image structure\n- S3 (suspend to RAM and resume)\n- A comprehensive memory map of OVMF\n- Known Secure Boot limitations\n- Variable store and LockBox in SMRAM\n- Select features\n  - X64-specific reset vector for OVMF\n  - Client library for QEMU's firmware configuration interface\n  - Guest ACPI tables\n  - Guest SMBIOS tables\n  - Platform-specific boot policy\n  - Virtio drivers\n  - Platform Driver\n  - Video driver\n- Afterword\n\nMotivation\n----------\n\nOVMF extends the usual benefits of virtualization to UEFI. Reasons to use OVMF\ninclude:\n\n- Legacy-free guests. A UEFI-based environment eliminates dependencies on\n  legacy address spaces and devices. This is especially beneficial when used\n  with physically assigned devices where the legacy operating mode is\n  troublesome to support, ex. assigned graphics cards operating in legacy-free,\n  non-VGA mode in the guest.\n\n- Future proof guests. The x86 market is steadily moving towards a legacy-free\n  platform and guest operating systems may eventually require a UEFI\n  environment. OVMF provides that next generation firmware support for such\n  applications.\n\n- GUID partition tables (GPTs). MBR partition tables represent partition\n  offsets and sizes with 32-bit integers, in units of 512 byte sectors. This\n  limits the addressable portion of the disk to 2 TB. GPT represents logical\n  block addresses with 64 bits.\n\n- Liberating boot loader binaries from residing in contested and poorly defined\n  space between the partition table and the partitions.\n\n- Support for booting off disks (eg. pass-through physical SCSI devices) with a\n  4kB physical and logical sector size, i.e. which don't have 512-byte block\n  emulation.\n\n- Development and testing of Secure Boot-related features in guest operating\n  systems. Although OVMF's Secure Boot implementation is currently not secure\n  against malicious UEFI drivers, UEFI applications, and guest kernels,\n  trusted guest code that only uses standard UEFI interfaces will find a valid\n  Secure Boot environment under OVMF, with working key enrollment and signature\n  validation. This enables development and testing of portable, Secure\n  Boot-related guest code.\n\n- Presence of non-volatile UEFI variables. This furthers development and\n  testing of OS installers, UEFI boot loaders, and unique, dependent guest OS\n  features. For example, an efivars-backed pstore (persistent storage)\n  file system works under Linux.\n\n- Altogether, a near production-level UEFI environment for virtual machines\n  when Secure Boot is not required.\n\nScope\n-----\n\nUEFI and especially Secure Boot have been topics fraught with controversy and\npolitical activism. This paper sidesteps these aspects and strives to focus on\nuse cases, hands-on information for end users, and technical details.\n\nUnless stated otherwise, the expression \"X supports Y\" means \"X is technically\ncompatible with interfaces provided or required by Y\". It does not imply\nsupport as an activity performed by natural persons or companies.\n\nWe discuss the status of OVMF at a state no earlier than edk2 SVN revision\n16158. The paper concentrates on upstream projects and communities, but\noccasionally it pans out about OVMF as it is planned to be shipped (as\nTechnical Preview) in Red Hat Enterprise Linux 7.1. Such digressions are marked\nwith the [RHEL] margin notation.\n\nAlthough other VMMs and accelerators are known to support (or plan to support)\nOVMF to various degrees -- for example, VirtualBox, Xen, BHyVe --, we'll\nemphasize OVMF on qemu/KVM, because QEMU and KVM have always been Red Hat's\nfocus wrt. OVMF.\n\nThe recommended upstream QEMU version is 2.1+. The recommended host Linux\nkernel (KVM) version is 3.10+. The recommended QEMU machine type is\n\"qemu-system-x86_64 -M pc-i440fx-2.1\" or later.\n\nThe term \"TianoCore\" is used interchangeably with \"edk2\" in this paper.\n\nExample qemu invocation\n-----------------------\n\nThe following commands give a quick foretaste of installing a UEFI operating\nsystem on OVMF, relying only on upstream edk2 and qemu.\n\n- Clone and build OVMF:\n\n  git clone https://github.com/tianocore/edk2.git\n  cd edk2\n  nice OvmfPkg/build.sh -a X64 -n $(getconf _NPROCESSORS_ONLN)\n\n  (Note that this ad-hoc build will not include the Secure Boot feature.)\n\n- The build output file, \"OVMF.fd\", includes not only the executable firmware\n  code, but the non-volatile variable store as well. For this reason, make a\n  VM-specific copy of the build output (the variable store should be private to\n  the virtual machine):\n\n  cp Build/OvmfX64/DEBUG_GCC4?/FV/OVMF.fd fedora.flash\n\n  (The variable store and the firmware executable are also available in the\n  build output as separate files: \"OVMF_VARS.fd\" and \"OVMF_CODE.fd\". This\n  enables central management and updates of the firmware executable, while each\n  virtual machine can retain its own variable store.)\n\n- Download a Fedora LiveCD:\n\n  wget https://dl.fedoraproject.org/pub/fedora/linux/releases/20/Live/x86_64/Fedora-Live-Xfce-x86_64-20-1.iso\n\n- Create a virtual disk (qcow2 format, 20 GB in size):\n\n  qemu-img create -f qcow2 fedora.img 20G\n\n- Create the following qemu wrapper script under the name \"fedora.sh\":\n\n  # Basic virtual machine properties: a recent i440fx machine type, KVM\n  # acceleration, 2048 MB RAM, two VCPUs.\n  OPTS=\"-M pc-i440fx-2.1 -enable-kvm -m 2048 -smp 2\"\n\n  # The OVMF binary, including the non-volatile variable store, appears as a\n  # \"normal\" qemu drive on the host side, and it is exposed to the guest as a\n  # persistent flash device.\n  OPTS=\"$OPTS -drive if=pflash,format=raw,file=fedora.flash\"\n\n  # The hard disk is exposed to the guest as a virtio-block device. OVMF has a\n  # driver stack that supports such a disk. We specify this disk as first boot\n  # option. OVMF recognizes the boot order specification.\n  OPTS=\"$OPTS -drive id=disk0,if=none,format=qcow2,file=fedora.img\"\n  OPTS=\"$OPTS -device virtio-blk-pci,drive=disk0,bootindex=0\"\n\n  # The Fedora installer disk appears as an IDE CD-ROM in the guest. This is\n  # the 2nd boot option.\n  OPTS=\"$OPTS -drive id=cd0,if=none,format=raw,readonly\"\n  OPTS=\"$OPTS,file=Fedora-Live-Xfce-x86_64-20-1.iso\"\n  OPTS=\"$OPTS -device ide-cd,bus=ide.1,drive=cd0,bootindex=1\"\n\n  # The following setting enables S3 (suspend to RAM). OVMF supports S3\n  # suspend/resume.\n  OPTS=\"$OPTS -global PIIX4_PM.disable_s3=0\"\n\n  # OVMF emits a number of info / debug messages to the QEMU debug console, at\n  # ioport 0x402. We configure qemu so that the debug console is indeed\n  # available at that ioport. We redirect the host side of the debug console to\n  # a file.\n  OPTS=\"$OPTS -global isa-debugcon.iobase=0x402 -debugcon file:fedora.ovmf.log\"\n\n  # QEMU accepts various commands and queries from the user on the monitor\n  # interface. Connect the monitor with the qemu process's standard input and\n  # output.\n  OPTS=\"$OPTS -monitor stdio\"\n\n  # A USB tablet device in the guest allows for accurate pointer tracking\n  # between the host and the guest.\n  OPTS=\"$OPTS -device piix3-usb-uhci -device usb-tablet\"\n\n  # Provide the guest with a virtual network card (virtio-net).\n  #\n  # Normally, qemu provides the guest with a UEFI-conformant network driver\n  # from the iPXE project, in the form of a PCI expansion ROM. For this test,\n  # we disable the expansion ROM and allow OVMF's built-in virtio-net driver to\n  # take effect.\n  #\n  # On the host side, we use the SLIRP (\"user\") network backend, which has\n  # relatively low performance, but it doesn't require extra privileges from\n  # the user executing qemu.\n  OPTS=\"$OPTS -netdev id=net0,type=user\"\n  OPTS=\"$OPTS -device virtio-net-pci,netdev=net0,romfile=\"\n\n  # A Spice QXL GPU is recommended as the primary VGA-compatible display\n  # device. It is a full-featured virtual video card, with great operating\n  # system driver support. OVMF supports it too.\n  OPTS=\"$OPTS -device qxl-vga\"\n\n  qemu-system-x86_64 $OPTS\n\n- Start the Fedora guest:\n\n  sh fedora.sh\n\n- The above command can be used for both installation and later boots of the\n  Fedora guest.\n\n- In order to verify basic OVMF network connectivity:\n\n  - Assuming that the non-privileged user running qemu belongs to group G\n    (where G is a numeric identifier), ensure as root on the host that the\n    group range in file \"/proc/sys/net/ipv4/ping_group_range\" includes G.\n\n  - As the non-privileged user, boot the guest as usual.\n\n  - On the TianoCore splash screen, press ESC.\n\n  - Navigate to Boot Manager | EFI Internal Shell\n\n  - In the UEFI Shell, issue the following commands:\n\n    ifconfig -s eth0 dhcp\n    ping A.B.C.D\n\n    where A.B.C.D is a public IPv4 address in dotted decimal notation that your\n    host can reach.\n\n  - Type \"quit\" at the (qemu) monitor prompt.\n\nInstallation of OVMF guests with virt-manager and virt-install\n--------------------------------------------------------------\n\n(1) Assuming OVMF has been installed on the host with the following files:\n    - /usr/share/OVMF/OVMF_CODE.fd\n    - /usr/share/OVMF/OVMF_VARS.fd\n\n    locate the \"nvram\" stanza in \"/etc/libvirt/qemu.conf\", and edit it as\n    follows:\n\n    nvram = [ \"/usr/share/OVMF/OVMF_CODE.fd:/usr/share/OVMF/OVMF_VARS.fd\" ]\n\n(2) Restart libvirtd with your Linux distribution's service management tool;\n    for example,\n\n    systemctl restart libvirtd\n\n(3) In virt-manager, proceed with the guest installation as usual:\n    - select File | New Virtual Machine,\n    - advance to Step 5 of 5,\n    - in Step 5, check \"Customize configuration before install\",\n    - click Finish;\n    - in the customization dialog, select Overview | Firmware, and choose UEFI,\n    - click Apply and Begin Installation.\n\n(4) With virt-install:\n\n    LDR=\"loader=/usr/share/OVMF/OVMF_CODE.fd,loader_ro=yes,loader_type=pflash\"\n    virt-install \\\n      --name fedora20 \\\n      --memory 2048 \\\n      --vcpus 2 \\\n      --os-variant fedora20 \\\n      --boot hd,cdrom,$LDR \\\n      --disk size=20 \\\n      --disk path=Fedora-Live-Xfce-x86_64-20-1.iso,device=cdrom,bus=scsi\n\n(5) A popular, distribution-independent, bleeding-edge OVMF package is\n    available under \u003chttps://www.kraxel.org/repos/\u003e, courtesy of Gerd Hoffmann.\n\n    The \"edk2.git-ovmf-x64\" package provides the following files, among others:\n    - /usr/share/edk2.git/ovmf-x64/OVMF_CODE-pure-efi.fd\n    - /usr/share/edk2.git/ovmf-x64/OVMF_VARS-pure-efi.fd\n\n    When using this package, adapt steps (1) and (4) accordingly.\n\n(6) Additionally, the \"edk2.git-ovmf-x64\" package seeks to simplify the\n    enablement of Secure Boot in a virtual machine (strictly for development\n    and testing purposes).\n\n    - Boot the virtual machine off the CD-ROM image called\n      \"/usr/share/edk2.git/ovmf-x64/UefiShell.iso\"; before or after installing\n      the main guest operating system.\n\n    - When the UEFI shell appears, issue the following commands:\n\n      EnrollDefaultKeys.efi\n      reset -s\n\n    - The EnrollDefaultKeys.efi utility enrolls the following keys:\n\n      - A static example X.509 certificate (CN=TestCommonName) as Platform Key\n        and first Key Exchange Key.\n\n        The private key matching this certificate has been destroyed (but you\n        shouldn't trust this statement).\n\n      - \"Microsoft Corporation KEK CA 2011\" as second Key Exchange Key\n        (SHA1: 31:59:0b:fd:89:c9:d7:4e:d0:87:df:ac:66:33:4b:39:31:25:4b:30).\n\n      - \"Microsoft Windows Production PCA 2011\" as first DB entry\n        (SHA1: 58:0a:6f:4c:c4:e4:b6:69:b9:eb:dc:1b:2b:3e:08:7b:80:d0:67:8d).\n\n      - \"Microsoft Corporation UEFI CA 2011\" as second DB entry\n        (SHA1: 46:de:f6:3b:5c:e6:1c:f8:ba:0d:e2:e6:63:9c:10:19:d0:ed:14:f3).\n\n      These keys suffice to boot released versions of popular Linux\n      distributions (through the shim.efi utility), and Windows 8 and Windows\n      Server 2012 R2, in Secure Boot mode.\n\nSupported guest operating systems\n---------------------------------\n\nUpstream OVMF does not favor some guest operating systems over others for\npolitical or ideological reasons. However, some operating systems are harder to\nobtain and/or technically more difficult to support. The general expectation is\nthat recent UEFI OSes should just work. Please consult the \"OvmfPkg/README\"\nfile.\n\nThe following guest OSes were tested with OVMF:\n- Red Hat Enterprise Linux 6\n- Red Hat Enterprise Linux 7\n- Fedora 18\n- Fedora 19\n- Fedora 20\n- Windows Server 2008 R2 SP1\n- Windows Server 2012\n- Windows 8\n\nNotes about Windows Server 2008 R2 (paraphrasing the \"OvmfPkg/README\" file):\n\n- QEMU should be started with one of the \"-device qxl-vga\" and \"-device VGA\"\n  options.\n\n- Only one video mode, 1024x768x32, is supported at OS runtime.\n\n  Please refer to the section about QemuVideoDxe (OVMF's built-in video driver)\n  for more details on this limitation.\n\n- The qxl-vga video card is recommended (\"-device qxl-vga\"). After booting the\n  installed guest OS, select the video card in Device Manager, and upgrade the\n  video driver to the QXL XDDM one.\n\n  The QXL XDDM driver can be downloaded from\n  \u003chttp://www.spice-space.org/download.html\u003e, under Guest | Windows binaries.\n\n  This driver enables additional graphics resolutions at OS runtime, and\n  provides S3 (suspend/resume) capability.\n\nNotes about Windows Server 2012 and Windows 8:\n\n- QEMU should be started with the \"-device qxl-vga,revision=4\" option (or a\n  later revision, if available).\n\n- The guest OS's builtin video driver inherits the video mode / frame buffer\n  from OVMF. There's no way to change the resolution at OS runtime.\n\n  For this reason, a platform driver has been developed for OVMF, which allows\n  users to change the preferred video mode in the firmware. Please refer to the\n  section about PlatformDxe for details.\n\n- It is recommended to upgrade the guest OS's video driver to the QXL WDDM one,\n  via Device Manager.\n\n  Binaries for the QXL WDDM driver can be found at\n  \u003chttp://people.redhat.com/~vrozenfe/qxlwddm\u003e (pick a version greater than or\n  equal to 0.6), while the source code resides at\n  \u003chttps://github.com/vrozenfe/qxl-dod\u003e.\n\n  This driver enables additional graphics resolutions at OS runtime, and\n  provides S3 (suspend/resume) capability.\n\nCompatibility Support Module (CSM)\n----------------------------------\n\nCollaboration between SeaBIOS and OVMF developers has enabled SeaBIOS to be\nbuilt as a Compatibility Support Module, and OVMF to embed and use it.\n\nBenefits of a SeaBIOS CSM include:\n\n- The ability to boot legacy (non-UEFI) operating systems, such as legacy Linux\n  systems, Windows 7, OpenBSD 5.2, FreeBSD 8/9, NetBSD, DragonflyBSD, Solaris\n  10/11.\n\n- Legacy (non-UEFI-compliant) PCI expansion ROMs, such as a VGA BIOS, mapped by\n  QEMU in emulated devices' ROM BARs, are loaded and executed by OVMF.\n\n  For example, this grants the Windows Server 2008 R2 SP1 guest's native,\n  legacy video driver access to all modes of all QEMU video cards.\n\nBuilding the CSM target of the SeaBIOS source tree is out of scope for this\nreport. Additionally, upstream OVMF does not enable the CSM by default.\n\nInterested users and developers should look for OVMF's \"-D CSM_ENABLE\"\nbuild-time option, and check out the \u003chttps://www.kraxel.org/repos/\u003e continuous\nintegration repository, which provides CSM-enabled OVMF builds.\n\n[RHEL] The \"OVMF_CODE.fd\" firmware image made available on the Red Hat\n       Enterprise Linux 7.1 host does not include a Compatibility Support\n       Module, for the following reasons:\n\n       - Virtual machines running officially supported, legacy guest operating\n         systems should just use the standalone SeaBIOS firmware. Firmware\n         selection is flexible in virtualization, see eg. \"Installation of OVMF\n         guests with virt-manager and virt-install\" above.\n\n       - The 16-bit thunking interface between OVMF and SeaBIOS is very complex\n         and presents a large debugging and support burden, based on past\n         experience.\n\n       - Secure Boot is incompatible with CSM.\n\n       - Inter-project dependencies should be minimized whenever possible.\n\n       - Using the default QXL video card, the Windows 2008 R2 SP1 guest can be\n         installed with its built-in, legacy video driver. Said driver will\n         select the only available video mode, 1024x768x32. After installation,\n         the video driver can be upgraded to the full-featured QXL XDDM driver.\n\nPhases of the boot process\n--------------------------\n\nThe PI and UEFI specifications, and Intel's UEFI and EDK II Learning and\nDevelopment materials provide ample information on PI and UEFI concepts. The\nfollowing is an absolutely minimal, rough glossary that is included only to\nhelp readers new to PI and UEFI understand references in later, OVMF-specific\nsections. We defer heavily to the official specifications and the training\nmaterials, and frequently quote them below.\n\nA central concept to mention early is the GUID -- globally unique identifier. A\nGUID is a 128-bit number, written as XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX,\nwhere each X stands for a hexadecimal nibble. GUIDs are used to name everything\nin PI and in UEFI. Programmers introduce new GUIDs with the \"uuidgen\" utility,\nand standards bodies standardize well-known services by positing their GUIDs.\n\nThe boot process is roughly divided in the following phases:\n\n- Reset vector code.\n\n- SEC: Security phase. This phase is the root of firmware integrity.\n\n- PEI: Pre-EFI Initialization. This phase performs \"minimal processor, chipset\n  and platform configuration for the purpose of discovering memory\". Modules in\n  PEI collectively save their findings about the platform in a list of HOBs\n  (hand-off blocks).\n\n  When developing PEI code, the Platform Initialization (PI) specification\n  should be consulted.\n\n- DXE: Driver eXecution Environment, pronounced as \"Dixie\". This \"is the phase\n  where the bulk of the booting occurs: devices are enumerated and initialized,\n  UEFI services are supported, and protocols and drivers are implemented. Also,\n  the tables that create the UEFI interface are produced\".\n\n  On the PEI/DXE boundary, the HOBs produced by PEI are consumed. For example,\n  this is how the memory space map is configured initially.\n\n- BDS: Boot Device Selection. It is \"responsible for determining how and where\n  you want to boot the operating system\".\n\n  When developing DXE and BDS code, it is mainly the UEFI specification that\n  should be consulted. When speaking about DXE, BDS is frequently considered to\n  be a part of it.\n\nThe following concepts are tied to specific boot process phases:\n\n- PEIM: a PEI Module (pronounced \"PIM\"). A binary module running in the PEI\n  phase, consuming some PPIs and producing other PPIs, and producing HOBs.\n\n- PPI: PEIM-to-PEIM interface. A structure of function pointers and related\n  data members that establishes a PEI service, or an instance of a PEI service.\n  PPIs are identified by GUID.\n\n  An example is EFI_PEI_S3_RESUME2_PPI (6D582DBC-DB85-4514-8FCC-5ADF6227B147).\n\n- DXE driver: a binary module running in the DXE and BDS phases, consuming some\n  protocols and producing other protocols.\n\n- Protocol: A structure of function pointers and related data members that\n  establishes a DXE service, or an instance of a DXE service. Protocols are\n  identified by GUID.\n\n  An example is EFI_BLOCK_IO_PROTOCOL (964E5B21-6459-11D2-8E39-00A0C969723B).\n\n- Architectural protocols: a set of standard protocols that are foundational to\n  the working of a UEFI system. Each architectural protocol has at most one\n  instance. Architectural protocols are implemented by a subset of DXE drivers.\n  DXE drivers explicitly list the set of protocols (including architectural\n  protocols) that they need to work. UEFI drivers can only be loaded once all\n  architectural protocols have become available during the DXE phase.\n\n  An example is EFI_VARIABLE_WRITE_ARCH_PROTOCOL\n  (6441F818-6362-4E44-B570-7DBA31DD2453).\n\nProject structure\n-----------------\n\nThe term \"OVMF\" usually denotes the project (community and development effort)\nthat provide and maintain the subject matter UEFI firmware for virtual\nmachines. However the term is also frequently applied to the firmware binary\nproper that a virtual machine executes.\n\nOVMF emerges as a compilation of several modules from the edk2 source\nrepository. \"edk2\" stands for EFI Development Kit II; it is a \"modern,\nfeature-rich, cross-platform firmware development environment for the UEFI and\nPI specifications\".\n\nThe composition of OVMF is dictated by the following build control files:\n\n  OvmfPkg/OvmfPkgIa32.dsc\n  OvmfPkg/OvmfPkgIa32.fdf\n\n  OvmfPkg/OvmfPkgIa32X64.dsc\n  OvmfPkg/OvmfPkgIa32X64.fdf\n\n  OvmfPkg/OvmfPkgX64.dsc\n  OvmfPkg/OvmfPkgX64.fdf\n\nThe format of these files is described in the edk2 DSC and FDF specifications.\nRoughly, the DSC file determines:\n- library instance resolutions for library class requirements presented by the\n  modules to be compiled,\n- the set of modules to compile.\n\nThe FDF file roughly determines:\n- what binary modules (compilation output files, precompiled binaries, graphics\n  image files, verbatim binary sections) to include in the firmware image,\n- how to lay out the firmware image.\n\nThe Ia32 flavor of these files builds a firmware where both PEI and DXE phases\nare 32-bit. The Ia32X64 flavor builds a firmware where the PEI phase consists\nof 32-bit modules, and the DXE phase is 64-bit. The X64 flavor builds a purely\n64-bit firmware.\n\nThe word size of the DXE phase must match the word size of the runtime OS -- a\n32-bit DXE can't cooperate with a 64-bit OS, and a 64-bit DXE can't work a\n32-bit OS.\n\nOVMF pulls together modules from across the edk2 tree. For example:\n\n- common drivers and libraries that are platform independent are usually\n  located under MdeModulePkg and MdePkg,\n\n- common but hardware-specific drivers and libraries that match QEMU's\n  pc-i440fx-* machine type are pulled in from IntelFrameworkModulePkg,\n  PcAtChipsetPkg and UefiCpuPkg,\n\n- the platform independent UEFI Shell is built from ShellPkg,\n\n- OvmfPkg includes drivers and libraries that are useful for virtual machines\n  and may or may not be specific to QEMU's pc-i440fx-* machine type.\n\nPlatform Configuration Database (PCD)\n-------------------------------------\n\nLike the \"Phases of the boot process\" section, this one introduces a concept in\nvery raw form. We defer to the PCD related edk2 specifications, and we won't\ndiscuss implementation details here. Our purpose is only to offer the reader a\nusable (albeit possibly inaccurate) definition, so that we can refer to PCDs\nlater on.\n\nColloquially, when we say \"PCD\", we actually mean \"PCD entry\"; that is, an\nentry stored in the Platform Configuration Database.\n\nThe Platform Configuration Database is\n- a firmware-wide\n- name-value store\n- of scalars and buffers\n- where each entry may be\n  - build-time constant, or\n  - run-time dynamic, or\n  - theoretically, a middle option: patchable in the firmware file itself,\n    using a dedicated tool. (OVMF does not utilize externally patchable\n    entries.)\n\nA PCD entry is declared in the DEC file of the edk2 top-level Package directory\nwhose modules (drivers and libraries) are the primary consumers of the PCD\nentry. (See for example OvmfPkg/OvmfPkg.dec). Basically, a PCD in a DEC file\nexposes a simple customization point.\n\nInterest in a PCD entry is communicated to the build system by naming the PCD\nentry in the INF file of the interested module (application, driver or\nlibrary). The module may read and -- dependent on the PCD entry's category --\nwrite the PCD entry.\n\nLet's investigate the characteristics of the Database and the PCD entries.\n\n- Firmware-wide: technically, all modules may access all entries they are\n  interested in, assuming they advertise their interest in their INF files.\n  With careful design, PCDs enable inter-driver propagation of (simple) system\n  configuration. PCDs are available in both PEI and DXE.\n\n  (UEFI drivers meant to be portable (ie. from third party vendors) are not\n  supposed to use PCDs, since PCDs qualify internal to the specific edk2\n  firmware in question.)\n\n- Name-value store of scalars and buffers: each PCD has a symbolic name, and a\n  fixed scalar type (UINT16, UINT32 etc), or VOID* for buffers. Each PCD entry\n  belongs to a namespace, where a namespace is (obviously) a GUID, defined in\n  the DEC file.\n\n- A DEC file can permit several categories for a PCD:\n  - build-time constant (\"FixedAtBuild\"),\n  - patchable in the firmware image (\"PatchableInModule\", unused in OVMF),\n  - runtime modifiable (\"Dynamic\").\n\nThe platform description file (DSC) of a top-level Package directory may choose\nthe exact category for a given PCD entry that its modules wish to use, and\nassign a default (or constant) initial value to it.\n\nIn addition, the edk2 build system too can initialize PCD entries to values\nthat it calculates while laying out the flash device image. Such PCD\nassignments are described in the FDF control file.\n\nFirmware image structure\n------------------------\n\n(We assume the common X64 choice for both PEI and DXE, and the default DEBUG\nbuild target.)\n\nThe OvmfPkg/OvmfPkgX64.fdf file defines the following layout for the flash\ndevice image \"OVMF.fd\":\n\n  Description                     Compression type        Size\n  ------------------------------  ----------------------  -------\n  Non-volatile data storage       open-coded binary data   128 KB\n    Variable store                                          56 KB\n    Event log                                                4 KB\n    Working block                                            4 KB\n    Spare area                                              64 KB\n\n  FVMAIN_COMPACT                  uncompressed            1712 KB\n    FV Firmware File System file  LZMA compressed\n      PEIFV                       uncompressed             896 KB\n        individual PEI modules    uncompressed\n      DXEFV                       uncompressed            8192 KB\n        individual DXE modules    uncompressed\n\n  SECFV                           uncompressed             208 KB\n    SEC driver\n    reset vector code\n\nThe top-level image consists of three regions (three firmware volumes):\n- non-volatile data store (128 KB),\n- main firmware volume (FVMAIN_COMPACT, 1712 KB),\n- firmware volume containing the reset vector code and the SEC phase code (208\n  KB).\n\nIn total, the OVMF.fd file has size 128 KB + 1712 KB + 208 KB == 2 MB.\n\n(1) The firmware volume with non-volatile data store (128 KB) has the following\n    internal structure, in blocks of 4 KB:\n\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+  L: event log\n       LIVE | varstore                  |L|W|  W: working block\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      SPARE |                               |\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n    The first half of this firmware volume is \"live\", while the second half is\n    \"spare\". The spare half is important when the variable driver reclaims\n    unused storage and reorganizes the variable store.\n\n    The live half dedicates 14 blocks (56 KB) to the variable store itself. On\n    top of those, one block is set aside for an event log, and one block is\n    used as the working block of the fault tolerant write protocol. Fault\n    tolerant writes are used to recover from an occasional (virtual) power loss\n    during variable updates.\n\n    The blocks in this firmware volume are accessed, in stacking order from\n    least abstract to most abstract, by:\n\n    - EFI_FIRMWARE_VOLUME_BLOCK_PROTOCOL (provided by\n      OvmfPkg/QemuFlashFvbServicesRuntimeDxe),\n\n    - EFI_FAULT_TOLERANT_WRITE_PROTOCOL (provided by\n      MdeModulePkg/Universal/FaultTolerantWriteDxe),\n\n    - architectural protocols instrumental to the runtime UEFI variable\n      services:\n      - EFI_VARIABLE_ARCH_PROTOCOL,\n      - EFI_VARIABLE_WRITE_ARCH_PROTOCOL.\n\n      In a non-secure boot build, the DXE driver providing these architectural\n      protocols is MdeModulePkg/Universal/Variable/RuntimeDxe. In a secure boot\n      build, where authenticated variables are available, the DXE driver\n      offering these protocols is SecurityPkg/VariableAuthenticated/RuntimeDxe.\n\n(2) The main firmware volume (FVMAIN_COMPACT, 1712 KB) embeds further firmware\n    volumes. The outermost layer is a Firmware File System (FFS), carrying a\n    single file. This file holds an LZMA-compressed section, which embeds two\n    firmware volumes: PEIFV (896 KB) with PEIMs, and DXEFV (8192 KB) with DXE\n    and UEFI drivers.\n\n    This scheme enables us to build 896 KB worth of PEI drivers and 8192 KB\n    worth of DXE and UEFI drivers, compress them all with LZMA in one go, and\n    store the compressed result in 1712 KB, saving room in the flash device.\n\n(3) The SECFV firmware volume (208 KB) is not compressed. It carries the\n    \"volume top file\" with the reset vector code, to end at 4 GB in\n    guest-physical address space, and the SEC phase driver (OvmfPkg/Sec).\n\n    The last 16 bytes of the volume top file (mapped directly under 4 GB)\n    contain a NOP slide and a jump instruction. This is where QEMU starts\n    executing the firmware, at address 0xFFFF_FFF0. The reset vector and the\n    SEC driver run from flash directly.\n\n    The SEC driver locates FVMAIN_COMPACT in the flash, and decompresses the\n    main firmware image to RAM. The rest of OVMF (PEI, DXE, BDS phases) run\n    from RAM.\n\nAs already mentioned, the OVMF.fd file is mapped by qemu's\n\"hw/block/pflash_cfi01.c\" device just under 4 GB in guest-physical address\nspace, according to the command line option\n\n  -drive if=pflash,format=raw,file=fedora.flash\n\n(refer to the Example qemu invocation). This is a \"ROMD device\", which can\nswitch out of \"ROMD mode\" and back into it.\n\nNamely, in the default ROMD mode, the guest-physical address range backed by\nthe flash device reads and executes as ROM (it does not trap from KVM to QEMU).\nThe first write access in this mode traps to QEMU, and flips the device out of\nROMD mode.\n\nIn non-ROMD mode, the flash chip is programmed by storing CFI (Common Flash\nInterface) command values at the flash-covered addresses; both reads and writes\ntrap to QEMU, and the flash contents are modified and synchronized to the\nhost-side file. A special CFI command flips the flash device back to ROMD mode.\n\nQemu implements the above based on the KVM_CAP_READONLY_MEM / KVM_MEM_READONLY\nKVM features, and OVMF puts it to use in its EFI_FIRMWARE_VOLUME_BLOCK_PROTOCOL\nimplementation, under \"OvmfPkg/QemuFlashFvbServicesRuntimeDxe\".\n\nIMPORTANT: Never pass OVMF.fd to qemu with the -bios option. That option maps\nthe firmware image as ROM into the guest's address space, and forces OVMF to\nemulate non-volatile variables with a fallback driver that is bound to have\ninsufficient and confusing semantics.\n\nThe 128 KB firmware volume with the variable store, discussed under (1), is\nalso built as a separate host-side file, named \"OVMF_VARS.fd\". The \"rest\" is\nbuilt into a third file, \"OVMF_CODE.fd\", which is only 1920 KB in size. The\nvariable store is mapped into its usual location, at 4 GB - 2 MB = 0xFFE0_0000,\nthrough the following qemu options:\n\n  -drive if=pflash,format=raw,readonly,file=OVMF_CODE.fd   \\\n  -drive if=pflash,format=raw,file=fedora.varstore.fd\n\nThis way qemu configures two flash chips consecutively, with start addresses\ngrowing downwards, which is transparent to OVMF.\n\n[RHEL] Red Hat Enterprise Linux 7.1 ships a Secure Boot-enabled, X64, DEBUG\n       firmware only. Furthermore, only the split files (\"OVMF_VARS.fd\" and\n       \"OVMF_CODE.fd\") are available.\n\nS3 (suspend to RAM and resume)\n------------------------------\n\nAs noted in Example qemu invocation, the\n\n  -global PIIX4_PM.disable_s3=0\n\ncommand line option tells qemu and OVMF if the user would like to enable S3\nsupport. (This is corresponds to the /domain/pm/suspend-to-mem/@enabled libvirt\ndomain XML attribute.)\n\nImplementing / orchestrating S3 was a considerable community effort in OVMF. A\ndetailed description exceeds the scope of this report; we only make a few\nstatements.\n\n(1) S3-related PPIs and protocols are well documented in the PI specification.\n\n(2) Edk2 contains most modules that are needed to implement S3 on a given\n    platform. One abstraction that is central to the porting / extending of the\n    S3-related modules to a new platform is the LockBox library interface,\n    which a specific platform can fill in by implementing its own LockBox\n    library instance.\n\n    The LockBox library provides a privileged name-value store (to be addressed\n    by GUIDs). The privilege separation stretches between the firmware and the\n    operating system. That is, the S3-related machinery of the firmware saves\n    some items in the LockBox securely, under well-known GUIDs, before booting\n    the operating system. During resume (which is a form of warm reset), the\n    firmware is activated again, and retrieves items from the LockBox. Before\n    jumping to the OS's resume vector, the LockBox is secured again.\n\n    We'll return to this later when we separately discuss SMRAM and SMM.\n\n(3) During resume, the DXE and later phases are never reached; only the reset\n    vector, and the SEC and PEI phases of the firmware run. The platform is\n    supposed to detect a resume in progress during PEI, and to store that fact\n    in the BootMode field of the Phase Handoff Information Table (PHIT) HOB.\n    OVMF keys this off the CMOS, see OvmfPkg/PlatformPei.\n\n    At the end of PEI, the DXE IPL PEIM (Initial Program Load PEI Module, see\n    MdeModulePkg/Core/DxeIplPeim) examines the Boot Mode, and if it says \"S3\n    resume in progress\", then the IPL branches to the PEIM that exports\n    EFI_PEI_S3_RESUME2_PPI (provided by UefiCpuPkg/Universal/Acpi/S3Resume2Pei)\n    rather than loading the DXE core.\n\n    S3Resume2Pei executes the technical steps of the resumption, relying on the\n    contents of the LockBox.\n\n(4) During first boot (or after a normal platform reset), when DXE does run,\n    hardware drivers in the DXE phase are encouraged to \"stash\" their hardware\n    configuration steps (eg. accesses to PCI config space, I/O ports, memory\n    mapped addresses, and so on) in a centrally maintained, so called \"S3 boot\n    script\". Hardware accesses are represented with opcodes of a special binary\n    script language.\n\n    This boot script is to be replayed during resume, by S3Resume2Pei. The\n    general goal is to bring back hardware devices -- which have been powered\n    off during suspend -- to their original after-first-boot state, and in\n    particular, to do so quickly.\n\n    At the moment, OVMF saves only one opcode in the S3 resume boot script: an\n    INFORMATION opcode, with contents 0xDEADBEEF (in network byte order). The\n    consensus between Linux developers seems to be that boot firmware is only\n    responsible for restoring basic chipset state, which OVMF does during PEI\n    anyway, independently of S3 vs. normal reset. (One example is the power\n    management registers of the i440fx chipset.) Device and peripheral state is\n    the responsibility of the runtime operating system.\n\n    Although an experimental OVMF S3 boot script was at one point captured for\n    the virtual Cirrus VGA card, such a boot script cannot follow eg. video\n    mode changes effected by the OS. Hence the operating system can never avoid\n    restoring device state, and most Linux display drivers (eg. stdvga, QXL)\n    already cover S3 resume fully.\n\n    The XDDM and WDDM driver models used under Windows OSes seem to recognize\n    this notion of runtime OS responsibility as well. (See the list of OSes\n    supported by OVMF in a separate section.)\n\n(5) The S3 suspend/resume data flow in OVMF is included here tersely, for\n    interested developers.\n\n    (a) BdsLibBootViaBootOption()\n          EFI_ACPI_S3_SAVE_PROTOCOL [AcpiS3SaveDxe]\n          - saves ACPI S3 Context to LockBox  ---------------------+\n            (including FACS address -- FACS ACPI table             |\n            contains OS waking vector)                             |\n                                                                   |\n          - prepares boot script:                                  |\n            EFI_S3_SAVE_STATE_PROTOCOL.Write() [S3SaveStateDxe]    |\n              S3BootScriptLib [PiDxeS3BootScriptLib]               |\n              - opcodes \u0026 arguments are saved in NVS.  --+         |\n                                                         |         |\n          - issues a notification by installing          |         |\n            EFI_DXE_SMM_READY_TO_LOCK_PROTOCOL           |         |\n                                                         |         |\n    (b) EFI_S3_SAVE_STATE_PROTOCOL [S3SaveStateDxe]      |         |\n          S3BootScriptLib [PiDxeS3BootScriptLib]         |         |\n          - closes script with special opcode  \u003c---------+         |\n          - script is available in non-volatile memory             |\n            via PcdS3BootScriptTablePrivateDataPtr  --+            |\n                                                      |            |\n        BootScriptExecutorDxe                         |            |\n          S3BootScriptLib [PiDxeS3BootScriptLib]      |            |\n          - Knows about boot script location by  \u003c----+            |\n            synchronizing with the other library                   |\n            instance via                                           |\n            PcdS3BootScriptTablePrivateDataPtr.                    |\n          - Copies relocated image of itself to                    |\n            reserved memory. --------------------------------+     |\n          - Saved image contains pointer to boot script.  ---|--+  |\n                                                             |  |  |\n    Runtime:                                                 |  |  |\n                                                             |  |  |\n    (c) OS is booted, writes OS waking vector to FACS,       |  |  |\n        suspends machine                                     |  |  |\n                                                             |  |  |\n    S3 Resume (PEI):                                         |  |  |\n                                                             |  |  |\n    (d) PlatformPei sets S3 Boot Mode based on CMOS          |  |  |\n                                                             |  |  |\n    (e) DXE core is skipped and EFI_PEI_S3_RESUME2 is        |  |  |\n        called as last step of PEI                           |  |  |\n                                                             |  |  |\n    (f) S3Resume2Pei retrieves from LockBox:                 |  |  |\n        - ACPI S3 Context (path to FACS)  \u003c------------------|--|--+\n                                          |                  |  |\n                                          +------------------|--|--+\n        - Boot Script Executor Image  \u003c----------------------+  |  |\n                                                                |  |\n    (g) BootScriptExecutorDxe                                   |  |\n          S3BootScriptLib [PiDxeS3BootScriptLib]                |  |\n          - executes boot script  \u003c-----------------------------+  |\n                                                                   |\n    (h) OS waking vector available from ACPI S3 Context / FACS  \u003c--+\n        is called\n\nA comprehensive memory map of OVMF\n----------------------------------\n\nThe following section gives a detailed analysis of memory ranges below 4 GB\nthat OVMF statically uses.\n\nIn the rightmost column, the PCD entry is identified by which the source refers\nto the address or size in question.\n\nThe flash-covered range has been discussed previously in \"Firmware image\nstructure\", therefore we include it only for completeness. Due to the fact that\nthis range is always backed by a memory mapped device (and never RAM), it is\nunaffected by S3 (suspend to RAM and resume).\n\n+--------------------------+ 4194304 KB\n|                          |\n|          SECFV           | size: 208 KB\n|                          |\n+--------------------------+ 4194096 KB\n|                          |\n|      FVMAIN_COMPACT      | size: 1712 KB\n|                          |\n+--------------------------+ 4192384 KB\n|                          |\n|      variable store      | size: 64 KB   PcdFlashNvStorageFtwSpareSize\n|        spare area        |\n|                          |\n+--------------------------+ 4192320 KB    PcdOvmfFlashNvStorageFtwSpareBase\n|                          |\n|    FTW working block     | size: 4 KB    PcdFlashNvStorageFtwWorkingSize\n|                          |\n+--------------------------+ 4192316 KB    PcdOvmfFlashNvStorageFtwWorkingBase\n|                          |\n|       Event log of       | size: 4 KB    PcdOvmfFlashNvStorageEventLogSize\n|   non-volatile storage   |\n|                          |\n+--------------------------+ 4192312 KB    PcdOvmfFlashNvStorageEventLogBase\n|                          |\n|      variable store      | size: 56 KB   PcdFlashNvStorageVariableSize\n|                          |\n+--------------------------+ 4192256 KB    PcdOvmfFlashNvStorageVariableBase\n\nThe flash-mapped image of OVMF.fd covers the entire structure above (2048 KB).\n\nWhen using the split files, the address 4192384 KB\n(PcdOvmfFlashNvStorageFtwSpareBase + PcdFlashNvStorageFtwSpareSize) is the\nboundary between the mapped images of OVMF_VARS.fd (56 KB + 4 KB + 4 KB + 64 KB\n= 128 KB) and OVMF_CODE.fd (1712 KB + 208 KB = 1920 KB).\n\nWith regard to RAM that is statically used by OVMF, S3 (suspend to RAM and\nresume) complicates matters. Many ranges have been introduced only to support\nS3, hence for all ranges below, the following questions will be audited:\n\n(a) when and how a given range is initialized after first boot of the VM,\n(b) how it is protected from memory allocations during DXE,\n(c) how it is protected from the OS,\n(d) how it is accessed on the S3 resume path,\n(e) how it is accessed on the warm reset path.\n\nImportantly, the term \"protected\" is meant as protection against inadvertent\nreallocations and overwrites by co-operating DXE and OS modules. It does not\nimply security against malicious code.\n\n+--------------------------+ 17408 KB\n|                          |\n|DXEFV from FVMAIN_COMPACT | size: 8192 KB PcdOvmfDxeMemFvSize\n|  decompressed firmware   |\n| volume with DXE modules  |\n|                          |\n+--------------------------+ 9216 KB       PcdOvmfDxeMemFvBase\n|                          |\n|PEIFV from FVMAIN_COMPACT | size: 896 KB  PcdOvmfPeiMemFvSize\n|  decompressed firmware   |\n| volume with PEI modules  |\n|                          |\n+--------------------------+ 8320 KB       PcdOvmfPeiMemFvBase\n|                          |\n| permanent PEI memory for | size: 32 KB   PcdS3AcpiReservedMemorySize\n|   the S3 resume path     |\n|                          |\n+--------------------------+ 8288 KB       PcdS3AcpiReservedMemoryBase\n|                          |\n|  temporary SEC/PEI heap  | size: 32 KB   PcdOvmfSecPeiTempRamSize\n|         and stack        |\n|                          |\n+--------------------------+ 8256 KB       PcdOvmfSecPeiTempRamBase\n|                          |\n|          unused          | size: 32 KB\n|                          |\n+--------------------------+ 8224 KB\n|                          |\n|      SEC's table of      | size: 4 KB    PcdGuidedExtractHandlerTableSize\n| GUIDed section handlers  |\n|                          |\n+--------------------------+ 8220 KB       PcdGuidedExtractHandlerTableAddress\n|                          |\n|     LockBox storage      | size: 4 KB    PcdOvmfLockBoxStorageSize\n|                          |\n+--------------------------+ 8216 KB       PcdOvmfLockBoxStorageBase\n|                          |\n| early page tables on X64 | size: 24 KB   PcdOvmfSecPageTablesSize\n|                          |\n+--------------------------+ 8192 KB       PcdOvmfSecPageTablesBase\n\n(1) Early page tables on X64:\n\n  (a) when and how it is initialized after first boot of the VM\n\n    The range is filled in during the SEC phase\n    [OvmfPkg/ResetVector/Ia32/PageTables64.asm]. The CR3 register is verified\n    against the base address in SecCoreStartupWithStack()\n    [OvmfPkg/Sec/SecMain.c].\n\n  (b) how it is protected from memory allocations during DXE\n\n    If S3 was enabled on the QEMU command line (see \"-global\n    PIIX4_PM.disable_s3=0\" earlier), then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] protects the range with an AcpiNVS memory\n    allocation HOB, in PEI.\n\n    If S3 was disabled, then this range is not protected. DXE's own page tables\n    are first built while still in PEI (see HandOffToDxeCore()\n    [MdeModulePkg/Core/DxeIplPeim/X64/DxeLoadFunc.c]). Those tables are located\n    in permanent PEI memory. After CR3 is switched over to them (which occurs\n    before jumping to the DXE core entry point), we don't have to preserve the\n    initial tables.\n\n  (c) how it is protected from the OS\n\n    If S3 is enabled, then (1b) reserves it from the OS too.\n\n    If S3 is disabled, then the range needs no protection.\n\n  (d) how it is accessed on the S3 resume path\n\n    It is rewritten same as in (1a), which is fine because (1c) reserved it.\n\n  (e) how it is accessed on the warm reset path\n\n    It is rewritten same as in (1a).\n\n(2) LockBox storage:\n\n  (a) when and how it is initialized after first boot of the VM\n\n    InitializeRamRegions() [OvmfPkg/PlatformPei/MemDetect.c] zeroes out the\n    area during PEI. This is correct but not strictly necessary, since on first\n    boot the area is zero-filled anyway.\n\n    The LockBox signature of the area is filled in by the PEI module or DXE\n    driver that has been linked against OVMF's LockBoxLib and is run first. The\n    signature is written in LockBoxLibInitialize()\n    [OvmfPkg/Library/LockBoxLib/LockBoxLib.c].\n\n    Any module calling SaveLockBox() [OvmfPkg/Library/LockBoxLib/LockBoxLib.c]\n    will co-populate this area.\n\n  (b) how it is protected from memory allocations during DXE\n\n    If S3 is enabled, then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] protects the range as AcpiNVS.\n\n    Otherwise, the range is covered with a BootServicesData memory allocation\n    HOB.\n\n  (c) how it is protected from the OS\n\n    If S3 is enabled, then (2b) protects it sufficiently.\n\n    Otherwise the range requires no runtime protection, and the\n    BootServicesData allocation type from (2b) ensures that the range will be\n    released to the OS.\n\n  (d) how it is accessed on the S3 resume path\n\n    The S3 Resume PEIM restores data from the LockBox, which has been correctly\n    protected in (2c).\n\n  (e) how it is accessed on the warm reset path\n\n    InitializeRamRegions() [OvmfPkg/PlatformPei/MemDetect.c] zeroes out the\n    range during PEI, effectively emptying the LockBox. Modules will\n    re-populate the LockBox as described in (2a).\n\n(3) SEC's table of GUIDed section handlers\n\n  (a) when and how it is initialized after first boot of the VM\n\n    The following two library instances are linked into SecMain:\n    - IntelFrameworkModulePkg/Library/LzmaCustomDecompressLib,\n    - MdePkg/Library/BaseExtractGuidedSectionLib.\n\n    The first library registers its LZMA decompressor plugin (which is a called\n    a \"section handler\") by calling the second library:\n\n    LzmaDecompressLibConstructor() [GuidedSectionExtraction.c]\n      ExtractGuidedSectionRegisterHandlers() [BaseExtractGuidedSectionLib.c]\n\n    The second library maintains its table of registered \"section handlers\", to\n    be indexed by GUID, in this fixed memory area, independently of S3\n    enablement.\n\n    (The decompression of FVMAIN_COMPACT's FFS file section that contains the\n    PEIFV and DXEFV firmware volumes occurs with the LZMA decompressor\n    registered above. See (6) and (7) below.)\n\n  (b) how it is protected from memory allocations during DXE\n\n    There is no need to protect this area from DXE: because nothing else in\n    OVMF links against BaseExtractGuidedSectionLib, the area loses its\n    significance as soon as OVMF progresses from SEC to PEI, therefore DXE is\n    allowed to overwrite the region.\n\n  (c) how it is protected from the OS\n\n    When S3 is enabled, we cover the range with an AcpiNVS memory allocation\n    HOB in InitializeRamRegions().\n\n    When S3 is disabled, the range is not protected.\n\n  (d) how it is accessed on the S3 resume path\n\n    The table of registered section handlers is again managed by\n    BaseExtractGuidedSectionLib linked into SecMain exclusively. Section\n    handler registrations update the table in-place (based on GUID matches).\n\n  (e) how it is accessed on the warm reset path\n\n    If S3 is enabled, then the OS won't damage the table (due to (3c)), thus\n    see (3d).\n\n    If S3 is disabled, then the OS has most probably overwritten the range with\n    its own data, hence (3a) -- complete reinitialization -- will come into\n    effect, based on the table signature check in BaseExtractGuidedSectionLib.\n\n(4) temporary SEC/PEI heap and stack\n\n  (a) when and how it is initialized after first boot of the VM\n\n    The range is configured in [OvmfPkg/Sec/X64/SecEntry.S] and\n    SecCoreStartupWithStack() [OvmfPkg/Sec/SecMain.c]. The stack half is read \u0026\n    written by the CPU transparently. The heap half is used for memory\n    allocations during PEI.\n\n    Data is migrated out (to permanent PEI stack \u0026 memory) in (or soon after)\n    PublishPeiMemory() [OvmfPkg/PlatformPei/MemDetect.c].\n\n  (b) how it is protected from memory allocations during DXE\n\n    It is not necessary to protect this range during DXE because its use ends\n    still in PEI.\n\n  (c) how it is protected from the OS\n\n    If S3 is enabled, then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] reserves it as AcpiNVS.\n\n    If S3 is disabled, then the range doesn't require protection.\n\n  (d) how it is accessed on the S3 resume path\n\n    Same as in (4a), except the target area of the migration triggered by\n    PublishPeiMemory() [OvmfPkg/PlatformPei/MemDetect.c] is different -- see\n    (5).\n\n  (e) how it is accessed on the warm reset path\n\n    Same as in (4a). The stack and heap halves both may contain garbage, but it\n    doesn't matter.\n\n(5) permanent PEI memory for the S3 resume path\n\n  (a) when and how it is initialized after first boot of the VM\n\n    No particular initialization or use.\n\n  (b) how it is protected from memory allocations during DXE\n\n    We don't need to protect this area during DXE.\n\n  (c) how it is protected from the OS\n\n    When S3 is enabled, InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] makes sure the OS stays away by covering\n    the range with an AcpiNVS memory allocation HOB.\n\n    When S3 is disabled, the range needs no protection.\n\n  (d) how it is accessed on the S3 resume path\n\n    PublishPeiMemory() installs the range as permanent RAM for PEI. The range\n    will serve as stack and will satisfy allocation requests during the rest of\n    PEI. OS data won't overlap due to (5c).\n\n  (e) how it is accessed on the warm reset path\n\n    Same as (5a).\n\n(6) PEIFV -- decompressed firmware volume with PEI modules\n\n  (a) when and how it is initialized after first boot of the VM\n\n    DecompressMemFvs() [OvmfPkg/Sec/SecMain.c] populates the area, by\n    decompressing the flash-mapped FVMAIN_COMPACT volume's contents. (Refer to\n    \"Firmware image structure\".)\n\n  (b) how it is protected from memory allocations during DXE\n\n    When S3 is disabled, PeiFvInitialization() [OvmfPkg/PlatformPei/Fv.c]\n    covers the range with a BootServicesData memory allocation HOB.\n\n    When S3 is enabled, the same is coverage is ensured, just with the stronger\n    AcpiNVS memory allocation type.\n\n  (c) how it is protected from the OS\n\n    When S3 is disabled, it is not necessary to keep the range from the OS.\n\n    Otherwise the AcpiNVS type allocation from (6b) provides coverage.\n\n  (d) how it is accessed on the S3 resume path\n\n    Rather than decompressing it again from FVMAIN_COMPACT, GetS3ResumePeiFv()\n    [OvmfPkg/Sec/SecMain.c] reuses the protected area for parsing / execution\n    from (6c).\n\n  (e) how it is accessed on the warm reset path\n\n    Same as (6a).\n\n(7) DXEFV -- decompressed firmware volume with DXE modules\n\n  (a) when and how it is initialized after first boot of the VM\n\n    Same as (6a).\n\n  (b) how it is protected from memory allocations during DXE\n\n    PeiFvInitialization() [OvmfPkg/PlatformPei/Fv.c] covers the range with a\n    BootServicesData memory allocation HOB.\n\n  (c) how it is protected from the OS\n\n    The OS is allowed to release and reuse this range.\n\n  (d) how it is accessed on the S3 resume path\n\n    It's not; DXE never runs during S3 resume.\n\n  (e) how it is accessed on the warm reset path\n\n    Same as in (7a).\n\nKnown Secure Boot limitations\n-----------------------------\n\nUnder \"Motivation\" we've mentioned that OVMF's Secure Boot implementation is\nnot suitable for production use yet -- it's only good for development and\ntesting of standards-conformant, non-malicious guest code (UEFI and operating\nsystem alike).\n\nNow that we've examined the persistent flash device, the workings of S3, and\nthe memory map, we can discuss two currently known shortcomings of OVMF's\nSecure Boot that in fact make it insecure. (Clearly problems other than these\ntwo might exist; the set of issues considered here is not meant to be\nexhaustive.)\n\nOne trait of Secure Boot is tamper-evidence. Secure Boot may not prevent\nmalicious modification of software components (for example, operating system\ndrivers), but by being the root of integrity on a platform, it can catch (or\nindirectly contribute to catching) unauthorized changes, by way of signature\nand certificate checks at the earliest phases of boot.\n\nIf an attacker can tamper with key material stored in authenticated and/or\nboot-time only persistent variables (for example, PK, KEK, db, dbt, dbx), then\nthe intended security of this scheme is compromised. The UEFI 2.4A\nspecification says\n\n- in section 28.3.4:\n\n  Platform Keys:\n\n    The public key must be stored in non-volatile storage which is tamper and\n    delete resistant.\n\n  Key Exchange Keys:\n\n    The public key must be stored in non-volatile storage which is tamper\n    resistant.\n\n- in section 28.6.1:\n\n  The signature database variables db, dbt, and dbx must be stored in\n  tamper-resistant non-volatile storage.\n\n(1) The combination of QEMU, KVM, and OVMF does not provide this kind of\n    resistance. The variable store in the emulated flash chip is directly\n    accessible to, and reprogrammable by, UEFI drivers, applications, and\n    operating systems.\n\n(2) Under \"S3 (suspend to RAM and resume)\" we pointed out that the LockBox\n    storage must be similarly secure and tamper-resistant.\n\n    On the S3 resume path, the PEIM providing EFI_PEI_S3_RESUME2_PPI\n    (UefiCpuPkg/Universal/Acpi/S3Resume2Pei) restores and interprets data from\n    the LockBox that has been saved there during boot. This PEIM, being part of\n    the firmware, has full access to the platform. If an operating system can\n    tamper with the contents of the LockBox, then at the next resume the\n    platform's integrity might be subverted.\n\n    OVMF stores the LockBox in normal guest RAM (refer to the memory map\n    section above). Operating systems and third party UEFI drivers and UEFI\n    applications that respect the UEFI memory map will not inadvertently\n    overwrite the LockBox storage, but there's nothing to prevent eg. a\n    malicious kernel from modifying the LockBox.\n\nOne means to address these issues is SMM and SMRAM (System Management Mode and\nSystem Management RAM).\n\nDuring boot and resume, the firmware can enter and leave SMM and access SMRAM.\nBefore the DXE phase is left, and control is transferred to the BDS phase (when\nthird party UEFI drivers and applications can be loaded, and an operating\nsystem can be loaded), SMRAM is locked in hardware, and subsequent modules\ncannot access it directly. (See EFI_DXE_SMM_READY_TO_LOCK_PROTOCOL.)\n\nOnce SMRAM has been locked, UEFI drivers and the operating system can enter SMM\nby raising a System Management Interrupt (SMI), at which point trusted code\n(part of the platform firmware) takes control. SMRAM is also unlocked by\nplatform reset, at which point the boot firmware takes control again.\n\nVariable store and LockBox in SMRAM\n-----------------------------------\n\nEdk2 provides almost all components to implement the variable store and the\nLockBox in SMRAM. In this section we summarize ideas for utilizing those\nfacilities.\n\nThe SMRAM and SMM infrastructure in edk2 is built up as follows:\n\n(1) The platform hardware provides SMM / SMI / SMRAM.\n\n    Qemu/KVM doesn't support these features currently and should implement them\n    in the longer term.\n\n(2) The platform vendor (in this case, OVMF developers) implement device\n    drivers for the platform's System Management Mode:\n\n    - EFI_SMM_CONTROL2_PROTOCOL: for raising a synchronous (and/or) periodic\n      SMI(s); that is, for entering SMM.\n\n    - EFI_SMM_ACCESS2_PROTOCOL: for describing and accessing SMRAM.\n\n    These protocols are documented in the PI Specification, Volume 4.\n\n(3) The platform DSC file is to include the following platform-independent\n    modules:\n\n    - MdeModulePkg/Core/PiSmmCore/PiSmmIpl.inf: SMM Initial Program Load\n    - MdeModulePkg/Core/PiSmmCore/PiSmmCore.inf: SMM Core\n\n(4) At this point, modules of type DXE_SMM_DRIVER can be loaded.\n\n    Such drivers are privileged. They run in SMM, have access to SMRAM, and are\n    separated and switched from other drivers through SMIs. Secure\n    communication between unprivileged (non-SMM) and privileged (SMM) drivers\n    happens through EFI_SMM_COMMUNICATION_PROTOCOL (implemented by the SMM\n    Core, see (3)).\n\n    DXE_SMM_DRIVER modules must sanitize their input (coming from unprivileged\n    drivers) carefully.\n\n(5) The authenticated runtime variable services driver (for Secure Boot builds)\n    is located under \"SecurityPkg/VariableAuthenticated/RuntimeDxe\". OVMF\n    currently builds the driver (a DXE_RUNTIME_DRIVER module) with the\n    \"VariableRuntimeDxe.inf\" control file (refer to \"OvmfPkg/OvmfPkgX64.dsc\"),\n    which does not use SMM.\n\n    The directory includes two more INF files:\n\n    - VariableSmm.inf -- module type: DXE_SMM_DRIVER. A privileged driver that\n      runs in SMM and has access to SMRAM.\n\n    - VariableSmmRuntimeDxe.inf -- module type: DXE_RUNTIME_DRIVER. A\n      non-privileged driver that implements the variable runtime services\n      (replacing the current \"VariableRuntimeDxe.inf\" file) by communicating\n      with the above privileged SMM half via EFI_SMM_COMMUNICATION_PROTOCOL.\n\n(6) An SMRAM-based LockBox implementation needs to be discussed in two parts,\n    because the LockBox is accessed in both PEI and DXE.\n\n    (a) During DXE, drivers save data in the LockBox. A save operation is\n        layered as follows:\n\n        - The unprivileged driver wishing to store data in the LockBox links\n          against the \"MdeModulePkg/Library/SmmLockBoxLib/SmmLockBoxDxeLib.inf\"\n          library instance.\n\n          The library allows the unprivileged driver to format requests for the\n          privileged SMM LockBox driver (see below), and to parse responses.\n\n        - The privileged SMM LockBox driver is built from\n          \"MdeModulePkg/Universal/LockBox/SmmLockBox/SmmLockBox.inf\". This\n          driver has module type DXE_SMM_DRIVER and can access SMRAM.\n\n          The driver delegates command parsing and response formatting to\n          \"MdeModulePkg/Library/SmmLockBoxLib/SmmLockBoxSmmLib.inf\".\n\n        - The above two halves (unprivileged and privileged) mirror what we've\n          seen in case of the variable service drivers, under (5).\n\n    (b) In PEI, the S3 Resume PEIM (UefiCpuPkg/Universal/Acpi/S3Resume2Pei)\n        retrieves data from the LockBox.\n\n        Presumably, S3Resume2Pei should be considered an \"unprivileged PEIM\",\n        and the SMRAM access should be layered as seen in DXE. Unfortunately,\n        edk2 does not implement all of the layers in PEI -- the code either\n        doesn't exist, or it is not open source:\n\n  role         | DXE: protocol/module           | PEI: PPI/module\n  -------------+--------------------------------+------------------------------\n  unprivileged | any                            | S3Resume2Pei.inf\n  driver       |                                |\n  -------------+--------------------------------+------------------------------\n  command      | LIBRARY_CLASS = LockBoxLib     | LIBRARY_CLASS = LockBoxLib\n  formatting   |                                |\n  and response | SmmLockBoxDxeLib.inf           | SmmLockBoxPeiLib.inf\n  parsing      |                                |\n  -------------+--------------------------------+------------------------------\n  privilege    | EFI_SMM_COMMUNICATION_PROTOCOL | EFI_PEI_SMM_COMMUNICATION_PPI\n  separation   |                                |\n               | PiSmmCore.inf                  | missing!\n  -------------+--------------------------------+------------------------------\n  platform SMM | EFI_SMM_CONTROL2_PROTOCOL      | PEI_SMM_CONTROL_PPI\n  and SMRAM    | EFI_SMM_ACCESS2_PROTOCOL       | PEI_SMM_ACCESS_PPI\n  access       |                                |\n               | to be done in OVMF             | to be done in OVMF\n  -------------+--------------------------------+------------------------------\n  command      | LIBRARY_CLASS = LockBoxLib     | LIBRARY_CLASS = LockBoxLib\n  parsing and  |                                |\n  response     | SmmLockBoxSmmLib.inf           | missing!\n  formatting   |                                |\n  -------------+--------------------------------+------------------------------\n  privileged   | SmmLockBox.inf                 | missing!\n  LockBox      |                                |\n  driver       |                                |\n\n        Alternatively, in the future OVMF might be able to provide a LockBoxLib\n        instance (an SmmLockBoxPeiLib substitute) for S3Resume2Pei that\n        accesses SMRAM directly, eliminating the need for deeper layers in the\n        stack (that is, EFI_PEI_SMM_COMMUNICATION_PPI and deeper).\n\n        In fact, a \"thin\" EFI_PEI_SMM_COMMUNICATION_PPI implementation whose\n        sole Communicate() member invariably returns EFI_NOT_STARTED would\n        cause the current SmmLockBoxPeiLib library instance to directly perform\n        full-depth SMRAM access and LockBox search, obviating the \"missing\"\n        cells. (With reference to A Tour Beyond BIOS: Implementing S3 Resume\n        with EDK2, by Jiewen Yao and Vincent Zimmer, October 2014.)\n\nSelect features\n---------------\n\nIn this section we'll browse the top-level \"OvmfPkg\" package directory, and\ndiscuss the more interesting drivers and libraries that have not been mentioned\nthus far.\n\nX64-specific reset vector for OVMF\n..................................\n\nThe \"OvmfPkg/ResetVector\" directory customizes the reset vector (found in\n\"UefiCpuPkg/ResetVector/Vtf0\") for \"OvmfPkgX64.fdf\", that is, when the SEC/PEI\nphases run in 64-bit (ie. long) mode.\n\nThe reset vector's control flow looks roughly like:\n\n  resetVector                               [Ia16/ResetVectorVtf0.asm]\n  EarlyBspInitReal16                        [Ia16/Init16.asm]\n  Main16                                    [Main.asm]\n    EarlyInit16                             [Ia16/Init16.asm]\n\n    ; Transition the processor from\n    ; 16-bit real mode to 32-bit flat mode\n    TransitionFromReal16To32BitFlat         [Ia16/Real16ToFlat32.asm]\n\n    ; Search for the\n    ; Boot Firmware Volume (BFV)\n    Flat32SearchForBfvBase                  [Ia32/SearchForBfvBase.asm]\n\n    ; Search for the SEC entry point\n    Flat32SearchForSecEntryPoint            [Ia32/SearchForSecEntry.asm]\n\n    %ifdef ARCH_IA32\n      ; Jump to the 32-bit SEC entry point\n    %else\n      ; Transition the processor\n      ; from 32-bit flat mode\n      ; to 64-bit flat mode\n      Transition32FlatTo64Flat              [Ia32/Flat32ToFlat64.asm]\n\n        SetCr3ForPageTables64               [Ia32/PageTables64.asm]\n          ; set CR3 to page tables\n          ; built into the ROM image\n\n        ; enable PAE\n        ; set LME\n        ; enable paging\n\n      ; Jump to the 64-bit SEC entry point\n    %endif\n\nOn physical platforms, the initial page tables referenced by\nSetCr3ForPageTables64 are built statically into the flash device image, and are\npresent in ROM at runtime. This is fine on physical platforms because the\npre-built page table entries have the Accessed and Dirty bits set from the\nstart.\n\nAccordingly, for OVMF running in long mode on qemu/KVM, the initial page tables\nwere mapped as a KVM_MEM_READONLY slot, as part of QEMU's pflash device (refer\nto \"Firmware image structure\" above).\n\nIn spite of the Accessed and Dirty bits being pre-set in the read-only,\nin-flash PTEs, in a virtual machine attempts are made to update said PTE bits,\ndifferently from physical hardware. The component attempting to update the\nread-only PTEs can be one of the following:\n\n- The processor itself, if it supports nested paging, and the user enables that\n  processor feature,\n\n- KVM code implementing shadow paging, otherwise.\n\nThe first case presents no user-visible symptoms, but the second case (KVM,\nshadow paging) used to cause a triple fault, prior to Linux commit ba6a354\n(\"KVM: mmu: allow page tables to be in read-only slots\").\n\nFor compatibility with earlier KVM versions, the OvmfPkg/ResetVector directory\nadapts the generic reset vector code as follows:\n\n      Transition32FlatTo64Flat         [UefiCpuPkg/.../Ia32/Flat32ToFlat64.asm]\n\n        SetCr3ForPageTables64       [OvmfPkg/ResetVector/Ia32/PageTables64.asm]\n\n          ; dynamically build the initial page tables in RAM, at address\n          ; PcdOvmfSecPageTablesBase (refer to the memory map above),\n          ; identity-mapping the first 4 GB of address space\n\n          ; set CR3 to PcdOvmfSecPageTablesBase\n\n        ; enable PAE\n        ; set LME\n        ; enable paging\n\nThis way the PTEs that earlier KVM versions try to update (during shadow\npaging) are located in a read-write memory slot, and the write attempts\nsucceed.\n\nClient library for QEMU's firmware configuration interface\n..........................................................\n\nQEMU provides a write-only, 16-bit wide control port, and a read-write, 8-bit\nwide data port for exchanging configuration elements with the firmware.\n\nThe firmware writes a selector (a key) to the control port (0x510), and then\nreads the corresponding configuration data (produced by QEMU) from the data\nport (0x511).\n\nIf the selected entry is writable, the firmware may overwrite it. If QEMU has\nassociated a callback with the entry, then when the entry is completely\nrewritten, QEMU runs the callback. (OVMF does not rewrite any entries at the\nmoment.)\n\nA number of selector values (keys) are predefined. In particular, key 0x19\nselects (returns) a directory of { name, selector, size } triplets, roughly\nspeaking.\n\nThe firmware can request configuration elements by well-known name as well, by\nlooking up the selector value first in the directory, by name, and then writing\nthe selector to the control port. The number of bytes to read subsequently from\nthe data port is known from the directory entry's \"size\" field.\n\nBy convention, directory entries (well-known symbolic names of configuration\nelements) are formatted as POSIX pathnames. For example, the array selected by\nthe \"etc/system-states\" name indicates (among other things) whether the user\nenabled S3 support in QEMU.\n\nThe above interface is called \"fw_cfg\".\n\nThe binary data associated with a symbolic name is called an \"fw_cfg file\".\n\nOVMF's fw_cfg client library is found in \"OvmfPkg/Library/QemuFwCfgLib\". OVMF\ndiscovers many aspects of the virtual system with it; we refer to a few\nexamples below.\n\nGuest ACPI tables\n.................\n\nAn operating system discovers a good amount of its hardware by parsing ACPI\ntables, and by interpreting ACPI objects and methods. On physical hardware, the\nplatform vendor's firmware installs ACPI tables in memory that match both the\nhardware present in the system and the user's firmware configuration (\"BIOS\nsetup\").\n\nUnder qemu/KVM, the owner of the (virtual) hardware configuration is QEMU.\nHardware can easily be reconfigured on the command line. Furthermore, features\nlike CPU hotplug, PCI hotplug, memory hotplug are continuously developed for\nQEMU, and operating systems need direct ACPI support to exploit these features.\n\nFor this reason, QEMU builds its own ACPI tables dynamically, in a\nself-descriptive manner, and exports them to the firmware through a complex,\nmulti-file fw_cfg interface. It is rooted in the \"etc/table-loader\" fw_cfg\nfile. (Further details of this interface are out of scope for this report.)\n\nOVMF's AcpiPlatformDxe driver fetches the ACPI tables, and installs them for\nthe guest OS with the EFI_ACPI_TABLE_PROTOCOL (which is in turn provided by the\ngeneric \"MdeModulePkg/Universal/Acpi/AcpiTableDxe\" driver).\n\nFor earlier QEMU versions and machine types (which we generally don't recommend\nfor OVMF; see \"Scope\"), the \"OvmfPkg/AcpiTables\" directory contains a few\nstatic ACPI table templates. When the \"etc/table-loader\" fw_cfg file is\nunavailable, AcpiPlatformDxe installs these default tables (with a little bit\nof dynamic patching).\n\nWhen OVMF runs in a Xen domU, AcpiTableDxe also installs ACPI tables that\noriginate from the hypervisor's environment.\n\nGuest SMBIOS tables\n...................\n\nQuoting the SMBIOS Reference Specification,\n\n  [...] the System Management BIOS Reference Specification addresses how\n  motherboard and system vendors present management information about their\n  products in a standard format [...]\n\nIn practice SMBIOS tables are just another set of tables that the platform\nvendor's firmware installs in RAM for the operating system, and, importantly,\nfor management applications running on the OS. Without rehashing the \"Guest\nACPI tables\" section in full, let's map the OVMF roles seen there from ACPI to\nSMBIOS:\n\n  role                     | ACPI                    | SMBIOS\n  -------------------------+-------------------------+-------------------------\n  fw_cfg file              | etc/table-loader        | etc/smbios/smbios-tables\n  -------------------------+-------------------------+-------------------------\n  OVMF driver              | AcpiPlatformDxe         | SmbiosPlatformDxe\n  under \"OvmfPkg\"          |                         |\n  -------------------------+-------------------------+-------------------------\n  Underlying protocol,     | EFI_ACPI_TABLE_PROTOCOL | EFI_SMBIOS_PROTOCOL\n  implemented by generic   |                         |\n  driver under             | Acpi/AcpiTableDxe       | SmbiosDxe\n  \"MdeModulePkg/Universal\" |                         |\n  -------------------------+-------------------------+-------------------------\n  default tables available | yes                     | [RHEL] yes, Type0 and\n  for earlier QEMU machine |                         |        Type1 tables\n  types, with hot-patching |                         |\n  -------------------------+-------------------------+-------------------------\n  tables fetched in Xen    | yes                     | yes\n  domUs                    |                         |\n\nPlatform-specific boot policy\n.............................\n\nOVMF's BDS (Boot Device Selection) phase is implemented by\nIntelFrameworkModulePkg/Universal/BdsDxe. Roughly speaking, this large driver:\n\n- provides the EFI BDS architectural protocol (which DXE transfers control to\n  after dispatching all DXE drivers),\n\n- connects drivers to devices,\n\n- enumerates boot devices,\n\n- auto-generates boot options,\n\n- provides \"BIOS setup\" screens, such as:\n\n  - Boot Manager, for booting an option,\n\n  - Boot Maintenance Manager, for adding, deleting, and reordering boot\n    options, changing console properties etc,\n\n  - Device Manager, where devices can register configuration forms, including\n\n    - Secure Boot configuration forms,\n\n    - OVMF's Platform Driver form (see under PlatformDxe).\n\nFirmware that includes the \"IntelFrameworkModulePkg/Universal/BdsDxe\" driver\ncan customize its behavior by providing an instance of the PlatformBdsLib\nlibrary class. The driver links against this platform library, and the\nplatform library can call Intel's BDS utility functions from\n\"IntelFrameworkModulePkg/Library/GenericBdsLib\".\n\nOVMF's PlatformBdsLib instance can be found in\n\"OvmfPkg/Library/PlatformBdsLib\". The main function where the BdsDxe driver\nenters the library is PlatformBdsPolicyBehavior(). We mention two OVMF\nparticulars here.\n\n(1) OVMF is capable of loading kernel images directly from fw_cfg, matching\n    QEMU's -kernel, -initrd, and -append command line options. This feature is\n    useful for rapid, repeated Linux kernel testing, and is implemented in the\n    following call tree:\n\n    PlatformBdsPolicyBehavior() [OvmfPkg/Library/PlatformBdsLib/BdsPlatform.c]\n      TryRunningQemuKernel() [OvmfPkg/Library/PlatformBdsLib/QemuKernel.c]\n        LoadLinux*() [OvmfPkg/Library/LoadLinuxLib/Linux.c]\n\n    OvmfPkg/Library/LoadLinuxLib ports the efilinux bootloader project into\n    OvmfPkg.\n\n(2) OVMF seeks to comply with the boot order specification passed down by QEMU\n    over fw_cfg.\n\n    (a) About Boot Modes\n\n      During the PEI phase, OVMF determines and stores the Boot Mode in the\n      PHIT HOB (already mentioned in \"S3 (suspend to RAM and resume)\"). The\n      boot mode is supposed to influence the rest of the system, for example it\n      distinguishes S3 resume (BOOT_ON_S3_RESUME) from a \"normal\" boot.\n\n      In general, \"normal\" boots can be further differentiated from each other;\n      for example for speed reasons. When the firmware can tell during PEI that\n      the chassis has not been opened since last power-up, then it might want\n      to save time by not connecting all devices and not enumerating all boot\n      options from scratch; it could just rely on the stored results of the\n      last enumeration. The matching BootMode value, to be set during PEI,\n      would be BOOT_ASSUMING_NO_CONFIGURATION_CHANGES.\n\n      OVMF only sets one of the following two boot modes, based on CMOS\n      contents:\n      - BOOT_ON_S3_RESUME,\n      - BOOT_WITH_FULL_CONFIGURATION.\n\n      For BOOT_ON_S3_RESUME, please refer to \"S3 (suspend to RAM and resume)\".\n      The other boot mode supported by OVMF, BOOT_WITH_FULL_CONFIGURATION, is\n      an appropriate \"catch-all\" for a virtual machine, where hardware can\n      easily change from boot to boot.\n\n    (b) Auto-generation of boot options\n\n      Accordingly, when not resuming from S3 sleep (*), OVMF always connects\n      all devices, and enumerates all bootable devices as new boot options\n      (non-volatile variables called Boot####).\n\n      (*) During S3 resume, DXE is not reached, hence BDS isn't either.\n\n      The auto-enumerated boot options are stored in the BootOrder non-volatile\n      variable after any preexistent options. (Boot options may exist before\n      auto-enumeration eg. because the user added them manually with the Boot\n      Maintenance Manager or the efibootmgr utility. They could also originate\n      from an earlier auto-enumeration.)\n\n      PlatformBdsPolicyBehavior()                   [OvmfPkg/.../BdsPlatform.c]\n        TryRunningQemuKernel()                       [OvmfPkg/.../QemuKernel.c]\n        BdsLibConnectAll()           [IntelFrameworkModulePkg/.../BdsConnect.c]\n        BdsLibEnumerateAllBootOption()  [IntelFrameworkModulePkg/.../BdsBoot.c]\n          BdsLibBuildOptionFromHandle() [IntelFrameworkModulePkg/.../BdsBoot.c]\n            BdsLibRegisterNewOption()   [IntelFrameworkModulePkg/.../BdsMisc.c]\n              //\n              // Append the new option number to the original option order\n              //\n\n    (c) Relative UEFI device paths in boot options\n\n      The handling of relative (\"short-form\") UEFI device paths is best\n      demonstrated through an example, and by quoting the UEFI 2.4A\n      specification.\n\n      A short-form hard drive UEFI device path could be (displaying each device\n      path node on a separate line for readability):\n\n        HD(1,GPT,14DD1CC5-D576-4BBF-8858-BAF877C8DF61,0x800,0x64000)/\n        \\EFI\\fedora\\shim.efi\n\n      This device path lacks prefix nodes (eg. hardware or messaging type\n      nodes) that would lead to the hard drive. During load option processing,\n      the above short-form or relative device path could be matched against the\n      following absolute device path:\n\n        PciRoot(0x0)/\n        Pci(0x4,0x0)/\n        HD(1,GPT,14DD1CC5-D576-4BBF-8858-BAF877C8DF61,0x800,0x64000)/\n        \\EFI\\fedora\\shim.efi\n\n      The motivation for this type of device path matching / completion is to\n      allow the user to move around the hard drive (for example, to plug a\n      controller in a different PCI slot, or to expose the block device on a\n      different iSCSI path) and still enable the firmware to find the hard\n      drive.\n\n      The UEFI specification says,\n\n        9.3.6 Media Device Path\n        9.3.6.1 Hard Drive\n\n          [...] Section 3.1.2 defines special rules for processing the Hard\n          Drive Media Device Path. These special rules enable a disk's location\n          to change and still have the system boot from the disk. [...]\n\n        3.1.2 Load Option Processing\n\n          [...] The boot manager must [...] support booting from a short-form\n          device path that starts with the first element being a hard drive\n          media device path [...]. The boot manager must use the GUID or\n          signature and partition number in the hard drive device path to match\n          it to a device in the system. If the drive supports the GPT\n          partitioning scheme the GUID in the hard drive media device path is\n          compared with the UniquePartitionGuid field of the GUID Partition\n          Entry [...]. If the drive supports the PC-AT MBR scheme the signature\n          in the hard drive media device path is compared with the\n          UniqueMBRSignature in the Legacy Master Boot Record [...]. If a\n          signature match is made, then the partition number must also be\n          matched. The hard drive device path can be appended to the matching\n          hardware device path and normal boot behavior can then be used. If\n          more than one device matches the hard drive device path, the boot\n          manager will pick one arbitrarily. Thus the operating system must\n          ensure the uniqueness of the signatures on hard drives to guarantee\n          deterministic boot behavior.\n\n      Edk2 implements and exposes the device path completion logic in the\n      already referenced \"IntelFrameworkModulePkg/Library/GenericBdsLib\"\n      library, in the BdsExpandPartitionPartialDevicePathToFull() function.\n\n    (d) Filtering and reordering the boot options based on fw_cfg\n\n      Once we have an \"all-inclusive\", partly preexistent, partly freshly\n      auto-generated boot option list from bullet (b), OVMF loads QEMU's\n      requested boot order from fw_cfg, and filters and reorders the list from\n      (b) with it:\n\n      PlatformBdsPolicyBehavior()                   [OvmfPkg/.../BdsPlatform.c]\n        TryRunningQemuKernel()                       [OvmfPkg/.../QemuKernel.c]\n        BdsLibConnectAll()           [IntelFrameworkModulePkg/.../BdsConnect.c]\n        BdsLibEnumerateAllBootOption()  [IntelFrameworkModulePkg/.../BdsBoot.c]\n        SetBootOrderFromQemu()                    [OvmfPkg/.../QemuBootOrder.c]\n\n      According to the (preferred) \"-device ...,bootindex=N\" and the (legacy)\n      '-boot order=drives' command line options, QEMU requests a boot order\n      from the firmware through the \"bootorder\" fw_cfg file. (For a bootindex\n      example, refer to the \"Example qemu invocation\" section.)\n\n      This fw_cfg file consists of OpenFirmware (OFW) device paths -- note: not\n      UEFI device paths! --, one per line. An example list is:\n\n        /pci@i0cf8/scsi@4/disk@0,0\n        /pci@i0cf8/ide@1,1/drive@1/disk@0\n        /pci@i0cf8/ethernet@3/ethernet-phy@0\n\n      OVMF filters and reorders the boot option list from bullet (b) with the\n      following nested loops algorithm:\n\n        new_uefi_order := \u003cempty\u003e\n        for each qemu_ofw_path in QEMU's OpenFirmware device path list:\n          qemu_uefi_path_prefix := translate(qemu_ofw_path)\n\n          for each boot_option in current_uefi_order:\n            full_boot_option := complete(boot_option)\n\n            if match(qemu_uefi_path_prefix, full_boot_option):\n              append(new_uefi_order, boot_option)\n              break\n\n        for each unmatched boot_option in current_uefi_order:\n          if survives(boot_option):\n            append(new_uefi_order, boot_option)\n\n        current_uefi_order := new_uefi_order\n\n      OVMF iterates over QEMU's OFW device paths in order, translates each to a\n      UEFI device path prefix, tries to match the translated prefix against the\n      UEFI boot options (which are completed from relative form to absolute\n      form for the purpose of prefix matching), and if there's a match, the\n      matching boot option is appended to the new boot order (which starts out\n      empty).\n\n      (We elaborate on the translate() function under bullet (e). The\n      complete() function has been explained in bullet (c).)\n\n      In addition, UEFI boot options that remain unmatched after filtering and\n      reordering are post-processed, and some of them \"survive\". Due to the\n      fact that OpenFirmware device paths have less expressive power than their\n      UEFI counterparts, some UEFI boot options are simply inexpressible (hence\n      unmatchable) by the nested loops algorithm.\n\n      An important example is the memory-mapped UEFI shell, whose UEFI device\n      path is inexpressible by QEMU's OFW device paths:\n\n        MemoryMapped(0xB,0x900000,0x10FFFFF)/\n        FvFile(7C04A583-9E3E-4F1C-AD65-E05268D0B4D1)\n\n      (Side remark: notice that the address range visible in the MemoryMapped()\n      node corresponds to DXEFV under \"comprehensive memory map of OVMF\"! In\n      addition, the FvFile() node's GUID originates from the FILE_GUID entry of\n      \"ShellPkg/Application/Shell/Shell.inf\".)\n\n      The UEFI shell can be booted by pressing ESC in OVMF on the TianoCore\n      splash screen, and navigating to Boot Manager | EFI Internal Shell. If\n      the \"survival policy\" was not implemented, the UEFI shell's boot option\n      would always be filtered out.\n\n      The current \"survival policy\" preserves all boot options that start with\n      neither PciRoot() nor HD().\n\n    (e) Translating QEMU's OpenFirmware device paths to UEFI device path\n        prefixes\n\n      In this section we list the (strictly heuristical) mappings currently\n      performed by OVMF.\n\n      The \"prefix only\" nature of the translation output is rooted minimally in\n      the fact that QEMU's OpenFirmware device paths cannot carry pathnames\n      within filesystems. There's no way to specify eg.\n\n        \\EFI\\fedora\\shim.efi\n\n      in an OFW device path, therefore a UEFI device path translated from an\n      OFW device path can at best be a prefix (not a full match) of a UEFI\n      device path that ends with \"\\EFI\\fedora\\shim.efi\".\n\n      - IDE disk, IDE CD-ROM:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/ide@1,1/drive@0/disk@0\n               ^         ^ ^       ^      ^\n               |         | |       |      master or slave\n               |         | |       primary or secondary\n               |         PCI slot \u0026 function holding IDE controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefix:\n\n          PciRoot(0x0)/Pci(0x1,0x1)/Ata(Primary,Master,0x0)\n                                                       ^\n                                                       fixed LUN\n\n      - Floppy disk:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/isa@1/fdc@03f0/floppy@0\n               ^         ^     ^           ^\n               |         |     |           A: or B:\n               |         |     ISA controller io-port (hex)\n               |         PCI slot holding ISA controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefix:\n\n          PciRoot(0x0)/Pci(0x1,0x0)/Floppy(0x0)\n                                           ^\n                                           ACPI UID (A: or B:)\n\n      - Virtio-block disk:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/scsi@6[,3]/disk@0,0\n               ^          ^  ^       ^ ^\n               |          |  |       fixed\n               |          |  PCI function corresponding to disk (optional)\n               |          PCI slot holding disk\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x6,0x0)/HD(\n          PciRoot(0x0)/Pci(0x6,0x3)/HD(\n\n      - Virtio-scsi disk and virtio-scsi passthrough:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/scsi@7[,3]/channel@0/disk@2,3\n               ^          ^             ^      ^ ^\n               |          |             |      | LUN\n               |          |             |      target\n               |          |             channel (unused, fixed 0)\n               |          PCI slot[, function] holding SCSI controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x7,0x0)/Scsi(0x2,0x3)\n          PciRoot(0x0)/Pci(0x7,0x3)/Scsi(0x2,0x3)\n\n      - Emulated and passed-through (physical) network cards:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/ethernet@3[,2]\n               ^              ^\n               |              PCI slot[, function] holding Ethernet card\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x3,0x0)\n          PciRoot(0x0)/Pci(0x3,0x2)\n\nVirtio drivers\n..............\n\nUEFI abstracts various types of hardware resources into protocols, and allows\nfirmware developers to implement those protocols in device drivers. The Virtio\nSpecification defines various types of virtual hardware for virtual machines.\nConnecting the two specifications, OVMF provides UEFI drivers for QEMU's\nvirtio-block, virtio-scsi, and virtio-net devices.\n\nThe following diagram presents the protocol and driver stack related to Virtio\ndevices in edk2 and OVMF. Each node in the graph identifies a protocol and/or\nthe edk2 driver that produces it. Nodes on the top are more abstract.\n\n  EFI_BLOCK_IO_PROTOCOL                             EFI_SIMPLE_NETWORK_PROTOCOL\n  [OvmfPkg/VirtioBlkDxe]                              [OvmfPkg/VirtioNetDxe]\n             |                                                   |\n             |         EFI_EXT_SCSI_PASS_THRU_PROTOCOL           |\n             |             [OvmfPkg/VirtioScsiDxe]               |\n             |                        |                          |\n             +------------------------+--------------------------+\n                                      |\n                           VIRTIO_DEVICE_PROTOCOL\n                                      |\n                +---------------------+---------------------+\n                |                                           |\n  [OvmfPkg/VirtioPciDeviceDxe]                  [custom platform drivers]\n                |                                           |\n                |                                           |\n       EFI_PCI_IO_PROTOCOL                [OvmfPkg/Library/VirtioMmioDeviceLib]\n [MdeModulePkg/Bus/Pci/PciBusDxe]              direct MMIO register access\n\nThe top three drivers produce standard UEFI abstractions: the Block IO\nProtocol, the Extended SCSI Pass Thru Protocol, and the Simple Network\nProtocol, for virtio-block, virtio-scsi, and virtio-net devices, respectively.\n\nComparing these device-specific virtio drivers to each other, we can determine:\n\n- They all conform to the UEFI Driver Model. This means that their entry point\n  functions don't immediately start to search for devices and to drive them,\n  they only register instances of the EFI_DRIVER_BINDING_PROTOCOL. The UEFI\n  Driver Model then enumerates devices and chains matching drivers\n  automatically.\n\n- They are as minimal as possible, while remaining correct (refer to source\n  code comments for details). For example, VirtioBlkDxe and VirtioScsiDxe both\n  support only one request in flight.\n\n  In theory, VirtioBlkDxe could implement EFI_BLOCK_IO2_PROTOCOL, which allows\n  queueing. Similarly, VirtioScsiDxe does not support the non-blocking mode of\n  EFI_EXT_SCSI_PASS_THRU_PROTOCOL.PassThru(). (Which is permitted by the UEFI\n  specification.) Both VirtioBlkDxe and VirtioScsiDxe delegate synchronous\n  request handling to \"OvmfPkg/Library/VirtioLib\". This limitation helps keep\n  the implementation simple, and testing thus far seems to imply satisfactory\n  performance, for a virtual boot firmware.\n\n  VirtioNetDxe cannot avoid queueing, because EFI_SIMPLE_NETWORK_PROTOCOL\n  requires it on the interface level. Consequently, VirtioNetDxe is\n  significantly more complex than VirtioBlkDxe and VirtioScsiDxe. Technical\n  notes are provided in \"OvmfPkg/VirtioNetDxe/TechNotes.txt\".\n\n- None of these drivers access hardware directly. Instead, the Virtio Device\n  Protocol (OvmfPkg/Include/Protocol/VirtioDevice.h) collects / extracts virtio\n  operations defined in the Virtio Specification, and these backend-independent\n  virtio device drivers go through the abstract VIRTIO_DEVICE_PROTOCOL.\n\n  IMPORTANT: the VIRTIO_DEVICE_PROTOCOL is not a standard UEFI protocol. It is\n  internal to edk2 and not described in the UEFI specification. It should only\n  be used by drivers and applications that live inside the edk2 source tree.\n\nCurrently two providers exist for VIRTIO_DEVICE_PROTOCOL:\n\n- The first one is the \"more traditional\" virtio-pci backend, implemented by\n  OvmfPkg/VirtioPciDeviceDxe. This driver also complies with the UEFI Driver\n  Model. It consumes an instance of the EFI_PCI_IO_PROTOCOL, and, if the PCI\n  device/function under probing appears to be a virtio device, it produces a\n  Virtio Device Protocol instance for it. The driver translates abstract virtio\n  operations to PCI accesses.\n\n- The second provider, the virtio-mmio backend, is a library, not a driver,\n  living in OvmfPkg/Library/VirtioMmioDeviceLib. This library translates\n  abstract virtio operations to MMIO accesses.\n\n  The virtio-mmio backend is only a library -- rather than a standalone, UEFI\n  Driver Model-compliant driver -- because the type of resource it consumes, an\n  MMIO register block base address, is not enumerable.\n\n  In other words, while the PCI root bridge driver and the PCI bus driver\n  produce instances of EFI_PCI_IO_PROTOCOL automatically, thereby enabling the\n  UEFI Driver Model to probe devices and stack up drivers automatically, no\n  such enumeration exists for MMIO register blocks.\n\n  For this reason, VirtioMmioDeviceLib needs to be linked into thin, custom\n  platform drivers that dispose over this kind of information. As soon as a\n  driver knows about the MMIO register block base addresses, it can pass each\n  to the library, and then the VIRTIO_DEVICE_PROTOCOL will be instantiated\n  (assuming a valid virtio-mmio register block of course). From that point on\n  the UEFI Driver Model again takes care of the chaining.\n\n  Typically, such a custom driver does not conform to the UEFI Driver Model\n  (because that would presuppose auto-enumeration for MMIO register blocks).\n  Hence it has the following responsibilities:\n\n  - it shall behave as a \"wrapper\" UEFI driver around the library,\n\n  - it shall know virtio-mmio base addresses,\n\n  - in its entry point function, it shall create a new UEFI handle with an\n    instance of the EFI_DEVICE_PATH_PROTOCOL for each virtio-mmio device it\n    knows the base address for,\n\n  - it shall call VirtioMmioInstallDevice() on those handles, with the\n    corresponding base addresses.\n\n  OVMF itself does not employ VirtioMmioDeviceLib. However, the library is used\n  (or has been tested as Proof-of-Concept) in the following 64-bit and 32-bit\n  ARM emulator setups:\n\n  - in \"RTSM_VE_FOUNDATIONV8_EFI.fd\" and \"FVP_AARCH64_EFI.fd\", on ARM Holdings'\n    ARM(R) v8-A Foundation Model and ARM(R) AEMv8-A Base Platform FVP\n    emulators, respectively:\n\n                           EFI_BLOCK_IO_PROTOCOL\n                           [OvmfPkg/VirtioBlkDxe]\n                                      |\n                           VIRTIO_DEVICE_PROTOCOL\n        [ArmPlatformPkg/ArmVExpressPkg/ArmVExpressDxe/ArmFvpDxe.inf]\n                                      |\n                    [OvmfPkg/Library/VirtioMmioDeviceLib]\n                         direct MMIO register access\n\n  - in \"RTSM_VE_CORTEX-A15_EFI.fd\" and \"RTSM_VE_CORTEX-A15_MPCORE_EFI.fd\", on\n    \"qemu-system-arm -M vexpress-a15\":\n\n        EFI_BLOCK_IO_PROTOCOL            EFI_SIMPLE_NETWORK_PROTOCOL\n        [OvmfPkg/VirtioBlkDxe]             [OvmfPkg/VirtioNetDxe]\n                   |                                  |\n                   +------------------+---------------+\n                                      |\n                           VIRTIO_DEVICE_PROTOCOL\n        [ArmPlatformPkg/ArmVExpressPkg/ArmVExpressDxe/ArmFvpDxe.inf]\n                                      |\n                    [OvmfPkg/Library/VirtioMmioDeviceLib]\n                         direct MMIO register access\n\n  In the above ARM / VirtioMmioDeviceLib configurations, VirtioBlkDxe was\n  tested with booting Linux distributions, while VirtioNetDxe was tested with\n  pinging public IPv4 addresses from the UEFI shell.\n\nPlatform Driver\n...............\n\nSometimes, elements of persistent firmware configuration are best exposed to\nthe user in a friendly way. OVMF's platform driver (OvmfPkg/PlatformDxe)\npresents such settings on the \"OVMF Platform Configuration\" dialog:\n\n- Press ESC on the TianoCore splash screen,\n- Navigate to Device Manager | OVMF Platform Configuration.\n\nAt the moment, OVMF's platform driver handles only one setting: the preferred\ngraphics resolution. This is useful for two purposes:\n\n- Some UEFI shell commands, like DRIVERS and DEVICES, benefit from a wide\n  display. Using the MODE shell command, the user can switch to a larger text\n  resolution (limited by the graphics resolution), and see the command output\n  in a more easily consumable way.\n\n  [RHEL] The list of text modes available to the MODE command is also limited\n         by ConSplitterDxe (found under MdeModulePkg/Universal/Console).\n         ConSplitterDxe builds an intersection of text modes that are\n         simultaneously supported by all consoles that ConSplitterDxe\n         multiplexes console output to.\n\n         In practice, the strongest text mode restriction comes from\n         TerminalDxe, which provides console I/O on serial ports. TerminalDxe\n         has a very limited built-in list of text modes, heavily pruning the\n         intersection built by ConSplitterDxe, and made available to the MODE\n         command.\n\n         On the Red Hat Enterprise Linux 7.1 host, TerminalDxe's list of modes\n         has been extended with text resolutions that match the Spice QXL GPU's\n         common graphics resolutions. This way a \"full screen\" text mode should\n         always be available in the MODE command.\n\n- The other advantage of controlling the graphics resolution lies with UEFI\n  operating systems that don't (yet) have a native driver for QEMU's virtual\n  video cards  -- eg. the Spice QXL GPU. Such OSes may choose to inherit the\n  properties of OVMF's EFI_GRAPHICS_OUTPUT_PROTOCOL (provided by\n  OvmfPkg/QemuVideoDxe, see later).\n\n  Although the display can be used at runtime in such cases, by direct\n  framebuffer access, its properties, for example, the resolution, cannot be\n  modified. The platform driver allows the user to select the preferred GOP\n  resolution, reboot, and let the guest OS inherit that preferred resolution.\n\nThe platform driver has three access points: the \"normal\" driver entry point, a\nset of HII callbacks, and a GOP installation callback.\n\n(1) Driver entry point: the PlatformInit() function.\n\n    (a) First, this function loads any available settings, and makes them take\n        effect. For the preferred graphics resolution in particular, this means\n        setting the following PCDs:\n\n          gEfiMdeModulePkgTokenSpaceGuid.PcdVideoHorizontalResolution\n          gEfiMdeModulePkgTokenSpaceGuid.PcdVideoVerticalResolution\n\n        These PCDs influence the GraphicsConsoleDxe driver (located under\n        MdeModulePkg/Universal/Console), which switches to the preferred\n        graphics mode, and produces EFI_SIMPLE_TEXT_OUTPUT_PROTOCOLs on GOPs:\n\n                    EFI_SIMPLE_TEXT_OUTPUT_PROTOCOL\n          [MdeModulePkg/Universal/Console/GraphicsConsoleDxe]\n                                   |\n                      EFI_GRAPHICS_OUTPUT_PROTOCOL\n                         [OvmfPkg/QemuVideoDxe]\n                                   |\n                          EFI_PCI_IO_PROTOCOL\n                   [MdeModulePkg/Bus/Pci/PciBusDxe]\n\n  (b) Second, the driver entry point registers the user interface, including\n      HII callbacks.\n\n  (c) Third, the driver entry point registers a GOP installation callback.\n\n(2) HII callbacks and the user interface.\n\n    The Human Interface Infrastructure (HII) \"is a set of protocols that allow\n    a UEFI driver to provide the ability to register user interface and\n    configuration content with the platform firmware\".\n\n    OVMF's platform driver:\n\n    - provides a static, basic, visual form (PlatformForms.vfr), written in the\n      Visual Forms Representation language,\n\n    - includes a UCS-16 encoded message catalog (Platform.uni),\n\n    - includes source code that dynamically populates parts of the form, with\n      the help of MdeModulePkg/Library/UefiHiiLib -- this library simplifies\n      the handling of IFR (Internal Forms Representation) opcodes,\n\n    - processes form actions that the user takes (Callback() function),\n\n    - loads and saves platform configuration in a private, non-volatile\n      variable (ExtractConfig() and RouteConfig() functions).\n\n    The ExtractConfig() HII callback implements the following stack of\n    conversions, for loading configuration and presenting it to the user:\n\n          MultiConfigAltResp       -- form engine / HII communication\n                  ^\n                  |\n           [BlockToConfig]\n                  |\n           MAIN_FORM_STATE         -- binary representation of form/widget\n                  ^                   state\n                  |\n      [PlatformConfigToFormState]\n                  |\n           PLATFORM_CONFIG         -- accessible to DXE and UEFI drivers\n                  ^\n                  |\n         [PlatformConfigLoad]\n                  |\n        UEFI non-volatile variable -- accessible to external utilities\n\n    The layers are very similar for the reverse direction, ie. when taking\n    input from the user, and saving the configuration (RouteConfig() HII\n    callback):\n\n             ConfigResp            -- form engine / HII communication\n                  |\n           [ConfigToBlock]\n                  |\n                  v\n           MAIN_FORM_STATE         -- binary representation of form/widget\n                  |                   state\n      [FormStateToPlatformConfig]\n                  |\n                  v\n           PLATFORM_CONFIG         -- accessible to DXE and UEFI drivers\n                  |\n         [PlatformConfigSave]\n                  |\n                  v\n        UEFI non-volatile variable -- accessible to external utilities\n\n(3) When the platform driver starts, a GOP may not be available yet. Thus the\n    driver entry point registers a callback (the GopInstalled() function) for\n    GOP installations.\n\n    When the first GOP is produced (usually by QemuVideoDxe, or potentially by\n    a third party video driver), PlatformDxe retrieves the list of graphics\n    modes the GOP supports, and dynamically populates the drop-down list of\n    available resolutions on the form. The GOP installation callback is then\n    removed.\n\nVideo driver\n............\n\nOvmfPkg/QemuVideoDxe is OVMF's built-in video driver. We can divide its\nservices in two parts: graphics output protocol (primary), and Int10h (VBE)\nshim (secondary).\n\n(1) QemuVideoDxe conforms to the UEFI Driver Model; it produces an instance of\n    the EFI_GRAPHICS_OUTPUT_PROTOCOL (GOP) on each PCI display that it supports\n    and is connected to:\n\n                      EFI_GRAPHICS_OUTPUT_PROTOCOL\n                         [OvmfPkg/QemuVideoDxe]\n                                   |\n                          EFI_PCI_IO_PROTOCOL\n                   [MdeModulePkg/Bus/Pci/PciBusDxe]\n\n    It supports the following QEMU video cards:\n\n    - Cirrus 5430 (\"-device cirrus-vga\"),\n    - Standard VGA (\"-device VGA\"),\n    - QXL VGA (\"-device qxl-vga\", \"-device qxl\").\n\n    For Cirrus the following resolutions and color depths are available:\n    640x480x32, 800x600x32, 1024x768x24. On stdvga and QXL a long list of\n    resolutions is available. The list is filtered against the frame buffer\n    size during initialization.\n\n    The size of the QXL VGA compatibility framebuffer can be changed with the\n\n      -device qxl-vga,vgamem_mb=$NUM_MB\n\n    QEMU option. If $NUM_MB exceeds 32, then the following is necessary\n    instead:\n\n      -device qxl-vga,vgamem_mb=$NUM_MB,ram_size_mb=$((NUM_MB*2))\n\n    because the compatibility framebuffer can't cover more than half of PCI BAR\n    #0. The latter defaults to 64MB in size, and is controlled by the\n    \"ram_size_mb\" property.\n\n(2) When QemuVideoDxe binds the first Standard VGA or QXL VGA device, and there\n    is no real VGA BIOS present in the C to F segments (which could originate\n    from a legacy PCI option ROM -- refer to \"Compatibility Support Module\n    (CSM)\"), then QemuVideoDxe installs a minimal, \"fake\" VGA BIOS -- an Int10h\n    (VBE) \"shim\".\n\n    The shim is implemented in 16-bit assembly in\n    \"OvmfPkg/QemuVideoDxe/VbeShim.asm\". The \"VbeShim.sh\" shell script assembles\n    it and formats it as a C array (\"VbeShim.h\") with the help of the \"nasm\"\n    utility. The driver's InstallVbeShim() function copies the shim in place\n    (the C segment), and fills in the VBE Info and VBE Mode Info structures.\n    The real-mode 10h interrupt vector is pointed to the shim's handler.\n\n    The shim is (correctly) irrelevant and invisible for all UEFI operating\n    systems we know about -- except Windows Server 2008 R2 and other Windows\n    operating systems in that family.\n\n    Namely, the Windows 2008 R2 SP1 (and Windows 7) UEFI guest's default video\n    driver dereferences the real mode Int10h vector, loads the pointed-to\n    handler code, and executes what it thinks to be VGA BIOS services in an\n    internal real-mode emulator. Consequently, video mode switching used not to\n    work in Windows 2008 R2 SP1 when it ran on the \"pure UEFI\" build of OVMF,\n    making the guest uninstallable. Hence the (otherwise optional, non-default)\n    Compatibility Support Module (CSM) ended up a requirement for running such\n    guests.\n\n    The hard dependency on the sophisticated SeaBIOS CSM and the complex\n    supporting edk2 infrastructure, for enabling this family of guests, was\n    considered suboptimal by some members of the upstream community,\n\n    [RHEL] and was certainly considered a serious maintenance disadvantage for\n           Red Hat Enterprise Linux 7.1 hosts.\n\n    Thus, the shim has been collaboratively developed for the Windows 7 /\n    Windows Server 2008 R2 family. The shim provides a real stdvga / QXL\n    implementation for the few services that are in fact necessary for the\n    Windows 2008 R2 SP1 (and Windows 7) UEFI guest, plus some \"fakes\" that the\n    guest invokes but whose effect is not important. The only supported mode is\n    1024x768x32, which is enough to install the guest and then upgrade its\n    video driver to the full-featured QXL XDDM one.\n\n    The C segment is not present in the UEFI memory map prepared by OVMF.\n    Memory space that would cover it is never added (either in PEI, in the form\n    of memory resource descriptor HOBs, or in DXE, via gDS-\u003eAddMemorySpace()).\n    This way the handler body is invisible to all other UEFI guests, and the\n    rest of edk2.\n\n    The Int10h real-mode IVT entry is covered with a Boot Services Code page,\n    making that too inaccessible to the rest of edk2. Due to the allocation\n    type, UEFI guest OSes different from the Windows Server 2008 family can\n    reclaim the page at zero. (The Windows 2008 family accesses that page\n    regardless of the allocation type.)\n\nAfterword\n---------\n\nAfter the bulk of this document was written in July 2014, OVMF development has\nnot stopped. To name two significant code contributions from the community: in\nJanuary 2015, OVMF runs on the \"q35\" machine type of QEMU, and it features a\ndriver for Xen paravirtual block devices (and another for the underlying Xen\nbus).\n\nFurthermore, a dedicated virtualization platform has been contributed to\nArmPlatformPkg that plays a role parallel to OvmfPkg's. It targets the \"virt\"\nmachine type of qemu-system-arm and qemu-system-aarch64. Parts of OvmfPkg are\nbeing refactored and modularized so they can be reused in\n\"ArmPlatformPkg/ArmVirtualizationPkg/ArmVirtualizationQemu.dsc\".","snippets":["#uefi #archive"],"rawContent":"# OVMF Whitepaper\n#uefi #archive\n\nI'm making a copy here since this is entirely in text format.\n\n----------------\n\nOpen Virtual Machine Firmware (OVMF) Status Report\nJuly 2014 (with updates in August 2014 - January 2015)\n\nAuthor: Laszlo Ersek \u003clersek@redhat.com\u003e\nCopyright (C) 2014-2015, Red Hat, Inc.\nCC BY-SA 4.0 \u003chttp://creativecommons.org/licenses/by-sa/4.0/\u003e\n\nAbstract\n--------\n\nThe Unified Extensible Firmware Interface (UEFI) is a specification that\ndefines a software interface between an operating system and platform firmware.\nUEFI is designed to replace the Basic Input/Output System (BIOS) firmware\ninterface.\n\nHardware platform vendors have been increasingly adopting the UEFI\nSpecification to govern their boot firmware developments. OVMF (Open Virtual\nMachine Firmware), a sub-project of Intel's EFI Development Kit II (edk2),\nenables UEFI support for Ia32 and X64 Virtual Machines.\n\nThis paper reports on the status of the OVMF project, treats features and\nlimitations, gives end-user hints, and examines some areas in-depth.\n\nKeywords: ACPI, boot options, CSM, edk2, firmware, flash, fw_cfg, KVM, memory\nmap, non-volatile variables, OVMF, PCD, QEMU, reset vector, S3, Secure Boot,\nSmbios, SMM, TianoCore, UEFI, VBE shim, Virtio\n\nTable of Contents\n-----------------\n\n- Motivation\n- Scope\n- Example qemu invocation\n- Installation of OVMF guests with virt-manager and virt-install\n- Supported guest operating systems\n- Compatibility Support Module (CSM)\n- Phases of the boot process\n- Project structure\n- Platform Configuration Database (PCD)\n- Firmware image structure\n- S3 (suspend to RAM and resume)\n- A comprehensive memory map of OVMF\n- Known Secure Boot limitations\n- Variable store and LockBox in SMRAM\n- Select features\n  - X64-specific reset vector for OVMF\n  - Client library for QEMU's firmware configuration interface\n  - Guest ACPI tables\n  - Guest SMBIOS tables\n  - Platform-specific boot policy\n  - Virtio drivers\n  - Platform Driver\n  - Video driver\n- Afterword\n\nMotivation\n----------\n\nOVMF extends the usual benefits of virtualization to UEFI. Reasons to use OVMF\ninclude:\n\n- Legacy-free guests. A UEFI-based environment eliminates dependencies on\n  legacy address spaces and devices. This is especially beneficial when used\n  with physically assigned devices where the legacy operating mode is\n  troublesome to support, ex. assigned graphics cards operating in legacy-free,\n  non-VGA mode in the guest.\n\n- Future proof guests. The x86 market is steadily moving towards a legacy-free\n  platform and guest operating systems may eventually require a UEFI\n  environment. OVMF provides that next generation firmware support for such\n  applications.\n\n- GUID partition tables (GPTs). MBR partition tables represent partition\n  offsets and sizes with 32-bit integers, in units of 512 byte sectors. This\n  limits the addressable portion of the disk to 2 TB. GPT represents logical\n  block addresses with 64 bits.\n\n- Liberating boot loader binaries from residing in contested and poorly defined\n  space between the partition table and the partitions.\n\n- Support for booting off disks (eg. pass-through physical SCSI devices) with a\n  4kB physical and logical sector size, i.e. which don't have 512-byte block\n  emulation.\n\n- Development and testing of Secure Boot-related features in guest operating\n  systems. Although OVMF's Secure Boot implementation is currently not secure\n  against malicious UEFI drivers, UEFI applications, and guest kernels,\n  trusted guest code that only uses standard UEFI interfaces will find a valid\n  Secure Boot environment under OVMF, with working key enrollment and signature\n  validation. This enables development and testing of portable, Secure\n  Boot-related guest code.\n\n- Presence of non-volatile UEFI variables. This furthers development and\n  testing of OS installers, UEFI boot loaders, and unique, dependent guest OS\n  features. For example, an efivars-backed pstore (persistent storage)\n  file system works under Linux.\n\n- Altogether, a near production-level UEFI environment for virtual machines\n  when Secure Boot is not required.\n\nScope\n-----\n\nUEFI and especially Secure Boot have been topics fraught with controversy and\npolitical activism. This paper sidesteps these aspects and strives to focus on\nuse cases, hands-on information for end users, and technical details.\n\nUnless stated otherwise, the expression \"X supports Y\" means \"X is technically\ncompatible with interfaces provided or required by Y\". It does not imply\nsupport as an activity performed by natural persons or companies.\n\nWe discuss the status of OVMF at a state no earlier than edk2 SVN revision\n16158. The paper concentrates on upstream projects and communities, but\noccasionally it pans out about OVMF as it is planned to be shipped (as\nTechnical Preview) in Red Hat Enterprise Linux 7.1. Such digressions are marked\nwith the [RHEL] margin notation.\n\nAlthough other VMMs and accelerators are known to support (or plan to support)\nOVMF to various degrees -- for example, VirtualBox, Xen, BHyVe --, we'll\nemphasize OVMF on qemu/KVM, because QEMU and KVM have always been Red Hat's\nfocus wrt. OVMF.\n\nThe recommended upstream QEMU version is 2.1+. The recommended host Linux\nkernel (KVM) version is 3.10+. The recommended QEMU machine type is\n\"qemu-system-x86_64 -M pc-i440fx-2.1\" or later.\n\nThe term \"TianoCore\" is used interchangeably with \"edk2\" in this paper.\n\nExample qemu invocation\n-----------------------\n\nThe following commands give a quick foretaste of installing a UEFI operating\nsystem on OVMF, relying only on upstream edk2 and qemu.\n\n- Clone and build OVMF:\n\n  git clone https://github.com/tianocore/edk2.git\n  cd edk2\n  nice OvmfPkg/build.sh -a X64 -n $(getconf _NPROCESSORS_ONLN)\n\n  (Note that this ad-hoc build will not include the Secure Boot feature.)\n\n- The build output file, \"OVMF.fd\", includes not only the executable firmware\n  code, but the non-volatile variable store as well. For this reason, make a\n  VM-specific copy of the build output (the variable store should be private to\n  the virtual machine):\n\n  cp Build/OvmfX64/DEBUG_GCC4?/FV/OVMF.fd fedora.flash\n\n  (The variable store and the firmware executable are also available in the\n  build output as separate files: \"OVMF_VARS.fd\" and \"OVMF_CODE.fd\". This\n  enables central management and updates of the firmware executable, while each\n  virtual machine can retain its own variable store.)\n\n- Download a Fedora LiveCD:\n\n  wget https://dl.fedoraproject.org/pub/fedora/linux/releases/20/Live/x86_64/Fedora-Live-Xfce-x86_64-20-1.iso\n\n- Create a virtual disk (qcow2 format, 20 GB in size):\n\n  qemu-img create -f qcow2 fedora.img 20G\n\n- Create the following qemu wrapper script under the name \"fedora.sh\":\n\n  # Basic virtual machine properties: a recent i440fx machine type, KVM\n  # acceleration, 2048 MB RAM, two VCPUs.\n  OPTS=\"-M pc-i440fx-2.1 -enable-kvm -m 2048 -smp 2\"\n\n  # The OVMF binary, including the non-volatile variable store, appears as a\n  # \"normal\" qemu drive on the host side, and it is exposed to the guest as a\n  # persistent flash device.\n  OPTS=\"$OPTS -drive if=pflash,format=raw,file=fedora.flash\"\n\n  # The hard disk is exposed to the guest as a virtio-block device. OVMF has a\n  # driver stack that supports such a disk. We specify this disk as first boot\n  # option. OVMF recognizes the boot order specification.\n  OPTS=\"$OPTS -drive id=disk0,if=none,format=qcow2,file=fedora.img\"\n  OPTS=\"$OPTS -device virtio-blk-pci,drive=disk0,bootindex=0\"\n\n  # The Fedora installer disk appears as an IDE CD-ROM in the guest. This is\n  # the 2nd boot option.\n  OPTS=\"$OPTS -drive id=cd0,if=none,format=raw,readonly\"\n  OPTS=\"$OPTS,file=Fedora-Live-Xfce-x86_64-20-1.iso\"\n  OPTS=\"$OPTS -device ide-cd,bus=ide.1,drive=cd0,bootindex=1\"\n\n  # The following setting enables S3 (suspend to RAM). OVMF supports S3\n  # suspend/resume.\n  OPTS=\"$OPTS -global PIIX4_PM.disable_s3=0\"\n\n  # OVMF emits a number of info / debug messages to the QEMU debug console, at\n  # ioport 0x402. We configure qemu so that the debug console is indeed\n  # available at that ioport. We redirect the host side of the debug console to\n  # a file.\n  OPTS=\"$OPTS -global isa-debugcon.iobase=0x402 -debugcon file:fedora.ovmf.log\"\n\n  # QEMU accepts various commands and queries from the user on the monitor\n  # interface. Connect the monitor with the qemu process's standard input and\n  # output.\n  OPTS=\"$OPTS -monitor stdio\"\n\n  # A USB tablet device in the guest allows for accurate pointer tracking\n  # between the host and the guest.\n  OPTS=\"$OPTS -device piix3-usb-uhci -device usb-tablet\"\n\n  # Provide the guest with a virtual network card (virtio-net).\n  #\n  # Normally, qemu provides the guest with a UEFI-conformant network driver\n  # from the iPXE project, in the form of a PCI expansion ROM. For this test,\n  # we disable the expansion ROM and allow OVMF's built-in virtio-net driver to\n  # take effect.\n  #\n  # On the host side, we use the SLIRP (\"user\") network backend, which has\n  # relatively low performance, but it doesn't require extra privileges from\n  # the user executing qemu.\n  OPTS=\"$OPTS -netdev id=net0,type=user\"\n  OPTS=\"$OPTS -device virtio-net-pci,netdev=net0,romfile=\"\n\n  # A Spice QXL GPU is recommended as the primary VGA-compatible display\n  # device. It is a full-featured virtual video card, with great operating\n  # system driver support. OVMF supports it too.\n  OPTS=\"$OPTS -device qxl-vga\"\n\n  qemu-system-x86_64 $OPTS\n\n- Start the Fedora guest:\n\n  sh fedora.sh\n\n- The above command can be used for both installation and later boots of the\n  Fedora guest.\n\n- In order to verify basic OVMF network connectivity:\n\n  - Assuming that the non-privileged user running qemu belongs to group G\n    (where G is a numeric identifier), ensure as root on the host that the\n    group range in file \"/proc/sys/net/ipv4/ping_group_range\" includes G.\n\n  - As the non-privileged user, boot the guest as usual.\n\n  - On the TianoCore splash screen, press ESC.\n\n  - Navigate to Boot Manager | EFI Internal Shell\n\n  - In the UEFI Shell, issue the following commands:\n\n    ifconfig -s eth0 dhcp\n    ping A.B.C.D\n\n    where A.B.C.D is a public IPv4 address in dotted decimal notation that your\n    host can reach.\n\n  - Type \"quit\" at the (qemu) monitor prompt.\n\nInstallation of OVMF guests with virt-manager and virt-install\n--------------------------------------------------------------\n\n(1) Assuming OVMF has been installed on the host with the following files:\n    - /usr/share/OVMF/OVMF_CODE.fd\n    - /usr/share/OVMF/OVMF_VARS.fd\n\n    locate the \"nvram\" stanza in \"/etc/libvirt/qemu.conf\", and edit it as\n    follows:\n\n    nvram = [ \"/usr/share/OVMF/OVMF_CODE.fd:/usr/share/OVMF/OVMF_VARS.fd\" ]\n\n(2) Restart libvirtd with your Linux distribution's service management tool;\n    for example,\n\n    systemctl restart libvirtd\n\n(3) In virt-manager, proceed with the guest installation as usual:\n    - select File | New Virtual Machine,\n    - advance to Step 5 of 5,\n    - in Step 5, check \"Customize configuration before install\",\n    - click Finish;\n    - in the customization dialog, select Overview | Firmware, and choose UEFI,\n    - click Apply and Begin Installation.\n\n(4) With virt-install:\n\n    LDR=\"loader=/usr/share/OVMF/OVMF_CODE.fd,loader_ro=yes,loader_type=pflash\"\n    virt-install \\\n      --name fedora20 \\\n      --memory 2048 \\\n      --vcpus 2 \\\n      --os-variant fedora20 \\\n      --boot hd,cdrom,$LDR \\\n      --disk size=20 \\\n      --disk path=Fedora-Live-Xfce-x86_64-20-1.iso,device=cdrom,bus=scsi\n\n(5) A popular, distribution-independent, bleeding-edge OVMF package is\n    available under \u003chttps://www.kraxel.org/repos/\u003e, courtesy of Gerd Hoffmann.\n\n    The \"edk2.git-ovmf-x64\" package provides the following files, among others:\n    - /usr/share/edk2.git/ovmf-x64/OVMF_CODE-pure-efi.fd\n    - /usr/share/edk2.git/ovmf-x64/OVMF_VARS-pure-efi.fd\n\n    When using this package, adapt steps (1) and (4) accordingly.\n\n(6) Additionally, the \"edk2.git-ovmf-x64\" package seeks to simplify the\n    enablement of Secure Boot in a virtual machine (strictly for development\n    and testing purposes).\n\n    - Boot the virtual machine off the CD-ROM image called\n      \"/usr/share/edk2.git/ovmf-x64/UefiShell.iso\"; before or after installing\n      the main guest operating system.\n\n    - When the UEFI shell appears, issue the following commands:\n\n      EnrollDefaultKeys.efi\n      reset -s\n\n    - The EnrollDefaultKeys.efi utility enrolls the following keys:\n\n      - A static example X.509 certificate (CN=TestCommonName) as Platform Key\n        and first Key Exchange Key.\n\n        The private key matching this certificate has been destroyed (but you\n        shouldn't trust this statement).\n\n      - \"Microsoft Corporation KEK CA 2011\" as second Key Exchange Key\n        (SHA1: 31:59:0b:fd:89:c9:d7:4e:d0:87:df:ac:66:33:4b:39:31:25:4b:30).\n\n      - \"Microsoft Windows Production PCA 2011\" as first DB entry\n        (SHA1: 58:0a:6f:4c:c4:e4:b6:69:b9:eb:dc:1b:2b:3e:08:7b:80:d0:67:8d).\n\n      - \"Microsoft Corporation UEFI CA 2011\" as second DB entry\n        (SHA1: 46:de:f6:3b:5c:e6:1c:f8:ba:0d:e2:e6:63:9c:10:19:d0:ed:14:f3).\n\n      These keys suffice to boot released versions of popular Linux\n      distributions (through the shim.efi utility), and Windows 8 and Windows\n      Server 2012 R2, in Secure Boot mode.\n\nSupported guest operating systems\n---------------------------------\n\nUpstream OVMF does not favor some guest operating systems over others for\npolitical or ideological reasons. However, some operating systems are harder to\nobtain and/or technically more difficult to support. The general expectation is\nthat recent UEFI OSes should just work. Please consult the \"OvmfPkg/README\"\nfile.\n\nThe following guest OSes were tested with OVMF:\n- Red Hat Enterprise Linux 6\n- Red Hat Enterprise Linux 7\n- Fedora 18\n- Fedora 19\n- Fedora 20\n- Windows Server 2008 R2 SP1\n- Windows Server 2012\n- Windows 8\n\nNotes about Windows Server 2008 R2 (paraphrasing the \"OvmfPkg/README\" file):\n\n- QEMU should be started with one of the \"-device qxl-vga\" and \"-device VGA\"\n  options.\n\n- Only one video mode, 1024x768x32, is supported at OS runtime.\n\n  Please refer to the section about QemuVideoDxe (OVMF's built-in video driver)\n  for more details on this limitation.\n\n- The qxl-vga video card is recommended (\"-device qxl-vga\"). After booting the\n  installed guest OS, select the video card in Device Manager, and upgrade the\n  video driver to the QXL XDDM one.\n\n  The QXL XDDM driver can be downloaded from\n  \u003chttp://www.spice-space.org/download.html\u003e, under Guest | Windows binaries.\n\n  This driver enables additional graphics resolutions at OS runtime, and\n  provides S3 (suspend/resume) capability.\n\nNotes about Windows Server 2012 and Windows 8:\n\n- QEMU should be started with the \"-device qxl-vga,revision=4\" option (or a\n  later revision, if available).\n\n- The guest OS's builtin video driver inherits the video mode / frame buffer\n  from OVMF. There's no way to change the resolution at OS runtime.\n\n  For this reason, a platform driver has been developed for OVMF, which allows\n  users to change the preferred video mode in the firmware. Please refer to the\n  section about PlatformDxe for details.\n\n- It is recommended to upgrade the guest OS's video driver to the QXL WDDM one,\n  via Device Manager.\n\n  Binaries for the QXL WDDM driver can be found at\n  \u003chttp://people.redhat.com/~vrozenfe/qxlwddm\u003e (pick a version greater than or\n  equal to 0.6), while the source code resides at\n  \u003chttps://github.com/vrozenfe/qxl-dod\u003e.\n\n  This driver enables additional graphics resolutions at OS runtime, and\n  provides S3 (suspend/resume) capability.\n\nCompatibility Support Module (CSM)\n----------------------------------\n\nCollaboration between SeaBIOS and OVMF developers has enabled SeaBIOS to be\nbuilt as a Compatibility Support Module, and OVMF to embed and use it.\n\nBenefits of a SeaBIOS CSM include:\n\n- The ability to boot legacy (non-UEFI) operating systems, such as legacy Linux\n  systems, Windows 7, OpenBSD 5.2, FreeBSD 8/9, NetBSD, DragonflyBSD, Solaris\n  10/11.\n\n- Legacy (non-UEFI-compliant) PCI expansion ROMs, such as a VGA BIOS, mapped by\n  QEMU in emulated devices' ROM BARs, are loaded and executed by OVMF.\n\n  For example, this grants the Windows Server 2008 R2 SP1 guest's native,\n  legacy video driver access to all modes of all QEMU video cards.\n\nBuilding the CSM target of the SeaBIOS source tree is out of scope for this\nreport. Additionally, upstream OVMF does not enable the CSM by default.\n\nInterested users and developers should look for OVMF's \"-D CSM_ENABLE\"\nbuild-time option, and check out the \u003chttps://www.kraxel.org/repos/\u003e continuous\nintegration repository, which provides CSM-enabled OVMF builds.\n\n[RHEL] The \"OVMF_CODE.fd\" firmware image made available on the Red Hat\n       Enterprise Linux 7.1 host does not include a Compatibility Support\n       Module, for the following reasons:\n\n       - Virtual machines running officially supported, legacy guest operating\n         systems should just use the standalone SeaBIOS firmware. Firmware\n         selection is flexible in virtualization, see eg. \"Installation of OVMF\n         guests with virt-manager and virt-install\" above.\n\n       - The 16-bit thunking interface between OVMF and SeaBIOS is very complex\n         and presents a large debugging and support burden, based on past\n         experience.\n\n       - Secure Boot is incompatible with CSM.\n\n       - Inter-project dependencies should be minimized whenever possible.\n\n       - Using the default QXL video card, the Windows 2008 R2 SP1 guest can be\n         installed with its built-in, legacy video driver. Said driver will\n         select the only available video mode, 1024x768x32. After installation,\n         the video driver can be upgraded to the full-featured QXL XDDM driver.\n\nPhases of the boot process\n--------------------------\n\nThe PI and UEFI specifications, and Intel's UEFI and EDK II Learning and\nDevelopment materials provide ample information on PI and UEFI concepts. The\nfollowing is an absolutely minimal, rough glossary that is included only to\nhelp readers new to PI and UEFI understand references in later, OVMF-specific\nsections. We defer heavily to the official specifications and the training\nmaterials, and frequently quote them below.\n\nA central concept to mention early is the GUID -- globally unique identifier. A\nGUID is a 128-bit number, written as XXXXXXXX-XXXX-XXXX-XXXX-XXXXXXXXXXXX,\nwhere each X stands for a hexadecimal nibble. GUIDs are used to name everything\nin PI and in UEFI. Programmers introduce new GUIDs with the \"uuidgen\" utility,\nand standards bodies standardize well-known services by positing their GUIDs.\n\nThe boot process is roughly divided in the following phases:\n\n- Reset vector code.\n\n- SEC: Security phase. This phase is the root of firmware integrity.\n\n- PEI: Pre-EFI Initialization. This phase performs \"minimal processor, chipset\n  and platform configuration for the purpose of discovering memory\". Modules in\n  PEI collectively save their findings about the platform in a list of HOBs\n  (hand-off blocks).\n\n  When developing PEI code, the Platform Initialization (PI) specification\n  should be consulted.\n\n- DXE: Driver eXecution Environment, pronounced as \"Dixie\". This \"is the phase\n  where the bulk of the booting occurs: devices are enumerated and initialized,\n  UEFI services are supported, and protocols and drivers are implemented. Also,\n  the tables that create the UEFI interface are produced\".\n\n  On the PEI/DXE boundary, the HOBs produced by PEI are consumed. For example,\n  this is how the memory space map is configured initially.\n\n- BDS: Boot Device Selection. It is \"responsible for determining how and where\n  you want to boot the operating system\".\n\n  When developing DXE and BDS code, it is mainly the UEFI specification that\n  should be consulted. When speaking about DXE, BDS is frequently considered to\n  be a part of it.\n\nThe following concepts are tied to specific boot process phases:\n\n- PEIM: a PEI Module (pronounced \"PIM\"). A binary module running in the PEI\n  phase, consuming some PPIs and producing other PPIs, and producing HOBs.\n\n- PPI: PEIM-to-PEIM interface. A structure of function pointers and related\n  data members that establishes a PEI service, or an instance of a PEI service.\n  PPIs are identified by GUID.\n\n  An example is EFI_PEI_S3_RESUME2_PPI (6D582DBC-DB85-4514-8FCC-5ADF6227B147).\n\n- DXE driver: a binary module running in the DXE and BDS phases, consuming some\n  protocols and producing other protocols.\n\n- Protocol: A structure of function pointers and related data members that\n  establishes a DXE service, or an instance of a DXE service. Protocols are\n  identified by GUID.\n\n  An example is EFI_BLOCK_IO_PROTOCOL (964E5B21-6459-11D2-8E39-00A0C969723B).\n\n- Architectural protocols: a set of standard protocols that are foundational to\n  the working of a UEFI system. Each architectural protocol has at most one\n  instance. Architectural protocols are implemented by a subset of DXE drivers.\n  DXE drivers explicitly list the set of protocols (including architectural\n  protocols) that they need to work. UEFI drivers can only be loaded once all\n  architectural protocols have become available during the DXE phase.\n\n  An example is EFI_VARIABLE_WRITE_ARCH_PROTOCOL\n  (6441F818-6362-4E44-B570-7DBA31DD2453).\n\nProject structure\n-----------------\n\nThe term \"OVMF\" usually denotes the project (community and development effort)\nthat provide and maintain the subject matter UEFI firmware for virtual\nmachines. However the term is also frequently applied to the firmware binary\nproper that a virtual machine executes.\n\nOVMF emerges as a compilation of several modules from the edk2 source\nrepository. \"edk2\" stands for EFI Development Kit II; it is a \"modern,\nfeature-rich, cross-platform firmware development environment for the UEFI and\nPI specifications\".\n\nThe composition of OVMF is dictated by the following build control files:\n\n  OvmfPkg/OvmfPkgIa32.dsc\n  OvmfPkg/OvmfPkgIa32.fdf\n\n  OvmfPkg/OvmfPkgIa32X64.dsc\n  OvmfPkg/OvmfPkgIa32X64.fdf\n\n  OvmfPkg/OvmfPkgX64.dsc\n  OvmfPkg/OvmfPkgX64.fdf\n\nThe format of these files is described in the edk2 DSC and FDF specifications.\nRoughly, the DSC file determines:\n- library instance resolutions for library class requirements presented by the\n  modules to be compiled,\n- the set of modules to compile.\n\nThe FDF file roughly determines:\n- what binary modules (compilation output files, precompiled binaries, graphics\n  image files, verbatim binary sections) to include in the firmware image,\n- how to lay out the firmware image.\n\nThe Ia32 flavor of these files builds a firmware where both PEI and DXE phases\nare 32-bit. The Ia32X64 flavor builds a firmware where the PEI phase consists\nof 32-bit modules, and the DXE phase is 64-bit. The X64 flavor builds a purely\n64-bit firmware.\n\nThe word size of the DXE phase must match the word size of the runtime OS -- a\n32-bit DXE can't cooperate with a 64-bit OS, and a 64-bit DXE can't work a\n32-bit OS.\n\nOVMF pulls together modules from across the edk2 tree. For example:\n\n- common drivers and libraries that are platform independent are usually\n  located under MdeModulePkg and MdePkg,\n\n- common but hardware-specific drivers and libraries that match QEMU's\n  pc-i440fx-* machine type are pulled in from IntelFrameworkModulePkg,\n  PcAtChipsetPkg and UefiCpuPkg,\n\n- the platform independent UEFI Shell is built from ShellPkg,\n\n- OvmfPkg includes drivers and libraries that are useful for virtual machines\n  and may or may not be specific to QEMU's pc-i440fx-* machine type.\n\nPlatform Configuration Database (PCD)\n-------------------------------------\n\nLike the \"Phases of the boot process\" section, this one introduces a concept in\nvery raw form. We defer to the PCD related edk2 specifications, and we won't\ndiscuss implementation details here. Our purpose is only to offer the reader a\nusable (albeit possibly inaccurate) definition, so that we can refer to PCDs\nlater on.\n\nColloquially, when we say \"PCD\", we actually mean \"PCD entry\"; that is, an\nentry stored in the Platform Configuration Database.\n\nThe Platform Configuration Database is\n- a firmware-wide\n- name-value store\n- of scalars and buffers\n- where each entry may be\n  - build-time constant, or\n  - run-time dynamic, or\n  - theoretically, a middle option: patchable in the firmware file itself,\n    using a dedicated tool. (OVMF does not utilize externally patchable\n    entries.)\n\nA PCD entry is declared in the DEC file of the edk2 top-level Package directory\nwhose modules (drivers and libraries) are the primary consumers of the PCD\nentry. (See for example OvmfPkg/OvmfPkg.dec). Basically, a PCD in a DEC file\nexposes a simple customization point.\n\nInterest in a PCD entry is communicated to the build system by naming the PCD\nentry in the INF file of the interested module (application, driver or\nlibrary). The module may read and -- dependent on the PCD entry's category --\nwrite the PCD entry.\n\nLet's investigate the characteristics of the Database and the PCD entries.\n\n- Firmware-wide: technically, all modules may access all entries they are\n  interested in, assuming they advertise their interest in their INF files.\n  With careful design, PCDs enable inter-driver propagation of (simple) system\n  configuration. PCDs are available in both PEI and DXE.\n\n  (UEFI drivers meant to be portable (ie. from third party vendors) are not\n  supposed to use PCDs, since PCDs qualify internal to the specific edk2\n  firmware in question.)\n\n- Name-value store of scalars and buffers: each PCD has a symbolic name, and a\n  fixed scalar type (UINT16, UINT32 etc), or VOID* for buffers. Each PCD entry\n  belongs to a namespace, where a namespace is (obviously) a GUID, defined in\n  the DEC file.\n\n- A DEC file can permit several categories for a PCD:\n  - build-time constant (\"FixedAtBuild\"),\n  - patchable in the firmware image (\"PatchableInModule\", unused in OVMF),\n  - runtime modifiable (\"Dynamic\").\n\nThe platform description file (DSC) of a top-level Package directory may choose\nthe exact category for a given PCD entry that its modules wish to use, and\nassign a default (or constant) initial value to it.\n\nIn addition, the edk2 build system too can initialize PCD entries to values\nthat it calculates while laying out the flash device image. Such PCD\nassignments are described in the FDF control file.\n\nFirmware image structure\n------------------------\n\n(We assume the common X64 choice for both PEI and DXE, and the default DEBUG\nbuild target.)\n\nThe OvmfPkg/OvmfPkgX64.fdf file defines the following layout for the flash\ndevice image \"OVMF.fd\":\n\n  Description                     Compression type        Size\n  ------------------------------  ----------------------  -------\n  Non-volatile data storage       open-coded binary data   128 KB\n    Variable store                                          56 KB\n    Event log                                                4 KB\n    Working block                                            4 KB\n    Spare area                                              64 KB\n\n  FVMAIN_COMPACT                  uncompressed            1712 KB\n    FV Firmware File System file  LZMA compressed\n      PEIFV                       uncompressed             896 KB\n        individual PEI modules    uncompressed\n      DXEFV                       uncompressed            8192 KB\n        individual DXE modules    uncompressed\n\n  SECFV                           uncompressed             208 KB\n    SEC driver\n    reset vector code\n\nThe top-level image consists of three regions (three firmware volumes):\n- non-volatile data store (128 KB),\n- main firmware volume (FVMAIN_COMPACT, 1712 KB),\n- firmware volume containing the reset vector code and the SEC phase code (208\n  KB).\n\nIn total, the OVMF.fd file has size 128 KB + 1712 KB + 208 KB == 2 MB.\n\n(1) The firmware volume with non-volatile data store (128 KB) has the following\n    internal structure, in blocks of 4 KB:\n\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+  L: event log\n       LIVE | varstore                  |L|W|  W: working block\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n      SPARE |                               |\n            +-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+-+\n\n    The first half of this firmware volume is \"live\", while the second half is\n    \"spare\". The spare half is important when the variable driver reclaims\n    unused storage and reorganizes the variable store.\n\n    The live half dedicates 14 blocks (56 KB) to the variable store itself. On\n    top of those, one block is set aside for an event log, and one block is\n    used as the working block of the fault tolerant write protocol. Fault\n    tolerant writes are used to recover from an occasional (virtual) power loss\n    during variable updates.\n\n    The blocks in this firmware volume are accessed, in stacking order from\n    least abstract to most abstract, by:\n\n    - EFI_FIRMWARE_VOLUME_BLOCK_PROTOCOL (provided by\n      OvmfPkg/QemuFlashFvbServicesRuntimeDxe),\n\n    - EFI_FAULT_TOLERANT_WRITE_PROTOCOL (provided by\n      MdeModulePkg/Universal/FaultTolerantWriteDxe),\n\n    - architectural protocols instrumental to the runtime UEFI variable\n      services:\n      - EFI_VARIABLE_ARCH_PROTOCOL,\n      - EFI_VARIABLE_WRITE_ARCH_PROTOCOL.\n\n      In a non-secure boot build, the DXE driver providing these architectural\n      protocols is MdeModulePkg/Universal/Variable/RuntimeDxe. In a secure boot\n      build, where authenticated variables are available, the DXE driver\n      offering these protocols is SecurityPkg/VariableAuthenticated/RuntimeDxe.\n\n(2) The main firmware volume (FVMAIN_COMPACT, 1712 KB) embeds further firmware\n    volumes. The outermost layer is a Firmware File System (FFS), carrying a\n    single file. This file holds an LZMA-compressed section, which embeds two\n    firmware volumes: PEIFV (896 KB) with PEIMs, and DXEFV (8192 KB) with DXE\n    and UEFI drivers.\n\n    This scheme enables us to build 896 KB worth of PEI drivers and 8192 KB\n    worth of DXE and UEFI drivers, compress them all with LZMA in one go, and\n    store the compressed result in 1712 KB, saving room in the flash device.\n\n(3) The SECFV firmware volume (208 KB) is not compressed. It carries the\n    \"volume top file\" with the reset vector code, to end at 4 GB in\n    guest-physical address space, and the SEC phase driver (OvmfPkg/Sec).\n\n    The last 16 bytes of the volume top file (mapped directly under 4 GB)\n    contain a NOP slide and a jump instruction. This is where QEMU starts\n    executing the firmware, at address 0xFFFF_FFF0. The reset vector and the\n    SEC driver run from flash directly.\n\n    The SEC driver locates FVMAIN_COMPACT in the flash, and decompresses the\n    main firmware image to RAM. The rest of OVMF (PEI, DXE, BDS phases) run\n    from RAM.\n\nAs already mentioned, the OVMF.fd file is mapped by qemu's\n\"hw/block/pflash_cfi01.c\" device just under 4 GB in guest-physical address\nspace, according to the command line option\n\n  -drive if=pflash,format=raw,file=fedora.flash\n\n(refer to the Example qemu invocation). This is a \"ROMD device\", which can\nswitch out of \"ROMD mode\" and back into it.\n\nNamely, in the default ROMD mode, the guest-physical address range backed by\nthe flash device reads and executes as ROM (it does not trap from KVM to QEMU).\nThe first write access in this mode traps to QEMU, and flips the device out of\nROMD mode.\n\nIn non-ROMD mode, the flash chip is programmed by storing CFI (Common Flash\nInterface) command values at the flash-covered addresses; both reads and writes\ntrap to QEMU, and the flash contents are modified and synchronized to the\nhost-side file. A special CFI command flips the flash device back to ROMD mode.\n\nQemu implements the above based on the KVM_CAP_READONLY_MEM / KVM_MEM_READONLY\nKVM features, and OVMF puts it to use in its EFI_FIRMWARE_VOLUME_BLOCK_PROTOCOL\nimplementation, under \"OvmfPkg/QemuFlashFvbServicesRuntimeDxe\".\n\nIMPORTANT: Never pass OVMF.fd to qemu with the -bios option. That option maps\nthe firmware image as ROM into the guest's address space, and forces OVMF to\nemulate non-volatile variables with a fallback driver that is bound to have\ninsufficient and confusing semantics.\n\nThe 128 KB firmware volume with the variable store, discussed under (1), is\nalso built as a separate host-side file, named \"OVMF_VARS.fd\". The \"rest\" is\nbuilt into a third file, \"OVMF_CODE.fd\", which is only 1920 KB in size. The\nvariable store is mapped into its usual location, at 4 GB - 2 MB = 0xFFE0_0000,\nthrough the following qemu options:\n\n  -drive if=pflash,format=raw,readonly,file=OVMF_CODE.fd   \\\n  -drive if=pflash,format=raw,file=fedora.varstore.fd\n\nThis way qemu configures two flash chips consecutively, with start addresses\ngrowing downwards, which is transparent to OVMF.\n\n[RHEL] Red Hat Enterprise Linux 7.1 ships a Secure Boot-enabled, X64, DEBUG\n       firmware only. Furthermore, only the split files (\"OVMF_VARS.fd\" and\n       \"OVMF_CODE.fd\") are available.\n\nS3 (suspend to RAM and resume)\n------------------------------\n\nAs noted in Example qemu invocation, the\n\n  -global PIIX4_PM.disable_s3=0\n\ncommand line option tells qemu and OVMF if the user would like to enable S3\nsupport. (This is corresponds to the /domain/pm/suspend-to-mem/@enabled libvirt\ndomain XML attribute.)\n\nImplementing / orchestrating S3 was a considerable community effort in OVMF. A\ndetailed description exceeds the scope of this report; we only make a few\nstatements.\n\n(1) S3-related PPIs and protocols are well documented in the PI specification.\n\n(2) Edk2 contains most modules that are needed to implement S3 on a given\n    platform. One abstraction that is central to the porting / extending of the\n    S3-related modules to a new platform is the LockBox library interface,\n    which a specific platform can fill in by implementing its own LockBox\n    library instance.\n\n    The LockBox library provides a privileged name-value store (to be addressed\n    by GUIDs). The privilege separation stretches between the firmware and the\n    operating system. That is, the S3-related machinery of the firmware saves\n    some items in the LockBox securely, under well-known GUIDs, before booting\n    the operating system. During resume (which is a form of warm reset), the\n    firmware is activated again, and retrieves items from the LockBox. Before\n    jumping to the OS's resume vector, the LockBox is secured again.\n\n    We'll return to this later when we separately discuss SMRAM and SMM.\n\n(3) During resume, the DXE and later phases are never reached; only the reset\n    vector, and the SEC and PEI phases of the firmware run. The platform is\n    supposed to detect a resume in progress during PEI, and to store that fact\n    in the BootMode field of the Phase Handoff Information Table (PHIT) HOB.\n    OVMF keys this off the CMOS, see OvmfPkg/PlatformPei.\n\n    At the end of PEI, the DXE IPL PEIM (Initial Program Load PEI Module, see\n    MdeModulePkg/Core/DxeIplPeim) examines the Boot Mode, and if it says \"S3\n    resume in progress\", then the IPL branches to the PEIM that exports\n    EFI_PEI_S3_RESUME2_PPI (provided by UefiCpuPkg/Universal/Acpi/S3Resume2Pei)\n    rather than loading the DXE core.\n\n    S3Resume2Pei executes the technical steps of the resumption, relying on the\n    contents of the LockBox.\n\n(4) During first boot (or after a normal platform reset), when DXE does run,\n    hardware drivers in the DXE phase are encouraged to \"stash\" their hardware\n    configuration steps (eg. accesses to PCI config space, I/O ports, memory\n    mapped addresses, and so on) in a centrally maintained, so called \"S3 boot\n    script\". Hardware accesses are represented with opcodes of a special binary\n    script language.\n\n    This boot script is to be replayed during resume, by S3Resume2Pei. The\n    general goal is to bring back hardware devices -- which have been powered\n    off during suspend -- to their original after-first-boot state, and in\n    particular, to do so quickly.\n\n    At the moment, OVMF saves only one opcode in the S3 resume boot script: an\n    INFORMATION opcode, with contents 0xDEADBEEF (in network byte order). The\n    consensus between Linux developers seems to be that boot firmware is only\n    responsible for restoring basic chipset state, which OVMF does during PEI\n    anyway, independently of S3 vs. normal reset. (One example is the power\n    management registers of the i440fx chipset.) Device and peripheral state is\n    the responsibility of the runtime operating system.\n\n    Although an experimental OVMF S3 boot script was at one point captured for\n    the virtual Cirrus VGA card, such a boot script cannot follow eg. video\n    mode changes effected by the OS. Hence the operating system can never avoid\n    restoring device state, and most Linux display drivers (eg. stdvga, QXL)\n    already cover S3 resume fully.\n\n    The XDDM and WDDM driver models used under Windows OSes seem to recognize\n    this notion of runtime OS responsibility as well. (See the list of OSes\n    supported by OVMF in a separate section.)\n\n(5) The S3 suspend/resume data flow in OVMF is included here tersely, for\n    interested developers.\n\n    (a) BdsLibBootViaBootOption()\n          EFI_ACPI_S3_SAVE_PROTOCOL [AcpiS3SaveDxe]\n          - saves ACPI S3 Context to LockBox  ---------------------+\n            (including FACS address -- FACS ACPI table             |\n            contains OS waking vector)                             |\n                                                                   |\n          - prepares boot script:                                  |\n            EFI_S3_SAVE_STATE_PROTOCOL.Write() [S3SaveStateDxe]    |\n              S3BootScriptLib [PiDxeS3BootScriptLib]               |\n              - opcodes \u0026 arguments are saved in NVS.  --+         |\n                                                         |         |\n          - issues a notification by installing          |         |\n            EFI_DXE_SMM_READY_TO_LOCK_PROTOCOL           |         |\n                                                         |         |\n    (b) EFI_S3_SAVE_STATE_PROTOCOL [S3SaveStateDxe]      |         |\n          S3BootScriptLib [PiDxeS3BootScriptLib]         |         |\n          - closes script with special opcode  \u003c---------+         |\n          - script is available in non-volatile memory             |\n            via PcdS3BootScriptTablePrivateDataPtr  --+            |\n                                                      |            |\n        BootScriptExecutorDxe                         |            |\n          S3BootScriptLib [PiDxeS3BootScriptLib]      |            |\n          - Knows about boot script location by  \u003c----+            |\n            synchronizing with the other library                   |\n            instance via                                           |\n            PcdS3BootScriptTablePrivateDataPtr.                    |\n          - Copies relocated image of itself to                    |\n            reserved memory. --------------------------------+     |\n          - Saved image contains pointer to boot script.  ---|--+  |\n                                                             |  |  |\n    Runtime:                                                 |  |  |\n                                                             |  |  |\n    (c) OS is booted, writes OS waking vector to FACS,       |  |  |\n        suspends machine                                     |  |  |\n                                                             |  |  |\n    S3 Resume (PEI):                                         |  |  |\n                                                             |  |  |\n    (d) PlatformPei sets S3 Boot Mode based on CMOS          |  |  |\n                                                             |  |  |\n    (e) DXE core is skipped and EFI_PEI_S3_RESUME2 is        |  |  |\n        called as last step of PEI                           |  |  |\n                                                             |  |  |\n    (f) S3Resume2Pei retrieves from LockBox:                 |  |  |\n        - ACPI S3 Context (path to FACS)  \u003c------------------|--|--+\n                                          |                  |  |\n                                          +------------------|--|--+\n        - Boot Script Executor Image  \u003c----------------------+  |  |\n                                                                |  |\n    (g) BootScriptExecutorDxe                                   |  |\n          S3BootScriptLib [PiDxeS3BootScriptLib]                |  |\n          - executes boot script  \u003c-----------------------------+  |\n                                                                   |\n    (h) OS waking vector available from ACPI S3 Context / FACS  \u003c--+\n        is called\n\nA comprehensive memory map of OVMF\n----------------------------------\n\nThe following section gives a detailed analysis of memory ranges below 4 GB\nthat OVMF statically uses.\n\nIn the rightmost column, the PCD entry is identified by which the source refers\nto the address or size in question.\n\nThe flash-covered range has been discussed previously in \"Firmware image\nstructure\", therefore we include it only for completeness. Due to the fact that\nthis range is always backed by a memory mapped device (and never RAM), it is\nunaffected by S3 (suspend to RAM and resume).\n\n+--------------------------+ 4194304 KB\n|                          |\n|          SECFV           | size: 208 KB\n|                          |\n+--------------------------+ 4194096 KB\n|                          |\n|      FVMAIN_COMPACT      | size: 1712 KB\n|                          |\n+--------------------------+ 4192384 KB\n|                          |\n|      variable store      | size: 64 KB   PcdFlashNvStorageFtwSpareSize\n|        spare area        |\n|                          |\n+--------------------------+ 4192320 KB    PcdOvmfFlashNvStorageFtwSpareBase\n|                          |\n|    FTW working block     | size: 4 KB    PcdFlashNvStorageFtwWorkingSize\n|                          |\n+--------------------------+ 4192316 KB    PcdOvmfFlashNvStorageFtwWorkingBase\n|                          |\n|       Event log of       | size: 4 KB    PcdOvmfFlashNvStorageEventLogSize\n|   non-volatile storage   |\n|                          |\n+--------------------------+ 4192312 KB    PcdOvmfFlashNvStorageEventLogBase\n|                          |\n|      variable store      | size: 56 KB   PcdFlashNvStorageVariableSize\n|                          |\n+--------------------------+ 4192256 KB    PcdOvmfFlashNvStorageVariableBase\n\nThe flash-mapped image of OVMF.fd covers the entire structure above (2048 KB).\n\nWhen using the split files, the address 4192384 KB\n(PcdOvmfFlashNvStorageFtwSpareBase + PcdFlashNvStorageFtwSpareSize) is the\nboundary between the mapped images of OVMF_VARS.fd (56 KB + 4 KB + 4 KB + 64 KB\n= 128 KB) and OVMF_CODE.fd (1712 KB + 208 KB = 1920 KB).\n\nWith regard to RAM that is statically used by OVMF, S3 (suspend to RAM and\nresume) complicates matters. Many ranges have been introduced only to support\nS3, hence for all ranges below, the following questions will be audited:\n\n(a) when and how a given range is initialized after first boot of the VM,\n(b) how it is protected from memory allocations during DXE,\n(c) how it is protected from the OS,\n(d) how it is accessed on the S3 resume path,\n(e) how it is accessed on the warm reset path.\n\nImportantly, the term \"protected\" is meant as protection against inadvertent\nreallocations and overwrites by co-operating DXE and OS modules. It does not\nimply security against malicious code.\n\n+--------------------------+ 17408 KB\n|                          |\n|DXEFV from FVMAIN_COMPACT | size: 8192 KB PcdOvmfDxeMemFvSize\n|  decompressed firmware   |\n| volume with DXE modules  |\n|                          |\n+--------------------------+ 9216 KB       PcdOvmfDxeMemFvBase\n|                          |\n|PEIFV from FVMAIN_COMPACT | size: 896 KB  PcdOvmfPeiMemFvSize\n|  decompressed firmware   |\n| volume with PEI modules  |\n|                          |\n+--------------------------+ 8320 KB       PcdOvmfPeiMemFvBase\n|                          |\n| permanent PEI memory for | size: 32 KB   PcdS3AcpiReservedMemorySize\n|   the S3 resume path     |\n|                          |\n+--------------------------+ 8288 KB       PcdS3AcpiReservedMemoryBase\n|                          |\n|  temporary SEC/PEI heap  | size: 32 KB   PcdOvmfSecPeiTempRamSize\n|         and stack        |\n|                          |\n+--------------------------+ 8256 KB       PcdOvmfSecPeiTempRamBase\n|                          |\n|          unused          | size: 32 KB\n|                          |\n+--------------------------+ 8224 KB\n|                          |\n|      SEC's table of      | size: 4 KB    PcdGuidedExtractHandlerTableSize\n| GUIDed section handlers  |\n|                          |\n+--------------------------+ 8220 KB       PcdGuidedExtractHandlerTableAddress\n|                          |\n|     LockBox storage      | size: 4 KB    PcdOvmfLockBoxStorageSize\n|                          |\n+--------------------------+ 8216 KB       PcdOvmfLockBoxStorageBase\n|                          |\n| early page tables on X64 | size: 24 KB   PcdOvmfSecPageTablesSize\n|                          |\n+--------------------------+ 8192 KB       PcdOvmfSecPageTablesBase\n\n(1) Early page tables on X64:\n\n  (a) when and how it is initialized after first boot of the VM\n\n    The range is filled in during the SEC phase\n    [OvmfPkg/ResetVector/Ia32/PageTables64.asm]. The CR3 register is verified\n    against the base address in SecCoreStartupWithStack()\n    [OvmfPkg/Sec/SecMain.c].\n\n  (b) how it is protected from memory allocations during DXE\n\n    If S3 was enabled on the QEMU command line (see \"-global\n    PIIX4_PM.disable_s3=0\" earlier), then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] protects the range with an AcpiNVS memory\n    allocation HOB, in PEI.\n\n    If S3 was disabled, then this range is not protected. DXE's own page tables\n    are first built while still in PEI (see HandOffToDxeCore()\n    [MdeModulePkg/Core/DxeIplPeim/X64/DxeLoadFunc.c]). Those tables are located\n    in permanent PEI memory. After CR3 is switched over to them (which occurs\n    before jumping to the DXE core entry point), we don't have to preserve the\n    initial tables.\n\n  (c) how it is protected from the OS\n\n    If S3 is enabled, then (1b) reserves it from the OS too.\n\n    If S3 is disabled, then the range needs no protection.\n\n  (d) how it is accessed on the S3 resume path\n\n    It is rewritten same as in (1a), which is fine because (1c) reserved it.\n\n  (e) how it is accessed on the warm reset path\n\n    It is rewritten same as in (1a).\n\n(2) LockBox storage:\n\n  (a) when and how it is initialized after first boot of the VM\n\n    InitializeRamRegions() [OvmfPkg/PlatformPei/MemDetect.c] zeroes out the\n    area during PEI. This is correct but not strictly necessary, since on first\n    boot the area is zero-filled anyway.\n\n    The LockBox signature of the area is filled in by the PEI module or DXE\n    driver that has been linked against OVMF's LockBoxLib and is run first. The\n    signature is written in LockBoxLibInitialize()\n    [OvmfPkg/Library/LockBoxLib/LockBoxLib.c].\n\n    Any module calling SaveLockBox() [OvmfPkg/Library/LockBoxLib/LockBoxLib.c]\n    will co-populate this area.\n\n  (b) how it is protected from memory allocations during DXE\n\n    If S3 is enabled, then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] protects the range as AcpiNVS.\n\n    Otherwise, the range is covered with a BootServicesData memory allocation\n    HOB.\n\n  (c) how it is protected from the OS\n\n    If S3 is enabled, then (2b) protects it sufficiently.\n\n    Otherwise the range requires no runtime protection, and the\n    BootServicesData allocation type from (2b) ensures that the range will be\n    released to the OS.\n\n  (d) how it is accessed on the S3 resume path\n\n    The S3 Resume PEIM restores data from the LockBox, which has been correctly\n    protected in (2c).\n\n  (e) how it is accessed on the warm reset path\n\n    InitializeRamRegions() [OvmfPkg/PlatformPei/MemDetect.c] zeroes out the\n    range during PEI, effectively emptying the LockBox. Modules will\n    re-populate the LockBox as described in (2a).\n\n(3) SEC's table of GUIDed section handlers\n\n  (a) when and how it is initialized after first boot of the VM\n\n    The following two library instances are linked into SecMain:\n    - IntelFrameworkModulePkg/Library/LzmaCustomDecompressLib,\n    - MdePkg/Library/BaseExtractGuidedSectionLib.\n\n    The first library registers its LZMA decompressor plugin (which is a called\n    a \"section handler\") by calling the second library:\n\n    LzmaDecompressLibConstructor() [GuidedSectionExtraction.c]\n      ExtractGuidedSectionRegisterHandlers() [BaseExtractGuidedSectionLib.c]\n\n    The second library maintains its table of registered \"section handlers\", to\n    be indexed by GUID, in this fixed memory area, independently of S3\n    enablement.\n\n    (The decompression of FVMAIN_COMPACT's FFS file section that contains the\n    PEIFV and DXEFV firmware volumes occurs with the LZMA decompressor\n    registered above. See (6) and (7) below.)\n\n  (b) how it is protected from memory allocations during DXE\n\n    There is no need to protect this area from DXE: because nothing else in\n    OVMF links against BaseExtractGuidedSectionLib, the area loses its\n    significance as soon as OVMF progresses from SEC to PEI, therefore DXE is\n    allowed to overwrite the region.\n\n  (c) how it is protected from the OS\n\n    When S3 is enabled, we cover the range with an AcpiNVS memory allocation\n    HOB in InitializeRamRegions().\n\n    When S3 is disabled, the range is not protected.\n\n  (d) how it is accessed on the S3 resume path\n\n    The table of registered section handlers is again managed by\n    BaseExtractGuidedSectionLib linked into SecMain exclusively. Section\n    handler registrations update the table in-place (based on GUID matches).\n\n  (e) how it is accessed on the warm reset path\n\n    If S3 is enabled, then the OS won't damage the table (due to (3c)), thus\n    see (3d).\n\n    If S3 is disabled, then the OS has most probably overwritten the range with\n    its own data, hence (3a) -- complete reinitialization -- will come into\n    effect, based on the table signature check in BaseExtractGuidedSectionLib.\n\n(4) temporary SEC/PEI heap and stack\n\n  (a) when and how it is initialized after first boot of the VM\n\n    The range is configured in [OvmfPkg/Sec/X64/SecEntry.S] and\n    SecCoreStartupWithStack() [OvmfPkg/Sec/SecMain.c]. The stack half is read \u0026\n    written by the CPU transparently. The heap half is used for memory\n    allocations during PEI.\n\n    Data is migrated out (to permanent PEI stack \u0026 memory) in (or soon after)\n    PublishPeiMemory() [OvmfPkg/PlatformPei/MemDetect.c].\n\n  (b) how it is protected from memory allocations during DXE\n\n    It is not necessary to protect this range during DXE because its use ends\n    still in PEI.\n\n  (c) how it is protected from the OS\n\n    If S3 is enabled, then InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] reserves it as AcpiNVS.\n\n    If S3 is disabled, then the range doesn't require protection.\n\n  (d) how it is accessed on the S3 resume path\n\n    Same as in (4a), except the target area of the migration triggered by\n    PublishPeiMemory() [OvmfPkg/PlatformPei/MemDetect.c] is different -- see\n    (5).\n\n  (e) how it is accessed on the warm reset path\n\n    Same as in (4a). The stack and heap halves both may contain garbage, but it\n    doesn't matter.\n\n(5) permanent PEI memory for the S3 resume path\n\n  (a) when and how it is initialized after first boot of the VM\n\n    No particular initialization or use.\n\n  (b) how it is protected from memory allocations during DXE\n\n    We don't need to protect this area during DXE.\n\n  (c) how it is protected from the OS\n\n    When S3 is enabled, InitializeRamRegions()\n    [OvmfPkg/PlatformPei/MemDetect.c] makes sure the OS stays away by covering\n    the range with an AcpiNVS memory allocation HOB.\n\n    When S3 is disabled, the range needs no protection.\n\n  (d) how it is accessed on the S3 resume path\n\n    PublishPeiMemory() installs the range as permanent RAM for PEI. The range\n    will serve as stack and will satisfy allocation requests during the rest of\n    PEI. OS data won't overlap due to (5c).\n\n  (e) how it is accessed on the warm reset path\n\n    Same as (5a).\n\n(6) PEIFV -- decompressed firmware volume with PEI modules\n\n  (a) when and how it is initialized after first boot of the VM\n\n    DecompressMemFvs() [OvmfPkg/Sec/SecMain.c] populates the area, by\n    decompressing the flash-mapped FVMAIN_COMPACT volume's contents. (Refer to\n    \"Firmware image structure\".)\n\n  (b) how it is protected from memory allocations during DXE\n\n    When S3 is disabled, PeiFvInitialization() [OvmfPkg/PlatformPei/Fv.c]\n    covers the range with a BootServicesData memory allocation HOB.\n\n    When S3 is enabled, the same is coverage is ensured, just with the stronger\n    AcpiNVS memory allocation type.\n\n  (c) how it is protected from the OS\n\n    When S3 is disabled, it is not necessary to keep the range from the OS.\n\n    Otherwise the AcpiNVS type allocation from (6b) provides coverage.\n\n  (d) how it is accessed on the S3 resume path\n\n    Rather than decompressing it again from FVMAIN_COMPACT, GetS3ResumePeiFv()\n    [OvmfPkg/Sec/SecMain.c] reuses the protected area for parsing / execution\n    from (6c).\n\n  (e) how it is accessed on the warm reset path\n\n    Same as (6a).\n\n(7) DXEFV -- decompressed firmware volume with DXE modules\n\n  (a) when and how it is initialized after first boot of the VM\n\n    Same as (6a).\n\n  (b) how it is protected from memory allocations during DXE\n\n    PeiFvInitialization() [OvmfPkg/PlatformPei/Fv.c] covers the range with a\n    BootServicesData memory allocation HOB.\n\n  (c) how it is protected from the OS\n\n    The OS is allowed to release and reuse this range.\n\n  (d) how it is accessed on the S3 resume path\n\n    It's not; DXE never runs during S3 resume.\n\n  (e) how it is accessed on the warm reset path\n\n    Same as in (7a).\n\nKnown Secure Boot limitations\n-----------------------------\n\nUnder \"Motivation\" we've mentioned that OVMF's Secure Boot implementation is\nnot suitable for production use yet -- it's only good for development and\ntesting of standards-conformant, non-malicious guest code (UEFI and operating\nsystem alike).\n\nNow that we've examined the persistent flash device, the workings of S3, and\nthe memory map, we can discuss two currently known shortcomings of OVMF's\nSecure Boot that in fact make it insecure. (Clearly problems other than these\ntwo might exist; the set of issues considered here is not meant to be\nexhaustive.)\n\nOne trait of Secure Boot is tamper-evidence. Secure Boot may not prevent\nmalicious modification of software components (for example, operating system\ndrivers), but by being the root of integrity on a platform, it can catch (or\nindirectly contribute to catching) unauthorized changes, by way of signature\nand certificate checks at the earliest phases of boot.\n\nIf an attacker can tamper with key material stored in authenticated and/or\nboot-time only persistent variables (for example, PK, KEK, db, dbt, dbx), then\nthe intended security of this scheme is compromised. The UEFI 2.4A\nspecification says\n\n- in section 28.3.4:\n\n  Platform Keys:\n\n    The public key must be stored in non-volatile storage which is tamper and\n    delete resistant.\n\n  Key Exchange Keys:\n\n    The public key must be stored in non-volatile storage which is tamper\n    resistant.\n\n- in section 28.6.1:\n\n  The signature database variables db, dbt, and dbx must be stored in\n  tamper-resistant non-volatile storage.\n\n(1) The combination of QEMU, KVM, and OVMF does not provide this kind of\n    resistance. The variable store in the emulated flash chip is directly\n    accessible to, and reprogrammable by, UEFI drivers, applications, and\n    operating systems.\n\n(2) Under \"S3 (suspend to RAM and resume)\" we pointed out that the LockBox\n    storage must be similarly secure and tamper-resistant.\n\n    On the S3 resume path, the PEIM providing EFI_PEI_S3_RESUME2_PPI\n    (UefiCpuPkg/Universal/Acpi/S3Resume2Pei) restores and interprets data from\n    the LockBox that has been saved there during boot. This PEIM, being part of\n    the firmware, has full access to the platform. If an operating system can\n    tamper with the contents of the LockBox, then at the next resume the\n    platform's integrity might be subverted.\n\n    OVMF stores the LockBox in normal guest RAM (refer to the memory map\n    section above). Operating systems and third party UEFI drivers and UEFI\n    applications that respect the UEFI memory map will not inadvertently\n    overwrite the LockBox storage, but there's nothing to prevent eg. a\n    malicious kernel from modifying the LockBox.\n\nOne means to address these issues is SMM and SMRAM (System Management Mode and\nSystem Management RAM).\n\nDuring boot and resume, the firmware can enter and leave SMM and access SMRAM.\nBefore the DXE phase is left, and control is transferred to the BDS phase (when\nthird party UEFI drivers and applications can be loaded, and an operating\nsystem can be loaded), SMRAM is locked in hardware, and subsequent modules\ncannot access it directly. (See EFI_DXE_SMM_READY_TO_LOCK_PROTOCOL.)\n\nOnce SMRAM has been locked, UEFI drivers and the operating system can enter SMM\nby raising a System Management Interrupt (SMI), at which point trusted code\n(part of the platform firmware) takes control. SMRAM is also unlocked by\nplatform reset, at which point the boot firmware takes control again.\n\nVariable store and LockBox in SMRAM\n-----------------------------------\n\nEdk2 provides almost all components to implement the variable store and the\nLockBox in SMRAM. In this section we summarize ideas for utilizing those\nfacilities.\n\nThe SMRAM and SMM infrastructure in edk2 is built up as follows:\n\n(1) The platform hardware provides SMM / SMI / SMRAM.\n\n    Qemu/KVM doesn't support these features currently and should implement them\n    in the longer term.\n\n(2) The platform vendor (in this case, OVMF developers) implement device\n    drivers for the platform's System Management Mode:\n\n    - EFI_SMM_CONTROL2_PROTOCOL: for raising a synchronous (and/or) periodic\n      SMI(s); that is, for entering SMM.\n\n    - EFI_SMM_ACCESS2_PROTOCOL: for describing and accessing SMRAM.\n\n    These protocols are documented in the PI Specification, Volume 4.\n\n(3) The platform DSC file is to include the following platform-independent\n    modules:\n\n    - MdeModulePkg/Core/PiSmmCore/PiSmmIpl.inf: SMM Initial Program Load\n    - MdeModulePkg/Core/PiSmmCore/PiSmmCore.inf: SMM Core\n\n(4) At this point, modules of type DXE_SMM_DRIVER can be loaded.\n\n    Such drivers are privileged. They run in SMM, have access to SMRAM, and are\n    separated and switched from other drivers through SMIs. Secure\n    communication between unprivileged (non-SMM) and privileged (SMM) drivers\n    happens through EFI_SMM_COMMUNICATION_PROTOCOL (implemented by the SMM\n    Core, see (3)).\n\n    DXE_SMM_DRIVER modules must sanitize their input (coming from unprivileged\n    drivers) carefully.\n\n(5) The authenticated runtime variable services driver (for Secure Boot builds)\n    is located under \"SecurityPkg/VariableAuthenticated/RuntimeDxe\". OVMF\n    currently builds the driver (a DXE_RUNTIME_DRIVER module) with the\n    \"VariableRuntimeDxe.inf\" control file (refer to \"OvmfPkg/OvmfPkgX64.dsc\"),\n    which does not use SMM.\n\n    The directory includes two more INF files:\n\n    - VariableSmm.inf -- module type: DXE_SMM_DRIVER. A privileged driver that\n      runs in SMM and has access to SMRAM.\n\n    - VariableSmmRuntimeDxe.inf -- module type: DXE_RUNTIME_DRIVER. A\n      non-privileged driver that implements the variable runtime services\n      (replacing the current \"VariableRuntimeDxe.inf\" file) by communicating\n      with the above privileged SMM half via EFI_SMM_COMMUNICATION_PROTOCOL.\n\n(6) An SMRAM-based LockBox implementation needs to be discussed in two parts,\n    because the LockBox is accessed in both PEI and DXE.\n\n    (a) During DXE, drivers save data in the LockBox. A save operation is\n        layered as follows:\n\n        - The unprivileged driver wishing to store data in the LockBox links\n          against the \"MdeModulePkg/Library/SmmLockBoxLib/SmmLockBoxDxeLib.inf\"\n          library instance.\n\n          The library allows the unprivileged driver to format requests for the\n          privileged SMM LockBox driver (see below), and to parse responses.\n\n        - The privileged SMM LockBox driver is built from\n          \"MdeModulePkg/Universal/LockBox/SmmLockBox/SmmLockBox.inf\". This\n          driver has module type DXE_SMM_DRIVER and can access SMRAM.\n\n          The driver delegates command parsing and response formatting to\n          \"MdeModulePkg/Library/SmmLockBoxLib/SmmLockBoxSmmLib.inf\".\n\n        - The above two halves (unprivileged and privileged) mirror what we've\n          seen in case of the variable service drivers, under (5).\n\n    (b) In PEI, the S3 Resume PEIM (UefiCpuPkg/Universal/Acpi/S3Resume2Pei)\n        retrieves data from the LockBox.\n\n        Presumably, S3Resume2Pei should be considered an \"unprivileged PEIM\",\n        and the SMRAM access should be layered as seen in DXE. Unfortunately,\n        edk2 does not implement all of the layers in PEI -- the code either\n        doesn't exist, or it is not open source:\n\n  role         | DXE: protocol/module           | PEI: PPI/module\n  -------------+--------------------------------+------------------------------\n  unprivileged | any                            | S3Resume2Pei.inf\n  driver       |                                |\n  -------------+--------------------------------+------------------------------\n  command      | LIBRARY_CLASS = LockBoxLib     | LIBRARY_CLASS = LockBoxLib\n  formatting   |                                |\n  and response | SmmLockBoxDxeLib.inf           | SmmLockBoxPeiLib.inf\n  parsing      |                                |\n  -------------+--------------------------------+------------------------------\n  privilege    | EFI_SMM_COMMUNICATION_PROTOCOL | EFI_PEI_SMM_COMMUNICATION_PPI\n  separation   |                                |\n               | PiSmmCore.inf                  | missing!\n  -------------+--------------------------------+------------------------------\n  platform SMM | EFI_SMM_CONTROL2_PROTOCOL      | PEI_SMM_CONTROL_PPI\n  and SMRAM    | EFI_SMM_ACCESS2_PROTOCOL       | PEI_SMM_ACCESS_PPI\n  access       |                                |\n               | to be done in OVMF             | to be done in OVMF\n  -------------+--------------------------------+------------------------------\n  command      | LIBRARY_CLASS = LockBoxLib     | LIBRARY_CLASS = LockBoxLib\n  parsing and  |                                |\n  response     | SmmLockBoxSmmLib.inf           | missing!\n  formatting   |                                |\n  -------------+--------------------------------+------------------------------\n  privileged   | SmmLockBox.inf                 | missing!\n  LockBox      |                                |\n  driver       |                                |\n\n        Alternatively, in the future OVMF might be able to provide a LockBoxLib\n        instance (an SmmLockBoxPeiLib substitute) for S3Resume2Pei that\n        accesses SMRAM directly, eliminating the need for deeper layers in the\n        stack (that is, EFI_PEI_SMM_COMMUNICATION_PPI and deeper).\n\n        In fact, a \"thin\" EFI_PEI_SMM_COMMUNICATION_PPI implementation whose\n        sole Communicate() member invariably returns EFI_NOT_STARTED would\n        cause the current SmmLockBoxPeiLib library instance to directly perform\n        full-depth SMRAM access and LockBox search, obviating the \"missing\"\n        cells. (With reference to A Tour Beyond BIOS: Implementing S3 Resume\n        with EDK2, by Jiewen Yao and Vincent Zimmer, October 2014.)\n\nSelect features\n---------------\n\nIn this section we'll browse the top-level \"OvmfPkg\" package directory, and\ndiscuss the more interesting drivers and libraries that have not been mentioned\nthus far.\n\nX64-specific reset vector for OVMF\n..................................\n\nThe \"OvmfPkg/ResetVector\" directory customizes the reset vector (found in\n\"UefiCpuPkg/ResetVector/Vtf0\") for \"OvmfPkgX64.fdf\", that is, when the SEC/PEI\nphases run in 64-bit (ie. long) mode.\n\nThe reset vector's control flow looks roughly like:\n\n  resetVector                               [Ia16/ResetVectorVtf0.asm]\n  EarlyBspInitReal16                        [Ia16/Init16.asm]\n  Main16                                    [Main.asm]\n    EarlyInit16                             [Ia16/Init16.asm]\n\n    ; Transition the processor from\n    ; 16-bit real mode to 32-bit flat mode\n    TransitionFromReal16To32BitFlat         [Ia16/Real16ToFlat32.asm]\n\n    ; Search for the\n    ; Boot Firmware Volume (BFV)\n    Flat32SearchForBfvBase                  [Ia32/SearchForBfvBase.asm]\n\n    ; Search for the SEC entry point\n    Flat32SearchForSecEntryPoint            [Ia32/SearchForSecEntry.asm]\n\n    %ifdef ARCH_IA32\n      ; Jump to the 32-bit SEC entry point\n    %else\n      ; Transition the processor\n      ; from 32-bit flat mode\n      ; to 64-bit flat mode\n      Transition32FlatTo64Flat              [Ia32/Flat32ToFlat64.asm]\n\n        SetCr3ForPageTables64               [Ia32/PageTables64.asm]\n          ; set CR3 to page tables\n          ; built into the ROM image\n\n        ; enable PAE\n        ; set LME\n        ; enable paging\n\n      ; Jump to the 64-bit SEC entry point\n    %endif\n\nOn physical platforms, the initial page tables referenced by\nSetCr3ForPageTables64 are built statically into the flash device image, and are\npresent in ROM at runtime. This is fine on physical platforms because the\npre-built page table entries have the Accessed and Dirty bits set from the\nstart.\n\nAccordingly, for OVMF running in long mode on qemu/KVM, the initial page tables\nwere mapped as a KVM_MEM_READONLY slot, as part of QEMU's pflash device (refer\nto \"Firmware image structure\" above).\n\nIn spite of the Accessed and Dirty bits being pre-set in the read-only,\nin-flash PTEs, in a virtual machine attempts are made to update said PTE bits,\ndifferently from physical hardware. The component attempting to update the\nread-only PTEs can be one of the following:\n\n- The processor itself, if it supports nested paging, and the user enables that\n  processor feature,\n\n- KVM code implementing shadow paging, otherwise.\n\nThe first case presents no user-visible symptoms, but the second case (KVM,\nshadow paging) used to cause a triple fault, prior to Linux commit ba6a354\n(\"KVM: mmu: allow page tables to be in read-only slots\").\n\nFor compatibility with earlier KVM versions, the OvmfPkg/ResetVector directory\nadapts the generic reset vector code as follows:\n\n      Transition32FlatTo64Flat         [UefiCpuPkg/.../Ia32/Flat32ToFlat64.asm]\n\n        SetCr3ForPageTables64       [OvmfPkg/ResetVector/Ia32/PageTables64.asm]\n\n          ; dynamically build the initial page tables in RAM, at address\n          ; PcdOvmfSecPageTablesBase (refer to the memory map above),\n          ; identity-mapping the first 4 GB of address space\n\n          ; set CR3 to PcdOvmfSecPageTablesBase\n\n        ; enable PAE\n        ; set LME\n        ; enable paging\n\nThis way the PTEs that earlier KVM versions try to update (during shadow\npaging) are located in a read-write memory slot, and the write attempts\nsucceed.\n\nClient library for QEMU's firmware configuration interface\n..........................................................\n\nQEMU provides a write-only, 16-bit wide control port, and a read-write, 8-bit\nwide data port for exchanging configuration elements with the firmware.\n\nThe firmware writes a selector (a key) to the control port (0x510), and then\nreads the corresponding configuration data (produced by QEMU) from the data\nport (0x511).\n\nIf the selected entry is writable, the firmware may overwrite it. If QEMU has\nassociated a callback with the entry, then when the entry is completely\nrewritten, QEMU runs the callback. (OVMF does not rewrite any entries at the\nmoment.)\n\nA number of selector values (keys) are predefined. In particular, key 0x19\nselects (returns) a directory of { name, selector, size } triplets, roughly\nspeaking.\n\nThe firmware can request configuration elements by well-known name as well, by\nlooking up the selector value first in the directory, by name, and then writing\nthe selector to the control port. The number of bytes to read subsequently from\nthe data port is known from the directory entry's \"size\" field.\n\nBy convention, directory entries (well-known symbolic names of configuration\nelements) are formatted as POSIX pathnames. For example, the array selected by\nthe \"etc/system-states\" name indicates (among other things) whether the user\nenabled S3 support in QEMU.\n\nThe above interface is called \"fw_cfg\".\n\nThe binary data associated with a symbolic name is called an \"fw_cfg file\".\n\nOVMF's fw_cfg client library is found in \"OvmfPkg/Library/QemuFwCfgLib\". OVMF\ndiscovers many aspects of the virtual system with it; we refer to a few\nexamples below.\n\nGuest ACPI tables\n.................\n\nAn operating system discovers a good amount of its hardware by parsing ACPI\ntables, and by interpreting ACPI objects and methods. On physical hardware, the\nplatform vendor's firmware installs ACPI tables in memory that match both the\nhardware present in the system and the user's firmware configuration (\"BIOS\nsetup\").\n\nUnder qemu/KVM, the owner of the (virtual) hardware configuration is QEMU.\nHardware can easily be reconfigured on the command line. Furthermore, features\nlike CPU hotplug, PCI hotplug, memory hotplug are continuously developed for\nQEMU, and operating systems need direct ACPI support to exploit these features.\n\nFor this reason, QEMU builds its own ACPI tables dynamically, in a\nself-descriptive manner, and exports them to the firmware through a complex,\nmulti-file fw_cfg interface. It is rooted in the \"etc/table-loader\" fw_cfg\nfile. (Further details of this interface are out of scope for this report.)\n\nOVMF's AcpiPlatformDxe driver fetches the ACPI tables, and installs them for\nthe guest OS with the EFI_ACPI_TABLE_PROTOCOL (which is in turn provided by the\ngeneric \"MdeModulePkg/Universal/Acpi/AcpiTableDxe\" driver).\n\nFor earlier QEMU versions and machine types (which we generally don't recommend\nfor OVMF; see \"Scope\"), the \"OvmfPkg/AcpiTables\" directory contains a few\nstatic ACPI table templates. When the \"etc/table-loader\" fw_cfg file is\nunavailable, AcpiPlatformDxe installs these default tables (with a little bit\nof dynamic patching).\n\nWhen OVMF runs in a Xen domU, AcpiTableDxe also installs ACPI tables that\noriginate from the hypervisor's environment.\n\nGuest SMBIOS tables\n...................\n\nQuoting the SMBIOS Reference Specification,\n\n  [...] the System Management BIOS Reference Specification addresses how\n  motherboard and system vendors present management information about their\n  products in a standard format [...]\n\nIn practice SMBIOS tables are just another set of tables that the platform\nvendor's firmware installs in RAM for the operating system, and, importantly,\nfor management applications running on the OS. Without rehashing the \"Guest\nACPI tables\" section in full, let's map the OVMF roles seen there from ACPI to\nSMBIOS:\n\n  role                     | ACPI                    | SMBIOS\n  -------------------------+-------------------------+-------------------------\n  fw_cfg file              | etc/table-loader        | etc/smbios/smbios-tables\n  -------------------------+-------------------------+-------------------------\n  OVMF driver              | AcpiPlatformDxe         | SmbiosPlatformDxe\n  under \"OvmfPkg\"          |                         |\n  -------------------------+-------------------------+-------------------------\n  Underlying protocol,     | EFI_ACPI_TABLE_PROTOCOL | EFI_SMBIOS_PROTOCOL\n  implemented by generic   |                         |\n  driver under             | Acpi/AcpiTableDxe       | SmbiosDxe\n  \"MdeModulePkg/Universal\" |                         |\n  -------------------------+-------------------------+-------------------------\n  default tables available | yes                     | [RHEL] yes, Type0 and\n  for earlier QEMU machine |                         |        Type1 tables\n  types, with hot-patching |                         |\n  -------------------------+-------------------------+-------------------------\n  tables fetched in Xen    | yes                     | yes\n  domUs                    |                         |\n\nPlatform-specific boot policy\n.............................\n\nOVMF's BDS (Boot Device Selection) phase is implemented by\nIntelFrameworkModulePkg/Universal/BdsDxe. Roughly speaking, this large driver:\n\n- provides the EFI BDS architectural protocol (which DXE transfers control to\n  after dispatching all DXE drivers),\n\n- connects drivers to devices,\n\n- enumerates boot devices,\n\n- auto-generates boot options,\n\n- provides \"BIOS setup\" screens, such as:\n\n  - Boot Manager, for booting an option,\n\n  - Boot Maintenance Manager, for adding, deleting, and reordering boot\n    options, changing console properties etc,\n\n  - Device Manager, where devices can register configuration forms, including\n\n    - Secure Boot configuration forms,\n\n    - OVMF's Platform Driver form (see under PlatformDxe).\n\nFirmware that includes the \"IntelFrameworkModulePkg/Universal/BdsDxe\" driver\ncan customize its behavior by providing an instance of the PlatformBdsLib\nlibrary class. The driver links against this platform library, and the\nplatform library can call Intel's BDS utility functions from\n\"IntelFrameworkModulePkg/Library/GenericBdsLib\".\n\nOVMF's PlatformBdsLib instance can be found in\n\"OvmfPkg/Library/PlatformBdsLib\". The main function where the BdsDxe driver\nenters the library is PlatformBdsPolicyBehavior(). We mention two OVMF\nparticulars here.\n\n(1) OVMF is capable of loading kernel images directly from fw_cfg, matching\n    QEMU's -kernel, -initrd, and -append command line options. This feature is\n    useful for rapid, repeated Linux kernel testing, and is implemented in the\n    following call tree:\n\n    PlatformBdsPolicyBehavior() [OvmfPkg/Library/PlatformBdsLib/BdsPlatform.c]\n      TryRunningQemuKernel() [OvmfPkg/Library/PlatformBdsLib/QemuKernel.c]\n        LoadLinux*() [OvmfPkg/Library/LoadLinuxLib/Linux.c]\n\n    OvmfPkg/Library/LoadLinuxLib ports the efilinux bootloader project into\n    OvmfPkg.\n\n(2) OVMF seeks to comply with the boot order specification passed down by QEMU\n    over fw_cfg.\n\n    (a) About Boot Modes\n\n      During the PEI phase, OVMF determines and stores the Boot Mode in the\n      PHIT HOB (already mentioned in \"S3 (suspend to RAM and resume)\"). The\n      boot mode is supposed to influence the rest of the system, for example it\n      distinguishes S3 resume (BOOT_ON_S3_RESUME) from a \"normal\" boot.\n\n      In general, \"normal\" boots can be further differentiated from each other;\n      for example for speed reasons. When the firmware can tell during PEI that\n      the chassis has not been opened since last power-up, then it might want\n      to save time by not connecting all devices and not enumerating all boot\n      options from scratch; it could just rely on the stored results of the\n      last enumeration. The matching BootMode value, to be set during PEI,\n      would be BOOT_ASSUMING_NO_CONFIGURATION_CHANGES.\n\n      OVMF only sets one of the following two boot modes, based on CMOS\n      contents:\n      - BOOT_ON_S3_RESUME,\n      - BOOT_WITH_FULL_CONFIGURATION.\n\n      For BOOT_ON_S3_RESUME, please refer to \"S3 (suspend to RAM and resume)\".\n      The other boot mode supported by OVMF, BOOT_WITH_FULL_CONFIGURATION, is\n      an appropriate \"catch-all\" for a virtual machine, where hardware can\n      easily change from boot to boot.\n\n    (b) Auto-generation of boot options\n\n      Accordingly, when not resuming from S3 sleep (*), OVMF always connects\n      all devices, and enumerates all bootable devices as new boot options\n      (non-volatile variables called Boot####).\n\n      (*) During S3 resume, DXE is not reached, hence BDS isn't either.\n\n      The auto-enumerated boot options are stored in the BootOrder non-volatile\n      variable after any preexistent options. (Boot options may exist before\n      auto-enumeration eg. because the user added them manually with the Boot\n      Maintenance Manager or the efibootmgr utility. They could also originate\n      from an earlier auto-enumeration.)\n\n      PlatformBdsPolicyBehavior()                   [OvmfPkg/.../BdsPlatform.c]\n        TryRunningQemuKernel()                       [OvmfPkg/.../QemuKernel.c]\n        BdsLibConnectAll()           [IntelFrameworkModulePkg/.../BdsConnect.c]\n        BdsLibEnumerateAllBootOption()  [IntelFrameworkModulePkg/.../BdsBoot.c]\n          BdsLibBuildOptionFromHandle() [IntelFrameworkModulePkg/.../BdsBoot.c]\n            BdsLibRegisterNewOption()   [IntelFrameworkModulePkg/.../BdsMisc.c]\n              //\n              // Append the new option number to the original option order\n              //\n\n    (c) Relative UEFI device paths in boot options\n\n      The handling of relative (\"short-form\") UEFI device paths is best\n      demonstrated through an example, and by quoting the UEFI 2.4A\n      specification.\n\n      A short-form hard drive UEFI device path could be (displaying each device\n      path node on a separate line for readability):\n\n        HD(1,GPT,14DD1CC5-D576-4BBF-8858-BAF877C8DF61,0x800,0x64000)/\n        \\EFI\\fedora\\shim.efi\n\n      This device path lacks prefix nodes (eg. hardware or messaging type\n      nodes) that would lead to the hard drive. During load option processing,\n      the above short-form or relative device path could be matched against the\n      following absolute device path:\n\n        PciRoot(0x0)/\n        Pci(0x4,0x0)/\n        HD(1,GPT,14DD1CC5-D576-4BBF-8858-BAF877C8DF61,0x800,0x64000)/\n        \\EFI\\fedora\\shim.efi\n\n      The motivation for this type of device path matching / completion is to\n      allow the user to move around the hard drive (for example, to plug a\n      controller in a different PCI slot, or to expose the block device on a\n      different iSCSI path) and still enable the firmware to find the hard\n      drive.\n\n      The UEFI specification says,\n\n        9.3.6 Media Device Path\n        9.3.6.1 Hard Drive\n\n          [...] Section 3.1.2 defines special rules for processing the Hard\n          Drive Media Device Path. These special rules enable a disk's location\n          to change and still have the system boot from the disk. [...]\n\n        3.1.2 Load Option Processing\n\n          [...] The boot manager must [...] support booting from a short-form\n          device path that starts with the first element being a hard drive\n          media device path [...]. The boot manager must use the GUID or\n          signature and partition number in the hard drive device path to match\n          it to a device in the system. If the drive supports the GPT\n          partitioning scheme the GUID in the hard drive media device path is\n          compared with the UniquePartitionGuid field of the GUID Partition\n          Entry [...]. If the drive supports the PC-AT MBR scheme the signature\n          in the hard drive media device path is compared with the\n          UniqueMBRSignature in the Legacy Master Boot Record [...]. If a\n          signature match is made, then the partition number must also be\n          matched. The hard drive device path can be appended to the matching\n          hardware device path and normal boot behavior can then be used. If\n          more than one device matches the hard drive device path, the boot\n          manager will pick one arbitrarily. Thus the operating system must\n          ensure the uniqueness of the signatures on hard drives to guarantee\n          deterministic boot behavior.\n\n      Edk2 implements and exposes the device path completion logic in the\n      already referenced \"IntelFrameworkModulePkg/Library/GenericBdsLib\"\n      library, in the BdsExpandPartitionPartialDevicePathToFull() function.\n\n    (d) Filtering and reordering the boot options based on fw_cfg\n\n      Once we have an \"all-inclusive\", partly preexistent, partly freshly\n      auto-generated boot option list from bullet (b), OVMF loads QEMU's\n      requested boot order from fw_cfg, and filters and reorders the list from\n      (b) with it:\n\n      PlatformBdsPolicyBehavior()                   [OvmfPkg/.../BdsPlatform.c]\n        TryRunningQemuKernel()                       [OvmfPkg/.../QemuKernel.c]\n        BdsLibConnectAll()           [IntelFrameworkModulePkg/.../BdsConnect.c]\n        BdsLibEnumerateAllBootOption()  [IntelFrameworkModulePkg/.../BdsBoot.c]\n        SetBootOrderFromQemu()                    [OvmfPkg/.../QemuBootOrder.c]\n\n      According to the (preferred) \"-device ...,bootindex=N\" and the (legacy)\n      '-boot order=drives' command line options, QEMU requests a boot order\n      from the firmware through the \"bootorder\" fw_cfg file. (For a bootindex\n      example, refer to the \"Example qemu invocation\" section.)\n\n      This fw_cfg file consists of OpenFirmware (OFW) device paths -- note: not\n      UEFI device paths! --, one per line. An example list is:\n\n        /pci@i0cf8/scsi@4/disk@0,0\n        /pci@i0cf8/ide@1,1/drive@1/disk@0\n        /pci@i0cf8/ethernet@3/ethernet-phy@0\n\n      OVMF filters and reorders the boot option list from bullet (b) with the\n      following nested loops algorithm:\n\n        new_uefi_order := \u003cempty\u003e\n        for each qemu_ofw_path in QEMU's OpenFirmware device path list:\n          qemu_uefi_path_prefix := translate(qemu_ofw_path)\n\n          for each boot_option in current_uefi_order:\n            full_boot_option := complete(boot_option)\n\n            if match(qemu_uefi_path_prefix, full_boot_option):\n              append(new_uefi_order, boot_option)\n              break\n\n        for each unmatched boot_option in current_uefi_order:\n          if survives(boot_option):\n            append(new_uefi_order, boot_option)\n\n        current_uefi_order := new_uefi_order\n\n      OVMF iterates over QEMU's OFW device paths in order, translates each to a\n      UEFI device path prefix, tries to match the translated prefix against the\n      UEFI boot options (which are completed from relative form to absolute\n      form for the purpose of prefix matching), and if there's a match, the\n      matching boot option is appended to the new boot order (which starts out\n      empty).\n\n      (We elaborate on the translate() function under bullet (e). The\n      complete() function has been explained in bullet (c).)\n\n      In addition, UEFI boot options that remain unmatched after filtering and\n      reordering are post-processed, and some of them \"survive\". Due to the\n      fact that OpenFirmware device paths have less expressive power than their\n      UEFI counterparts, some UEFI boot options are simply inexpressible (hence\n      unmatchable) by the nested loops algorithm.\n\n      An important example is the memory-mapped UEFI shell, whose UEFI device\n      path is inexpressible by QEMU's OFW device paths:\n\n        MemoryMapped(0xB,0x900000,0x10FFFFF)/\n        FvFile(7C04A583-9E3E-4F1C-AD65-E05268D0B4D1)\n\n      (Side remark: notice that the address range visible in the MemoryMapped()\n      node corresponds to DXEFV under \"comprehensive memory map of OVMF\"! In\n      addition, the FvFile() node's GUID originates from the FILE_GUID entry of\n      \"ShellPkg/Application/Shell/Shell.inf\".)\n\n      The UEFI shell can be booted by pressing ESC in OVMF on the TianoCore\n      splash screen, and navigating to Boot Manager | EFI Internal Shell. If\n      the \"survival policy\" was not implemented, the UEFI shell's boot option\n      would always be filtered out.\n\n      The current \"survival policy\" preserves all boot options that start with\n      neither PciRoot() nor HD().\n\n    (e) Translating QEMU's OpenFirmware device paths to UEFI device path\n        prefixes\n\n      In this section we list the (strictly heuristical) mappings currently\n      performed by OVMF.\n\n      The \"prefix only\" nature of the translation output is rooted minimally in\n      the fact that QEMU's OpenFirmware device paths cannot carry pathnames\n      within filesystems. There's no way to specify eg.\n\n        \\EFI\\fedora\\shim.efi\n\n      in an OFW device path, therefore a UEFI device path translated from an\n      OFW device path can at best be a prefix (not a full match) of a UEFI\n      device path that ends with \"\\EFI\\fedora\\shim.efi\".\n\n      - IDE disk, IDE CD-ROM:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/ide@1,1/drive@0/disk@0\n               ^         ^ ^       ^      ^\n               |         | |       |      master or slave\n               |         | |       primary or secondary\n               |         PCI slot \u0026 function holding IDE controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefix:\n\n          PciRoot(0x0)/Pci(0x1,0x1)/Ata(Primary,Master,0x0)\n                                                       ^\n                                                       fixed LUN\n\n      - Floppy disk:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/isa@1/fdc@03f0/floppy@0\n               ^         ^     ^           ^\n               |         |     |           A: or B:\n               |         |     ISA controller io-port (hex)\n               |         PCI slot holding ISA controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefix:\n\n          PciRoot(0x0)/Pci(0x1,0x0)/Floppy(0x0)\n                                           ^\n                                           ACPI UID (A: or B:)\n\n      - Virtio-block disk:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/scsi@6[,3]/disk@0,0\n               ^          ^  ^       ^ ^\n               |          |  |       fixed\n               |          |  PCI function corresponding to disk (optional)\n               |          PCI slot holding disk\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x6,0x0)/HD(\n          PciRoot(0x0)/Pci(0x6,0x3)/HD(\n\n      - Virtio-scsi disk and virtio-scsi passthrough:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/scsi@7[,3]/channel@0/disk@2,3\n               ^          ^             ^      ^ ^\n               |          |             |      | LUN\n               |          |             |      target\n               |          |             channel (unused, fixed 0)\n               |          PCI slot[, function] holding SCSI controller\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x7,0x0)/Scsi(0x2,0x3)\n          PciRoot(0x0)/Pci(0x7,0x3)/Scsi(0x2,0x3)\n\n      - Emulated and passed-through (physical) network cards:\n\n        OpenFirmware device path:\n\n          /pci@i0cf8/ethernet@3[,2]\n               ^              ^\n               |              PCI slot[, function] holding Ethernet card\n               PCI root at system bus port, PIO\n\n        UEFI device path prefixes (dependent on the presence of a nonzero PCI\n        function in the OFW device path):\n\n          PciRoot(0x0)/Pci(0x3,0x0)\n          PciRoot(0x0)/Pci(0x3,0x2)\n\nVirtio drivers\n..............\n\nUEFI abstracts various types of hardware resources into protocols, and allows\nfirmware developers to implement those protocols in device drivers. The Virtio\nSpecification defines various types of virtual hardware for virtual machines.\nConnecting the two specifications, OVMF provides UEFI drivers for QEMU's\nvirtio-block, virtio-scsi, and virtio-net devices.\n\nThe following diagram presents the protocol and driver stack related to Virtio\ndevices in edk2 and OVMF. Each node in the graph identifies a protocol and/or\nthe edk2 driver that produces it. Nodes on the top are more abstract.\n\n  EFI_BLOCK_IO_PROTOCOL                             EFI_SIMPLE_NETWORK_PROTOCOL\n  [OvmfPkg/VirtioBlkDxe]                              [OvmfPkg/VirtioNetDxe]\n             |                                                   |\n             |         EFI_EXT_SCSI_PASS_THRU_PROTOCOL           |\n             |             [OvmfPkg/VirtioScsiDxe]               |\n             |                        |                          |\n             +------------------------+--------------------------+\n                                      |\n                           VIRTIO_DEVICE_PROTOCOL\n                                      |\n                +---------------------+---------------------+\n                |                                           |\n  [OvmfPkg/VirtioPciDeviceDxe]                  [custom platform drivers]\n                |                                           |\n                |                                           |\n       EFI_PCI_IO_PROTOCOL                [OvmfPkg/Library/VirtioMmioDeviceLib]\n [MdeModulePkg/Bus/Pci/PciBusDxe]              direct MMIO register access\n\nThe top three drivers produce standard UEFI abstractions: the Block IO\nProtocol, the Extended SCSI Pass Thru Protocol, and the Simple Network\nProtocol, for virtio-block, virtio-scsi, and virtio-net devices, respectively.\n\nComparing these device-specific virtio drivers to each other, we can determine:\n\n- They all conform to the UEFI Driver Model. This means that their entry point\n  functions don't immediately start to search for devices and to drive them,\n  they only register instances of the EFI_DRIVER_BINDING_PROTOCOL. The UEFI\n  Driver Model then enumerates devices and chains matching drivers\n  automatically.\n\n- They are as minimal as possible, while remaining correct (refer to source\n  code comments for details). For example, VirtioBlkDxe and VirtioScsiDxe both\n  support only one request in flight.\n\n  In theory, VirtioBlkDxe could implement EFI_BLOCK_IO2_PROTOCOL, which allows\n  queueing. Similarly, VirtioScsiDxe does not support the non-blocking mode of\n  EFI_EXT_SCSI_PASS_THRU_PROTOCOL.PassThru(). (Which is permitted by the UEFI\n  specification.) Both VirtioBlkDxe and VirtioScsiDxe delegate synchronous\n  request handling to \"OvmfPkg/Library/VirtioLib\". This limitation helps keep\n  the implementation simple, and testing thus far seems to imply satisfactory\n  performance, for a virtual boot firmware.\n\n  VirtioNetDxe cannot avoid queueing, because EFI_SIMPLE_NETWORK_PROTOCOL\n  requires it on the interface level. Consequently, VirtioNetDxe is\n  significantly more complex than VirtioBlkDxe and VirtioScsiDxe. Technical\n  notes are provided in \"OvmfPkg/VirtioNetDxe/TechNotes.txt\".\n\n- None of these drivers access hardware directly. Instead, the Virtio Device\n  Protocol (OvmfPkg/Include/Protocol/VirtioDevice.h) collects / extracts virtio\n  operations defined in the Virtio Specification, and these backend-independent\n  virtio device drivers go through the abstract VIRTIO_DEVICE_PROTOCOL.\n\n  IMPORTANT: the VIRTIO_DEVICE_PROTOCOL is not a standard UEFI protocol. It is\n  internal to edk2 and not described in the UEFI specification. It should only\n  be used by drivers and applications that live inside the edk2 source tree.\n\nCurrently two providers exist for VIRTIO_DEVICE_PROTOCOL:\n\n- The first one is the \"more traditional\" virtio-pci backend, implemented by\n  OvmfPkg/VirtioPciDeviceDxe. This driver also complies with the UEFI Driver\n  Model. It consumes an instance of the EFI_PCI_IO_PROTOCOL, and, if the PCI\n  device/function under probing appears to be a virtio device, it produces a\n  Virtio Device Protocol instance for it. The driver translates abstract virtio\n  operations to PCI accesses.\n\n- The second provider, the virtio-mmio backend, is a library, not a driver,\n  living in OvmfPkg/Library/VirtioMmioDeviceLib. This library translates\n  abstract virtio operations to MMIO accesses.\n\n  The virtio-mmio backend is only a library -- rather than a standalone, UEFI\n  Driver Model-compliant driver -- because the type of resource it consumes, an\n  MMIO register block base address, is not enumerable.\n\n  In other words, while the PCI root bridge driver and the PCI bus driver\n  produce instances of EFI_PCI_IO_PROTOCOL automatically, thereby enabling the\n  UEFI Driver Model to probe devices and stack up drivers automatically, no\n  such enumeration exists for MMIO register blocks.\n\n  For this reason, VirtioMmioDeviceLib needs to be linked into thin, custom\n  platform drivers that dispose over this kind of information. As soon as a\n  driver knows about the MMIO register block base addresses, it can pass each\n  to the library, and then the VIRTIO_DEVICE_PROTOCOL will be instantiated\n  (assuming a valid virtio-mmio register block of course). From that point on\n  the UEFI Driver Model again takes care of the chaining.\n\n  Typically, such a custom driver does not conform to the UEFI Driver Model\n  (because that would presuppose auto-enumeration for MMIO register blocks).\n  Hence it has the following responsibilities:\n\n  - it shall behave as a \"wrapper\" UEFI driver around the library,\n\n  - it shall know virtio-mmio base addresses,\n\n  - in its entry point function, it shall create a new UEFI handle with an\n    instance of the EFI_DEVICE_PATH_PROTOCOL for each virtio-mmio device it\n    knows the base address for,\n\n  - it shall call VirtioMmioInstallDevice() on those handles, with the\n    corresponding base addresses.\n\n  OVMF itself does not employ VirtioMmioDeviceLib. However, the library is used\n  (or has been tested as Proof-of-Concept) in the following 64-bit and 32-bit\n  ARM emulator setups:\n\n  - in \"RTSM_VE_FOUNDATIONV8_EFI.fd\" and \"FVP_AARCH64_EFI.fd\", on ARM Holdings'\n    ARM(R) v8-A Foundation Model and ARM(R) AEMv8-A Base Platform FVP\n    emulators, respectively:\n\n                           EFI_BLOCK_IO_PROTOCOL\n                           [OvmfPkg/VirtioBlkDxe]\n                                      |\n                           VIRTIO_DEVICE_PROTOCOL\n        [ArmPlatformPkg/ArmVExpressPkg/ArmVExpressDxe/ArmFvpDxe.inf]\n                                      |\n                    [OvmfPkg/Library/VirtioMmioDeviceLib]\n                         direct MMIO register access\n\n  - in \"RTSM_VE_CORTEX-A15_EFI.fd\" and \"RTSM_VE_CORTEX-A15_MPCORE_EFI.fd\", on\n    \"qemu-system-arm -M vexpress-a15\":\n\n        EFI_BLOCK_IO_PROTOCOL            EFI_SIMPLE_NETWORK_PROTOCOL\n        [OvmfPkg/VirtioBlkDxe]             [OvmfPkg/VirtioNetDxe]\n                   |                                  |\n                   +------------------+---------------+\n                                      |\n                           VIRTIO_DEVICE_PROTOCOL\n        [ArmPlatformPkg/ArmVExpressPkg/ArmVExpressDxe/ArmFvpDxe.inf]\n                                      |\n                    [OvmfPkg/Library/VirtioMmioDeviceLib]\n                         direct MMIO register access\n\n  In the above ARM / VirtioMmioDeviceLib configurations, VirtioBlkDxe was\n  tested with booting Linux distributions, while VirtioNetDxe was tested with\n  pinging public IPv4 addresses from the UEFI shell.\n\nPlatform Driver\n...............\n\nSometimes, elements of persistent firmware configuration are best exposed to\nthe user in a friendly way. OVMF's platform driver (OvmfPkg/PlatformDxe)\npresents such settings on the \"OVMF Platform Configuration\" dialog:\n\n- Press ESC on the TianoCore splash screen,\n- Navigate to Device Manager | OVMF Platform Configuration.\n\nAt the moment, OVMF's platform driver handles only one setting: the preferred\ngraphics resolution. This is useful for two purposes:\n\n- Some UEFI shell commands, like DRIVERS and DEVICES, benefit from a wide\n  display. Using the MODE shell command, the user can switch to a larger text\n  resolution (limited by the graphics resolution), and see the command output\n  in a more easily consumable way.\n\n  [RHEL] The list of text modes available to the MODE command is also limited\n         by ConSplitterDxe (found under MdeModulePkg/Universal/Console).\n         ConSplitterDxe builds an intersection of text modes that are\n         simultaneously supported by all consoles that ConSplitterDxe\n         multiplexes console output to.\n\n         In practice, the strongest text mode restriction comes from\n         TerminalDxe, which provides console I/O on serial ports. TerminalDxe\n         has a very limited built-in list of text modes, heavily pruning the\n         intersection built by ConSplitterDxe, and made available to the MODE\n         command.\n\n         On the Red Hat Enterprise Linux 7.1 host, TerminalDxe's list of modes\n         has been extended with text resolutions that match the Spice QXL GPU's\n         common graphics resolutions. This way a \"full screen\" text mode should\n         always be available in the MODE command.\n\n- The other advantage of controlling the graphics resolution lies with UEFI\n  operating systems that don't (yet) have a native driver for QEMU's virtual\n  video cards  -- eg. the Spice QXL GPU. Such OSes may choose to inherit the\n  properties of OVMF's EFI_GRAPHICS_OUTPUT_PROTOCOL (provided by\n  OvmfPkg/QemuVideoDxe, see later).\n\n  Although the display can be used at runtime in such cases, by direct\n  framebuffer access, its properties, for example, the resolution, cannot be\n  modified. The platform driver allows the user to select the preferred GOP\n  resolution, reboot, and let the guest OS inherit that preferred resolution.\n\nThe platform driver has three access points: the \"normal\" driver entry point, a\nset of HII callbacks, and a GOP installation callback.\n\n(1) Driver entry point: the PlatformInit() function.\n\n    (a) First, this function loads any available settings, and makes them take\n        effect. For the preferred graphics resolution in particular, this means\n        setting the following PCDs:\n\n          gEfiMdeModulePkgTokenSpaceGuid.PcdVideoHorizontalResolution\n          gEfiMdeModulePkgTokenSpaceGuid.PcdVideoVerticalResolution\n\n        These PCDs influence the GraphicsConsoleDxe driver (located under\n        MdeModulePkg/Universal/Console), which switches to the preferred\n        graphics mode, and produces EFI_SIMPLE_TEXT_OUTPUT_PROTOCOLs on GOPs:\n\n                    EFI_SIMPLE_TEXT_OUTPUT_PROTOCOL\n          [MdeModulePkg/Universal/Console/GraphicsConsoleDxe]\n                                   |\n                      EFI_GRAPHICS_OUTPUT_PROTOCOL\n                         [OvmfPkg/QemuVideoDxe]\n                                   |\n                          EFI_PCI_IO_PROTOCOL\n                   [MdeModulePkg/Bus/Pci/PciBusDxe]\n\n  (b) Second, the driver entry point registers the user interface, including\n      HII callbacks.\n\n  (c) Third, the driver entry point registers a GOP installation callback.\n\n(2) HII callbacks and the user interface.\n\n    The Human Interface Infrastructure (HII) \"is a set of protocols that allow\n    a UEFI driver to provide the ability to register user interface and\n    configuration content with the platform firmware\".\n\n    OVMF's platform driver:\n\n    - provides a static, basic, visual form (PlatformForms.vfr), written in the\n      Visual Forms Representation language,\n\n    - includes a UCS-16 encoded message catalog (Platform.uni),\n\n    - includes source code that dynamically populates parts of the form, with\n      the help of MdeModulePkg/Library/UefiHiiLib -- this library simplifies\n      the handling of IFR (Internal Forms Representation) opcodes,\n\n    - processes form actions that the user takes (Callback() function),\n\n    - loads and saves platform configuration in a private, non-volatile\n      variable (ExtractConfig() and RouteConfig() functions).\n\n    The ExtractConfig() HII callback implements the following stack of\n    conversions, for loading configuration and presenting it to the user:\n\n          MultiConfigAltResp       -- form engine / HII communication\n                  ^\n                  |\n           [BlockToConfig]\n                  |\n           MAIN_FORM_STATE         -- binary representation of form/widget\n                  ^                   state\n                  |\n      [PlatformConfigToFormState]\n                  |\n           PLATFORM_CONFIG         -- accessible to DXE and UEFI drivers\n                  ^\n                  |\n         [PlatformConfigLoad]\n                  |\n        UEFI non-volatile variable -- accessible to external utilities\n\n    The layers are very similar for the reverse direction, ie. when taking\n    input from the user, and saving the configuration (RouteConfig() HII\n    callback):\n\n             ConfigResp            -- form engine / HII communication\n                  |\n           [ConfigToBlock]\n                  |\n                  v\n           MAIN_FORM_STATE         -- binary representation of form/widget\n                  |                   state\n      [FormStateToPlatformConfig]\n                  |\n                  v\n           PLATFORM_CONFIG         -- accessible to DXE and UEFI drivers\n                  |\n         [PlatformConfigSave]\n                  |\n                  v\n        UEFI non-volatile variable -- accessible to external utilities\n\n(3) When the platform driver starts, a GOP may not be available yet. Thus the\n    driver entry point registers a callback (the GopInstalled() function) for\n    GOP installations.\n\n    When the first GOP is produced (usually by QemuVideoDxe, or potentially by\n    a third party video driver), PlatformDxe retrieves the list of graphics\n    modes the GOP supports, and dynamically populates the drop-down list of\n    available resolutions on the form. The GOP installation callback is then\n    removed.\n\nVideo driver\n............\n\nOvmfPkg/QemuVideoDxe is OVMF's built-in video driver. We can divide its\nservices in two parts: graphics output protocol (primary), and Int10h (VBE)\nshim (secondary).\n\n(1) QemuVideoDxe conforms to the UEFI Driver Model; it produces an instance of\n    the EFI_GRAPHICS_OUTPUT_PROTOCOL (GOP) on each PCI display that it supports\n    and is connected to:\n\n                      EFI_GRAPHICS_OUTPUT_PROTOCOL\n                         [OvmfPkg/QemuVideoDxe]\n                                   |\n                          EFI_PCI_IO_PROTOCOL\n                   [MdeModulePkg/Bus/Pci/PciBusDxe]\n\n    It supports the following QEMU video cards:\n\n    - Cirrus 5430 (\"-device cirrus-vga\"),\n    - Standard VGA (\"-device VGA\"),\n    - QXL VGA (\"-device qxl-vga\", \"-device qxl\").\n\n    For Cirrus the following resolutions and color depths are available:\n    640x480x32, 800x600x32, 1024x768x24. On stdvga and QXL a long list of\n    resolutions is available. The list is filtered against the frame buffer\n    size during initialization.\n\n    The size of the QXL VGA compatibility framebuffer can be changed with the\n\n      -device qxl-vga,vgamem_mb=$NUM_MB\n\n    QEMU option. If $NUM_MB exceeds 32, then the following is necessary\n    instead:\n\n      -device qxl-vga,vgamem_mb=$NUM_MB,ram_size_mb=$((NUM_MB*2))\n\n    because the compatibility framebuffer can't cover more than half of PCI BAR\n    #0. The latter defaults to 64MB in size, and is controlled by the\n    \"ram_size_mb\" property.\n\n(2) When QemuVideoDxe binds the first Standard VGA or QXL VGA device, and there\n    is no real VGA BIOS present in the C to F segments (which could originate\n    from a legacy PCI option ROM -- refer to \"Compatibility Support Module\n    (CSM)\"), then QemuVideoDxe installs a minimal, \"fake\" VGA BIOS -- an Int10h\n    (VBE) \"shim\".\n\n    The shim is implemented in 16-bit assembly in\n    \"OvmfPkg/QemuVideoDxe/VbeShim.asm\". The \"VbeShim.sh\" shell script assembles\n    it and formats it as a C array (\"VbeShim.h\") with the help of the \"nasm\"\n    utility. The driver's InstallVbeShim() function copies the shim in place\n    (the C segment), and fills in the VBE Info and VBE Mode Info structures.\n    The real-mode 10h interrupt vector is pointed to the shim's handler.\n\n    The shim is (correctly) irrelevant and invisible for all UEFI operating\n    systems we know about -- except Windows Server 2008 R2 and other Windows\n    operating systems in that family.\n\n    Namely, the Windows 2008 R2 SP1 (and Windows 7) UEFI guest's default video\n    driver dereferences the real mode Int10h vector, loads the pointed-to\n    handler code, and executes what it thinks to be VGA BIOS services in an\n    internal real-mode emulator. Consequently, video mode switching used not to\n    work in Windows 2008 R2 SP1 when it ran on the \"pure UEFI\" build of OVMF,\n    making the guest uninstallable. Hence the (otherwise optional, non-default)\n    Compatibility Support Module (CSM) ended up a requirement for running such\n    guests.\n\n    The hard dependency on the sophisticated SeaBIOS CSM and the complex\n    supporting edk2 infrastructure, for enabling this family of guests, was\n    considered suboptimal by some members of the upstream community,\n\n    [RHEL] and was certainly considered a serious maintenance disadvantage for\n           Red Hat Enterprise Linux 7.1 hosts.\n\n    Thus, the shim has been collaboratively developed for the Windows 7 /\n    Windows Server 2008 R2 family. The shim provides a real stdvga / QXL\n    implementation for the few services that are in fact necessary for the\n    Windows 2008 R2 SP1 (and Windows 7) UEFI guest, plus some \"fakes\" that the\n    guest invokes but whose effect is not important. The only supported mode is\n    1024x768x32, which is enough to install the guest and then upgrade its\n    video driver to the full-featured QXL XDDM one.\n\n    The C segment is not present in the UEFI memory map prepared by OVMF.\n    Memory space that would cover it is never added (either in PEI, in the form\n    of memory resource descriptor HOBs, or in DXE, via gDS-\u003eAddMemorySpace()).\n    This way the handler body is invisible to all other UEFI guests, and the\n    rest of edk2.\n\n    The Int10h real-mode IVT entry is covered with a Boot Services Code page,\n    making that too inaccessible to the rest of edk2. Due to the allocation\n    type, UEFI guest OSes different from the Windows Server 2008 family can\n    reclaim the page at zero. (The Windows 2008 family accesses that page\n    regardless of the allocation type.)\n\nAfterword\n---------\n\nAfter the bulk of this document was written in July 2014, OVMF development has\nnot stopped. To name two significant code contributions from the community: in\nJanuary 2015, OVMF runs on the \"q35\" machine type of QEMU, and it features a\ndriver for Xen paravirtual block devices (and another for the underlying Xen\nbus).\n\nFurthermore, a dedicated virtualization platform has been contributed to\nArmPlatformPkg that plays a role parallel to OvmfPkg's. It targets the \"virt\"\nmachine type of qemu-system-arm and qemu-system-aarch64. Parts of OvmfPkg are\nbeing refactored and modularized so they can be reused in\n\"ArmPlatformPkg/ArmVirtualizationPkg/ArmVirtualizationQemu.dsc\".\n\n\n\n","wordCount":13699,"tags":["uefi","archive"],"metadata":{},"created":"2023-08-14T02:59:45.103584636Z","modified":"2023-08-14T03:01:56.744512244Z","checksum":"eb1228503d425106e2316fc7bec7a792082d549efa1901a50c77fa157504165a"},
    {"filename":"n9bxzpge.md","filenameStem":"n9bxzpge","path":"n9bxzpge.md","absPath":"/home/khadd/mynotes/n9bxzpge.md","title":"Obfuscated execution techniques","link":"[[n9bxzpge]]","lead":"#oblivious","body":"#oblivious \n\nObfuscated execution techniques transform the program such that all code and memory accesses are constant regardless of sensitive input.\n\n\nThis type of protection commonly has very high overheads, due to the threat model being too strict (attackers with perfect observation of program counter and memory accesses).\nHowever, in practice, the observable side channels are usually more coarse-grained, at cache-line or page-fault-level. For instance, in SGX, attacker side-channels usually need page-fault-level trace before performing more fine-grained cache side-channel attacks. Hence, been works that only target page-fault-level leakage ([[5kzr3hwx]]), for more practical protection.\n\n# Raccoon\n@rane2015raccoon was the first to propose this idea. It transforms the program to use predicated execution to execute *both* branches of a sensitive-dependent branch.\nA transactional-like memory\n\nThis type of protection can protect both code and data accesses. \n\nOverheads of this is about 9X @zhang2020klotski.\n\n# Constantine\n@borrello2021constantine is currently the state-of-the-art.\n\n\n```c\nfn handle_pagefault(addr):\n  idx = virt_addr_to_oram_idx(addr);\n  oram_fetch_to_cache(idx);\n  map_vaddr_to_cache(addr, 0x1000);\n  return\n```","snippets":["#oblivious"],"rawContent":"# Obfuscated execution techniques\n#oblivious \n\nObfuscated execution techniques transform the program such that all code and memory accesses are constant regardless of sensitive input.\n\n\nThis type of protection commonly has very high overheads, due to the threat model being too strict (attackers with perfect observation of program counter and memory accesses).\nHowever, in practice, the observable side channels are usually more coarse-grained, at cache-line or page-fault-level. For instance, in SGX, attacker side-channels usually need page-fault-level trace before performing more fine-grained cache side-channel attacks. Hence, been works that only target page-fault-level leakage ([[5kzr3hwx]]), for more practical protection.\n\n# Raccoon\n@rane2015raccoon was the first to propose this idea. It transforms the program to use predicated execution to execute *both* branches of a sensitive-dependent branch.\nA transactional-like memory\n\nThis type of protection can protect both code and data accesses. \n\nOverheads of this is about 9X @zhang2020klotski.\n\n# Constantine\n@borrello2021constantine is currently the state-of-the-art.\n\n\n```c\nfn handle_pagefault(addr):\n  idx = virt_addr_to_oram_idx(addr);\n  oram_fetch_to_cache(idx);\n  map_vaddr_to_cache(addr, 0x1000);\n  return\n```\n\n","wordCount":161,"tags":["oblivious"],"metadata":{},"created":"2023-06-19T03:04:24.903375118Z","modified":"2023-07-27T09:50:43.274155999Z","checksum":"a609ec58f59e9bf37aeda61b4916cb8d954eedb99858ab345e8a4c9e07359207"},
    {"filename":"b4nls7up.md","filenameStem":"b4nls7up","path":"b4nls7up.md","absPath":"/home/khadd/mynotes/b4nls7up.md","title":"Oblivious paging against controlled-channel","link":"[[b4nls7up]]","lead":"#tee #sgx #oblivous #controlled-channel","body":"#tee #sgx #oblivous #controlled-channel\n\nOblivious paging is a direction to tackle the paging control-channel in SGX, by enabling the enclave with the ability to perform page table management. \n\n\nPrevious work on this tries to implement *self-paging enclaves*. Self-paging enclaves let the enclaves manage their own memory mappings. Page faults to the enclave-managed pages are forwarded to the enclave fault handler, so the faulting address is hidden from the OS.\n\n\n\n\n\n@aga2019invisipage uses two page tables, as inspired by @costan2016sanctum, where one table is maintained by the enclave, and the other is maintained by the OS. The OS-maintained page table is similar to the traditional one. The enclave page table is used for paging of EPC pages.\nThe memory for enclave page table is stored in the EPC, and \nAn additional page table base register is added, and when an EPC page fault occur, the the private page table is walked instead.\n\n@orenbach2020autarky argue that ORAM-based oblivious paging requires intrusive hardware modifications to the CPU, thus is not practical.\n\n# Challenges\n## Supporting for demand paging\nDemand paging allows the OS to map the memory page into the address space only when the process actually touch the page. When it is touch, a page fault will be raised, informing the OS to map the page the the process's page table.\n\nDemand demand paging obviously conflict with the goal of hiding page faults from the OS.\n\nA simple solution is to statically separate public and private pages, such that fault from the enclaves are served by the enclave never served by the OS. This design creates an additional problem: it rob the ability to perform memory management from the OS. Once a private page has been mapped, the OS no longer hav the ability to reclaim the page from the enclave. A malicious enclave can prevent the OS from ever reusing the page. Moreover, once an enclave page is reclaimed, the OS can still learn about accesses on the page @aga2019invisipage.","snippets":["#tee #sgx #oblivous #controlled-channel"],"rawContent":"# Oblivious paging against controlled-channel\n#tee #sgx #oblivous #controlled-channel\n\nOblivious paging is a direction to tackle the paging control-channel in SGX, by enabling the enclave with the ability to perform page table management. \n\n\nPrevious work on this tries to implement *self-paging enclaves*. Self-paging enclaves let the enclaves manage their own memory mappings. Page faults to the enclave-managed pages are forwarded to the enclave fault handler, so the faulting address is hidden from the OS.\n\n\n\n\n\n@aga2019invisipage uses two page tables, as inspired by @costan2016sanctum, where one table is maintained by the enclave, and the other is maintained by the OS. The OS-maintained page table is similar to the traditional one. The enclave page table is used for paging of EPC pages.\nThe memory for enclave page table is stored in the EPC, and \nAn additional page table base register is added, and when an EPC page fault occur, the the private page table is walked instead.\n\n@orenbach2020autarky argue that ORAM-based oblivious paging requires intrusive hardware modifications to the CPU, thus is not practical.\n\n# Challenges\n## Supporting for demand paging\nDemand paging allows the OS to map the memory page into the address space only when the process actually touch the page. When it is touch, a page fault will be raised, informing the OS to map the page the the process's page table.\n\nDemand demand paging obviously conflict with the goal of hiding page faults from the OS.\n\nA simple solution is to statically separate public and private pages, such that fault from the enclaves are served by the enclave never served by the OS. This design creates an additional problem: it rob the ability to perform memory management from the OS. Once a private page has been mapped, the OS no longer hav the ability to reclaim the page from the enclave. A malicious enclave can prevent the OS from ever reusing the page. Moreover, once an enclave page is reclaimed, the OS can still learn about accesses on the page @aga2019invisipage.\n\n\n","wordCount":333,"tags":["sgx","tee","controlled-channel","oblivous"],"metadata":{},"created":"2023-06-12T05:12:49.854971447Z","modified":"2023-06-19T02:01:17.89523677Z","checksum":"f93160258229935ddfca7fff009d5256513c79af849988e55b2652cb7033d37c"},
    {"filename":"gel6dwih.md","filenameStem":"gel6dwih","path":"projects/gel6dwih.md","absPath":"/home/khadd/mynotes/projects/gel6dwih.md","title":"Oblivium: Paging-powered Obfuscated Execution","link":"[[projects/gel6dwih]]","lead":"#project","body":"#project\n\n\n\n\n\n# ORAM operations\n## EvictPath\n\nIt look at blocks inside the stash and try to push them to the ORAM tree.\n\n# Page fault handler\n```mermaid\nflowchart LR\n  test\n  dec{tet}\n```\n\n# FAQ\n## How does malloc interacts with the oblivious paging system?\nmalloc only needs to be aware of the memory ranges containing the ORAM storage.\n\nIn traditional malloc, heap memory is expanded on-demand. \n\nWe can grow the tree, following @aga2019invisipage.\n\nOtherwise, malloc is agnostic of the oblivious paging system.\n`malloc` is just an abstraction over the virtual address space. `malloc` takes a piece out of the virtual address space, while `free` returns that piece. Hence, it does not care which physical backing is used. \n\nOn the other hand, the oblivious paging maintain the physical memory accesses and must not change the virtual address maintained by `malloc`.\n\nThe paging system need to maintain two invariants:\n1. It must not touch the virtual address maintained by the heap allocator to be compatible.\n2. a virtual address must points to the corresponding content, regardless of the physical address.\n\n\nIf `0xff100` points to page with content `AAAA`, the oblivious paging system must make sure that the when the `0xff100` is accessed later, the content must still be `AAAA`. This must be done by data copy.\n\n### How do you bootstrap malloc?\nThere seem to be a chicken-and-egg problem in unikraft. To add a virtual address range to the memory allocator, the allocator must write its metadata to some pages within the address range.\n\n### Security tradeoff vs. ORAM\nUsing NPF, attacker can probably infer read/write within the stash.\n\nWe cannot intercept read/write after it is mapped to the ORAM, so the frequency of access to the stash can be leaked. However, maybe it is not a big deal, since it is the same for klotski.\n\n\n#### Guarantees\nAll memory accesses of the application are coming from the stash.\n\nOn-demand accesses \n\n\n### When do you perform ORAM operations? \n#### Update the page mapping\nInvariant must be maintained: \nEvery virtual address mapping must either points to an address inside the stash, or a path on ORAM.\n\nLet say we initially allocate memory directly within the stash.\n\nOn stash allocation, they must be updated to points to stash.\n\nWhen these are evicted from the stash, the mapping must be updated to a block on a tree. The blocks can be chosen randomly.\n\n\n#### Evict path\nIn Path ORAM, this is called on every read and write.\nIn Ring ORAM, this is called deterministically after $G$ accesses.\n\n\nCan this be called only when the stash reaches certain threshold? \n- Possibly. What is the worse that can be inferred? Maybe there is a reason that all ORAM require deterministic. \n- Maybe the information that *the application access to ORAM memory more, given some input* can be leaked. This can help infer the input. Hence eviction must be deterministic.\n- On the other hand, accesses to the stash already leak similar information, since we cannot capture all accesses to a virtual address when they are mapped, so deterministic eviction cannot be performed.\n  - Does SEV allows the VM to acknowledge NPF? If so, we can perform eviction based on this.\n  - No, VM is not aware of NPF.\n~~There seem to be a chicken-and-egg problem in unikraft. To add a virtual address range to the memory allocator, the allocator must write its metadata to some pages within the address range.~~\n- Nope there isn't.\nDoes the block size need to be page size?\nIt don't need to be. ORAM block can be smaller than a page. 2KB blocks works, since accesses to physical memory will be randomized anyway, regardless of block sizes.\n\nMaking block size page size may be easier ot maintain, since frame allocator allocates memory at page granularity (not sure if related).\nAlso, memory mapping has page granularity (not sure if related),\n\nAllocating a new page on page faults may even leads to more memory consumption. An address `0x40000fff` may have offset `0x0fff`, which is at the ned of the page boundary. If we map it to a new physical page inside stash, say, `0x1000`, then only the end of the page is used.  Access to `0x40001000` will continue to fault, which leads to alocation of another stash block (e.g., `0x2000`).\n\n### Sub-page block size\nTo have sub-page block size, we needs to map two virtual addresses to the same page. \n\n# Notes\n## 2023-07-06\n- Modified `ukvmem` to export the PTE to our fault handler. \n## 2023-07-07\n- Use a reverse mapping table that map from block_id into vaddr, for *blocks inside tree*\n- Stash-only posmap keeps track of blocks within  the stash\n\n## 2023-07-08\n```c\n\u003cbbuddy.c @  155\u003e Assertion failure: memr != ((void *) 0)\n```\n- This bug is probably caused by wrong address mapping in pte\n- Must FLUSH TLB on any PT UPDATE\n  - Probably not the problem...  \n- sanity checks: PTE must exist\n\n- Somehow there is more stash blocks than ORAM blocks\n  - It make sense, since the tree blocks are limited, so blocks must remain in the stash. \n- TODO: `do_unhandled_trap`: need investigation :(\n## 2023-07-12\n- Can we retrofit page table for reversed mapping?\n- How do we reduce the number of page table update?\n## 2023-07-13\n- Refactored functions to take contexts.\n- Found that function to get bucket_idx to block_id is completely wrong\n## 2023-07-16\n- Refactor again, with generalized use cases in mind.\n## 2023-07-19\n- Fixed problems with ISR. It's probably caused by a missing TLB flush on eviction path.\n- Found some conundrums about stash sizes/stash usage in ORAM. Maybe implementing Ring ORAM from the start would avoid them.\n- We don't need to update the page table entry for every block read (unless you want to keep the block inside the stash).\n\n## 2023-07-20\n- Found a bug that cause infinite loop. If two consecutive faults happen due to a single instruction (because of XMM crossing the page boundary), and the second ORAM access evicts the block fetched by the first ORAM access, it will loop forever.  \n\n```\n →   0x12a82b \u003cbench_random_access+139\u003e movups XMMWORD PTR [r15], xmm0\n     0x12a82f \u003cbench_random_access+143\u003e movups XMMWORD PTR [r15+0x10], xmm0\n     0x12a834 \u003cbench_random_access+148\u003e movups XMMWORD PTR [r15+0x20], xmm0\n     0x12a839 \u003cbench_random_access+153\u003e movups XMMWORD PTR [r15+0x30], xmm0\n```\n- This can be solved by fetching two pages in one ORAM access. Maybe check if the falt address and the next page is smaller than 128 bits (XMM register size). If it is, then fetch the next page. \n- @ren2013design mentions some techniques for improving locality of ORAM.\n\n- Passing a *keep list* to evict may be a good idea?\n\n## 2023-07-22\n- Maybe the title could be Oblivious VMA: an OS-powered defense agaisnt controlled channel attacks\n- For more information about VMAs, could refer to @gupta2021rebooting\n## 2023-07-25\n- Emulation of instruction is harder than it seems.\n- Probably need to add an emulation engine. Look at [Ceberus](https://github.com/ku-leuven-msec/The-Cerberus-Project/tree/main/cerberus_ReMon) \n  - [ReMon](https://github.com/ReMon-MVEE/ReMon/tree/master/MVEE/Src/arch/amd64/shared_mem)\n  - \n\n## 2023-07-28\n- *Reads* also need to be emulated.\n- \n\n## 2023-07-29\n```cpp\n// Old code\nauto* typed_destination = *((uint64_t*)((unsigned long long))monitor_base + offset);\n// New code:\nMAP_FAULTING_PADDR(destination);\nuint64_t* typed_destination = (uint64_t*) destination\n```\nThe old code obtains the destination addr from some memory. The new code just map the faulting address and used as destination\n\n\n\n## 2023-09-05\n\n## 2023-09-08","snippets":["#project"],"rawContent":"# Oblivium: Paging-powered Obfuscated Execution\n#project\n\n\n\n\n\n# ORAM operations\n## EvictPath\n\nIt look at blocks inside the stash and try to push them to the ORAM tree.\n\n# Page fault handler\n```mermaid\nflowchart LR\n  test\n  dec{tet}\n```\n\n# FAQ\n## How does malloc interacts with the oblivious paging system?\nmalloc only needs to be aware of the memory ranges containing the ORAM storage.\n\nIn traditional malloc, heap memory is expanded on-demand. \n\nWe can grow the tree, following @aga2019invisipage.\n\nOtherwise, malloc is agnostic of the oblivious paging system.\n`malloc` is just an abstraction over the virtual address space. `malloc` takes a piece out of the virtual address space, while `free` returns that piece. Hence, it does not care which physical backing is used. \n\nOn the other hand, the oblivious paging maintain the physical memory accesses and must not change the virtual address maintained by `malloc`.\n\nThe paging system need to maintain two invariants:\n1. It must not touch the virtual address maintained by the heap allocator to be compatible.\n2. a virtual address must points to the corresponding content, regardless of the physical address.\n\n\nIf `0xff100` points to page with content `AAAA`, the oblivious paging system must make sure that the when the `0xff100` is accessed later, the content must still be `AAAA`. This must be done by data copy.\n\n### How do you bootstrap malloc?\nThere seem to be a chicken-and-egg problem in unikraft. To add a virtual address range to the memory allocator, the allocator must write its metadata to some pages within the address range.\n\n### Security tradeoff vs. ORAM\nUsing NPF, attacker can probably infer read/write within the stash.\n\nWe cannot intercept read/write after it is mapped to the ORAM, so the frequency of access to the stash can be leaked. However, maybe it is not a big deal, since it is the same for klotski.\n\n\n#### Guarantees\nAll memory accesses of the application are coming from the stash.\n\nOn-demand accesses \n\n\n### When do you perform ORAM operations? \n#### Update the page mapping\nInvariant must be maintained: \nEvery virtual address mapping must either points to an address inside the stash, or a path on ORAM.\n\nLet say we initially allocate memory directly within the stash.\n\nOn stash allocation, they must be updated to points to stash.\n\nWhen these are evicted from the stash, the mapping must be updated to a block on a tree. The blocks can be chosen randomly.\n\n\n#### Evict path\nIn Path ORAM, this is called on every read and write.\nIn Ring ORAM, this is called deterministically after $G$ accesses.\n\n\nCan this be called only when the stash reaches certain threshold? \n- Possibly. What is the worse that can be inferred? Maybe there is a reason that all ORAM require deterministic. \n- Maybe the information that *the application access to ORAM memory more, given some input* can be leaked. This can help infer the input. Hence eviction must be deterministic.\n- On the other hand, accesses to the stash already leak similar information, since we cannot capture all accesses to a virtual address when they are mapped, so deterministic eviction cannot be performed.\n  - Does SEV allows the VM to acknowledge NPF? If so, we can perform eviction based on this.\n  - No, VM is not aware of NPF.\n~~There seem to be a chicken-and-egg problem in unikraft. To add a virtual address range to the memory allocator, the allocator must write its metadata to some pages within the address range.~~\n- Nope there isn't.\nDoes the block size need to be page size?\nIt don't need to be. ORAM block can be smaller than a page. 2KB blocks works, since accesses to physical memory will be randomized anyway, regardless of block sizes.\n\nMaking block size page size may be easier ot maintain, since frame allocator allocates memory at page granularity (not sure if related).\nAlso, memory mapping has page granularity (not sure if related),\n\nAllocating a new page on page faults may even leads to more memory consumption. An address `0x40000fff` may have offset `0x0fff`, which is at the ned of the page boundary. If we map it to a new physical page inside stash, say, `0x1000`, then only the end of the page is used.  Access to `0x40001000` will continue to fault, which leads to alocation of another stash block (e.g., `0x2000`).\n\n### Sub-page block size\nTo have sub-page block size, we needs to map two virtual addresses to the same page. \n\n# Notes\n## 2023-07-06\n- Modified `ukvmem` to export the PTE to our fault handler. \n## 2023-07-07\n- Use a reverse mapping table that map from block_id into vaddr, for *blocks inside tree*\n- Stash-only posmap keeps track of blocks within  the stash\n\n## 2023-07-08\n```c\n\u003cbbuddy.c @  155\u003e Assertion failure: memr != ((void *) 0)\n```\n- This bug is probably caused by wrong address mapping in pte\n- Must FLUSH TLB on any PT UPDATE\n  - Probably not the problem...  \n- sanity checks: PTE must exist\n\n- Somehow there is more stash blocks than ORAM blocks\n  - It make sense, since the tree blocks are limited, so blocks must remain in the stash. \n- TODO: `do_unhandled_trap`: need investigation :(\n## 2023-07-12\n- Can we retrofit page table for reversed mapping?\n- How do we reduce the number of page table update?\n## 2023-07-13\n- Refactored functions to take contexts.\n- Found that function to get bucket_idx to block_id is completely wrong\n## 2023-07-16\n- Refactor again, with generalized use cases in mind.\n## 2023-07-19\n- Fixed problems with ISR. It's probably caused by a missing TLB flush on eviction path.\n- Found some conundrums about stash sizes/stash usage in ORAM. Maybe implementing Ring ORAM from the start would avoid them.\n- We don't need to update the page table entry for every block read (unless you want to keep the block inside the stash).\n\n## 2023-07-20\n- Found a bug that cause infinite loop. If two consecutive faults happen due to a single instruction (because of XMM crossing the page boundary), and the second ORAM access evicts the block fetched by the first ORAM access, it will loop forever.  \n\n```\n →   0x12a82b \u003cbench_random_access+139\u003e movups XMMWORD PTR [r15], xmm0\n     0x12a82f \u003cbench_random_access+143\u003e movups XMMWORD PTR [r15+0x10], xmm0\n     0x12a834 \u003cbench_random_access+148\u003e movups XMMWORD PTR [r15+0x20], xmm0\n     0x12a839 \u003cbench_random_access+153\u003e movups XMMWORD PTR [r15+0x30], xmm0\n```\n- This can be solved by fetching two pages in one ORAM access. Maybe check if the falt address and the next page is smaller than 128 bits (XMM register size). If it is, then fetch the next page. \n- @ren2013design mentions some techniques for improving locality of ORAM.\n\n- Passing a *keep list* to evict may be a good idea?\n\n## 2023-07-22\n- Maybe the title could be Oblivious VMA: an OS-powered defense agaisnt controlled channel attacks\n- For more information about VMAs, could refer to @gupta2021rebooting\n## 2023-07-25\n- Emulation of instruction is harder than it seems.\n- Probably need to add an emulation engine. Look at [Ceberus](https://github.com/ku-leuven-msec/The-Cerberus-Project/tree/main/cerberus_ReMon) \n  - [ReMon](https://github.com/ReMon-MVEE/ReMon/tree/master/MVEE/Src/arch/amd64/shared_mem)\n  - \n\n## 2023-07-28\n- *Reads* also need to be emulated.\n- \n\n## 2023-07-29\n```cpp\n// Old code\nauto* typed_destination = *((uint64_t*)((unsigned long long))monitor_base + offset);\n// New code:\nMAP_FAULTING_PADDR(destination);\nuint64_t* typed_destination = (uint64_t*) destination\n```\nThe old code obtains the destination addr from some memory. The new code just map the faulting address and used as destination\n\n\n\n## 2023-09-05\n\n## 2023-09-08\n","wordCount":1226,"tags":["project"],"metadata":{},"created":"2023-07-04T14:42:40.194861138Z","modified":"2023-09-08T07:51:59.941518133Z","checksum":"89521d7a4eb9ffedc7de52d35e692604bff83dcf5915d471a4cc6cd07cc6ed6e"},
    {"filename":"adn8i9cz.md","filenameStem":"adn8i9cz","path":"adn8i9cz.md","absPath":"/home/khadd/mynotes/adn8i9cz.md","title":"One sentence paper summary","link":"[[adn8i9cz]]","lead":"#writing #reading","body":"#writing #reading\n\nMost papers can be summarized into one sentence that capture the highest-level ideas. For instance,\n\u003e Obliviate introduces an data-oblivious file system using ORAM primitives.\n\u003e Capacity retrofit PAC and MTE primitives to enable capability-based access control for file and memory.\n\nIdeas that cannot be consolidated into one sentence is either over-complicated, not well-defined, and not well-contained.\n\nKnowing this has implications for both reading and writing.\n\nFirst, when reading a paper try to find the main ideas of the paper and summarize it into one sentence.\n\nSecond, when writing papers, identify the core idea of the in one sentence first. This will determine the scope of the paper and avoid over-complicating things. Moreover, it allows for concise writing. Each sentence/paragraph should contributes to the main idea.","snippets":["#writing #reading"],"rawContent":"# One sentence paper summary\n#writing #reading\n\nMost papers can be summarized into one sentence that capture the highest-level ideas. For instance,\n\u003e Obliviate introduces an data-oblivious file system using ORAM primitives.\n\u003e Capacity retrofit PAC and MTE primitives to enable capability-based access control for file and memory.\n\nIdeas that cannot be consolidated into one sentence is either over-complicated, not well-defined, and not well-contained.\n\nKnowing this has implications for both reading and writing.\n\nFirst, when reading a paper try to find the main ideas of the paper and summarize it into one sentence.\n\nSecond, when writing papers, identify the core idea of the in one sentence first. This will determine the scope of the paper and avoid over-complicating things. Moreover, it allows for concise writing. Each sentence/paragraph should contributes to the main idea.\n\n","wordCount":133,"tags":["reading","writing"],"metadata":{},"created":"2023-05-25T05:38:44.0635008Z","modified":"2024-05-20T08:51:32.036814994Z","checksum":"e1f271e3267d4beef9083fa315dfe98590ed6e2062c1f0b03c9f78a96bea41ad"},
    {"filename":"kwe5ygmo.md","filenameStem":"kwe5ygmo","path":"literature/kwe5ygmo.md","absPath":"/home/khadd/mynotes/literature/kwe5ygmo.md","title":"Operating System Support for Safe and Efficient Auxiliary Execution Operating System Support for Safe and Efficient Auxiliary Execution","link":"[[literature/kwe5ygmo]]","lead":"#literature\n@jing2022operating","body":"#literature\n@jing2022operating\n\n# Questions/Notes during reading\n- [ ] What makes an execution entity? \n- [ ] What does *schedulable* means in this context?\n- [ ] How do you define first-class execution entity?\n- [ ] How address space isolation is achieved? Is it through page table switching/page permissions?\n- [ ] \n-\n\n# Random thoughts\n- Categorize previous works into *groups*, then say that they don't solve a particular problem\n\n# Summary\nThe paper studies the so-called *auxiliary tasks* employed in existing applications. An auxiliary task is a task that performs supporting functionalities aside from the main program logic. For instance, the authors categorize MySQL's deadlock-detecting  `check_and_resolve` as an auxilary task. \nNote that this definition is entirely subjective (as mentioned in section 6). However, the authors did show the prevalence of such auxiliary tasks, used in 6 different production applications. \n\nBased on the characteristics of the auxiliary tasks: (1) need to be isolated from the main process and (2) need good observability of the main process, the authors pointed out the limitations of the existing methods, mainly SFI, Process-based isolation and threads in performing such tasks. Threads lacks memory isolation, processes and SFI lacks observability.\n\nThe authors introduced a new abstraction called the _orbit_ which is specialized for auxiliary tasks. To summarize, an orbit is an OS-schedulable entity (similar to processes and threads) that is address-space isolated from the main process.  The orbit can be invoked synchronously or asynchronously.\n\nFor main-\u003eorbit data synchronization, orbit shares a limited memory area with the main process called the *orbit area*. Those pages are copy-on-write *when there is an orbit invocation* (essentially snapshotting the pages): whenever the orbit or the main process is written into this page, the page will be cloned, and the writer will work on its copy instead.\nNo concurrency control is done on the orbit area page, so snapshotting might not be thread-safe. Application-level synchronization is relied on instead.\n\nFor orbit-\u003emain program data synchronization, the paper proposed a *controlled state alteration* policy. Orbit uses syscall  `orbit_push` to push the changes that they want to make into a *scratchpad memory*. On the main program side, `orbit_pull` is used to bring the updates to the main program's memory.","snippets":["#literature\n@jing2022operating"],"rawContent":"# Operating System Support for Safe and Efficient Auxiliary Execution Operating System Support for Safe and Efficient Auxiliary Execution \n#literature\n@jing2022operating\n\n# Questions/Notes during reading\n- [ ] What makes an execution entity? \n- [ ] What does *schedulable* means in this context?\n- [ ] How do you define first-class execution entity?\n- [ ] How address space isolation is achieved? Is it through page table switching/page permissions?\n- [ ] \n-\n\n# Random thoughts\n- Categorize previous works into *groups*, then say that they don't solve a particular problem\n\n# Summary\nThe paper studies the so-called *auxiliary tasks* employed in existing applications. An auxiliary task is a task that performs supporting functionalities aside from the main program logic. For instance, the authors categorize MySQL's deadlock-detecting  `check_and_resolve` as an auxilary task. \nNote that this definition is entirely subjective (as mentioned in section 6). However, the authors did show the prevalence of such auxiliary tasks, used in 6 different production applications. \n\nBased on the characteristics of the auxiliary tasks: (1) need to be isolated from the main process and (2) need good observability of the main process, the authors pointed out the limitations of the existing methods, mainly SFI, Process-based isolation and threads in performing such tasks. Threads lacks memory isolation, processes and SFI lacks observability.\n\nThe authors introduced a new abstraction called the _orbit_ which is specialized for auxiliary tasks. To summarize, an orbit is an OS-schedulable entity (similar to processes and threads) that is address-space isolated from the main process.  The orbit can be invoked synchronously or asynchronously.\n\nFor main-\u003eorbit data synchronization, orbit shares a limited memory area with the main process called the *orbit area*. Those pages are copy-on-write *when there is an orbit invocation* (essentially snapshotting the pages): whenever the orbit or the main process is written into this page, the page will be cloned, and the writer will work on its copy instead.\nNo concurrency control is done on the orbit area page, so snapshotting might not be thread-safe. Application-level synchronization is relied on instead.\n\nFor orbit-\u003emain program data synchronization, the paper proposed a *controlled state alteration* policy. Orbit uses syscall  `orbit_push` to push the changes that they want to make into a *scratchpad memory*. On the main program side, `orbit_pull` is used to bring the updates to the main program's memory.\n\n\n\n\n\n\n\n\n","wordCount":387,"tags":["literature"],"metadata":{},"created":"2023-09-01T04:18:43.966329363Z","modified":"2023-09-01T08:32:13.88895507Z","checksum":"e8192117831bc66675c9459062c679305dabe7fbe47db6b43afac35f0117c0bd"},
    {"filename":"5kzr3hwx.md","filenameStem":"5kzr3hwx","path":"5kzr3hwx.md","absPath":"/home/khadd/mynotes/5kzr3hwx.md","title":"Page fault-based Side-channels Protection in SGX","link":"[[5kzr3hwx]]","lead":"#tee #sgx #side-channel","body":"#tee #sgx #side-channel\n\n# Comparision critera\n## Code \u0026 data\nSome work provides protection to only data accesses, while other protect both code and data accesses.\n\n## Granularity\nPerfect trace, Cache-line, Page-level.\n\n\n# Obfuscated execution techniques\nThe first line of defense is obfuscated execution ([[n9bxzpge]]), which guarantees that code and data accesses of a program looks the same, given a sensitive input.\nThey usually have high overheads and are considered impractical.\n\n\n# Detecting page faults\nOne class of defense is to treat all possible page fault triggered by the OS as malicious. This requires that the enclave pages are statically determined and mapped to enclave. Hence, demand paging is not possible in this model.\n\n\nMost of these defenses uses  Intel TSX [[dx7vz8d5]], due to its ability to supress page faults. \nFor more details, see [[fvom56lw]]. \n\nSince their introduction, there has been attacks that can leak secrets _without_ explicitly triggering page faults #cite-needed. Hence, these defenses are incomplete to today's standard.\n\n\n# Virtualizing Virtual Memory\nAnother category of defense is to replace all memory instructions of the enclave (through compiler instrumentation) with requests to a reference monitor that make the actual request indistinguishable to attackers (e.g., using ORAM primitives). \nThey have stronger guarantees than \n\nFor instance, the following LLVM IR could be instruments as follows:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n\n---\n%1 = call oblivious_load(%arg1)\n%2 = add %1, 100\ncall obliviou_call(\u0026foo)\ncall oblivious_store(%2, %1)\n```\n\n\n## Obfuscuro\n\n## Klotski\n\n## CosMIX\n\n\n\n# Self-paging enclaves\nAnother way to hide page faults from the OS is to the the enclave perform its own paging. Though, in SGX, this model is not possible without hardware extensions @orenbach2020autarky, @aga2019invisipage.\n\nThese defenses maintain a separated page table that is exclusively used to map EPC pages. This page table can only be updated by the trusted code inside the enclave.","snippets":["#tee #sgx #side-channel"],"rawContent":"# Page fault-based Side-channels Protection in SGX\n#tee #sgx #side-channel\n\n# Comparision critera\n## Code \u0026 data\nSome work provides protection to only data accesses, while other protect both code and data accesses.\n\n## Granularity\nPerfect trace, Cache-line, Page-level.\n\n\n# Obfuscated execution techniques\nThe first line of defense is obfuscated execution ([[n9bxzpge]]), which guarantees that code and data accesses of a program looks the same, given a sensitive input.\nThey usually have high overheads and are considered impractical.\n\n\n# Detecting page faults\nOne class of defense is to treat all possible page fault triggered by the OS as malicious. This requires that the enclave pages are statically determined and mapped to enclave. Hence, demand paging is not possible in this model.\n\n\nMost of these defenses uses  Intel TSX [[dx7vz8d5]], due to its ability to supress page faults. \nFor more details, see [[fvom56lw]]. \n\nSince their introduction, there has been attacks that can leak secrets _without_ explicitly triggering page faults #cite-needed. Hence, these defenses are incomplete to today's standard.\n\n\n# Virtualizing Virtual Memory\nAnother category of defense is to replace all memory instructions of the enclave (through compiler instrumentation) with requests to a reference monitor that make the actual request indistinguishable to attackers (e.g., using ORAM primitives). \nThey have stronger guarantees than \n\nFor instance, the following LLVM IR could be instruments as follows:\n\n```llvm\n%0 = alloca 100\n%1 = load ptr %arg1\n%2 = add %1, 100\ncall foo()\nstore %2, ptr %0\n\n---\n%1 = call oblivious_load(%arg1)\n%2 = add %1, 100\ncall obliviou_call(\u0026foo)\ncall oblivious_store(%2, %1)\n```\n\n\n## Obfuscuro\n\n## Klotski\n\n## CosMIX\n\n\n\n# Self-paging enclaves\nAnother way to hide page faults from the OS is to the the enclave perform its own paging. Though, in SGX, this model is not possible without hardware extensions @orenbach2020autarky, @aga2019invisipage.\n\nThese defenses maintain a separated page table that is exclusively used to map EPC pages. This page table can only be updated by the trusted code inside the enclave.\n\n","wordCount":327,"tags":["sgx","tee","side-channel","cite-needed"],"metadata":{},"created":"2023-06-19T03:04:24.876823985Z","modified":"2023-08-30T05:50:53.704361954Z","checksum":"1d199f86b06ed2d57ce6d724660a787a6533c7b7b43c07f6da8df09b3980140c"},
    {"filename":"xpolyx1l.md","filenameStem":"xpolyx1l","path":"xpolyx1l.md","absPath":"/home/khadd/mynotes/xpolyx1l.md","title":"Paging in Unikraft (x86)","link":"[[xpolyx1l]]","lead":"#unikraft #os","body":"#unikraft #os\n\n# Enabling paging\nPaging is enabled with the configuration PAGING, enabled by setting Platform Configuration -\u003e Platform Interface Option -\u003e Virtual memory API in `make menuconfig`.\n\n`PAGING` option affects `plat/kvm/x86/setup.c`, where `mem_init()` would calls `init_paging()`. \nThen, `ukplat_pt_init` is called to initialize the page table.\n- It calls `pgarch_init()` to initialize architectural-dependent info, such as checking 1GiB pages support, PAT support.\n\n\n# Initializing paging\n## `kernel_pt`\nThis global struct stores info for the initialization time kernel page table.\n\nLater, a virtual address space (VAS) is created, which also points to this page table.\n## `ukplat_bootinfo`\nAt build time, the linker prepare a `boot_info` structure.\nBoot info contains a list of *physical* memory regions (kernel image, uninitialized memory, ...).\n\n## `mem_init`\nThe function inserts the remaining memory from after the kernel image (after `__END`) to the remaining physical memory to the list of memory regions. This region flag is `UKPLAT_MEMRF_UNMAP`, which means that these pages are unmapped from the kernel page table, and are only mapped on-demand.\n```c\nrc = ukplat_memregion_list_insert(\u0026bi-\u003emrds,\n\t\t\u0026(struct ukplat_memregion_desc){\n\t\t\t.vbase = PAGE_ALIGN_UP(__END),\n\t\t\t.pbase = 0,\n\t\t\t.len   = PLATFORM_MAX_MEM_ADDR - PAGE_ALIGN_UP(__END),\n\t\t\t.type  = 0,\n\t\t\t.flags = UKPLAT_MEMRF_UNMAP,\n```\n\nIt then calls `paging_init`\n\n## `paging_init` \nThe function initializes the kernel's page table. On Linux, there is also the same function, but the process is a bit different  ([[cn9u3d79]]).\n\nFirst, it calls `ukplat_pt_init`, which initializes the page table facilities, using a free memory region.\n1. `pgarch_init()` setup the CPU features\n2. `pgarch_pt_init` initialize the frame allocator and adds all physical memory to it.\n\nAfter the page table\n\nFor every region with the flag `UKPLAT_MEMRF_UNMAP`, it unmaps them from the page table. Finally, it maps regions with the flag `UKPLAT_MEMRF_MAP` to memory. \n\n\n\n## `pgarch_pt_init`\nArchitectual-specific page table initialization is performed here. On X86, it reserves space for the frame allocator (`struct uk_falloc`), initializes the allocator, then adds the remaining physical memory to the frame allocator pool of memory.\n\n\n# Page fault handler\nThe page fault handler is defined separatedly as `do_page_fault` in `common/x86/traps.c`. It calls `rc = uk_raise_event(UKARCH_TRAP_PAGE_FAULT, \u0026ctx);` (more details is in event.h).\n\nThe handler for this event is found in `ukvmem/arch/x86_64/pagefault.c`, registered as\n```c\nUK_EVENT_HANDLER_PRIO(UKARCH_TRAP_PAGE_FAULT, vmem_arch_pagefault,\n\t\t      CONFIG_LIBUKVMEM_PAGEFAULT_HANDLER_PRIO);\n```\n\nSee [[1k9i1cr3]] for more about Unikraft's interrupt handling.\n\nwith `ukvmem`, different page fault handlers can be registered for different VMAs. On a page fault. the VMA for the faulting address is looked up, then the VMA's registered page fault handler is called. \n\n# ukvmem\nukvmem enables APIs for virtual memory management. It creates Virtual Address Spaces (VAS), which contains smaller regions called Virtual Memory Areas (VMAs).\n\nThere are APIs that are required for paging that are defined here. For example, the page fault handler above `vmem_arch_pagefault` would call `vmem_pagefault` defined in `vmem.c`.\n\n`pg_page_mapx` (`paging.c`) performs the allocating of page table entries. \n\n\n# Page table entry\n`pg_page_mapx` sets the \"template\" as 0, which is set in the new PTE on a fault.\n\n## Registering fault handler\n\n# Related notes\n- [[cn9u3d79]]","snippets":["#unikraft #os"],"rawContent":"# Paging in Unikraft (x86)\n#unikraft #os\n\n# Enabling paging\nPaging is enabled with the configuration PAGING, enabled by setting Platform Configuration -\u003e Platform Interface Option -\u003e Virtual memory API in `make menuconfig`.\n\n`PAGING` option affects `plat/kvm/x86/setup.c`, where `mem_init()` would calls `init_paging()`. \nThen, `ukplat_pt_init` is called to initialize the page table.\n- It calls `pgarch_init()` to initialize architectural-dependent info, such as checking 1GiB pages support, PAT support.\n\n\n# Initializing paging\n## `kernel_pt`\nThis global struct stores info for the initialization time kernel page table.\n\nLater, a virtual address space (VAS) is created, which also points to this page table.\n## `ukplat_bootinfo`\nAt build time, the linker prepare a `boot_info` structure.\nBoot info contains a list of *physical* memory regions (kernel image, uninitialized memory, ...).\n\n## `mem_init`\nThe function inserts the remaining memory from after the kernel image (after `__END`) to the remaining physical memory to the list of memory regions. This region flag is `UKPLAT_MEMRF_UNMAP`, which means that these pages are unmapped from the kernel page table, and are only mapped on-demand.\n```c\nrc = ukplat_memregion_list_insert(\u0026bi-\u003emrds,\n\t\t\u0026(struct ukplat_memregion_desc){\n\t\t\t.vbase = PAGE_ALIGN_UP(__END),\n\t\t\t.pbase = 0,\n\t\t\t.len   = PLATFORM_MAX_MEM_ADDR - PAGE_ALIGN_UP(__END),\n\t\t\t.type  = 0,\n\t\t\t.flags = UKPLAT_MEMRF_UNMAP,\n```\n\nIt then calls `paging_init`\n\n## `paging_init` \nThe function initializes the kernel's page table. On Linux, there is also the same function, but the process is a bit different  ([[cn9u3d79]]).\n\nFirst, it calls `ukplat_pt_init`, which initializes the page table facilities, using a free memory region.\n1. `pgarch_init()` setup the CPU features\n2. `pgarch_pt_init` initialize the frame allocator and adds all physical memory to it.\n\nAfter the page table\n\nFor every region with the flag `UKPLAT_MEMRF_UNMAP`, it unmaps them from the page table. Finally, it maps regions with the flag `UKPLAT_MEMRF_MAP` to memory. \n\n\n\n## `pgarch_pt_init`\nArchitectual-specific page table initialization is performed here. On X86, it reserves space for the frame allocator (`struct uk_falloc`), initializes the allocator, then adds the remaining physical memory to the frame allocator pool of memory.\n\n\n# Page fault handler\nThe page fault handler is defined separatedly as `do_page_fault` in `common/x86/traps.c`. It calls `rc = uk_raise_event(UKARCH_TRAP_PAGE_FAULT, \u0026ctx);` (more details is in event.h).\n\nThe handler for this event is found in `ukvmem/arch/x86_64/pagefault.c`, registered as\n```c\nUK_EVENT_HANDLER_PRIO(UKARCH_TRAP_PAGE_FAULT, vmem_arch_pagefault,\n\t\t      CONFIG_LIBUKVMEM_PAGEFAULT_HANDLER_PRIO);\n```\n\nSee [[1k9i1cr3]] for more about Unikraft's interrupt handling.\n\nwith `ukvmem`, different page fault handlers can be registered for different VMAs. On a page fault. the VMA for the faulting address is looked up, then the VMA's registered page fault handler is called. \n\n# ukvmem\nukvmem enables APIs for virtual memory management. It creates Virtual Address Spaces (VAS), which contains smaller regions called Virtual Memory Areas (VMAs).\n\nThere are APIs that are required for paging that are defined here. For example, the page fault handler above `vmem_arch_pagefault` would call `vmem_pagefault` defined in `vmem.c`.\n\n`pg_page_mapx` (`paging.c`) performs the allocating of page table entries. \n\n\n# Page table entry\n`pg_page_mapx` sets the \"template\" as 0, which is set in the new PTE on a fault.\n\n## Registering fault handler\n\n# Related notes\n- [[cn9u3d79]]\n\n","wordCount":495,"tags":["os","unikraft"],"metadata":{},"created":"2023-07-03T02:43:48.502203262Z","modified":"2023-07-07T02:53:30.515381038Z","checksum":"b2214267b8ad24d86979e31d37a61d8571d4a1d2294c9a60258b290b4d2832a3"},
    {"filename":"mgz1zmm2.md","filenameStem":"mgz1zmm2","path":"mgz1zmm2.md","absPath":"/home/khadd/mynotes/mgz1zmm2.md","title":"Porting SEV to Unikraft","link":"[[mgz1zmm2]]","lead":"# Notes\n## 2023-08-15\n- Failed to open file \\EFI\\BOOT\\app-helloworld.cmdl, error: 9223372036854775822 \n- Probably need to add cmdl file to boot option\n- EFI kernel","body":"# Notes\n## 2023-08-15\n- Failed to open file \\EFI\\BOOT\\app-helloworld.cmdl, error: 9223372036854775822 \n- Probably need to add cmdl file to boot option\n- EFI kernel","snippets":["# Notes\n## 2023-08-15\n- Failed to open file \\EFI\\BOOT\\app-helloworld.cmdl, error: 9223372036854775822 \n- Probably need to add cmdl file to boot option\n- EFI kernel"],"rawContent":"# Porting SEV to Unikraft\n\n\n\n\n\n# Notes\n## 2023-08-15\n- Failed to open file \\EFI\\BOOT\\app-helloworld.cmdl, error: 9223372036854775822 \n- Probably need to add cmdl file to boot option\n- EFI kernel\n","wordCount":30,"tags":[],"metadata":{},"created":"2023-08-15T08:54:50.284558284Z","modified":"2023-09-22T11:04:40.471069262Z","checksum":"395e6bbebf9c8f70ea731cdb2fc76d7f14f7804e590788b15b46126864d39680"},
    {"filename":"0sk3p5q6.md","filenameStem":"0sk3p5q6","path":"0sk3p5q6.md","absPath":"/home/khadd/mynotes/0sk3p5q6.md","title":"Potential Postdoc Position","link":"[[0sk3p5q6]]","lead":"- [Secure Systems, Univ. of Waterloo, N. Asokan](https://asokan.org/asokan/research/SecureSystems-open-positions-Jul2021.php): The home of Pac it up, PACStack","body":"- [Secure Systems, Univ. of Waterloo, N. Asokan](https://asokan.org/asokan/research/SecureSystems-open-positions-Jul2021.php): The home of Pac it up, PACStack","snippets":["- [Secure Systems, Univ. of Waterloo, N. Asokan](https://asokan.org/asokan/research/SecureSystems-open-positions-Jul2021.php): The home of Pac it up, PACStack"],"rawContent":"# Potential Postdoc Position\n\n\n- [Secure Systems, Univ. of Waterloo, N. Asokan](https://asokan.org/asokan/research/SecureSystems-open-positions-Jul2021.php): The home of Pac it up, PACStack\n\n\n","wordCount":19,"tags":[],"metadata":{},"created":"2023-08-22T07:48:40.356007934Z","modified":"2023-08-22T07:52:28.596097503Z","checksum":"7763bd7d15bf65ee72dae22e878857caed71a078716f30ab1d8173b18f125d69"},
    {"filename":"4zdjxws6.md","filenameStem":"4zdjxws6","path":"literature/4zdjxws6.md","absPath":"/home/khadd/mynotes/literature/4zdjxws6.md","title":"Practical Program Modularization with Type-Based Dependence Analysis","link":"[[literature/4zdjxws6]]","lead":"#literature #analysis #compartmentalization\n@lu2023practical","body":"#literature #analysis #compartmentalization\n@lu2023practical\n\n# Main arguments\nData-flow-based dependence analyses are impractical on large programs due to incorrect results and scalability issues, and A type-based dependence analysis avoid data-flow analysis.\n- See [[dgdvhu1e]]\n- The proposed approach can handle multi-entry, multi-threaded programs, and does not rely on points-to analysis.\n\nModule-aware type-based dependence analysis enables practical dependence analysis. \n- If only the module boundaries are analyzed (function arguments and global variables), the inner complexity of module is does not matter.\n- The proposed analysis only analyses the two types of typed-based data-flow, through function arguments and through global variable.\n\nModule-based analysis and type-based analysis are complementary.\n- Module-aware analysis complement type-analysis:\n  - Previous type-only approaches @lu2019where are imprecise because they scan the entire program for a particular type.\n  - There are modules in programs that has contain same types, but not related at all\n  - The approach can further refine the CFI targets by using dependent module information\n- Type-aware analysis improves module-aware analysis:\n  - A module-only analysis would be highly imprecise (only identifying if module A can write into B), using the Type of argument further restrict the data flow, making it an effective approach.\n\nThe proposed analysis is effective and sound (as a dependence analysis)\n- It is effective (in restricting data-flow) because it is difficult to form the data flow between modules with a given type, and that there are also modules between a module.\n- It is sound (as a dependence analysis), since the approach will catch all cross-module data-flow if there is one.\n\nThe analysis improve upon existing security applications.\n- When used for indirect call target reduction, it have high reduction rate on large application (up to 70% on firefox).\n- It identify 90% write instructions in linux as non-sensitive, which can be enforced with techniques such as DFI, WIT. (No enforcement were tested).\n  \n# Observation\nThere is only two type of data-flow between modules: through function arguments/return values and through global variables \n\n# Type-based dependence analysis\nThe key idea is to perform type-based dependence analysis between modules (i.e., compilation unit). \nA *type-based dependence analysis* determine if modules of the programs may propagate the object of a certain types to a particular module.\n\nThe following types of dependencies are detected:\n\nDirect (through argument):\n- If M1 pass argument of type T1 to M2, there is direct data flow M1-\u003eM2.\n\nIndirect (through global)\n- If M1 write to global g type T, M2 read global type T, then there is data flow M1-\u003eg-\u003eM2.\n\nTransitive:\n- There can be chaining of cross-module data flow, e.g., M1-\u003eM2-\u003eg-\u003eM3-\u003eM4 \n\n# The analysis\nThe analysis takes a pair of type and module \u003ctype,module\u003e, and automatically all dependent modules. There are three main steps.\n- The first step collect castable types into a CastMap. This is to handle unsafe casting operations in C/C++, all possible casted types are also considered in the data flow.\n- The second step find out the direction and type of the data flow between two particular modules and store it into a `FlowMap`. Finding out the direction possible data flow ([[#direction]]).\n- The final step compute dependent modules and the dependent types.\n\nIt is also observe that type-based indirect calls can be further refined using module-awareness. The author use an iterative method to refine the indirect call targets:\n- In first iteration, find dependent modules of an indirect call\n- Next, limit the type-based call target matching to only using the dependent modules.\n- Repeat until no more refinement is made\n\n\n## Finding data flow direction \n[]{#direction}\n\nFor two modules $M$, $V$, and a use $U$ of type $T$:\n- If the use in $V$ is a *load* LLVM instruction, then the direction is $M-\u003eV$.\n- If it is a $store$ instruction, then the direction is $V-\u003eM$.\n- If it is the GEP instruction, also analyze the use of the instruction\n- Else, it is bidirectional.\n\nOn struct types and pointer types, the types of the field is also analyzed. This is done through recursion on GEP instructions.\n\nThe result is stored in a structure called the $FlowMap$ that record Type, Direction of data flow between two modules.\n\n## Type elevation\n*Type elevation* is also proposed to improve the precision. The idea is that instead of using the type of the use site, which might have many false possitive, *elevate* it to the type of the containing struct.\nFor example, when an indirect call type $T1$ in a struct $T2$ is called, we first find the set of dependent modules using the type $T1$. Then, we find the dependent modules using the struct type $T2$. Finally, we *intersect* the two set to have a more refined dependent module set for the type $T1$.\n\nThis approach is unsound for container types (*base type*) that can be created from within the module, because cross-module data-flow will not find dependent module for those types. The paper suggests a simple *externality analysis*: If the base type is ever assigned (through `store` and initilizers), it cannot be used for elevation.\n\nEssentially, it is just following chain of GEP instructions to get the outermost type as the *base type* (section 5)\n\n\n# Implementation notes\n## Type comparison\nThe authors found that type comparison in LLVM poses challenges: \n- Type may have different underlying memory objects so pointer comparison does not work\n- The same struct type might have different variants, so string comparison may not work.\n- Struct types may or may not have name.\n\n## Unions\nUnion types is handled by using the union type itself, instead of the instantiated type. This hurts precision but guarantee soundness.","snippets":["#literature #analysis #compartmentalization\n@lu2023practical"],"rawContent":"# Practical Program Modularization with Type-Based Dependence Analysis\n#literature #analysis #compartmentalization\n@lu2023practical\n\n# Main arguments\nData-flow-based dependence analyses are impractical on large programs due to incorrect results and scalability issues, and A type-based dependence analysis avoid data-flow analysis.\n- See [[dgdvhu1e]]\n- The proposed approach can handle multi-entry, multi-threaded programs, and does not rely on points-to analysis.\n\nModule-aware type-based dependence analysis enables practical dependence analysis. \n- If only the module boundaries are analyzed (function arguments and global variables), the inner complexity of module is does not matter.\n- The proposed analysis only analyses the two types of typed-based data-flow, through function arguments and through global variable.\n\nModule-based analysis and type-based analysis are complementary.\n- Module-aware analysis complement type-analysis:\n  - Previous type-only approaches @lu2019where are imprecise because they scan the entire program for a particular type.\n  - There are modules in programs that has contain same types, but not related at all\n  - The approach can further refine the CFI targets by using dependent module information\n- Type-aware analysis improves module-aware analysis:\n  - A module-only analysis would be highly imprecise (only identifying if module A can write into B), using the Type of argument further restrict the data flow, making it an effective approach.\n\nThe proposed analysis is effective and sound (as a dependence analysis)\n- It is effective (in restricting data-flow) because it is difficult to form the data flow between modules with a given type, and that there are also modules between a module.\n- It is sound (as a dependence analysis), since the approach will catch all cross-module data-flow if there is one.\n\nThe analysis improve upon existing security applications.\n- When used for indirect call target reduction, it have high reduction rate on large application (up to 70% on firefox).\n- It identify 90% write instructions in linux as non-sensitive, which can be enforced with techniques such as DFI, WIT. (No enforcement were tested).\n  \n# Observation\nThere is only two type of data-flow between modules: through function arguments/return values and through global variables \n\n# Type-based dependence analysis\nThe key idea is to perform type-based dependence analysis between modules (i.e., compilation unit). \nA *type-based dependence analysis* determine if modules of the programs may propagate the object of a certain types to a particular module.\n\nThe following types of dependencies are detected:\n\nDirect (through argument):\n- If M1 pass argument of type T1 to M2, there is direct data flow M1-\u003eM2.\n\nIndirect (through global)\n- If M1 write to global g type T, M2 read global type T, then there is data flow M1-\u003eg-\u003eM2.\n\nTransitive:\n- There can be chaining of cross-module data flow, e.g., M1-\u003eM2-\u003eg-\u003eM3-\u003eM4 \n\n# The analysis\nThe analysis takes a pair of type and module \u003ctype,module\u003e, and automatically all dependent modules. There are three main steps.\n- The first step collect castable types into a CastMap. This is to handle unsafe casting operations in C/C++, all possible casted types are also considered in the data flow.\n- The second step find out the direction and type of the data flow between two particular modules and store it into a `FlowMap`. Finding out the direction possible data flow ([[#direction]]).\n- The final step compute dependent modules and the dependent types.\n\nIt is also observe that type-based indirect calls can be further refined using module-awareness. The author use an iterative method to refine the indirect call targets:\n- In first iteration, find dependent modules of an indirect call\n- Next, limit the type-based call target matching to only using the dependent modules.\n- Repeat until no more refinement is made\n\n\n## Finding data flow direction \n[]{#direction}\n\nFor two modules $M$, $V$, and a use $U$ of type $T$:\n- If the use in $V$ is a *load* LLVM instruction, then the direction is $M-\u003eV$.\n- If it is a $store$ instruction, then the direction is $V-\u003eM$.\n- If it is the GEP instruction, also analyze the use of the instruction\n- Else, it is bidirectional.\n\nOn struct types and pointer types, the types of the field is also analyzed. This is done through recursion on GEP instructions.\n\nThe result is stored in a structure called the $FlowMap$ that record Type, Direction of data flow between two modules.\n\n## Type elevation\n*Type elevation* is also proposed to improve the precision. The idea is that instead of using the type of the use site, which might have many false possitive, *elevate* it to the type of the containing struct.\nFor example, when an indirect call type $T1$ in a struct $T2$ is called, we first find the set of dependent modules using the type $T1$. Then, we find the dependent modules using the struct type $T2$. Finally, we *intersect* the two set to have a more refined dependent module set for the type $T1$.\n\nThis approach is unsound for container types (*base type*) that can be created from within the module, because cross-module data-flow will not find dependent module for those types. The paper suggests a simple *externality analysis*: If the base type is ever assigned (through `store` and initilizers), it cannot be used for elevation.\n\nEssentially, it is just following chain of GEP instructions to get the outermost type as the *base type* (section 5)\n\n\n# Implementation notes\n## Type comparison\nThe authors found that type comparison in LLVM poses challenges: \n- Type may have different underlying memory objects so pointer comparison does not work\n- The same struct type might have different variants, so string comparison may not work.\n- Struct types may or may not have name.\n\n## Unions\nUnion types is handled by using the union type itself, instead of the instantiated type. This hurts precision but guarantee soundness.  \n\n\n","wordCount":943,"tags":["literature","analysis","compartmentalization","direction"],"metadata":{},"created":"2023-05-22T02:06:14.459506884Z","modified":"2023-05-19T07:24:19.687192761Z","checksum":"662216095694e5f63ea615a18c9434fdb3665f8c9b0a58bf6736947edcab9fb0"},
    {"filename":"lxm4bklm.md","filenameStem":"lxm4bklm","path":"literature/lxm4bklm.md","absPath":"/home/khadd/mynotes/literature/lxm4bklm.md","title":"Preventing Kernel Hacks with HAKC","link":"[[literature/lxm4bklm]]","lead":"#literature #compartmentalization #os #pointer-authentication #mte","body":"#literature #compartmentalization #os #pointer-authentication #mte\n\n\n\n\n# Summary\nThe paper introduces a framework for complementing software called Hardware-assisted Kernel Compartmentalization (HAKC). The goal is to divide code and data into partitions and enforce access control on data access and control flow between partitions. The hardware primitives assumed are PA and MTE.\n\n\nThe paper claims two main contributions, *Compartmentalization Policy* and *Enforcement* strategy.\n\nRegarding the Policy, a two-level partitioning scheme is proposed. At a high level, there are Cliques and Compartments. One compartment contains several Cliques (at most 15 -- MTE number of tags). Two types of policies must be defined by the programmer:  Clique Access Policy (CAP) and Compartment Transition Policy (CTP).\n\nCAP is defined per-Cliques. It define data and code from other Cliques, a clique can access. The system enforce that a Clique's code and data accesses always access memory (1) belong to its own compartment and (2) within its permissions.\n\nCTP allows a clique to transfer its control flow outside of the compartment. It specify which other compartment's clique, a clique is able to call. When a clique transfer its control outside, data in the argument need to also be recolored to the target.\n\nThe authors argue that such a two-level design enable several advantages:\n- First, it overcome the limited number of MTE tags, since all control/data flow outside of the compartment must be explicitly validated.\n- Second, it enable local data optimization. More particular, within a clique, the access control is more light-weight, while other heavy-weight checks and data copies are left to the cross-comartment transitions.\n- Third, it allows fine-grained security boundaries, for performance-security trade-off.\n\n## Enforcement\nUsing MTE, all pointer will be encoded with a tag (a.k.a., cojoined metadata (CM)), indicating which clique owns the underlying memory. HAKC's strategy is to check all pointer dereference, to enforce that the pointer access is in accordance with the specified policies (the memory belong to the current compartment, and the current clique has the permission to access this data).\n\nAt runtime, a *candidate* CM is computed to be compared with a pointer's CM. The candiate CM is basically what the CM should looks like, given the current clique/compartment permissions.\n\nPAC is used to ensure that p\u003enter is not tamperedwith.\n\n\nMore particularly, in PA and MTE terms, every pointers is tagged with the clique's color. The pointer is then signed with a *signing token* as the modifier (which is the color of the owning clique *XOR* the compartment ID).\nI.e.,  $Tok_{sign} = CompartmantmentID XOR (Pointer's tag)$.\nLater, when the pointer is used, an *authentication token* is reconstructed the pointer's tag and the permission bitmask $Tok_{acl}$.\nOr,  $Tok_{aut} = CompartmantmentID XOR (Pointer's tag AND Tok_{acl})$.\n\nFor instance, if a pointer's tag is 3, its bitmask is $100$. A $Tok_{acl}$ of $111$ means that a clique is able to access cliques of color 1, 2 and 3. Assuming compartment ID is 2.\nThen,\n$Tok_{sign} = $5 XOR 100$\nAt the use site,\n$Tok_{aut} = $5 XOR (100 AND 111)$\n\nWhy is MTE/PAC is even needed?","snippets":["#literature #compartmentalization #os #pointer-authentication #mte"],"rawContent":"# Preventing Kernel Hacks with HAKC\n#literature #compartmentalization #os #pointer-authentication #mte\n\n\n\n\n# Summary\nThe paper introduces a framework for complementing software called Hardware-assisted Kernel Compartmentalization (HAKC). The goal is to divide code and data into partitions and enforce access control on data access and control flow between partitions. The hardware primitives assumed are PA and MTE.\n\n\nThe paper claims two main contributions, *Compartmentalization Policy* and *Enforcement* strategy.\n\nRegarding the Policy, a two-level partitioning scheme is proposed. At a high level, there are Cliques and Compartments. One compartment contains several Cliques (at most 15 -- MTE number of tags). Two types of policies must be defined by the programmer:  Clique Access Policy (CAP) and Compartment Transition Policy (CTP).\n\nCAP is defined per-Cliques. It define data and code from other Cliques, a clique can access. The system enforce that a Clique's code and data accesses always access memory (1) belong to its own compartment and (2) within its permissions.\n\nCTP allows a clique to transfer its control flow outside of the compartment. It specify which other compartment's clique, a clique is able to call. When a clique transfer its control outside, data in the argument need to also be recolored to the target.\n\nThe authors argue that such a two-level design enable several advantages:\n- First, it overcome the limited number of MTE tags, since all control/data flow outside of the compartment must be explicitly validated.\n- Second, it enable local data optimization. More particular, within a clique, the access control is more light-weight, while other heavy-weight checks and data copies are left to the cross-comartment transitions.\n- Third, it allows fine-grained security boundaries, for performance-security trade-off.\n\n## Enforcement\nUsing MTE, all pointer will be encoded with a tag (a.k.a., cojoined metadata (CM)), indicating which clique owns the underlying memory. HAKC's strategy is to check all pointer dereference, to enforce that the pointer access is in accordance with the specified policies (the memory belong to the current compartment, and the current clique has the permission to access this data).\n\nAt runtime, a *candidate* CM is computed to be compared with a pointer's CM. The candiate CM is basically what the CM should looks like, given the current clique/compartment permissions.\n\nPAC is used to ensure that p\u003enter is not tamperedwith.\n\n\nMore particularly, in PA and MTE terms, every pointers is tagged with the clique's color. The pointer is then signed with a *signing token* as the modifier (which is the color of the owning clique *XOR* the compartment ID).\nI.e.,  $Tok_{sign} = CompartmantmentID XOR (Pointer's tag)$.\nLater, when the pointer is used, an *authentication token* is reconstructed the pointer's tag and the permission bitmask $Tok_{acl}$.\nOr,  $Tok_{aut} = CompartmantmentID XOR (Pointer's tag AND Tok_{acl})$.\n\nFor instance, if a pointer's tag is 3, its bitmask is $100$. A $Tok_{acl}$ of $111$ means that a clique is able to access cliques of color 1, 2 and 3. Assuming compartment ID is 2.\nThen,\n$Tok_{sign} = $5 XOR 100$\nAt the use site,\n$Tok_{aut} = $5 XOR (100 AND 111)$\n\nWhy is MTE/PAC is even needed?\n\n\n","wordCount":510,"tags":["literature","os","compartmentalization","pointer-authentication","mte"],"metadata":{},"created":"2023-06-29T08:46:51.548086228Z","modified":"2023-08-09T06:07:14.994440814Z","checksum":"564a30970834e04e2e50679a599ea305254cf9c1b0424b12af8f0223d86bdec4"},
    {"filename":"a0g41kid.md","filenameStem":"a0g41kid","path":"a0g41kid.md","absPath":"/home/khadd/mynotes/a0g41kid.md","title":"Process","link":"[[a0g41kid]]","lead":"#os","body":"#os\n\nIn the most simple term, a process is a running program (that have been loaded from the disk into memory and launched by the OS). A running process is defined by its states, which includes its memory, its registers contents, and opening files.\n\nThe OS stores a process's state is stored in the process control block PCB (`task_struct` in linux). For instance, in xv6, the PCB contains:\n\n\n```c\n// Per-process state\nstruct proc {\n  uint sz;                     // Size of process memory (bytes)\n  pde_t* pgdir;                // Page table\n  char *kstack;                // Bottom of kernel stack for this process\n  enum procstate state;        // Process state\n  volatile int pid;            // Process ID\n  struct proc *parent;         // Parent process\n  struct trapframe *tf;        // Trap frame for current syscall\n  struct context *context;     // swtch() here to run process\n  void *chan;                  // If non-zero, sleeping on chan\n  int killed;                  // If non-zero, have been killed\n  struct file *ofile[NOFILE];  // Open files\n  struct inode *cwd;           // Current directory\n  struct shared *shared;       // Shared memory record (0 -\u003e none)\n  char name[16];               // Process name (debugging)\n};\n```\n\nThe list of all process is stored by the OS in a *process list* data structure.\n\n## APIs\nProcesses are created through process system call APIs. There are API for:\n- Creation\n  - `fork()` creates a new process identical to the current one\n  - `exec()` spawn a new process with a given executable and arguments\n- Destroy\n  - A process is controlled through *signals*. The `kill()` syscall send signals to a process (e.g., `SIGINT`) to control it.\n- Wait\n  - The `wait()` system call wait for a spawned process to finish.","snippets":["#os"],"rawContent":"# Process\n#os\n\nIn the most simple term, a process is a running program (that have been loaded from the disk into memory and launched by the OS). A running process is defined by its states, which includes its memory, its registers contents, and opening files.\n\nThe OS stores a process's state is stored in the process control block PCB (`task_struct` in linux). For instance, in xv6, the PCB contains:\n\n\n```c\n// Per-process state\nstruct proc {\n  uint sz;                     // Size of process memory (bytes)\n  pde_t* pgdir;                // Page table\n  char *kstack;                // Bottom of kernel stack for this process\n  enum procstate state;        // Process state\n  volatile int pid;            // Process ID\n  struct proc *parent;         // Parent process\n  struct trapframe *tf;        // Trap frame for current syscall\n  struct context *context;     // swtch() here to run process\n  void *chan;                  // If non-zero, sleeping on chan\n  int killed;                  // If non-zero, have been killed\n  struct file *ofile[NOFILE];  // Open files\n  struct inode *cwd;           // Current directory\n  struct shared *shared;       // Shared memory record (0 -\u003e none)\n  char name[16];               // Process name (debugging)\n};\n```\n\nThe list of all process is stored by the OS in a *process list* data structure.\n\n## APIs\nProcesses are created through process system call APIs. There are API for:\n- Creation\n  - `fork()` creates a new process identical to the current one\n  - `exec()` spawn a new process with a given executable and arguments\n- Destroy\n  - A process is controlled through *signals*. The `kill()` syscall send signals to a process (e.g., `SIGINT`) to control it.\n- Wait\n  - The `wait()` system call wait for a spawned process to finish.\n\n\n","wordCount":273,"tags":["os"],"metadata":{},"created":"2023-05-26T07:17:27.665890979Z","modified":"2024-05-20T09:07:50.680725297Z","checksum":"40ed37a4595c1c8952ec7c4584b6f47c2f466dcab8f04543d6c4b20882ef499a"},
    {"filename":"l3lzsza3.md","filenameStem":"l3lzsza3","path":"l3lzsza3.md","absPath":"/home/khadd/mynotes/l3lzsza3.md","title":"Project: Obfuscated execution against Controlled-channel attacks","link":"[[l3lzsza3]]","lead":"#project","body":"#project\n\n# Background\n# Controlled-channel attacks against confidential computing\nControlled-channel attacks [[1yhmh234]]\n\nControlled-channel attacks on SGX are the most well-studied\n\nThere has also been controlled-channel attack studies for AMD SEV.\n\n## Obfuscated execution\n### Obfuscated execution for SGX\n\n# Obfuscated execution for confidential VM: What is lacking\n### Handling large TCB\nDifferent from SGX, the whole OS now has to be included into the TCB. This enlarges the attack surfaces for controlled-channel attacks.\n\nHowever, most of the proposed work cannot be scaled to this level.\n\n\nObfuscuro @ahmad2019obfuscuro requires sensitive code and data to fit into 4KB.\n\nKlotski only evaluated on small applications. Is is not sure how it handles larger one. \n\nOne other issue is that it is not sure how the previous models can be adapted to a large amount of inter-connected code.\nFor instance, sensitive code/data can induce paging, which may leads to controlled-channel visible by the VMM. \nThis is worsen due to the extended interfaces between the OS and VM [[#extended-interfaces]].\n\nObliviate @ahmad2018obliviate obfuscates the file system accesses, which may leads to \n\n### Extended interfaces\nThe interfaces between enlave-OS is significantly smaller than the interfaces between OS\u003c-\u003eVMM. It is expected that this interface would create other controlled-channels.\n\n### Under-studied attack vectors\nTODO: read these\n[Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization](https://www.usenix.org/conference/usenixsecurity19/presentation/li-mengyuan)\n[The SEVerESt Of Them All: Inference Attacks Against Secure Virtual Enclaves](https://dl.acm.org/doi/10.1145/3321705.3329820)\n\n[Security Analysis of Encrypted Virtual Machines](https://dl.acm.org/doi/10.1145/3140607.3050763)\n\n@li2021crossline\n@li2021tlb\n@morbitzer2019extracting\n\nThere lacks a systematic study about side-channel threats in this interface. \n\n### Taming the overheads\nOne way forward is to determine all sensitive data-dependent control-flow and data-flow to selectively apply protectionl. This is explored in Constantine @borrello2021constantine, but for very fine-grained obfuscated execution. A specialized method for selective data protection for confidential computing would greatly reduces the overheads.\n\nAnother way is to trade-off the granularity of protection. Klotski @zhang2020klotski uses caches for data and code that is larger than the 4KB page size, which improve performance, but allows observers to extracts coarse-grained information.","snippets":["#project"],"rawContent":"# Project: Obfuscated execution against Controlled-channel attacks\n#project\n\n# Background\n# Controlled-channel attacks against confidential computing\nControlled-channel attacks [[1yhmh234]]\n\nControlled-channel attacks on SGX are the most well-studied\n\nThere has also been controlled-channel attack studies for AMD SEV.\n\n## Obfuscated execution\n### Obfuscated execution for SGX\n\n# Obfuscated execution for confidential VM: What is lacking\n### Handling large TCB\nDifferent from SGX, the whole OS now has to be included into the TCB. This enlarges the attack surfaces for controlled-channel attacks.\n\nHowever, most of the proposed work cannot be scaled to this level.\n\n\nObfuscuro @ahmad2019obfuscuro requires sensitive code and data to fit into 4KB.\n\nKlotski only evaluated on small applications. Is is not sure how it handles larger one. \n\nOne other issue is that it is not sure how the previous models can be adapted to a large amount of inter-connected code.\nFor instance, sensitive code/data can induce paging, which may leads to controlled-channel visible by the VMM. \nThis is worsen due to the extended interfaces between the OS and VM [[#extended-interfaces]].\n\nObliviate @ahmad2018obliviate obfuscates the file system accesses, which may leads to \n\n### Extended interfaces\nThe interfaces between enlave-OS is significantly smaller than the interfaces between OS\u003c-\u003eVMM. It is expected that this interface would create other controlled-channels.\n\n### Under-studied attack vectors\nTODO: read these\n[Exploiting Unprotected I/O Operations in AMD’s Secure Encrypted Virtualization](https://www.usenix.org/conference/usenixsecurity19/presentation/li-mengyuan)\n[The SEVerESt Of Them All: Inference Attacks Against Secure Virtual Enclaves](https://dl.acm.org/doi/10.1145/3321705.3329820)\n\n[Security Analysis of Encrypted Virtual Machines](https://dl.acm.org/doi/10.1145/3140607.3050763)\n\n@li2021crossline\n@li2021tlb\n@morbitzer2019extracting\n\nThere lacks a systematic study about side-channel threats in this interface. \n\n### Taming the overheads\nOne way forward is to determine all sensitive data-dependent control-flow and data-flow to selectively apply protectionl. This is explored in Constantine @borrello2021constantine, but for very fine-grained obfuscated execution. A specialized method for selective data protection for confidential computing would greatly reduces the overheads.\n\nAnother way is to trade-off the granularity of protection. Klotski @zhang2020klotski uses caches for data and code that is larger than the 4KB page size, which improve performance, but allows observers to extracts coarse-grained information. \n\n","wordCount":336,"tags":["project"],"metadata":{},"created":"2023-06-12T04:34:51.343761577Z","modified":"2023-06-19T06:43:44.746747363Z","checksum":"869deadb424e21993d6ddd3c7c9d5e77858ca02ecd18a98d516586567a1c4281"},
    {"filename":"013pr50f.md","filenameStem":"013pr50f","path":"013pr50f.md","absPath":"/home/khadd/mynotes/013pr50f.md","title":"Pure functions in Rust","link":"[[013pr50f]]","lead":"# rust #pure-function","body":"# rust #pure-function\n\n\nPure functions is a concept from functional programming languages that marks that a function have no *side-effect*. More concretely, in D programming language, Pure functions are functions that cannot access global variables, and cannot make changes to their arguments.\n\n\n[This issue](https://github.com/rust-lang/rfcs/issues/1631) discuss the posibility of adding pure function support in Rust a a keyword (e.g., `pure fn foo()`). Pure functions was eventually deem not useful:\n- There are rarely any use cases for it, even in the D programming language.\n- There is no agreed upon definition for pure functions.\n- Rust tried implementing this concept before, but removed it.\n- Rust already has something similar to this concept as `const fn`. Those functions can take runtime arguments,  but cannot do anything related to runtime execution.","snippets":["# rust #pure-function"],"rawContent":"# Pure functions in Rust\n# rust #pure-function\n\n\nPure functions is a concept from functional programming languages that marks that a function have no *side-effect*. More concretely, in D programming language, Pure functions are functions that cannot access global variables, and cannot make changes to their arguments.\n\n\n[This issue](https://github.com/rust-lang/rfcs/issues/1631) discuss the posibility of adding pure function support in Rust a a keyword (e.g., `pure fn foo()`). Pure functions was eventually deem not useful:\n- There are rarely any use cases for it, even in the D programming language.\n- There is no agreed upon definition for pure functions.\n- Rust tried implementing this concept before, but removed it.\n- Rust already has something similar to this concept as `const fn`. Those functions can take runtime arguments,  but cannot do anything related to runtime execution. \n\n","wordCount":134,"tags":["pure-function"],"metadata":{},"created":"2023-06-15T02:58:33.89539734Z","modified":"2023-06-15T03:06:45.917316085Z","checksum":"f66720d27bb7aefdf7b5c9d3c15bccdb7327baa37aee6bc0c34a6860e6392fdd"},
    {"filename":"7dzydfim.md","filenameStem":"7dzydfim","path":"7dzydfim.md","absPath":"/home/khadd/mynotes/7dzydfim.md","title":"RLBox Implementation","link":"[[7dzydfim]]","lead":"# Tainted type","body":"# Tainted type\n\nTainted types includes `tainted` and `tainted_volatile`.\n\nThey inherits from the base class `tained_base_impl`\n## Signature\n## Overriding\n\n\n### internal_factory\n`internal_factory` is used to create new tainted values from the result of operators. Why is it \"internal?\" because it is only used internally. Sometimes values are created from pointers, which is considered dangerous. I guess they enforce that only `allocate_in_sandbox` can create pointers or something.\n\n\n\n### BinaryOpValAndPtr\ni.e., Binary operators for values and pointers. These include + and -.\n`tainted\u003cT, T_Sbx\u003e + T_Rhs -\u003e tainted\u003cT, T_Sbx\u003e`\n\nIf T is ptr (ptr + ptr or ptr + value):\n1. T must not be null\n2. Perform the operation\n3. Check if the result is within the sandbox. This check is sandbox-dependent\n4. call `internal_factory`  on the result to create a new `tainted` value.\n\n\n## BinaryOp\nBinaryOp contains the remaining binary operations only performed on primitive types\n\n## Dereference\n```cpp\nprivate:\n using T_OpDerefRet = tainted_volatile\u003cstd::remove_pointer_t\u003cT\u003e, T_Sbx\u003e;\n\npublic:\n  inline T_OpDerefRet\u0026 operator*() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e, \"Operator * only allowed on pointers\");\n    auto ret_ptr_const =\n      reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n    // Safe - If T_OpDerefRet is not a const ptr, this is trivially safe\n    //        If T_OpDerefRet is a const ptr, then the const is captured\n    //        inside the wrapper\n    auto ret_ptr = const_cast\u003cT_OpDerefRet*\u003e(ret_ptr_const);\n    return *ret_ptr;\n  }\n\n  // We need to implement the -\u003e operator even if T is not a struct\n  // So that we can support code patterns such as the below\n  // tainted\u003cT*\u003e a;\n  // a-\u003eUNSAFE_unverified();\n  inline const T_OpDerefRet* operator-\u003e() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e,\n                  \"Operator -\u003e only supported for pointer types\");\n    return reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n  }\n```","snippets":["# Tainted type"],"rawContent":"# RLBox Implementation\n\n# Tainted type\n\nTainted types includes `tainted` and `tainted_volatile`.\n\nThey inherits from the base class `tained_base_impl`\n## Signature\n## Overriding\n\n\n### internal_factory\n`internal_factory` is used to create new tainted values from the result of operators. Why is it \"internal?\" because it is only used internally. Sometimes values are created from pointers, which is considered dangerous. I guess they enforce that only `allocate_in_sandbox` can create pointers or something.\n\n\n\n### BinaryOpValAndPtr\ni.e., Binary operators for values and pointers. These include + and -.\n`tainted\u003cT, T_Sbx\u003e + T_Rhs -\u003e tainted\u003cT, T_Sbx\u003e`\n\nIf T is ptr (ptr + ptr or ptr + value):\n1. T must not be null\n2. Perform the operation\n3. Check if the result is within the sandbox. This check is sandbox-dependent\n4. call `internal_factory`  on the result to create a new `tainted` value.\n\n\n## BinaryOp\nBinaryOp contains the remaining binary operations only performed on primitive types\n\n## Dereference\n```cpp\nprivate:\n using T_OpDerefRet = tainted_volatile\u003cstd::remove_pointer_t\u003cT\u003e, T_Sbx\u003e;\n\npublic:\n  inline T_OpDerefRet\u0026 operator*() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e, \"Operator * only allowed on pointers\");\n    auto ret_ptr_const =\n      reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n    // Safe - If T_OpDerefRet is not a const ptr, this is trivially safe\n    //        If T_OpDerefRet is a const ptr, then the const is captured\n    //        inside the wrapper\n    auto ret_ptr = const_cast\u003cT_OpDerefRet*\u003e(ret_ptr_const);\n    return *ret_ptr;\n  }\n\n  // We need to implement the -\u003e operator even if T is not a struct\n  // So that we can support code patterns such as the below\n  // tainted\u003cT*\u003e a;\n  // a-\u003eUNSAFE_unverified();\n  inline const T_OpDerefRet* operator-\u003e() const\n  {\n    static_assert(std::is_pointer_v\u003cT\u003e,\n                  \"Operator -\u003e only supported for pointer types\");\n    return reinterpret_cast\u003cconst T_OpDerefRet*\u003e(impl().get_raw_value());\n  }\n```\n","wordCount":265,"tags":[],"metadata":{},"created":"2023-07-17T02:06:16.844071623Z","modified":"2023-07-27T09:47:55.860215953Z","checksum":"f8af5dcd1dacc75ba8f5f51172e114602ed8240cbe694c72d41107c4ebdf74c5"},
    {"filename":"2dw6pwrd.md","filenameStem":"2dw6pwrd","path":"2dw6pwrd.md","absPath":"/home/khadd/mynotes/2dw6pwrd.md","title":"Research Ideas","link":"[[2dw6pwrd]]","lead":"#research","body":"#research\n\n- [[fleeting/douswvq0]]\n\n- Better methods for hooking of syscalls\n- Carat Cake @suchy2022carat propose getting rid of paging, and use software instrumentation to provide OS-like abstractions. Capacity may be adaptable to this.","snippets":["#research"],"rawContent":"# Research Ideas\n#research\n\n- [[fleeting/douswvq0]]\n\n- Better methods for hooking of syscalls\n- Carat Cake @suchy2022carat propose getting rid of paging, and use software instrumentation to provide OS-like abstractions. Capacity may be adaptable to this.\n\n","wordCount":36,"tags":["research"],"metadata":{},"created":"2023-05-22T02:06:14.447571155Z","modified":"2023-06-22T02:25:32.116844863Z","checksum":"5120e4e2202e9dc26c211a0c4a1eae31c42b4512119e12ed43a418c7dff47d47"},
    {"filename":"0wijbapr.md","filenameStem":"0wijbapr","path":"fleeting/0wijbapr.md","absPath":"/home/khadd/mynotes/fleeting/0wijbapr.md","title":"RustSan data flow analysis example","link":"[[fleeting/0wijbapr]]","lead":"#fleeting","body":"#fleeting\n\nGodbolt flags\n```\n -C llvm-args=\"--opaque-pointers=0\"  -Z mir-opt-level=0\n```\n\n```rust\nuse std::*;\n\nfn foo(arg: \u0026mut i32, arg2: \u0026i32){\n    let mut x: i32 = 0;\n    let y: i32 = *arg2;\n    \n    unsafe {\n        x = 20;\n        *arg = y + x;\n    }    \n\n}\n\n\n\npub fn main() {\n    let mut x: i32 = 5;\n    let y: i32 = 6;\n    hint::black_box(foo(\u0026mut x, \u0026y));\n}\n\n```\n \n``` llvm\ndefine internal void @_ZN7example3foo17h16d9ab8665c1c250E(i32* align 4 %arg, i32* align 4 %arg2) unnamed_addr #1 !dbg !15 {\nstart:\n  %x = alloca i32, align 4\n  store i32 0, i32* %x, align 4, !dbg !18\n  %y = load i32, i32* %arg2, align 4, !dbg !19, !noundef !11\n  store i32 20, i32* %x, align 4, !dbg !21\n  %_6 = load i32, i32* %x, align 4, !dbg !24, !noundef !11\n  %0 = call { i32, i1 } @llvm.sadd.with.overflow.i32(i32 %y, i32 %_6), !dbg !25\n  %_7.0 = extractvalue { i32, i1 } %0, 0, !dbg !25\n  %_7.1 = extractvalue { i32, i1 } %0, 1, !dbg !25\n  %1 = call i1 @llvm.expect.i1(i1 %_7.1, i1 false), !dbg !25\n  br i1 %1, label %panic, label %bb1, !dbg !25\n\nbb1:                                              ; preds = %start\n  store i32 %_7.0, i32* %arg, align 4, !dbg !26\n  ret void, !dbg !27\n\npanic:                                            ; preds = %start\n  call void @_ZN4core9panicking5panic17hcaff1f3d20618491E([0 x i8]* align 1 bitcast ([28 x i8]* @str.0 to [0 x i8]*), i64 28, %\"core::panic::location::Location\u003c'_\u003e\"* align 8 bitcast (\u003c{ i8*, [16 x i8] }\u003e* @alloc_9bc9feaf68b8c234019a4170dc48b236 to %\"core::panic::location::Location\u003c'_\u003e\"*)) #5, !dbg !25\n  unreachable, !dbg !25\n}\n```","snippets":["#fleeting"],"rawContent":"# RustSan data flow analysis example\n#fleeting\n\nGodbolt flags\n```\n -C llvm-args=\"--opaque-pointers=0\"  -Z mir-opt-level=0\n```\n\n```rust\nuse std::*;\n\nfn foo(arg: \u0026mut i32, arg2: \u0026i32){\n    let mut x: i32 = 0;\n    let y: i32 = *arg2;\n    \n    unsafe {\n        x = 20;\n        *arg = y + x;\n    }    \n\n}\n\n\n\npub fn main() {\n    let mut x: i32 = 5;\n    let y: i32 = 6;\n    hint::black_box(foo(\u0026mut x, \u0026y));\n}\n\n```\n \n``` llvm\ndefine internal void @_ZN7example3foo17h16d9ab8665c1c250E(i32* align 4 %arg, i32* align 4 %arg2) unnamed_addr #1 !dbg !15 {\nstart:\n  %x = alloca i32, align 4\n  store i32 0, i32* %x, align 4, !dbg !18\n  %y = load i32, i32* %arg2, align 4, !dbg !19, !noundef !11\n  store i32 20, i32* %x, align 4, !dbg !21\n  %_6 = load i32, i32* %x, align 4, !dbg !24, !noundef !11\n  %0 = call { i32, i1 } @llvm.sadd.with.overflow.i32(i32 %y, i32 %_6), !dbg !25\n  %_7.0 = extractvalue { i32, i1 } %0, 0, !dbg !25\n  %_7.1 = extractvalue { i32, i1 } %0, 1, !dbg !25\n  %1 = call i1 @llvm.expect.i1(i1 %_7.1, i1 false), !dbg !25\n  br i1 %1, label %panic, label %bb1, !dbg !25\n\nbb1:                                              ; preds = %start\n  store i32 %_7.0, i32* %arg, align 4, !dbg !26\n  ret void, !dbg !27\n\npanic:                                            ; preds = %start\n  call void @_ZN4core9panicking5panic17hcaff1f3d20618491E([0 x i8]* align 1 bitcast ([28 x i8]* @str.0 to [0 x i8]*), i64 28, %\"core::panic::location::Location\u003c'_\u003e\"* align 8 bitcast (\u003c{ i8*, [16 x i8] }\u003e* @alloc_9bc9feaf68b8c234019a4170dc48b236 to %\"core::panic::location::Location\u003c'_\u003e\"*)) #5, !dbg !25\n  unreachable, !dbg !25\n}\n```\n","wordCount":250,"tags":["fleeting"],"metadata":{},"created":"2023-06-03T06:15:55.795973808Z","modified":"2023-06-03T06:46:58.419466921Z","checksum":"93fcde9ab335e05339e5d1f71abbf778fed47d069490537315222d663e59da04"},
    {"filename":"0kmxhvf5.md","filenameStem":"0kmxhvf5","path":"0kmxhvf5.md","absPath":"/home/khadd/mynotes/0kmxhvf5.md","title":"S\u0026P 2023","link":"[[0kmxhvf5]]","lead":"#conference\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)\n# System-ish papers\nNew architecture\n- SecureCells: A Secure Compartmentalized Architecture\n- Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture","body":"#conference\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)\n# System-ish papers\nNew architecture\n- SecureCells: A Secure Compartmentalized Architecture\n- Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture\n\nSecure System\n- WaVe: A Verifiably Secure WebAssembly Sandboxing Runtime\n- uSWITCH: Fast Kernel Context Isolation with Implicit Context Switches\n\nSystem for ML\n- ShadowNet: A Secure and Efficient On-device Model Inference System for Convolutional Neural Networks\n\nExploits\n- WarpAttack: Bypassing CFI through Compiler-Introduced Double-Fetches\n\nKernel bugs\n- Precise Detection of Kernel Data Races with Probabilistic Lockset Analysis\n- When Top-down Meets Bottom-up: Detecting and Exploiting Use-After-Cleanup Bugs in Linux Kernel\n- AEM: Facilitating Cross-Version Exploitability Assessment of Linux Kernel Vulnerabilities\n\nProgram analysis, compartmentalization\n- Practical Program Modularization with Type-Based Dependence Analysis\n- EC: Embedded Systems Compartmentalization via Intra-Kernel Isolation\n- Low-Cost Privilege Separation with Compile Time Compartmentalization for Embedded Systems","snippets":["#conference\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)\n# System-ish papers\nNew architecture\n- SecureCells: A Secure Compartmentalized Architecture\n- Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture"],"rawContent":"# S\u0026P 2023\n#conference\n[Papers are here](https://www.computer.org/csdl/proceedings/sp/2023/1He7WWuJExG)\n# System-ish papers\nNew architecture\n- SecureCells: A Secure Compartmentalized Architecture\n- Control Flow and Pointer Integrity Enforcement in a Secure Tagged Architecture\n\nSecure System\n- WaVe: A Verifiably Secure WebAssembly Sandboxing Runtime\n- uSWITCH: Fast Kernel Context Isolation with Implicit Context Switches\n\nSystem for ML\n- ShadowNet: A Secure and Efficient On-device Model Inference System for Convolutional Neural Networks\n\nExploits\n- WarpAttack: Bypassing CFI through Compiler-Introduced Double-Fetches\n\nKernel bugs\n- Precise Detection of Kernel Data Races with Probabilistic Lockset Analysis\n- When Top-down Meets Bottom-up: Detecting and Exploiting Use-After-Cleanup Bugs in Linux Kernel\n- AEM: Facilitating Cross-Version Exploitability Assessment of Linux Kernel Vulnerabilities\n\nProgram analysis, compartmentalization\n- Practical Program Modularization with Type-Based Dependence Analysis\n- EC: Embedded Systems Compartmentalization via Intra-Kernel Isolation\n- Low-Cost Privilege Separation with Compile Time Compartmentalization for Embedded Systems\n","wordCount":141,"tags":["conference"],"metadata":{},"created":"2023-05-22T02:06:14.446281169Z","modified":"2023-05-18T08:47:29.167591966Z","checksum":"976f60f6c0bf31ca85f498fdfc4be03db90e463f0c94c656998b861cbd7720db"},
    {"filename":"8igqoq32.md","filenameStem":"8igqoq32","path":"8igqoq32.md","absPath":"/home/khadd/mynotes/8igqoq32.md","title":"Single Address Space systems","link":"[[8igqoq32]]","lead":"#os","body":"#os \n\n\n\n# Redleaf\n@narayanan2020redleaf\n\nMemory safety of Rust (without `unsafe`) guarantee the isolation between subsystems. \n\n# CARAT\nCARAT @suchy2020carat, @suchy2022carat,explore removing paging abstraction and the reliance on paging hardware (Page table walker, MMU, TLB). Instead, all software need to be compiled by a trusted compiler to use physical addressing.\n\nMemory protection is achieved by compiler-inserted guards.","snippets":["#os"],"rawContent":"# Single Address Space systems\n#os \n\n\n\n# Redleaf\n@narayanan2020redleaf\n\nMemory safety of Rust (without `unsafe`) guarantee the isolation between subsystems. \n\n# CARAT\nCARAT @suchy2020carat, @suchy2022carat,explore removing paging abstraction and the reliance on paging hardware (Page table walker, MMU, TLB). Instead, all software need to be compiled by a trusted compiler to use physical addressing.\n\nMemory protection is achieved by compiler-inserted guards.\n\n\n","wordCount":61,"tags":["os"],"metadata":{},"created":"2023-06-19T03:04:24.886303372Z","modified":"2024-05-20T08:51:49.06021482Z","checksum":"4d06c169e558b8648e087d9d2a7ca3345b8d96160d57ea151c52aa40bd1fa442"},
    {"filename":"2j6s9zpm.md","filenameStem":"2j6s9zpm","path":"2j6s9zpm.md","absPath":"/home/khadd/mynotes/2j6s9zpm.md","title":"State spill","link":"[[2j6s9zpm]]","lead":"#os #microkernel","body":"#os #microkernel\n\nState spills happen when a seemingly isolated and modularized software component change its state due to interactions with other components, such that future correctness depends on such state.\n\nState spills harms extensibility/migration of systems. This happens when an entity provides an abstraction layer for other entities. \n- For example, in Linux, the OS process abstraction stores state into members of `task_struct`, which might also contains objects from other OS entities. This prevents *process mitigation*, since the OS must keep track of all changes made to other OS entities. \n- In microkernels, abstraction layer is provided by userspace server. State spills into the userspace servers prevents their live update and hot-swapping, since other applications are depended on those states.\n\nState spills hurt availability of systems (it breaks fault isolation and fault tolerance). This happen when an entity acts as a *multiplexer* that allows multiple clients to access an underlying resource. \n- Corruptions caused by state spills in *Process management* entities in OS cause all process to be affected.\n- *Recovery* of servers is also hindered due to state spill, recovery on behalf of one client can affect other clients.\n\nAs a final note, removing state spill forces the caller to memory to allocate the context used for cross-compartment interaction. In a sense, it also improves the security of the per-compartment interface. See 1 and 4 in [[qti6u06p]].\n\n\n## References\n- @boos2017characterizationl: Introduce the term state spill and provides its classification.\n- @boos2020theseus (see [[literature/jfm8ud28]]): An operating system that aim to minimize state spill.","snippets":["#os #microkernel"],"rawContent":"# State spill\n#os #microkernel\n\nState spills happen when a seemingly isolated and modularized software component change its state due to interactions with other components, such that future correctness depends on such state.\n\nState spills harms extensibility/migration of systems. This happens when an entity provides an abstraction layer for other entities. \n- For example, in Linux, the OS process abstraction stores state into members of `task_struct`, which might also contains objects from other OS entities. This prevents *process mitigation*, since the OS must keep track of all changes made to other OS entities. \n- In microkernels, abstraction layer is provided by userspace server. State spills into the userspace servers prevents their live update and hot-swapping, since other applications are depended on those states.\n\nState spills hurt availability of systems (it breaks fault isolation and fault tolerance). This happen when an entity acts as a *multiplexer* that allows multiple clients to access an underlying resource. \n- Corruptions caused by state spills in *Process management* entities in OS cause all process to be affected.\n- *Recovery* of servers is also hindered due to state spill, recovery on behalf of one client can affect other clients.\n\nAs a final note, removing state spill forces the caller to memory to allocate the context used for cross-compartment interaction. In a sense, it also improves the security of the per-compartment interface. See 1 and 4 in [[qti6u06p]].\n\n\n## References\n- @boos2017characterizationl: Introduce the term state spill and provides its classification.\n- @boos2020theseus (see [[literature/jfm8ud28]]): An operating system that aim to minimize state spill. \n","wordCount":257,"tags":["microkernel","os"],"metadata":{},"created":"2023-05-17T03:51:43.216766843Z","modified":"2023-05-25T06:09:51.185041651Z","checksum":"25c6574a6f1038ace54ec6f43397708818272fd3435bf365b784d35017cb91ca"},
    {"filename":"awlfkl73.md","filenameStem":"awlfkl73","path":"awlfkl73.md","absPath":"/home/khadd/mynotes/awlfkl73.md","title":"System Design","link":"[[awlfkl73]]","lead":"- [[xxn0pki0]]","body":"- [[xxn0pki0]]\n\n# Reference\n- [What we talk about when we talk about System Design](https://maheshba.bitbucket.io/blog/2023/07/12/Design.html): Awesome blog about experiences in system design by a distributed system designer.","snippets":["- [[xxn0pki0]]"],"rawContent":"# System Design\n\n- [[xxn0pki0]]\n\n# Reference\n- [What we talk about when we talk about System Design](https://maheshba.bitbucket.io/blog/2023/07/12/Design.html): Awesome blog about experiences in system design by a distributed system designer.\n","wordCount":30,"tags":[],"metadata":{},"created":"2023-08-11T08:47:56.544351934Z","modified":"2024-05-20T08:51:35.953496951Z","checksum":"6881fa363ad009a68335e37887ef799ee5447654ea0538b6109bca9051e03144"},
    {"filename":"todo.md","filenameStem":"todo","path":"todo.md","absPath":"/home/khadd/mynotes/todo.md","title":"TODO","link":"[[todo]]","lead":"","body":"","snippets":[],"rawContent":"# TODO\n\n\n\n","wordCount":2,"tags":[],"metadata":{},"created":"2023-06-21T03:34:09.93430684Z","modified":"2023-08-09T06:08:41.141462811Z","checksum":"1cb5fdec4736d757043a41eb88e0b45f0d8ccab43c375f32883aa108c1a6e8ba"},
    {"filename":"fvom56lw.md","filenameStem":"fvom56lw","path":"fvom56lw.md","absPath":"/home/khadd/mynotes/fvom56lw.md","title":"TSX-based control-channel defenses","link":"[[fvom56lw]]","lead":"#tsx #controlled-channel","body":"#tsx #controlled-channel\n\nFor more context, see [[5kzr3hwx]].\n\n# T-SGX\nT-SGX @shih2017tsgx uses Intel TSX  to prevent the OS from knowing the page fault, since TSX supresses page faults on during a transaction. The system transform the program such that (almost) all code is executed in a TSX transaction. Any page fault is treated as an attack attempt by the OS. \nReported overheads of the system is about 50%.\n\n\n# Deja Vu\n@chen2017detecting uses TSX to *detect* wheter an AEX has occured during the execution of critical code. The program is instrumented to periodically measure its execution time, and if the execution time deviate too much from its expected time, an AEX is detected.\n\n```c\nwhile (1) {\n  // update counter\n  if (_xbegin() == _XBEGIN_STARTED)\n  {\n      int rand = random();\n      for (int i =0; i \u003c rand; i++){\n        // rand cycles is performed\n      }\n      _xend();\n  }\n  else {\n    interrupted += 1;\n    continue;\n  }\n  timer += rand;\n}\n```\n\nA thread is used to continuously update a global timer variable.\nThe program is then instrumented to uses this timer to detect attacks (e.g., if a basic block takes too long to complete and the there was an interrupt, then there is a high chance that an AEX occurred).\nThe counter thread uses TSX to determine whether an interrupt happened.","snippets":["#tsx #controlled-channel"],"rawContent":"# TSX-based control-channel defenses\n#tsx #controlled-channel\n\nFor more context, see [[5kzr3hwx]].\n\n# T-SGX\nT-SGX @shih2017tsgx uses Intel TSX  to prevent the OS from knowing the page fault, since TSX supresses page faults on during a transaction. The system transform the program such that (almost) all code is executed in a TSX transaction. Any page fault is treated as an attack attempt by the OS. \nReported overheads of the system is about 50%.\n\n\n# Deja Vu\n@chen2017detecting uses TSX to *detect* wheter an AEX has occured during the execution of critical code. The program is instrumented to periodically measure its execution time, and if the execution time deviate too much from its expected time, an AEX is detected.\n\n```c\nwhile (1) {\n  // update counter\n  if (_xbegin() == _XBEGIN_STARTED)\n  {\n      int rand = random();\n      for (int i =0; i \u003c rand; i++){\n        // rand cycles is performed\n      }\n      _xend();\n  }\n  else {\n    interrupted += 1;\n    continue;\n  }\n  timer += rand;\n}\n```\n\nA thread is used to continuously update a global timer variable.\nThe program is then instrumented to uses this timer to detect attacks (e.g., if a basic block takes too long to complete and the there was an interrupt, then there is a high chance that an AEX occurred).\nThe counter thread uses TSX to determine whether an interrupt happened.\n","wordCount":221,"tags":["controlled-channel","tsx"],"metadata":{},"created":"2023-06-19T03:04:24.89591636Z","modified":"2023-07-27T09:51:27.100986669Z","checksum":"e8e1651786c7f285a789a1d3566323802e4d84166a16c5014f9e086adf30285f"},
    {"filename":"jsygj3tb.md","filenameStem":"jsygj3tb","path":"jsygj3tb.md","absPath":"/home/khadd/mynotes/jsygj3tb.md","title":"The Second-system Effect","link":"[[jsygj3tb]]","lead":"#programming","body":"#programming\n\n[@brooks1975mythical] coins the term *the Second-System effect*: The second system that a system architect builds is the most *dangerous* (i.e., over-designed) one. The reasons are as follows. The first system is ought to be carefully designed and clean. The designer would leaves all the crazy ideas until \"next time\". With the confidence of the first successful system, the architect would go on and design the second system without any restriction.\n\nThis might  be the reason for over-designed systems.\n\nAs for third and later systems, the architect gains experiences and generalized knowledge of what would work and would not work for the type of system.\n\n\n\nTo avoid this effect, [@brooks1975mythical] suggests to design the second system with self-discipline.\n\n\n\n[@brooks1975mythical]: The Mythical Man Month","snippets":["#programming"],"rawContent":"# The Second-system Effect\n#programming\n\n[@brooks1975mythical] coins the term *the Second-System effect*: The second system that a system architect builds is the most *dangerous* (i.e., over-designed) one. The reasons are as follows. The first system is ought to be carefully designed and clean. The designer would leaves all the crazy ideas until \"next time\". With the confidence of the first successful system, the architect would go on and design the second system without any restriction.\n\nThis might  be the reason for over-designed systems.\n\nAs for third and later systems, the architect gains experiences and generalized knowledge of what would work and would not work for the type of system.\n\n\n\nTo avoid this effect, [@brooks1975mythical] suggests to design the second system with self-discipline.\n\n\n\n[@brooks1975mythical]: The Mythical Man Month\n","wordCount":127,"tags":["programming"],"metadata":{},"created":"2023-05-22T06:09:03.041943041Z","modified":"2023-05-22T06:20:33.188909341Z","checksum":"19ac7da7ec63d51fb52a31349562b2426198f07e5b46833fe57a5ca2e61c2397"},
    {"filename":"7t4jlnaq.md","filenameStem":"7t4jlnaq","path":"7t4jlnaq.md","absPath":"/home/khadd/mynotes/7t4jlnaq.md","title":"The goals of an Operating System","link":"[[7t4jlnaq]]","lead":"#os","body":"#os\n\nThere are two main goals of an OS: abstraction and resource management.\n\nFrom the top-down view of the user, the OS provides abstraction over complex interactions with the hardware. \nIt turns an impossible task (write applications that interacts with the hardware directly) in to two manageable tasks: (1) design and implement the abstraction, and (2) use the abstraction to do works.\nTwo most fundamental abstractions provided by most OSes are *files* and *processes*. Files and file-related system calls abstract away the communication and management of data stored on the disk. Process is a unit of execution that enable multitasking (1.1, [@tanenbaum2015modern]). \n\n\nFrom a bottom-up view, an operating system enable fair resource sharing among multiple users. This is called *multiplexing*. There can be *space multiplexing*, sharing a part of a resource between users (e.g., memory), and *time multiplexing*, sharing time slices of a resource (e.g., cpu time) between users.\nAlso, from the user point of view, the resources are being *virtualized*: the OS give the user an *illusion* of having access to entire system (e.g., all of physical memory).\n\nSee also:\n- [[k60yjf6q]]","snippets":["#os"],"rawContent":"# The goals of an Operating System\n#os\n\nThere are two main goals of an OS: abstraction and resource management.\n\nFrom the top-down view of the user, the OS provides abstraction over complex interactions with the hardware. \nIt turns an impossible task (write applications that interacts with the hardware directly) in to two manageable tasks: (1) design and implement the abstraction, and (2) use the abstraction to do works.\nTwo most fundamental abstractions provided by most OSes are *files* and *processes*. Files and file-related system calls abstract away the communication and management of data stored on the disk. Process is a unit of execution that enable multitasking (1.1, [@tanenbaum2015modern]). \n\n\nFrom a bottom-up view, an operating system enable fair resource sharing among multiple users. This is called *multiplexing*. There can be *space multiplexing*, sharing a part of a resource between users (e.g., memory), and *time multiplexing*, sharing time slices of a resource (e.g., cpu time) between users.\nAlso, from the user point of view, the resources are being *virtualized*: the OS give the user an *illusion* of having access to entire system (e.g., all of physical memory).\n\nSee also:\n- [[k60yjf6q]]\n\n","wordCount":190,"tags":["os"],"metadata":{},"created":"2023-05-22T02:06:14.448908623Z","modified":"2023-05-24T06:38:38.567914512Z","checksum":"20d1c90b6d1df790b2f5e5a7f15b16d05b3e7c401ecdfeae2ba20094f2eb6ff6"},
    {"filename":"jfm8ud28.md","filenameStem":"jfm8ud28","path":"literature/jfm8ud28.md","absPath":"/home/khadd/mynotes/literature/jfm8ud28.md","title":"Theseus: an Experiment in Operating System Structure and State Management","link":"[[literature/jfm8ud28]]","lead":"#literature #os #rust\n@boos2020theseus","body":"#literature #os #rust\n@boos2020theseus\n\n# Main arguments\nState spill harms availability and evolvability of system software (see [[2j6s9zpm]]).\n\nTo mitigate state spills, it is necessary to restructure the OS architecture\n- The proposed system rearchitect OS components into Cells that has *runtime-persistent* bound [[#cells]].\n- It then avoid state spill through exporting states to the clients in similar way to RESTful APIs [[#state-management]]\n\nProgramming language can statically ensure certain correctness invariants in the OS.\n- Theseus incorporates resource-specific invariants into Rust compiler checks. For instance, memory management is implemented via the `MappedPages` types that also introduce new static invariants for mapping memory (see 4.3).\n\nIt is necessary to match runtime execution environment with that of the language's runtime model (i.e., *intralingual* design) to take advantages of Rust\n- Cells in Theseus are single-address space, single-privilege level, and use a single allocator instance. \n- It enable compiler to assist resource management,\n- It enables compiler to assert safety checks without gaps in code behaviors.\n\n## Cells\nAll OS components are splitted into minimal cells, to be executed in single-address space (SAS), single privilege level (SPL), and are isolated using Rust. Cells in Theseus have *runtime-persistent* bounds, in that the bounds are persisted throughout compile time (crate bound), load time (memory regions), and runtime (by keeping track of dependency metadata).\n- This idea is opposite to the intertwined bounds introduces in monolithic kernels. Takes kernel modules as an example, they don't have clearly defined bounds; kernel module can access other OS entities in the code, and at runtime. \n- Persistent cell bounds allows for clean cell-swapping (aka migration) and cell evolution (aka live update) and fault recovery.\n\n\n## State management\nState spill is avoided by *opaque exportation*, which essentially means that the client owns the state for client, but cannot read, or modify the state due to Type safety.\n- This is similar to Object-capability systems (#capabilities), the callee might hold the capabilities to invoke a function, but not using the capabilities by themself. Due to Rust's type safety, variables are akin to capabilities. \n- Similarly, RESTful web architectures also employ a similar kind of *stateless communication*, where the client pass everything that is needed to handle the request to the server.\n- This is only possible when the client is enforced with Rust type safety.\n\nTheseus also enables *soft states* that can be discarded without error and *unavoidable states* (clientless state required by the hardware and states invoked by hardware). Those states are stored into a unique cell call `state_db`.\n- Static states are moved into state_db, and only a weak reference is used. This decouple the server cells that use hardware states from the hardware state lifetime, so they can be swapped.  \n- state_db cell must be serialized into non-volatile storage when swapping.\n\n\n## Cell swapping \u0026 evolution\nTODO","snippets":["#literature #os #rust\n@boos2020theseus"],"rawContent":"# Theseus: an Experiment in Operating System Structure and State Management\n#literature #os #rust\n@boos2020theseus\n\n# Main arguments\nState spill harms availability and evolvability of system software (see [[2j6s9zpm]]).\n\nTo mitigate state spills, it is necessary to restructure the OS architecture\n- The proposed system rearchitect OS components into Cells that has *runtime-persistent* bound [[#cells]].\n- It then avoid state spill through exporting states to the clients in similar way to RESTful APIs [[#state-management]]\n\nProgramming language can statically ensure certain correctness invariants in the OS.\n- Theseus incorporates resource-specific invariants into Rust compiler checks. For instance, memory management is implemented via the `MappedPages` types that also introduce new static invariants for mapping memory (see 4.3).\n\nIt is necessary to match runtime execution environment with that of the language's runtime model (i.e., *intralingual* design) to take advantages of Rust\n- Cells in Theseus are single-address space, single-privilege level, and use a single allocator instance. \n- It enable compiler to assist resource management,\n- It enables compiler to assert safety checks without gaps in code behaviors.\n\n## Cells\nAll OS components are splitted into minimal cells, to be executed in single-address space (SAS), single privilege level (SPL), and are isolated using Rust. Cells in Theseus have *runtime-persistent* bounds, in that the bounds are persisted throughout compile time (crate bound), load time (memory regions), and runtime (by keeping track of dependency metadata).\n- This idea is opposite to the intertwined bounds introduces in monolithic kernels. Takes kernel modules as an example, they don't have clearly defined bounds; kernel module can access other OS entities in the code, and at runtime. \n- Persistent cell bounds allows for clean cell-swapping (aka migration) and cell evolution (aka live update) and fault recovery.\n\n\n## State management\nState spill is avoided by *opaque exportation*, which essentially means that the client owns the state for client, but cannot read, or modify the state due to Type safety.\n- This is similar to Object-capability systems (#capabilities), the callee might hold the capabilities to invoke a function, but not using the capabilities by themself. Due to Rust's type safety, variables are akin to capabilities. \n- Similarly, RESTful web architectures also employ a similar kind of *stateless communication*, where the client pass everything that is needed to handle the request to the server.\n- This is only possible when the client is enforced with Rust type safety.\n\nTheseus also enables *soft states* that can be discarded without error and *unavoidable states* (clientless state required by the hardware and states invoked by hardware). Those states are stored into a unique cell call `state_db`.\n- Static states are moved into state_db, and only a weak reference is used. This decouple the server cells that use hardware states from the hardware state lifetime, so they can be swapped.  \n- state_db cell must be serialized into non-volatile storage when swapping.\n\n\n## Cell swapping \u0026 evolution\nTODO\n","wordCount":480,"tags":["literature","capabilities","os","rust"],"metadata":{},"created":"2023-05-17T02:11:08.117442236Z","modified":"2023-05-18T04:46:20.063707084Z","checksum":"4fa674038def9a92c9953808048b3263dcce546541f94d3e451726d75c99f422"},
    {"filename":"xxn0pki0.md","filenameStem":"xxn0pki0","path":"xxn0pki0.md","absPath":"/home/khadd/mynotes/xxn0pki0.md","title":"Think in parallel; Design together; Implement in parallel; Review together","link":"[[xxn0pki0]]","lead":"#design","body":"#design\n\nThinking should not be restricted or coordinated.\n\nDesign should be done together.\n\nImplementation can be done in parallel. \n\nReviewing should be centralized.\n\n\n# Reference\n- [Design](https://maheshba.bitbucket.io/blog/2023/07/12/Design.html)","snippets":["#design"],"rawContent":"# Think in parallel; Design together; Implement in parallel; Review together\n#design\n\nThinking should not be restricted or coordinated.\n\nDesign should be done together.\n\nImplementation can be done in parallel. \n\nReviewing should be centralized.\n\n\n# Reference\n- [Design](https://maheshba.bitbucket.io/blog/2023/07/12/Design.html)\n","wordCount":38,"tags":["design"],"metadata":{},"created":"2023-08-11T08:42:20.819648413Z","modified":"2024-05-20T08:54:24.744160142Z","checksum":"21ab3036c44a491534f9b2cabb52fa5984e88f0cda3131c186b9f0bc922af42b"},
    {"filename":"k60yjf6q.md","filenameStem":"k60yjf6q","path":"k60yjf6q.md","absPath":"/home/khadd/mynotes/k60yjf6q.md","title":"Three pieces of an Operating System","link":"[[k60yjf6q]]","lead":"#os","body":"#os\n\nThere are three main concept in achieving an operating system: *virtualization*, *concurrency* and  *persistent* [@arpaci-dusseauoperating].\n\n## Virtualization\nVirtualization give an process an illusion of having access to the whole underlying resource. To do so, the OS take physical resources and transform them into virtual resources, and hand them out to the users.\n\nThis is the key in maximizing resource usage, since a single job rarely utilize all of the available hardware resource. Virtualization also make the system easier to use. \n\nThe key problem with virtualization is how to do it efficiently, how to attain fairness, and what hardware support is needed.\n\n## Concurrency\nConcurrency allows multiple jobs to execute at once. This is especially important in maximizing CPU efficiency: when waiting for slow I/O jobs, the CPU time is better used executing other tasks.\nIn a sense, concurrency is achieved by virtualizing CPU time?\n\nIn the OS, there is two granularity of concurrency, threads and processes.\n\nThe main problems with concurrency is correctness. Given multiple concurrent tasks that access to the same underlying resources, how to ensure a correct and consistent execution. To achieve this, the OS gives privimites. \n\n\n## Persistent\nFinally, persistent deals with how to reliably store and retrieve data in a persistent storage (e.g., disk). This is provided by the *file system*.\n\nThe main problems is how manage information on the disk efficiently, and how deal with failures.\n\n# See also\n- [[7t4jlnaq]]","snippets":["#os"],"rawContent":"# Three pieces of an Operating System\n#os\n\nThere are three main concept in achieving an operating system: *virtualization*, *concurrency* and  *persistent* [@arpaci-dusseauoperating].\n\n## Virtualization\nVirtualization give an process an illusion of having access to the whole underlying resource. To do so, the OS take physical resources and transform them into virtual resources, and hand them out to the users.\n\nThis is the key in maximizing resource usage, since a single job rarely utilize all of the available hardware resource. Virtualization also make the system easier to use. \n\nThe key problem with virtualization is how to do it efficiently, how to attain fairness, and what hardware support is needed.\n\n## Concurrency\nConcurrency allows multiple jobs to execute at once. This is especially important in maximizing CPU efficiency: when waiting for slow I/O jobs, the CPU time is better used executing other tasks.\nIn a sense, concurrency is achieved by virtualizing CPU time?\n\nIn the OS, there is two granularity of concurrency, threads and processes.\n\nThe main problems with concurrency is correctness. Given multiple concurrent tasks that access to the same underlying resources, how to ensure a correct and consistent execution. To achieve this, the OS gives privimites. \n\n\n## Persistent\nFinally, persistent deals with how to reliably store and retrieve data in a persistent storage (e.g., disk). This is provided by the *file system*.\n\nThe main problems is how manage information on the disk efficiently, and how deal with failures.\n\n# See also\n- [[7t4jlnaq]]\n\n\n\n","wordCount":244,"tags":["os"],"metadata":{},"created":"2023-05-24T06:21:06.186090369Z","modified":"2023-05-24T06:39:18.834733523Z","checksum":"d547fee0d1c262856348c3a48580e733965359f20312bf824f49ae5b5d3ed3d8"},
    {"filename":"cosmdjej.md","filenameStem":"cosmdjej","path":"cosmdjej.md","absPath":"/home/khadd/mynotes/cosmdjej.md","title":"Transactional memory","link":"[[cosmdjej]]","lead":"#conccurency","body":"#conccurency\n\n\nTransactional memory is a technique that simplify concurrent programming by allowing critical sections to execute *optimistically* (i.e., [optimistic concurrency control](https://en.wikipedia.org/wiki/Optimistic_concurrency_control)).\n\n\nA transaction consists of series of intermediate *atomic* read and writes to some memory location. A transaction can be *commited*, as long as there is no conflicts.\nOn the otherhand, if there is any conflict during a transaction, the it is rolled back, and an error handler is invoked (e.g., to retry the transaction).\n\n\nA section of critical code marked as transactional can execute with minimal interventions (e.g., acquiring lock). This leads to a much simpler programming model, and also less error-prone (e.g., deadlocks), since the validity of transactions is guaranteed by tranactional memory mechanisms.","snippets":["#conccurency"],"rawContent":"# Transactional memory\n#conccurency\n\n\nTransactional memory is a technique that simplify concurrent programming by allowing critical sections to execute *optimistically* (i.e., [optimistic concurrency control](https://en.wikipedia.org/wiki/Optimistic_concurrency_control)).\n\n\nA transaction consists of series of intermediate *atomic* read and writes to some memory location. A transaction can be *commited*, as long as there is no conflicts.\nOn the otherhand, if there is any conflict during a transaction, the it is rolled back, and an error handler is invoked (e.g., to retry the transaction).\n\n\nA section of critical code marked as transactional can execute with minimal interventions (e.g., acquiring lock). This leads to a much simpler programming model, and also less error-prone (e.g., deadlocks), since the validity of transactions is guaranteed by tranactional memory mechanisms.\n","wordCount":119,"tags":["conccurency"],"metadata":{},"created":"2023-06-19T03:04:24.889404158Z","modified":"2023-06-19T02:01:17.89523677Z","checksum":"6b45a4d7969d52b49762cacccc1a118156b86d78f4a0c5f2d6de91478741ef7c"},
    {"filename":"cv3peid6.md","filenameStem":"cv3peid6","path":"cv3peid6.md","absPath":"/home/khadd/mynotes/cv3peid6.md","title":"Turning reading notes to permanent notes","link":"[[cv3peid6]]","lead":"#note-taking #zettelkasten","body":"#note-taking #zettelkasten\n\n\n# Steps\n\n## While reading\nIt is useful to keep a physical notes.\n\n## After reading\n[create-zettel-from-reading-notes] suggested using three phases:\n- Pull all the notes out. The order do not matter.\n- Cluster the notes. What are the big ideas that emerges?\n- Write notes about the clusters that emerges.\n\n# References\n[create-zettel-from-reading-notes](https://zettelkasten.de/posts/create-zettel-from-reading-notes/)\n\n[How to process reading annotations into evergreen notes](https://notes.andymatuschak.org/z2PJ51tCXuPFxnfFVUxxgwjvZ1geu4YnYm7hK)\n\u003e\n1. Write a broad note which captures the “big idea” of one of your clusters.\n  - Are there multiple big ideas? Write multiple broad notes to maintain Evergreen notes should be atomic.\n2. Write finer-grained notes: Look through the individual scraps in that cluster. Write notes which capture more nuanced atomic ideas within that cluster.\n3. Connect: Search for relevant past notes which relate to these new notes. Link, merge, and revise as necessary to represent your new, synthesized conception of those ideas.\n  - See Evergreen notes should be densely linked and Create speculative outlines while you write.\n4. Revise: Return to the broad note and improve your summary based on what you’ve learned writing the detailed notes and the details you’ve unpacked, if it’s possible to do so without muddying their focus. Remove detailed notes that are no longer necessary; update others based on what you learned writing your updated broad note if appropriate.\n5. Loop","snippets":["#note-taking #zettelkasten"],"rawContent":"# Turning reading notes to permanent notes\n#note-taking #zettelkasten\n\n\n# Steps\n\n## While reading\nIt is useful to keep a physical notes.\n\n## After reading\n[create-zettel-from-reading-notes] suggested using three phases:\n- Pull all the notes out. The order do not matter.\n- Cluster the notes. What are the big ideas that emerges?\n- Write notes about the clusters that emerges.\n\n# References\n[create-zettel-from-reading-notes](https://zettelkasten.de/posts/create-zettel-from-reading-notes/)\n\n[How to process reading annotations into evergreen notes](https://notes.andymatuschak.org/z2PJ51tCXuPFxnfFVUxxgwjvZ1geu4YnYm7hK)\n\u003e\n1. Write a broad note which captures the “big idea” of one of your clusters.\n  - Are there multiple big ideas? Write multiple broad notes to maintain Evergreen notes should be atomic.\n2. Write finer-grained notes: Look through the individual scraps in that cluster. Write notes which capture more nuanced atomic ideas within that cluster.\n3. Connect: Search for relevant past notes which relate to these new notes. Link, merge, and revise as necessary to represent your new, synthesized conception of those ideas.\n  - See Evergreen notes should be densely linked and Create speculative outlines while you write.\n4. Revise: Return to the broad note and improve your summary based on what you’ve learned writing the detailed notes and the details you’ve unpacked, if it’s possible to do so without muddying their focus. Remove detailed notes that are no longer necessary; update others based on what you learned writing your updated broad note if appropriate.\n5. Loop\n\n\n","wordCount":229,"tags":["zettelkasten","note-taking"],"metadata":{},"created":"2023-07-04T05:15:19.820068673Z","modified":"2023-07-04T05:24:18.753357325Z","checksum":"697bbcc7e2d2a2efd3f08ab145bdf697116270f2a507e420abbb1fbb42d012b6"},
    {"filename":"k57qb7oh.md","filenameStem":"k57qb7oh","path":"k57qb7oh.md","absPath":"/home/khadd/mynotes/k57qb7oh.md","title":"Ubuntu notes","link":"[[k57qb7oh]]","lead":"#linux #distro","body":"#linux #distro\n\n\n# Package manager\n## Maintaining apt mirror\n\nIt is unecessary to manually rewrite `/etc/apt/source.list` with the fastest one. Apt supports selecting from a list of mirrors. Just put this to the top of `/etc/apt/source.list`:\n```bash\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-updates main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-backports main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-security main restricted universe multiverse\n```","snippets":["#linux #distro"],"rawContent":"# Ubuntu notes\n#linux #distro\n\n\n# Package manager\n## Maintaining apt mirror\n\nIt is unecessary to manually rewrite `/etc/apt/source.list` with the fastest one. Apt supports selecting from a list of mirrors. Just put this to the top of `/etc/apt/source.list`:\n```bash\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-updates main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-backports main restricted universe multiverse\ndeb mirror://mirrors.ubuntu.com/mirrors.txt jammy-security main restricted universe multiverse\n```\n\n\n","wordCount":69,"tags":["linux","distro"],"metadata":{},"created":"2023-06-16T08:04:25.806849293Z","modified":"2023-06-16T06:30:27.727664455Z","checksum":"f4fc4626b56ad0e2779ce3478f78b432d4f325ae6126ddd6a246f0b4f84d9592"},
    {"filename":"e7p8xpz4.md","filenameStem":"e7p8xpz4","path":"e7p8xpz4.md","absPath":"/home/khadd/mynotes/e7p8xpz4.md","title":"Unikernel Security","link":"[[e7p8xpz4]]","lead":"#unikernel #os #security #hardening","body":"#unikernel #os #security #hardening\n\n# The plus\nOverall, unikernels enables extreme attack surface reduction due to being specialized. Especially, attack surfaces are reduced in three aspect:\n- First, there is no shell implemented in unikernels, making attacks that aims to launch a shell infeasible.\n- Second, unikernels do not implement system calls, which can be an entry point for attacks. Hence, attackers are forced to use control-flow hijacking-based attacks to jump to unikernel functions,which can be mitigated through ASLR/CFI.  \n- Third, since the hardware are interfaces not emulated, attack against emulated hardware interface (the Venom attack (TODO)) is mitigated. \n- Forth, their infrastructures is *immutable*, to rebuild the unikernel app, the entire infrastructure (OS, application, libraries) need to be rebuilt. This avoid illegal modification, vulnerabilities from out-dated configurations.\n\n# The negative\nThe negatives (in security) of unikernels comes from two aspect: due to hardware virtualization, and due to lack of ring separation.\n- Because hardware is virtualized, entrophy suffers. Due to hardware being virtualized, random number generator based on hardware events lacks entropy. This leads to attacks on random number generator.\n- Second, due to the lack of ring separation, arbitrary execution attacks on application code enable access to kernel space, making privilege escalation unnecessary.\n- Moreover, many security features that are commonly deployed are missing on unikernels (maybe due to it being hard to maintain for both applications and kernel code). Examples are ASLR, __FORTIFY_SOURCE\n\n# References\n- @hindy2020security provides an overview of security of unikernels.","snippets":["#unikernel #os #security #hardening"],"rawContent":"# Unikernel Security\n#unikernel #os #security #hardening\n\n# The plus\nOverall, unikernels enables extreme attack surface reduction due to being specialized. Especially, attack surfaces are reduced in three aspect:\n- First, there is no shell implemented in unikernels, making attacks that aims to launch a shell infeasible.\n- Second, unikernels do not implement system calls, which can be an entry point for attacks. Hence, attackers are forced to use control-flow hijacking-based attacks to jump to unikernel functions,which can be mitigated through ASLR/CFI.  \n- Third, since the hardware are interfaces not emulated, attack against emulated hardware interface (the Venom attack (TODO)) is mitigated. \n- Forth, their infrastructures is *immutable*, to rebuild the unikernel app, the entire infrastructure (OS, application, libraries) need to be rebuilt. This avoid illegal modification, vulnerabilities from out-dated configurations.\n\n# The negative\nThe negatives (in security) of unikernels comes from two aspect: due to hardware virtualization, and due to lack of ring separation.\n- Because hardware is virtualized, entrophy suffers. Due to hardware being virtualized, random number generator based on hardware events lacks entropy. This leads to attacks on random number generator.\n- Second, due to the lack of ring separation, arbitrary execution attacks on application code enable access to kernel space, making privilege escalation unnecessary.\n- Moreover, many security features that are commonly deployed are missing on unikernels (maybe due to it being hard to maintain for both applications and kernel code). Examples are ASLR, __FORTIFY_SOURCE\n\n# References\n- @hindy2020security provides an overview of security of unikernels.\n","wordCount":250,"tags":["os","unikernel","security","hardening"],"metadata":{},"created":"2023-05-22T02:06:14.454012603Z","modified":"2023-05-22T02:03:53.601483238Z","checksum":"08f7aaf461dcf083ce967ebe97a84290974a8b2032ee7fede4a1a8e1d52c9a73"},
    {"filename":"fcf5pozg.md","filenameStem":"fcf5pozg","path":"fcf5pozg.md","absPath":"/home/khadd/mynotes/fcf5pozg.md","title":"Unikraft development notes","link":"[[fcf5pozg]]","lead":"#unikraft #unikernel","body":"#unikraft #unikernel\n\n# Development environment\nThe kraft tutorials are completely broken (at this moment).\n\nTo set up a functional development, first create a directory structure like this. \n```\n- root\n  - unikraft // The unikraft repo\n  - apps // external application\n    - helloworld\n    - ...\n  - libs // external libraries\n    - lib_test  \n    - ... \n```\n`unikraft` is cloned from the main repo, and apps can be any applications. There must be an application for testing the unikernel. \nThe helloworld application is a good starting point for testing. \n\n```bash\ngit clone https://github.com/unikraft/unikraft.git\ncd apps\ngit clone https://github.com/unikraft/app-helloworld.git\n```\n# Building applications\nFirst, the application needs to be configured. Use \n```\nmake menuconfig\n```\nand walk through the configuration.\n\nAfter the kernel is configured, just run to build.\n```\nmake\n```\n\n\n## Running\n``` bash\nqemu-system-x86_64 -enable-kvm -nographic -cpu host -kernel build/helloworld_qemu-x86_64\n\n```\n# Coding convention\n## Variable definition\nUse `const` for constant variable.\n\n## Addresses\nPhysical addresses has the type `__paddr_t`. There is also `__vaddr_t`\n\n## Function definition\n`static inline` is used for short functions.\n\n\n## struct definition\nstructs are sometimes defined in C files, or header files.\n\n`typedef struct` is not used.\n\n## Private states\nModules contains a pointer to their private states. \n```c\nstatic struct uk_vas *vmem_active_vas;\n```\n\n# Debugging\nrun qemu with the flags `-S -s` on the non-debugging image.\n\nSoftware breakpoints does not work, so hardware breakpoints need to be used with `hbreak`.\n\n## Debugging test case\nTest case name will be concactenated like this: `_uk_testsuite_ukvmem_case_test_basic_vas_layout`\n\n## Printing raw bytes\n`uk_hexdumpk` dumps the content of some region to printk. \n\n# Other notes\n- [[7gbms9if]]\n- [[xpolyx1l]]\n- [[1k9i1cr3]]\n- [[projects/gel6dwih]]","snippets":["#unikraft #unikernel"],"rawContent":"# Unikraft development notes\n#unikraft #unikernel\n\n# Development environment\nThe kraft tutorials are completely broken (at this moment).\n\nTo set up a functional development, first create a directory structure like this. \n```\n- root\n  - unikraft // The unikraft repo\n  - apps // external application\n    - helloworld\n    - ...\n  - libs // external libraries\n    - lib_test  \n    - ... \n```\n`unikraft` is cloned from the main repo, and apps can be any applications. There must be an application for testing the unikernel. \nThe helloworld application is a good starting point for testing. \n\n```bash\ngit clone https://github.com/unikraft/unikraft.git\ncd apps\ngit clone https://github.com/unikraft/app-helloworld.git\n```\n# Building applications\nFirst, the application needs to be configured. Use \n```\nmake menuconfig\n```\nand walk through the configuration.\n\nAfter the kernel is configured, just run to build.\n```\nmake\n```\n\n\n## Running\n``` bash\nqemu-system-x86_64 -enable-kvm -nographic -cpu host -kernel build/helloworld_qemu-x86_64\n\n```\n# Coding convention\n## Variable definition\nUse `const` for constant variable.\n\n## Addresses\nPhysical addresses has the type `__paddr_t`. There is also `__vaddr_t`\n\n## Function definition\n`static inline` is used for short functions.\n\n\n## struct definition\nstructs are sometimes defined in C files, or header files.\n\n`typedef struct` is not used.\n\n## Private states\nModules contains a pointer to their private states. \n```c\nstatic struct uk_vas *vmem_active_vas;\n```\n\n# Debugging\nrun qemu with the flags `-S -s` on the non-debugging image.\n\nSoftware breakpoints does not work, so hardware breakpoints need to be used with `hbreak`.\n\n## Debugging test case\nTest case name will be concactenated like this: `_uk_testsuite_ukvmem_case_test_basic_vas_layout`\n\n## Printing raw bytes\n`uk_hexdumpk` dumps the content of some region to printk. \n\n# Other notes\n- [[7gbms9if]]\n- [[xpolyx1l]]\n- [[1k9i1cr3]]\n- [[projects/gel6dwih]]\n","wordCount":277,"tags":["unikernel","unikraft"],"metadata":{},"created":"2023-06-16T08:04:25.803782694Z","modified":"2023-07-12T06:12:46.544984563Z","checksum":"c4e66faa57f63ee2847288232b7c914e27df2715323aed97ef41cc7f8aa2968a"},
    {"filename":"7gbms9if.md","filenameStem":"7gbms9if","path":"7gbms9if.md","absPath":"/home/khadd/mynotes/7gbms9if.md","title":"Unikraft's heap allocator","link":"[[7gbms9if]]","lead":"#unikraft","body":"#unikraft\n\n# Choice of allocator\nThe original paper says that Unikraft supports up to 5 allocator backends: buddy, TLFS, real-time, tinyalloc, mimalloc and Oscar\n\n@lupu2023nephele says tiny has the best performance among all\n\n# ukalloc\nUnikraft enables swapping of different allocator backends through the `ukalloc` interface. `ukalloc` keeps a linked-list pointers to `struct uk_alloc* _uk_alloc_head`, that points to the currently registered allocator.\n\n\n## Registration\nNew allocators must implement the interface\nAllocators are registered with `uk_alloc_register`, which assign `_uk_alloc_head` to the new allocator.\n\n\nIn `boot.c`, the allocators are hard-coded as:\n```c\n#if CONFIG_LIBUKBOOT_INITBBUDDY\n#include \u003cuk/allocbbuddy.h\u003e\n#define uk_alloc_init uk_allocbbuddy_init\n#elif CONFIG_LIBUKBOOT_INITREGION\n#include \u003cuk/allocregion.h\u003e\n#define uk_alloc_init uk_allocregion_init\n#elif CONFIG_LIBUKBOOT_INITMIMALLOC\n#include \u003cuk/mimalloc.h\u003e\n#define uk_alloc_init uk_mimalloc_init\n#elif CONFIG_LIBUKBOOT_INITTLSF\n#include \u003cuk/tlsf.h\u003e\n#define uk_alloc_init uk_tlsf_init\n#elif CONFIG_LIBUKBOOT_INITTINYALLOC\n#include \u003cuk/tinyalloc.h\u003e\n#define uk_alloc_init uk_tinyalloc_init\n#endif\n```\nHence, any allocator that are selected will be set as the heap allocator.\n\nThe `heap_init()` function takes the remaining memory (starting from `CONFIG_LIBUKBOOT_HEAP_BASE`), map them as anonymous pages, and adds them to the memory pool of the allocator.\n```c\n```\n\n\nFinally, `ukplat_memallocator_set()` set the current memory allocator\n\n## POSIX malloc\n`malloc` definition in `stdlib.h`:\n\n```c\nstatic inline void malloc(size_t size){\n  return uk_malloc(uk_alloc_get_default(), size);\n}\n```\nWhere `uk_alloc_get_default()` returns `_uk_alloc_head`.","snippets":["#unikraft"],"rawContent":"# Unikraft's heap allocator\n#unikraft\n\n# Choice of allocator\nThe original paper says that Unikraft supports up to 5 allocator backends: buddy, TLFS, real-time, tinyalloc, mimalloc and Oscar\n\n@lupu2023nephele says tiny has the best performance among all\n\n# ukalloc\nUnikraft enables swapping of different allocator backends through the `ukalloc` interface. `ukalloc` keeps a linked-list pointers to `struct uk_alloc* _uk_alloc_head`, that points to the currently registered allocator.\n\n\n## Registration\nNew allocators must implement the interface\nAllocators are registered with `uk_alloc_register`, which assign `_uk_alloc_head` to the new allocator.\n\n\nIn `boot.c`, the allocators are hard-coded as:\n```c\n#if CONFIG_LIBUKBOOT_INITBBUDDY\n#include \u003cuk/allocbbuddy.h\u003e\n#define uk_alloc_init uk_allocbbuddy_init\n#elif CONFIG_LIBUKBOOT_INITREGION\n#include \u003cuk/allocregion.h\u003e\n#define uk_alloc_init uk_allocregion_init\n#elif CONFIG_LIBUKBOOT_INITMIMALLOC\n#include \u003cuk/mimalloc.h\u003e\n#define uk_alloc_init uk_mimalloc_init\n#elif CONFIG_LIBUKBOOT_INITTLSF\n#include \u003cuk/tlsf.h\u003e\n#define uk_alloc_init uk_tlsf_init\n#elif CONFIG_LIBUKBOOT_INITTINYALLOC\n#include \u003cuk/tinyalloc.h\u003e\n#define uk_alloc_init uk_tinyalloc_init\n#endif\n```\nHence, any allocator that are selected will be set as the heap allocator.\n\nThe `heap_init()` function takes the remaining memory (starting from `CONFIG_LIBUKBOOT_HEAP_BASE`), map them as anonymous pages, and adds them to the memory pool of the allocator.\n```c\n```\n\n\nFinally, `ukplat_memallocator_set()` set the current memory allocator\n\n## POSIX malloc\n`malloc` definition in `stdlib.h`:\n\n```c\nstatic inline void malloc(size_t size){\n  return uk_malloc(uk_alloc_get_default(), size);\n}\n```\nWhere `uk_alloc_get_default()` returns `_uk_alloc_head`.\n\n\n","wordCount":200,"tags":["unikraft"],"metadata":{},"created":"2023-07-04T11:22:42.589135038Z","modified":"2023-07-05T05:40:34.581242282Z","checksum":"d1d4cc2ea29e61b8b349637b95abd9113cfbc852a0372a2c872eb49add41a1b5"},
    {"filename":"eqbigndi.md","filenameStem":"eqbigndi","path":"eqbigndi.md","absPath":"/home/khadd/mynotes/eqbigndi.md","title":"Virtual Memory","link":"[[eqbigndi]]","lead":"#os #virtualization","body":"#os #virtualization\n\n\n\nVirtual memory eases the programming efforts.\n- First, it virtualizes and abstracts physical memory such that a single physical space can be shared among different processes.\n- Second, its facilitates communication between cores (shared memory mapping), and CPU-device communication (through DMA/MMIO).\n- Third, it enables memory access control between processes (each process use a different page table set up by the OS), and within a single process (RWX permissions).\n\n\n# Caveats\n## Address translation overheads\nAddress address translation creates significant overheads @yan20219translation. First, the OS needs to handle page faults in the software. Second, the CPU's MMU needs to walk the page table, which requires multiple memory accesses.\n\nModern architectures cope with this overhead by increasing the TLB size.\n\nChanges in hardware are proposed to address translation overheads.\n\nOne of the reasons for virtual memory is to couple access control with resource management. CARAT @suchy2022carat proposed using compiler-inserted checks to replace the MMU-provided access control.","snippets":["#os #virtualization"],"rawContent":"# Virtual Memory\n#os #virtualization\n\n\n\nVirtual memory eases the programming efforts.\n- First, it virtualizes and abstracts physical memory such that a single physical space can be shared among different processes.\n- Second, its facilitates communication between cores (shared memory mapping), and CPU-device communication (through DMA/MMIO).\n- Third, it enables memory access control between processes (each process use a different page table set up by the OS), and within a single process (RWX permissions).\n\n\n# Caveats\n## Address translation overheads\nAddress address translation creates significant overheads @yan20219translation. First, the OS needs to handle page faults in the software. Second, the CPU's MMU needs to walk the page table, which requires multiple memory accesses.\n\nModern architectures cope with this overhead by increasing the TLB size.\n\nChanges in hardware are proposed to address translation overheads.\n\nOne of the reasons for virtual memory is to couple access control with resource management. CARAT @suchy2022carat proposed using compiler-inserted checks to replace the MMU-provided access control.\n\n\n","wordCount":160,"tags":["os","virtualization"],"metadata":{},"created":"2023-07-22T08:12:54.947881231Z","modified":"2023-07-22T08:27:14.744101023Z","checksum":"671a699082178a379c5265e243204a4ae2affff2cffcfdb9002b330728027c4b"},
    {"filename":"s16ct1rj.md","filenameStem":"s16ct1rj","path":"s16ct1rj.md","absPath":"/home/khadd/mynotes/s16ct1rj.md","title":"Virtualization","link":"[[s16ct1rj]]","lead":"#os #virtualization","body":"#os #virtualization\n\nVirtualization gives a subject (process, virtual machine) the illusion of having access to physical resource (memory, CPU time). \n\nVirtualization is obtained through two properties, *interposition* and *transparency*\n\n## Interposition\nInterposition (aka, trap-and-emulate) let the reference monitor (OS/Hypervisor) interject the control upon a certain action of the virtualized subject. This enable it to serve virtualized resources on-demand.\n\nFor instance, page faults allows the OS to interpose virtual to physical translation, and add missing page mapping on-demand.\n\nOn the other hand, the hypervisor can interpose hardware interrupts, page faults, VM enter and exit, and handle them in software (handling them in the actual hardware would affect the entire system). This give the illusion to virtual machine have actual access to those hardware resources. See [[d3nt6uix]].\n\nInterposition is achieved commonly through three means. \n- Binary translation interprete every executed instruction and interpose on the sensitive instructions (used in QEMU).\n- Para-virtualization requires patching the guest OS to delegate a certain action to the hypervisor.\n- Interposition through hardware events forward the interrupts from the VM to the hypervisor.\n\n## Transparency\nVirtualization enable transparency. The virtualized subject do not have knowledge it being virtualized (except for the paravirtualization case).","snippets":["#os #virtualization"],"rawContent":"# Virtualization\n#os #virtualization\n\nVirtualization gives a subject (process, virtual machine) the illusion of having access to physical resource (memory, CPU time). \n\nVirtualization is obtained through two properties, *interposition* and *transparency*\n\n## Interposition\nInterposition (aka, trap-and-emulate) let the reference monitor (OS/Hypervisor) interject the control upon a certain action of the virtualized subject. This enable it to serve virtualized resources on-demand.\n\nFor instance, page faults allows the OS to interpose virtual to physical translation, and add missing page mapping on-demand.\n\nOn the other hand, the hypervisor can interpose hardware interrupts, page faults, VM enter and exit, and handle them in software (handling them in the actual hardware would affect the entire system). This give the illusion to virtual machine have actual access to those hardware resources. See [[d3nt6uix]].\n\nInterposition is achieved commonly through three means. \n- Binary translation interprete every executed instruction and interpose on the sensitive instructions (used in QEMU).\n- Para-virtualization requires patching the guest OS to delegate a certain action to the hypervisor.\n- Interposition through hardware events forward the interrupts from the VM to the hypervisor.\n\n## Transparency\nVirtualization enable transparency. The virtualized subject do not have knowledge it being virtualized (except for the paravirtualization case).  \n\n\n","wordCount":199,"tags":["os","virtualization"],"metadata":{},"created":"2023-05-24T06:39:32.992715982Z","modified":"2023-05-24T08:57:50.294105902Z","checksum":"32a6854ccd137cae52ad9cee1686f11bfc87cf277b0de7597c81efec9d490729"},
    {"filename":"9sbjh4gy.md","filenameStem":"9sbjh4gy","path":"9sbjh4gy.md","absPath":"/home/khadd/mynotes/9sbjh4gy.md","title":"Von Neumann Architecture","link":"[[9sbjh4gy]]","lead":"The von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device.","body":"The von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device.\n\nAt each cycle, the CPU fetch an instruction from memory, then execute it. The instruction may perform data read/write from memory, perform operations, or write to input/output devices.\n\nVon Neumann architecture has a bottleneck where instruction fetch and data operations cannot be performed in one cycle due to them using the same bus. Computer caches with separated icache and dcache mitigates this. There are also non-von Neumann architectures that significantly departure from the von Neumann model (to overcome this bottleneck?).","snippets":["The von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device."],"rawContent":"# Von Neumann Architecture\n\nThe von Neumann model is a computer architecture that was described by Jon von Neumann in 1945 in the text [First draft of a report on the EDVAC](https://en.wikipedia.org/wiki/First_Draft_of_a_Report_on_the_EDVAC). The design is for a *stored-program* computer (program code is stored in memory instead of hard-coded through wires), which is also used by modern processcomputer architectures. The design consisted of:\n- A central processing unit that contains registers, control unit (the program counter?), and logical/arithmetic units.\n- A memory\n- Input/output device.\n\nAt each cycle, the CPU fetch an instruction from memory, then execute it. The instruction may perform data read/write from memory, perform operations, or write to input/output devices.\n\nVon Neumann architecture has a bottleneck where instruction fetch and data operations cannot be performed in one cycle due to them using the same bus. Computer caches with separated icache and dcache mitigates this. There are also non-von Neumann architectures that significantly departure from the von Neumann model (to overcome this bottleneck?).\n\n","wordCount":164,"tags":[],"metadata":{},"created":"2023-05-22T05:10:44.094878652Z","modified":"2023-05-22T06:08:52.376270738Z","checksum":"f0ef069f4eb9e6dbc715b9ca6672f6afb1a51ab59c9647d97f3875cb1da99693"},
    {"filename":"5st7ndhi.md","filenameStem":"5st7ndhi","path":"5st7ndhi.md","absPath":"/home/khadd/mynotes/5st7ndhi.md","title":"Wayland notes","link":"[[5st7ndhi]]","lead":"#distro #wayland","body":"#distro #wayland\n\n# Monitor sleep \nThis is specific to hyprland. To turn off monitor run:\n```bash\nhyprctl dispatch dpms off\n```\nHowever, there have to be a way to turn it back on, so in `hyprland.conf`, add the following to `misc`: \n\n```\nmisc {\n    mouse_move_enables_dpms = true\n    key_press_enables_dpms = true\n}\n```\n\n\n\n# Clipboard management on Wayland\n#wayland #distro\n\nWayland uses a different clipboard management system than X11.  \n\n## SSH clipboard\n\nOn both the remote and local machine, [`waypipe`](https://gitlab.freedesktop.org/mstoeckl/waypipe) and `wl-clipboard` need to be installed. On ubuntu, waypipe is not provided by APT, so it needs to be compiled and installed manually. Follow the instructions on [gitlab](https://gitlab.freedesktop.org/mstoeckl/waypipe.).\n\nAfter `waypipe` is installed, on the local machine, just add the prefix `waypipe` to the call to `ssh`:\n```bash\nwaypipe ssh theserver\n```\n\n## Neovim\nNeovim will automatically detect if `wl-clipboard` (`wl-copy` and `wl-paste`) exists.","snippets":["#distro #wayland"],"rawContent":"# Wayland notes\n#distro #wayland\n\n# Monitor sleep \nThis is specific to hyprland. To turn off monitor run:\n```bash\nhyprctl dispatch dpms off\n```\nHowever, there have to be a way to turn it back on, so in `hyprland.conf`, add the following to `misc`: \n\n```\nmisc {\n    mouse_move_enables_dpms = true\n    key_press_enables_dpms = true\n}\n```\n\n\n\n# Clipboard management on Wayland\n#wayland #distro\n\nWayland uses a different clipboard management system than X11.  \n\n## SSH clipboard\n\nOn both the remote and local machine, [`waypipe`](https://gitlab.freedesktop.org/mstoeckl/waypipe) and `wl-clipboard` need to be installed. On ubuntu, waypipe is not provided by APT, so it needs to be compiled and installed manually. Follow the instructions on [gitlab](https://gitlab.freedesktop.org/mstoeckl/waypipe.).\n\nAfter `waypipe` is installed, on the local machine, just add the prefix `waypipe` to the call to `ssh`:\n```bash\nwaypipe ssh theserver\n```\n\n## Neovim\nNeovim will automatically detect if `wl-clipboard` (`wl-copy` and `wl-paste`) exists.\n\n\n\n","wordCount":145,"tags":["distro","wayland"],"metadata":{},"created":"2023-09-07T04:44:41.836778012Z","modified":"2023-09-07T04:47:55.227523371Z","checksum":"6ab4a174d0912a488df96b7a3aa6bb0df6cb9ba0a0c11443c9a0c845ef958585"},
    {"filename":"hog0h5z8.md","filenameStem":"hog0h5z8","path":"hog0h5z8.md","absPath":"/home/khadd/mynotes/hog0h5z8.md","title":"sel4 Resources","link":"[[hog0h5z8]]","lead":"#sel4 #os #capabilities","body":"#sel4 #os #capabilities\n\n- [L4 microkernels: The lessons from 20 years of research and deployment](https://trustworthy.systems/publications/nictaabstracts/Heiser_Elphinstone_16.abstract): A summary of seL4 in the context of previous research such as EROS, KeykOS.\n- [seL4 Overview and Tutorial](http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf): tutorial slides","snippets":["#sel4 #os #capabilities"],"rawContent":"# sel4 Resources\n#sel4 #os #capabilities\n\n- [L4 microkernels: The lessons from 20 years of research and deployment](https://trustworthy.systems/publications/nictaabstracts/Heiser_Elphinstone_16.abstract): A summary of seL4 in the context of previous research such as EROS, KeykOS.\n- [seL4 Overview and Tutorial](http://secdev.ieee.org/wp-content/uploads/2020/11/t1-03-evancich.pdf): tutorial slides\n\n","wordCount":39,"tags":["sel4","capabilities","os"],"metadata":{},"created":"2023-05-22T02:06:14.45509701Z","modified":"2023-05-17T05:11:30.05308355Z","checksum":"f34bc12d5fac842170f578aced5310a89266a99f4fc7d2527fdbfc7c7b47f0aa"},
    {"filename":"o53nse4p.md","filenameStem":"o53nse4p","path":"literature/o53nse4p.md","absPath":"/home/khadd/mynotes/literature/o53nse4p.md","title":"vSGX: Virtualizing SGX Enclaves on AMD SEV","link":"[[literature/o53nse4p]]","lead":"#literature #sgx #tee #sev #virtualization","body":"#literature #sgx #tee #sev #virtualization\n\n\n\n\n# Main arguments \n## Benefits of virtualizing SGX on AMD\n- Binary compatiblity: unmodified applications be ran on AMD SEV machines, while having comparable security guarantees.\n- Finer-grain trust:  SGX model only places the trust in the small userspace enclave, and does not trust the OS and the untrusted part of the process. In ths paper, they *trust the OS in the VM that run the enclave (EVM)*, but do not trust the untrusted part of the enclave program.\n\n## SGX can be virtualized on AMD SEV","snippets":["#literature #sgx #tee #sev #virtualization"],"rawContent":"# vSGX: Virtualizing SGX Enclaves on AMD SEV \n#literature #sgx #tee #sev #virtualization\n\n\n\n\n# Main arguments \n## Benefits of virtualizing SGX on AMD\n- Binary compatiblity: unmodified applications be ran on AMD SEV machines, while having comparable security guarantees.\n- Finer-grain trust:  SGX model only places the trust in the small userspace enclave, and does not trust the OS and the untrusted part of the process. In ths paper, they *trust the OS in the VM that run the enclave (EVM)*, but do not trust the untrusted part of the enclave program.\n\n## SGX can be virtualized on AMD SEV\n","wordCount":100,"tags":["literature","sgx","tee","sev","virtualization"],"metadata":{},"created":"2023-05-24T05:52:46.898417453Z","modified":"2023-05-24T08:18:16.37816809Z","checksum":"08775c58c9139dae19c71506982746829a9e3028db5dc47a5a86e81bb1a7511d"},
    {"filename":"d22taxo6.md","filenameStem":"d22taxo6","path":"d22taxo6.md","absPath":"/home/khadd/mynotes/d22taxo6.md","title":"x86 prefixes","link":"[[d22taxo6]]","lead":"#instruction-encoding #intel","body":"#instruction-encoding #intel\n\n\n\n\nPrefixes  are divided into 4 groups\n\n| Prefix                 | Group |\n|------------------------|-------|\n| F0, F2, F3             | Grp 1 |\n| 2E, 36, 3E, 26, 64, 67 | Grp 2 |\n| 66                     | Grp 3 |\n| 67                     | Grp 4 |\n\n\n\n```\nprefix\n▲  ┌► two-byte opcode prefix\n│  │  ┌─────────────►(Move Unaligned Packed Single-Precision Floating-Point Values)\n│  │  │\n│  │  │\n-- 0f 10             MOVUPS \txmm \txmm/m128\n\nGrp 3                (Move Unaligned Packed Double-Precision Floating-Point Values)\n▲\n│\n66 0f 11             MOVUPD   xmm   xmm/m128\n\nGrp 1 with REPNE/REPNZ encoded                (Move Unaligned Packed Single-Precision Floating-Point Values)\n▲\n│\nF2 0f 11                                      MOVSD    xmm   xmm/m64\n\nGrp 1 REPE/REPZ encoded                       (Move or Merge Scalar Single-Precision Floating-Point Value)\n▲\n│\nF3 0f 11                                      MOVSS    xmm   xmm/m32\n\n```","snippets":["#instruction-encoding #intel"],"rawContent":"# x86 prefixes\n#instruction-encoding #intel\n\n\n\n\nPrefixes  are divided into 4 groups\n\n| Prefix                 | Group |\n|------------------------|-------|\n| F0, F2, F3             | Grp 1 |\n| 2E, 36, 3E, 26, 64, 67 | Grp 2 |\n| 66                     | Grp 3 |\n| 67                     | Grp 4 |\n\n\n\n```\nprefix\n▲  ┌► two-byte opcode prefix\n│  │  ┌─────────────►(Move Unaligned Packed Single-Precision Floating-Point Values)\n│  │  │\n│  │  │\n-- 0f 10             MOVUPS \txmm \txmm/m128\n\nGrp 3                (Move Unaligned Packed Double-Precision Floating-Point Values)\n▲\n│\n66 0f 11             MOVUPD   xmm   xmm/m128\n\nGrp 1 with REPNE/REPNZ encoded                (Move Unaligned Packed Single-Precision Floating-Point Values)\n▲\n│\nF2 0f 11                                      MOVSD    xmm   xmm/m64\n\nGrp 1 REPE/REPZ encoded                       (Move or Merge Scalar Single-Precision Floating-Point Value)\n▲\n│\nF3 0f 11                                      MOVSS    xmm   xmm/m32\n\n```\n\n\n","wordCount":130,"tags":["intel","instruction-encoding"],"metadata":{},"created":"2023-07-29T03:13:23.64852312Z","modified":"2023-08-09T06:04:56.500519354Z","checksum":"7c24b41b7556c95f781ffbcde34e1d3d8140105f5c36356eb38641ad3f7e1856"}
  ],
  "links": [
    {"title":"dyx2t4oz","href":"dyx2t4oz","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Using frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.","snippetStart":242,"snippetEnd":367,"sourceId":23,"sourcePath":"cemsxh4n.md","targetId":24,"targetPath":"dyx2t4oz.md"},
    {"title":"zz3cedu0","href":"zz3cedu0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Using frameworks like *idea compass* [[zz3cedu0]] or *knowledge flower* [[dyx2t4oz]] helps establish the context of the note.","snippetStart":242,"snippetEnd":367,"sourceId":23,"sourcePath":"cemsxh4n.md","targetId":215,"targetPath":"zz3cedu0.md"},
    {"title":"hourglass structure of information","href":"b740rhio","type":"wiki-link","isExternal":false,"rels":[],"snippet":"In this step, it is also important to remember the  [[b740rhio|hourglass structure of information]], so spend more time on the beginning and the end of the section.","snippetStart":1096,"snippetEnd":1260,"sourceId":43,"sourcePath":"k0wjwjhg.md","targetId":44,"targetPath":"b740rhio.md"},
    {"title":"i2blyo37#Overhead analysis","href":"i2blyo37#Overhead analysis","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The paper argues that the cost of IPC in microkernels are too high, and proposed using MPK-based domains to reduce the number of context switches during IPCs.\nThe paper provides a motivation study by profiling the overheads of IPC in common microkernels (see [[i2blyo37#Overhead analysis]]).","snippetStart":185,"snippetEnd":476,"sourceId":46,"sourcePath":"literature/2a7l7odo.md","targetId":47,"targetPath":"i2blyo37.md"},
    {"title":"literature/2a7l7odo","href":"literature/2a7l7odo","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[@gu2020harmonizing] (see [[literature/2a7l7odo]]) performed a study of the source of overheads of such IPC. SQLite3 is ran on Zircon and seL4 microkernels. It is found that total IPC time is 79% of the time on Zircon and 44% of the time on seL4 (with KPTI).","snippetStart":661,"snippetEnd":919,"sourceId":47,"sourcePath":"i2blyo37.md","targetId":46,"targetPath":"literature/2a7l7odo.md"},
    {"title":"h3manv25","href":"h3manv25","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Containers and Virtual machines both have disadvantages for implementing isolation and sharing. See [[h3manv25]].","snippetStart":347,"snippetEnd":460,"sourceId":52,"sourcePath":"literature/zw0lj520.md","targetId":53,"targetPath":"h3manv25.md"},
    {"title":"s16ct1rj","href":"s16ct1rj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Containers and virtual machines ([[s16ct1rj]]) are two main isolation primitives when it come to cloud isolation.","snippetStart":82,"snippetEnd":195,"sourceId":53,"sourcePath":"h3manv25.md","targetId":100,"targetPath":"s16ct1rj.md"},
    {"title":"c4icaua4","href":"c4icaua4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Hierarchical layering limits flexibility: See [[c4icaua4]].","snippetStart":132,"snippetEnd":191,"sourceId":64,"sourcePath":"literature/zecj938z.md","targetId":92,"targetPath":"c4icaua4.md"},
    {"title":"2j6s9zpm","href":"2j6s9zpm","type":"wiki-link","isExternal":false,"rels":[],"snippet":"State spill harms availability and evolvability of system software (see [[2j6s9zpm]]).","snippetStart":133,"snippetEnd":219,"sourceId":67,"sourcePath":"literature/jfm8ud28.md","targetId":68,"targetPath":"2j6s9zpm.md"},
    {"title":"literature/jfm8ud28","href":"literature/jfm8ud28","type":"wiki-link","isExternal":false,"rels":[],"snippet":"@boos2020theseus (see [[literature/jfm8ud28]]): An operating system that aim to minimize state spill.","snippetStart":1617,"snippetEnd":1718,"sourceId":68,"sourcePath":"2j6s9zpm.md","targetId":67,"targetPath":"literature/jfm8ud28.md"},
    {"title":"qti6u06p","href":"qti6u06p","type":"wiki-link","isExternal":false,"rels":[],"snippet":"As a final note, removing state spill forces the caller to memory to allocate the context used for cross-compartment interaction. In a sense, it also improves the security of the per-compartment interface. See 1 and 4 in [[qti6u06p]].","snippetStart":1270,"snippetEnd":1504,"sourceId":68,"sourcePath":"2j6s9zpm.md","targetId":95,"targetPath":"qti6u06p.md"},
    {"title":"fleeting/douswvq0","href":"fleeting/douswvq0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[fleeting/douswvq0]]","snippetStart":30,"snippetEnd":51,"sourceId":70,"sourcePath":"2dw6pwrd.md","targetId":76,"targetPath":"fleeting/douswvq0.md"},
    {"title":"k60yjf6q","href":"k60yjf6q","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[k60yjf6q]]","snippetStart":1209,"snippetEnd":1221,"sourceId":71,"sourcePath":"7t4jlnaq.md","targetId":99,"targetPath":"k60yjf6q.md"},
    {"title":"dyx2t4oz","href":"dyx2t4oz","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[dyx2t4oz]]","snippetStart":438,"snippetEnd":450,"sourceId":72,"sourcePath":"a6uh87al.md","targetId":24,"targetPath":"dyx2t4oz.md"},
    {"title":"zz3cedu0","href":"zz3cedu0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[zz3cedu0]]","snippetStart":453,"snippetEnd":465,"sourceId":72,"sourcePath":"a6uh87al.md","targetId":215,"targetPath":"zz3cedu0.md"},
    {"title":"literature/4zdjxws6","href":"literature/4zdjxws6","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[@lu2023practical] ([[literature/4zdjxws6]]) notes several limitations with such an approach:","snippetStart":537,"snippetEnd":630,"sourceId":74,"sourcePath":"dgdvhu1e.md","targetId":80,"targetPath":"literature/4zdjxws6.md"},
    {"title":"Norman Hardy","href":"j19hdkto","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[Capability Theory by Sound Bytes](http://www.cap-lore.com/CapTheory/): Notes of capabilities by [[j19hdkto|Norman Hardy]] himself","snippetStart":28,"snippetEnd":158,"sourceId":78,"sourcePath":"icjubure.md","targetId":79,"targetPath":"j19hdkto.md"},
    {"title":"y9wu5ut7","href":"y9wu5ut7","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Maybe the first one to coin the term confused deputy [[y9wu5ut7]] in his paper [@hardy1988confused].","snippetStart":184,"snippetEnd":284,"sourceId":79,"sourcePath":"j19hdkto.md","targetId":211,"targetPath":"y9wu5ut7.md"},
    {"title":"dgdvhu1e","href":"dgdvhu1e","type":"wiki-link","isExternal":false,"rels":[],"snippet":"See [[dgdvhu1e]]","snippetStart":334,"snippetEnd":350,"sourceId":80,"sourcePath":"literature/4zdjxws6.md","targetId":74,"targetPath":"dgdvhu1e.md"},
    {"title":"ns7lcn8t","href":"ns7lcn8t","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This directly address the Iago Attack [[ns7lcn8t]] where the untrusted OS feeds incorrect values to trusted application.","snippetStart":1031,"snippetEnd":1151,"sourceId":84,"sourcePath":"literature/u55zie42.md","targetId":85,"targetPath":"ns7lcn8t.md"},
    {"title":"y9wu5ut7","href":"y9wu5ut7","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Also, a strict hierarchical system leads to increasingly privileged system components, and therefore leads to a component that have the \"most privileged\" only because of it place in the system. This leads to confused deputy problems ([[y9wu5ut7]]) in those components.","snippetStart":726,"snippetEnd":994,"sourceId":92,"sourcePath":"c4icaua4.md","targetId":211,"targetPath":"y9wu5ut7.md"},
    {"title":"7t4jlnaq","href":"7t4jlnaq","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[7t4jlnaq]]","snippetStart":1561,"snippetEnd":1573,"sourceId":99,"sourcePath":"k60yjf6q.md","targetId":71,"targetPath":"7t4jlnaq.md"},
    {"title":"d3nt6uix","href":"d3nt6uix","type":"wiki-link","isExternal":false,"rels":[],"snippet":"On the other hand, the hypervisor can interpose hardware interrupts, page faults, VM enter and exit, and handle them in software (handling them in the actual hardware would affect the entire system). This give the illusion to virtual machine have actual access to those hardware resources. See [[d3nt6uix]].","snippetStart":610,"snippetEnd":917,"sourceId":100,"sourcePath":"s16ct1rj.md","targetId":101,"targetPath":"d3nt6uix.md"},
    {"title":"s16ct1rj#interposition","href":"s16ct1rj#interposition","type":"wiki-link","isExternal":false,"rels":[],"snippet":"It performs interposition ([[s16ct1rj#interposition]]) on a certain *interesting* instructions to *emulate* then, hence *trap-and-emulate*. Those interesting instruction can be:","snippetStart":121,"snippetEnd":298,"sourceId":101,"sourcePath":"d3nt6uix.md","targetId":100,"targetPath":"s16ct1rj.md"},
    {"title":"s16ct1rj","href":"s16ct1rj","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[s16ct1rj]]","snippetStart":5191,"snippetEnd":5203,"sourceId":111,"sourcePath":"c7cva598.md","targetId":100,"targetPath":"s16ct1rj.md"},
    {"title":"d3nt6uix","href":"d3nt6uix","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[d3nt6uix]]","snippetStart":5176,"snippetEnd":5188,"sourceId":111,"sourcePath":"c7cva598.md","targetId":101,"targetPath":"d3nt6uix.md"},
    {"title":"zmt276jl","href":"zmt276jl","type":"wiki-link","isExternal":false,"rels":[],"snippet":"See [[zmt276jl]].","snippetStart":5139,"snippetEnd":5156,"sourceId":111,"sourcePath":"c7cva598.md","targetId":213,"targetPath":"zmt276jl.md"},
    {"title":"taztx2mo","href":"taztx2mo","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[taztx2mo]]","snippetStart":1294,"snippetEnd":1306,"sourceId":119,"sourcePath":"jcoxpgnk.md","targetId":203,"targetPath":"taztx2mo.md"},
    {"title":"1yhmh234","href":"1yhmh234","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Controlled-channel attacks [[1yhmh234]]","snippetStart":150,"snippetEnd":189,"sourceId":120,"sourcePath":"l3lzsza3.md","targetId":106,"targetPath":"1yhmh234.md"},
    {"title":"013pr50f","href":"013pr50f","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Purity (e.g., always returns same value for the same input, have no side effect) (possibly related to [[013pr50f]])","snippetStart":1719,"snippetEnd":1834,"sourceId":124,"sourcePath":"2hnk4l00.md","targetId":126,"targetPath":"013pr50f.md"},
    {"title":"zzq5zy5v","href":"zzq5zy5v","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[zzq5zy5v]]","snippetStart":3343,"snippetEnd":3355,"sourceId":124,"sourcePath":"2hnk4l00.md","targetId":216,"targetPath":"zzq5zy5v.md"},
    {"title":"1k9i1cr3","href":"1k9i1cr3","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[1k9i1cr3]]","snippetStart":1914,"snippetEnd":1926,"sourceId":129,"sourcePath":"fcf5pozg.md","targetId":146,"targetPath":"1k9i1cr3.md"},
    {"title":"xpolyx1l","href":"xpolyx1l","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[xpolyx1l]]","snippetStart":1899,"snippetEnd":1911,"sourceId":129,"sourcePath":"fcf5pozg.md","targetId":148,"targetPath":"xpolyx1l.md"},
    {"title":"7gbms9if","href":"7gbms9if","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[7gbms9if]]","snippetStart":1884,"snippetEnd":1896,"sourceId":129,"sourcePath":"fcf5pozg.md","targetId":156,"targetPath":"7gbms9if.md"},
    {"title":"projects/gel6dwih","href":"projects/gel6dwih","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[projects/gel6dwih]]","snippetStart":1929,"snippetEnd":1950,"sourceId":129,"sourcePath":"fcf5pozg.md","targetId":158,"targetPath":"projects/gel6dwih.md"},
    {"title":"dx7vz8d5","href":"dx7vz8d5","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Most of these defenses uses  Intel TSX [[dx7vz8d5]], due to its ability to supress page faults. \nFor more details, see [[fvom56lw]].","snippetStart":793,"snippetEnd":925,"sourceId":132,"sourcePath":"5kzr3hwx.md","targetId":135,"targetPath":"dx7vz8d5.md"},
    {"title":"fvom56lw","href":"fvom56lw","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Most of these defenses uses  Intel TSX [[dx7vz8d5]], due to its ability to supress page faults. \nFor more details, see [[fvom56lw]].","snippetStart":793,"snippetEnd":925,"sourceId":132,"sourcePath":"5kzr3hwx.md","targetId":136,"targetPath":"fvom56lw.md"},
    {"title":"n9bxzpge","href":"n9bxzpge","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The first line of defense is obfuscated execution ([[n9bxzpge]]), which guarantees that code and data accesses of a program looks the same, given a sensitive input.\nThey usually have high overheads and are considered impractical.","snippetStart":306,"snippetEnd":535,"sourceId":132,"sourcePath":"5kzr3hwx.md","targetId":138,"targetPath":"n9bxzpge.md"},
    {"title":"cosmdjej","href":"cosmdjej","type":"wiki-link","isExternal":false,"rels":[],"snippet":"TSX simplifies concurrent programming with transactional memory ([[cosmdjej]]).","snippetStart":69,"snippetEnd":148,"sourceId":135,"sourcePath":"dx7vz8d5.md","targetId":134,"targetPath":"cosmdjej.md"},
    {"title":"fvom56lw","href":"fvom56lw","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Since page faults are supressed, the OS cannot know whether page faults occurs or not. This property has been exploited by defenses against control-channel attacks on SGX @shih2017tsgx. The enclave can stop execution, when ever it encounter a page fault. See [[fvom56lw]].","snippetStart":1671,"snippetEnd":1943,"sourceId":135,"sourcePath":"dx7vz8d5.md","targetId":136,"targetPath":"fvom56lw.md"},
    {"title":"5kzr3hwx","href":"5kzr3hwx","type":"wiki-link","isExternal":false,"rels":[],"snippet":"For more context, see [[5kzr3hwx]].","snippetStart":63,"snippetEnd":98,"sourceId":136,"sourcePath":"fvom56lw.md","targetId":132,"targetPath":"5kzr3hwx.md"},
    {"title":"5kzr3hwx","href":"5kzr3hwx","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This type of protection commonly has very high overheads, due to the threat model being too strict (attackers with perfect observation of program counter and memory accesses).\nHowever, in practice, the observable side channels are usually more coarse-grained, at cache-line or page-fault-level. For instance, in SGX, attacker side-channels usually need page-fault-level trace before performing more fine-grained cache side-channel attacks. Hence, been works that only target page-fault-level leakage ([[5kzr3hwx]]), for more practical protection.","snippetStart":186,"snippetEnd":732,"sourceId":138,"sourcePath":"n9bxzpge.md","targetId":132,"targetPath":"5kzr3hwx.md"},
    {"title":"d3nt6uix","href":"d3nt6uix","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Virtualization hardware enables two-stage translation process from gVA to gPA, and from gPA to hPA through the nested page table (NPT) ([[d3nt6uix]]). This is the same in SEV. Although there is no official documentation, many paper indicate that hypervisor cannot intercept guest page faults (gPF) and look for faulting address.","snippetStart":120,"snippetEnd":448,"sourceId":142,"sourcePath":"qq4qcbos.md","targetId":101,"targetPath":"d3nt6uix.md"},
    {"title":"literature/ncfh611p","href":"literature/ncfh611p","type":"wiki-link","isExternal":false,"rels":[],"snippet":"@li2019exploiting: [[literature/ncfh611p]]","snippetStart":1077,"snippetEnd":1119,"sourceId":142,"sourcePath":"qq4qcbos.md","targetId":151,"targetPath":"literature/ncfh611p.md"},
    {"title":"1k9i1cr3","href":"1k9i1cr3","type":"wiki-link","isExternal":false,"rels":[],"snippet":"See [[1k9i1cr3]] for more about Unikraft's interrupt handling.","snippetStart":2740,"snippetEnd":2802,"sourceId":148,"sourcePath":"xpolyx1l.md","targetId":146,"targetPath":"1k9i1cr3.md"},
    {"title":"cn9u3d79","href":"cn9u3d79","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The function initializes the kernel's page table. On Linux, there is also the same function, but the process is a bit different  ([[cn9u3d79]]).","snippetStart":1488,"snippetEnd":1632,"sourceId":148,"sourcePath":"xpolyx1l.md","targetId":159,"targetPath":"cn9u3d79.md"},
    {"title":"cn9u3d79","href":"cn9u3d79","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[cn9u3d79]]","snippetStart":3586,"snippetEnd":3598,"sourceId":148,"sourcePath":"xpolyx1l.md","targetId":159,"targetPath":"cn9u3d79.md"},
    {"title":"qq4qcbos","href":"qq4qcbos","type":"wiki-link","isExternal":false,"rels":[],"snippet":"Pattern matching stage uses the nested page fault side-channel [[qq4qcbos]] to determine which pages are being accessed when the VM serves the SSH packet. The hypervisor first sends an SSH packet to the VM, then clears the present bits in the NPT PTEs.\nIt collects the sequences of page fault accesses to build a _signature_ of the page accessed from the time of receiving the request, to the time right before sending the packet. It then uses this signature to determine the page containing the `sk_buff` structure that contains the packet.","snippetStart":1318,"snippetEnd":1859,"sourceId":151,"sourcePath":"literature/ncfh611p.md","targetId":142,"targetPath":"qq4qcbos.md"},
    {"title":"zmt276jl","href":"zmt276jl","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The target of the attack is an SSH service running inside a cVM. While the ssh packets are encrypted, due to unprotected I/O [[zmt276jl]], the hypervisor can observe and modify the TCP and IP headers.","snippetStart":611,"snippetEnd":811,"sourceId":151,"sourcePath":"literature/ncfh611p.md","targetId":213,"targetPath":"zmt276jl.md"},
    {"title":"lfyjdfv4","href":"lfyjdfv4","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[lfyjdfv4]]","snippetStart":59,"snippetEnd":71,"sourceId":165,"sourcePath":"mwf41frv.md","targetId":161,"targetPath":"lfyjdfv4.md"},
    {"title":"xxn0pki0","href":"xxn0pki0","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[xxn0pki0]]","snippetStart":19,"snippetEnd":31,"sourceId":186,"sourcePath":"awlfkl73.md","targetId":185,"targetPath":"xxn0pki0.md"},
    {"title":"nobagcn6","href":"nobagcn6","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[nobagcn6]]","snippetStart":93,"snippetEnd":105,"sourceId":199,"sourcePath":"s5ss13en.md","targetId":139,"targetPath":"nobagcn6.md"},
    {"title":"llhmwuim","href":"llhmwuim","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[llhmwuim]]","snippetStart":78,"snippetEnd":90,"sourceId":199,"sourcePath":"s5ss13en.md","targetId":195,"targetPath":"llhmwuim.md"},
    {"title":"1yhmh234","href":"1yhmh234","type":"wiki-link","isExternal":false,"rels":[],"snippet":"The paper's main argument against the previous work is that a *practical* solution for the control channels for SGX must be backward compatible with existing x86 software, and also the OS. Hence, solutions that employ two separate page tables, such as @aga2019invisipage, and @costan2016sanctum are not practical as they require changes to even the host OS. On the other hand, other software-only defenses (at the time of the paper, there are @shih2017tsgx, and @oleksenko2018varys) restrict the usability as forbid demand paging, have huge overheads, and are also susceptible to non-page-fault attacks that use the dirty bits [[1yhmh234]].","snippetStart":139,"snippetEnd":779,"sourceId":201,"sourcePath":"literature/36d79g1n.md","targetId":106,"targetPath":"1yhmh234.md"},
    {"title":"taztx2mo","href":"taztx2mo","type":"wiki-link","isExternal":false,"rels":[],"snippet":"While introducing hardware changes, the work aims to do it in the least intrusive manner. It tries to *change only the same path that SGX's mechanisms change in x86 architectures*. This includes (1) SGX-specific checks that are performed after PTE checks during enclave mode, and (2) AEX page fault procedure ([[taztx2mo]]).","snippetStart":814,"snippetEnd":1138,"sourceId":201,"sourcePath":"literature/36d79g1n.md","targetId":203,"targetPath":"taztx2mo.md"},
    {"title":"1yhmh234","href":"1yhmh234","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[1yhmh234]]","snippetStart":3971,"snippetEnd":3983,"sourceId":203,"sourcePath":"taztx2mo.md","targetId":106,"targetPath":"1yhmh234.md"},
    {"title":"fvom56lw","href":"fvom56lw","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[fvom56lw]]","snippetStart":3956,"snippetEnd":3968,"sourceId":203,"sourcePath":"taztx2mo.md","targetId":136,"targetPath":"fvom56lw.md"},
    {"title":"literature/ncfh611p","href":"literature/ncfh611p","type":"wiki-link","isExternal":false,"rels":[],"snippet":"@li2019exploiting: [[literature/ncfh611p]]","snippetStart":1876,"snippetEnd":1918,"sourceId":213,"sourcePath":"zmt276jl.md","targetId":151,"targetPath":"literature/ncfh611p.md"},
    {"title":"7isqcppd","href":"7isqcppd","type":"wiki-link","isExternal":false,"rels":[],"snippet":"[[7isqcppd]]","snippetStart":432,"snippetEnd":444,"sourceId":214,"sourcePath":"zy68i5ym.md","targetId":147,"targetPath":"7isqcppd.md"},
    {"title":"cemsxh4n","href":"cemsxh4n","type":"wiki-link","isExternal":false,"rels":[],"snippet":"This idea helps to discover the context of a Zettelkasten note. More importantly, helps writing notes easier [[cemsxh4n]]","snippetStart":1706,"snippetEnd":1827,"sourceId":215,"sourcePath":"zz3cedu0.md","targetId":23,"targetPath":"cemsxh4n.md"},
    {"title":"dyx2t4oz","href":"dyx2t4oz","type":"wiki-link","isExternal":false,"rels":[],"snippet":"WEST: *“What is similar to _X?”_ [This](https://zettelkasten.de/posts/creative-technique-within-zettelkasten-framework/) introduces another technique called the *knowledge flower* [[dyx2t4oz]] that is more open for interpretation.","snippetStart":1872,"snippetEnd":2106,"sourceId":215,"sourcePath":"zz3cedu0.md","targetId":24,"targetPath":"dyx2t4oz.md"}
  ]
}
